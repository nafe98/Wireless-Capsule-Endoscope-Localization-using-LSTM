{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered_Reg3.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217.387304</td>\n",
       "      <td>239.632697</td>\n",
       "      <td>182.725063</td>\n",
       "      <td>203.059660</td>\n",
       "      <td>264.890845</td>\n",
       "      <td>282.278849</td>\n",
       "      <td>235.977931</td>\n",
       "      <td>251.334953</td>\n",
       "      <td>219.915989</td>\n",
       "      <td>241.321246</td>\n",
       "      <td>...</td>\n",
       "      <td>214.917267</td>\n",
       "      <td>200.097971</td>\n",
       "      <td>223.118071</td>\n",
       "      <td>192.165241</td>\n",
       "      <td>268.938292</td>\n",
       "      <td>228.674862</td>\n",
       "      <td>190.456779</td>\n",
       "      <td>221.871669</td>\n",
       "      <td>150.526460</td>\n",
       "      <td>184.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219.216983</td>\n",
       "      <td>243.127927</td>\n",
       "      <td>186.076866</td>\n",
       "      <td>223.010844</td>\n",
       "      <td>258.217790</td>\n",
       "      <td>284.320675</td>\n",
       "      <td>238.608922</td>\n",
       "      <td>252.873845</td>\n",
       "      <td>225.261010</td>\n",
       "      <td>237.785939</td>\n",
       "      <td>...</td>\n",
       "      <td>204.559853</td>\n",
       "      <td>194.129695</td>\n",
       "      <td>226.526877</td>\n",
       "      <td>189.639239</td>\n",
       "      <td>271.669115</td>\n",
       "      <td>247.625906</td>\n",
       "      <td>200.880064</td>\n",
       "      <td>225.302866</td>\n",
       "      <td>155.694214</td>\n",
       "      <td>182.720021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.481822</td>\n",
       "      <td>239.164306</td>\n",
       "      <td>181.619201</td>\n",
       "      <td>207.468166</td>\n",
       "      <td>258.417039</td>\n",
       "      <td>286.117682</td>\n",
       "      <td>236.709830</td>\n",
       "      <td>252.283666</td>\n",
       "      <td>224.949191</td>\n",
       "      <td>240.069946</td>\n",
       "      <td>...</td>\n",
       "      <td>202.729931</td>\n",
       "      <td>202.705497</td>\n",
       "      <td>227.549722</td>\n",
       "      <td>190.058791</td>\n",
       "      <td>267.890942</td>\n",
       "      <td>238.505997</td>\n",
       "      <td>207.549963</td>\n",
       "      <td>217.333086</td>\n",
       "      <td>155.818169</td>\n",
       "      <td>177.425112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226.912857</td>\n",
       "      <td>247.346521</td>\n",
       "      <td>178.527737</td>\n",
       "      <td>213.346028</td>\n",
       "      <td>265.617093</td>\n",
       "      <td>276.202148</td>\n",
       "      <td>227.382298</td>\n",
       "      <td>246.907115</td>\n",
       "      <td>226.114014</td>\n",
       "      <td>232.127600</td>\n",
       "      <td>...</td>\n",
       "      <td>196.970477</td>\n",
       "      <td>201.050381</td>\n",
       "      <td>235.438679</td>\n",
       "      <td>183.998234</td>\n",
       "      <td>265.697482</td>\n",
       "      <td>239.225517</td>\n",
       "      <td>199.571852</td>\n",
       "      <td>222.746420</td>\n",
       "      <td>148.976842</td>\n",
       "      <td>185.256562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215.854729</td>\n",
       "      <td>243.081486</td>\n",
       "      <td>194.388198</td>\n",
       "      <td>209.401136</td>\n",
       "      <td>256.016224</td>\n",
       "      <td>287.663834</td>\n",
       "      <td>225.265475</td>\n",
       "      <td>249.349604</td>\n",
       "      <td>222.300716</td>\n",
       "      <td>238.435527</td>\n",
       "      <td>...</td>\n",
       "      <td>209.957008</td>\n",
       "      <td>198.137327</td>\n",
       "      <td>226.222890</td>\n",
       "      <td>199.824567</td>\n",
       "      <td>263.585700</td>\n",
       "      <td>239.992091</td>\n",
       "      <td>202.597683</td>\n",
       "      <td>224.404725</td>\n",
       "      <td>150.253948</td>\n",
       "      <td>179.728113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>231.861402</td>\n",
       "      <td>231.271407</td>\n",
       "      <td>181.166326</td>\n",
       "      <td>170.837471</td>\n",
       "      <td>284.266499</td>\n",
       "      <td>281.454421</td>\n",
       "      <td>250.096372</td>\n",
       "      <td>233.984524</td>\n",
       "      <td>237.254345</td>\n",
       "      <td>230.833456</td>\n",
       "      <td>...</td>\n",
       "      <td>206.716732</td>\n",
       "      <td>213.482600</td>\n",
       "      <td>231.672060</td>\n",
       "      <td>171.866958</td>\n",
       "      <td>280.630909</td>\n",
       "      <td>238.596867</td>\n",
       "      <td>224.786270</td>\n",
       "      <td>214.040483</td>\n",
       "      <td>159.112946</td>\n",
       "      <td>135.015597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>240.631456</td>\n",
       "      <td>234.905586</td>\n",
       "      <td>187.530608</td>\n",
       "      <td>169.967064</td>\n",
       "      <td>291.177594</td>\n",
       "      <td>274.392715</td>\n",
       "      <td>254.065510</td>\n",
       "      <td>237.204343</td>\n",
       "      <td>229.794249</td>\n",
       "      <td>227.195860</td>\n",
       "      <td>...</td>\n",
       "      <td>218.209066</td>\n",
       "      <td>217.203975</td>\n",
       "      <td>235.623711</td>\n",
       "      <td>170.052648</td>\n",
       "      <td>280.954229</td>\n",
       "      <td>237.542731</td>\n",
       "      <td>232.369613</td>\n",
       "      <td>213.187594</td>\n",
       "      <td>166.395165</td>\n",
       "      <td>146.505704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>240.491672</td>\n",
       "      <td>221.013207</td>\n",
       "      <td>183.728473</td>\n",
       "      <td>165.157791</td>\n",
       "      <td>288.169408</td>\n",
       "      <td>278.552772</td>\n",
       "      <td>250.454405</td>\n",
       "      <td>241.635466</td>\n",
       "      <td>238.436237</td>\n",
       "      <td>224.733331</td>\n",
       "      <td>...</td>\n",
       "      <td>200.329198</td>\n",
       "      <td>217.664427</td>\n",
       "      <td>225.940879</td>\n",
       "      <td>176.382437</td>\n",
       "      <td>270.202165</td>\n",
       "      <td>244.186452</td>\n",
       "      <td>225.412719</td>\n",
       "      <td>212.400501</td>\n",
       "      <td>165.406860</td>\n",
       "      <td>147.567081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>242.202559</td>\n",
       "      <td>223.382961</td>\n",
       "      <td>185.631104</td>\n",
       "      <td>171.995249</td>\n",
       "      <td>300.768787</td>\n",
       "      <td>275.425026</td>\n",
       "      <td>253.157318</td>\n",
       "      <td>236.775310</td>\n",
       "      <td>224.089013</td>\n",
       "      <td>226.589322</td>\n",
       "      <td>...</td>\n",
       "      <td>206.793569</td>\n",
       "      <td>217.761307</td>\n",
       "      <td>232.585838</td>\n",
       "      <td>175.889921</td>\n",
       "      <td>284.951096</td>\n",
       "      <td>246.462395</td>\n",
       "      <td>227.389790</td>\n",
       "      <td>211.475883</td>\n",
       "      <td>157.014311</td>\n",
       "      <td>145.981187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>247.511962</td>\n",
       "      <td>221.663370</td>\n",
       "      <td>184.869120</td>\n",
       "      <td>169.457837</td>\n",
       "      <td>292.581997</td>\n",
       "      <td>278.591968</td>\n",
       "      <td>250.347536</td>\n",
       "      <td>237.940294</td>\n",
       "      <td>230.692789</td>\n",
       "      <td>221.176160</td>\n",
       "      <td>...</td>\n",
       "      <td>213.368955</td>\n",
       "      <td>218.888112</td>\n",
       "      <td>224.257645</td>\n",
       "      <td>175.028785</td>\n",
       "      <td>278.530441</td>\n",
       "      <td>241.066108</td>\n",
       "      <td>226.188127</td>\n",
       "      <td>206.196509</td>\n",
       "      <td>170.841993</td>\n",
       "      <td>147.096876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     217.387304  239.632697  182.725063  203.059660  264.890845  282.278849   \n",
       "1     219.216983  243.127927  186.076866  223.010844  258.217790  284.320675   \n",
       "2     215.481822  239.164306  181.619201  207.468166  258.417039  286.117682   \n",
       "3     226.912857  247.346521  178.527737  213.346028  265.617093  276.202148   \n",
       "4     215.854729  243.081486  194.388198  209.401136  256.016224  287.663834   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  231.861402  231.271407  181.166326  170.837471  284.266499  281.454421   \n",
       "2439  240.631456  234.905586  187.530608  169.967064  291.177594  274.392715   \n",
       "2440  240.491672  221.013207  183.728473  165.157791  288.169408  278.552772   \n",
       "2441  242.202559  223.382961  185.631104  171.995249  300.768787  275.425026   \n",
       "2442  247.511962  221.663370  184.869120  169.457837  292.581997  278.591968   \n",
       "\n",
       "              6           7           8           9   ...          38  \\\n",
       "0     235.977931  251.334953  219.915989  241.321246  ...  214.917267   \n",
       "1     238.608922  252.873845  225.261010  237.785939  ...  204.559853   \n",
       "2     236.709830  252.283666  224.949191  240.069946  ...  202.729931   \n",
       "3     227.382298  246.907115  226.114014  232.127600  ...  196.970477   \n",
       "4     225.265475  249.349604  222.300716  238.435527  ...  209.957008   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  250.096372  233.984524  237.254345  230.833456  ...  206.716732   \n",
       "2439  254.065510  237.204343  229.794249  227.195860  ...  218.209066   \n",
       "2440  250.454405  241.635466  238.436237  224.733331  ...  200.329198   \n",
       "2441  253.157318  236.775310  224.089013  226.589322  ...  206.793569   \n",
       "2442  250.347536  237.940294  230.692789  221.176160  ...  213.368955   \n",
       "\n",
       "              39          40          41          42          43          44  \\\n",
       "0     200.097971  223.118071  192.165241  268.938292  228.674862  190.456779   \n",
       "1     194.129695  226.526877  189.639239  271.669115  247.625906  200.880064   \n",
       "2     202.705497  227.549722  190.058791  267.890942  238.505997  207.549963   \n",
       "3     201.050381  235.438679  183.998234  265.697482  239.225517  199.571852   \n",
       "4     198.137327  226.222890  199.824567  263.585700  239.992091  202.597683   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  213.482600  231.672060  171.866958  280.630909  238.596867  224.786270   \n",
       "2439  217.203975  235.623711  170.052648  280.954229  237.542731  232.369613   \n",
       "2440  217.664427  225.940879  176.382437  270.202165  244.186452  225.412719   \n",
       "2441  217.761307  232.585838  175.889921  284.951096  246.462395  227.389790   \n",
       "2442  218.888112  224.257645  175.028785  278.530441  241.066108  226.188127   \n",
       "\n",
       "              45          46          47  \n",
       "0     221.871669  150.526460  184.283621  \n",
       "1     225.302866  155.694214  182.720021  \n",
       "2     217.333086  155.818169  177.425112  \n",
       "3     222.746420  148.976842  185.256562  \n",
       "4     224.404725  150.253948  179.728113  \n",
       "...          ...         ...         ...  \n",
       "2438  214.040483  159.112946  135.015597  \n",
       "2439  213.187594  166.395165  146.505704  \n",
       "2440  212.400501  165.406860  147.567081  \n",
       "2441  211.475883  157.014311  145.981187  \n",
       "2442  206.196509  170.841993  147.096876  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_Reg2_3.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.968791</td>\n",
       "      <td>60.239368</td>\n",
       "      <td>-105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-75.314716</td>\n",
       "      <td>60.181623</td>\n",
       "      <td>-104.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.653109</td>\n",
       "      <td>60.131806</td>\n",
       "      <td>-104.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.984037</td>\n",
       "      <td>60.089935</td>\n",
       "      <td>-104.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.307567</td>\n",
       "      <td>60.056029</td>\n",
       "      <td>-104.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-99.899763</td>\n",
       "      <td>81.788725</td>\n",
       "      <td>65.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-99.939531</td>\n",
       "      <td>81.389997</td>\n",
       "      <td>65.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-99.969304</td>\n",
       "      <td>80.990713</td>\n",
       "      <td>65.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-99.989081</td>\n",
       "      <td>80.591032</td>\n",
       "      <td>65.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-99.998859</td>\n",
       "      <td>80.191116</td>\n",
       "      <td>65.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1       2\n",
       "0    -75.968791  60.239368 -105.00\n",
       "1    -75.314716  60.181623 -104.93\n",
       "2    -74.653109  60.131806 -104.86\n",
       "3    -73.984037  60.089935 -104.79\n",
       "4    -73.307567  60.056029 -104.72\n",
       "...         ...        ...     ...\n",
       "2438 -99.899763  81.788725   65.66\n",
       "2439 -99.939531  81.389997   65.73\n",
       "2440 -99.969304  80.990713   65.80\n",
       "2441 -99.989081  80.591032   65.87\n",
       "2442 -99.998859  80.191116   65.94\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217.387304</td>\n",
       "      <td>239.632697</td>\n",
       "      <td>182.725063</td>\n",
       "      <td>203.059660</td>\n",
       "      <td>264.890845</td>\n",
       "      <td>282.278849</td>\n",
       "      <td>235.977931</td>\n",
       "      <td>251.334953</td>\n",
       "      <td>219.915989</td>\n",
       "      <td>241.321246</td>\n",
       "      <td>...</td>\n",
       "      <td>214.917267</td>\n",
       "      <td>200.097971</td>\n",
       "      <td>223.118071</td>\n",
       "      <td>192.165241</td>\n",
       "      <td>268.938292</td>\n",
       "      <td>228.674862</td>\n",
       "      <td>190.456779</td>\n",
       "      <td>221.871669</td>\n",
       "      <td>150.526460</td>\n",
       "      <td>184.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219.216983</td>\n",
       "      <td>243.127927</td>\n",
       "      <td>186.076866</td>\n",
       "      <td>223.010844</td>\n",
       "      <td>258.217790</td>\n",
       "      <td>284.320675</td>\n",
       "      <td>238.608922</td>\n",
       "      <td>252.873845</td>\n",
       "      <td>225.261010</td>\n",
       "      <td>237.785939</td>\n",
       "      <td>...</td>\n",
       "      <td>204.559853</td>\n",
       "      <td>194.129695</td>\n",
       "      <td>226.526877</td>\n",
       "      <td>189.639239</td>\n",
       "      <td>271.669115</td>\n",
       "      <td>247.625906</td>\n",
       "      <td>200.880064</td>\n",
       "      <td>225.302866</td>\n",
       "      <td>155.694214</td>\n",
       "      <td>182.720021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.481822</td>\n",
       "      <td>239.164306</td>\n",
       "      <td>181.619201</td>\n",
       "      <td>207.468166</td>\n",
       "      <td>258.417039</td>\n",
       "      <td>286.117682</td>\n",
       "      <td>236.709830</td>\n",
       "      <td>252.283666</td>\n",
       "      <td>224.949191</td>\n",
       "      <td>240.069946</td>\n",
       "      <td>...</td>\n",
       "      <td>202.729931</td>\n",
       "      <td>202.705497</td>\n",
       "      <td>227.549722</td>\n",
       "      <td>190.058791</td>\n",
       "      <td>267.890942</td>\n",
       "      <td>238.505997</td>\n",
       "      <td>207.549963</td>\n",
       "      <td>217.333086</td>\n",
       "      <td>155.818169</td>\n",
       "      <td>177.425112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226.912857</td>\n",
       "      <td>247.346521</td>\n",
       "      <td>178.527737</td>\n",
       "      <td>213.346028</td>\n",
       "      <td>265.617093</td>\n",
       "      <td>276.202148</td>\n",
       "      <td>227.382298</td>\n",
       "      <td>246.907115</td>\n",
       "      <td>226.114014</td>\n",
       "      <td>232.127600</td>\n",
       "      <td>...</td>\n",
       "      <td>196.970477</td>\n",
       "      <td>201.050381</td>\n",
       "      <td>235.438679</td>\n",
       "      <td>183.998234</td>\n",
       "      <td>265.697482</td>\n",
       "      <td>239.225517</td>\n",
       "      <td>199.571852</td>\n",
       "      <td>222.746420</td>\n",
       "      <td>148.976842</td>\n",
       "      <td>185.256562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215.854729</td>\n",
       "      <td>243.081486</td>\n",
       "      <td>194.388198</td>\n",
       "      <td>209.401136</td>\n",
       "      <td>256.016224</td>\n",
       "      <td>287.663834</td>\n",
       "      <td>225.265475</td>\n",
       "      <td>249.349604</td>\n",
       "      <td>222.300716</td>\n",
       "      <td>238.435527</td>\n",
       "      <td>...</td>\n",
       "      <td>209.957008</td>\n",
       "      <td>198.137327</td>\n",
       "      <td>226.222890</td>\n",
       "      <td>199.824567</td>\n",
       "      <td>263.585700</td>\n",
       "      <td>239.992091</td>\n",
       "      <td>202.597683</td>\n",
       "      <td>224.404725</td>\n",
       "      <td>150.253948</td>\n",
       "      <td>179.728113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>231.861402</td>\n",
       "      <td>231.271407</td>\n",
       "      <td>181.166326</td>\n",
       "      <td>170.837471</td>\n",
       "      <td>284.266499</td>\n",
       "      <td>281.454421</td>\n",
       "      <td>250.096372</td>\n",
       "      <td>233.984524</td>\n",
       "      <td>237.254345</td>\n",
       "      <td>230.833456</td>\n",
       "      <td>...</td>\n",
       "      <td>206.716732</td>\n",
       "      <td>213.482600</td>\n",
       "      <td>231.672060</td>\n",
       "      <td>171.866958</td>\n",
       "      <td>280.630909</td>\n",
       "      <td>238.596867</td>\n",
       "      <td>224.786270</td>\n",
       "      <td>214.040483</td>\n",
       "      <td>159.112946</td>\n",
       "      <td>135.015597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>240.631456</td>\n",
       "      <td>234.905586</td>\n",
       "      <td>187.530608</td>\n",
       "      <td>169.967064</td>\n",
       "      <td>291.177594</td>\n",
       "      <td>274.392715</td>\n",
       "      <td>254.065510</td>\n",
       "      <td>237.204343</td>\n",
       "      <td>229.794249</td>\n",
       "      <td>227.195860</td>\n",
       "      <td>...</td>\n",
       "      <td>218.209066</td>\n",
       "      <td>217.203975</td>\n",
       "      <td>235.623711</td>\n",
       "      <td>170.052648</td>\n",
       "      <td>280.954229</td>\n",
       "      <td>237.542731</td>\n",
       "      <td>232.369613</td>\n",
       "      <td>213.187594</td>\n",
       "      <td>166.395165</td>\n",
       "      <td>146.505704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>240.491672</td>\n",
       "      <td>221.013207</td>\n",
       "      <td>183.728473</td>\n",
       "      <td>165.157791</td>\n",
       "      <td>288.169408</td>\n",
       "      <td>278.552772</td>\n",
       "      <td>250.454405</td>\n",
       "      <td>241.635466</td>\n",
       "      <td>238.436237</td>\n",
       "      <td>224.733331</td>\n",
       "      <td>...</td>\n",
       "      <td>200.329198</td>\n",
       "      <td>217.664427</td>\n",
       "      <td>225.940879</td>\n",
       "      <td>176.382437</td>\n",
       "      <td>270.202165</td>\n",
       "      <td>244.186452</td>\n",
       "      <td>225.412719</td>\n",
       "      <td>212.400501</td>\n",
       "      <td>165.406860</td>\n",
       "      <td>147.567081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>242.202559</td>\n",
       "      <td>223.382961</td>\n",
       "      <td>185.631104</td>\n",
       "      <td>171.995249</td>\n",
       "      <td>300.768787</td>\n",
       "      <td>275.425026</td>\n",
       "      <td>253.157318</td>\n",
       "      <td>236.775310</td>\n",
       "      <td>224.089013</td>\n",
       "      <td>226.589322</td>\n",
       "      <td>...</td>\n",
       "      <td>206.793569</td>\n",
       "      <td>217.761307</td>\n",
       "      <td>232.585838</td>\n",
       "      <td>175.889921</td>\n",
       "      <td>284.951096</td>\n",
       "      <td>246.462395</td>\n",
       "      <td>227.389790</td>\n",
       "      <td>211.475883</td>\n",
       "      <td>157.014311</td>\n",
       "      <td>145.981187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>247.511962</td>\n",
       "      <td>221.663370</td>\n",
       "      <td>184.869120</td>\n",
       "      <td>169.457837</td>\n",
       "      <td>292.581997</td>\n",
       "      <td>278.591968</td>\n",
       "      <td>250.347536</td>\n",
       "      <td>237.940294</td>\n",
       "      <td>230.692789</td>\n",
       "      <td>221.176160</td>\n",
       "      <td>...</td>\n",
       "      <td>213.368955</td>\n",
       "      <td>218.888112</td>\n",
       "      <td>224.257645</td>\n",
       "      <td>175.028785</td>\n",
       "      <td>278.530441</td>\n",
       "      <td>241.066108</td>\n",
       "      <td>226.188127</td>\n",
       "      <td>206.196509</td>\n",
       "      <td>170.841993</td>\n",
       "      <td>147.096876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     217.387304  239.632697  182.725063  203.059660  264.890845  282.278849   \n",
       "1     219.216983  243.127927  186.076866  223.010844  258.217790  284.320675   \n",
       "2     215.481822  239.164306  181.619201  207.468166  258.417039  286.117682   \n",
       "3     226.912857  247.346521  178.527737  213.346028  265.617093  276.202148   \n",
       "4     215.854729  243.081486  194.388198  209.401136  256.016224  287.663834   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  231.861402  231.271407  181.166326  170.837471  284.266499  281.454421   \n",
       "2439  240.631456  234.905586  187.530608  169.967064  291.177594  274.392715   \n",
       "2440  240.491672  221.013207  183.728473  165.157791  288.169408  278.552772   \n",
       "2441  242.202559  223.382961  185.631104  171.995249  300.768787  275.425026   \n",
       "2442  247.511962  221.663370  184.869120  169.457837  292.581997  278.591968   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor39  \\\n",
       "0     235.977931  251.334953  219.915989  241.321246  ...  214.917267   \n",
       "1     238.608922  252.873845  225.261010  237.785939  ...  204.559853   \n",
       "2     236.709830  252.283666  224.949191  240.069946  ...  202.729931   \n",
       "3     227.382298  246.907115  226.114014  232.127600  ...  196.970477   \n",
       "4     225.265475  249.349604  222.300716  238.435527  ...  209.957008   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  250.096372  233.984524  237.254345  230.833456  ...  206.716732   \n",
       "2439  254.065510  237.204343  229.794249  227.195860  ...  218.209066   \n",
       "2440  250.454405  241.635466  238.436237  224.733331  ...  200.329198   \n",
       "2441  253.157318  236.775310  224.089013  226.589322  ...  206.793569   \n",
       "2442  250.347536  237.940294  230.692789  221.176160  ...  213.368955   \n",
       "\n",
       "        sensor40    sensor41    sensor42    sensor43    sensor44    sensor45  \\\n",
       "0     200.097971  223.118071  192.165241  268.938292  228.674862  190.456779   \n",
       "1     194.129695  226.526877  189.639239  271.669115  247.625906  200.880064   \n",
       "2     202.705497  227.549722  190.058791  267.890942  238.505997  207.549963   \n",
       "3     201.050381  235.438679  183.998234  265.697482  239.225517  199.571852   \n",
       "4     198.137327  226.222890  199.824567  263.585700  239.992091  202.597683   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  213.482600  231.672060  171.866958  280.630909  238.596867  224.786270   \n",
       "2439  217.203975  235.623711  170.052648  280.954229  237.542731  232.369613   \n",
       "2440  217.664427  225.940879  176.382437  270.202165  244.186452  225.412719   \n",
       "2441  217.761307  232.585838  175.889921  284.951096  246.462395  227.389790   \n",
       "2442  218.888112  224.257645  175.028785  278.530441  241.066108  226.188127   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     221.871669  150.526460  184.283621  \n",
       "1     225.302866  155.694214  182.720021  \n",
       "2     217.333086  155.818169  177.425112  \n",
       "3     222.746420  148.976842  185.256562  \n",
       "4     224.404725  150.253948  179.728113  \n",
       "...          ...         ...         ...  \n",
       "2438  214.040483  159.112946  135.015597  \n",
       "2439  213.187594  166.395165  146.505704  \n",
       "2440  212.400501  165.406860  147.567081  \n",
       "2441  211.475883  157.014311  145.981187  \n",
       "2442  206.196509  170.841993  147.096876  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.968791</td>\n",
       "      <td>60.239368</td>\n",
       "      <td>-105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-75.314716</td>\n",
       "      <td>60.181623</td>\n",
       "      <td>-104.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.653109</td>\n",
       "      <td>60.131806</td>\n",
       "      <td>-104.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.984037</td>\n",
       "      <td>60.089935</td>\n",
       "      <td>-104.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.307567</td>\n",
       "      <td>60.056029</td>\n",
       "      <td>-104.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-99.899763</td>\n",
       "      <td>81.788725</td>\n",
       "      <td>65.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-99.939531</td>\n",
       "      <td>81.389997</td>\n",
       "      <td>65.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-99.969304</td>\n",
       "      <td>80.990713</td>\n",
       "      <td>65.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-99.989081</td>\n",
       "      <td>80.591032</td>\n",
       "      <td>65.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-99.998859</td>\n",
       "      <td>80.191116</td>\n",
       "      <td>65.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y   Pos Z\n",
       "0    -75.968791  60.239368 -105.00\n",
       "1    -75.314716  60.181623 -104.93\n",
       "2    -74.653109  60.131806 -104.86\n",
       "3    -73.984037  60.089935 -104.79\n",
       "4    -73.307567  60.056029 -104.72\n",
       "...         ...        ...     ...\n",
       "2438 -99.899763  81.788725   65.66\n",
       "2439 -99.939531  81.389997   65.73\n",
       "2440 -99.969304  80.990713   65.80\n",
       "2441 -99.989081  80.591032   65.87\n",
       "2442 -99.998859  80.191116   65.94\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 16s 22ms/step - loss: 4087.0259 - val_loss: 3914.5486\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3759.1499 - val_loss: 3679.8445\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3552.2480 - val_loss: 3486.9502\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3376.0317 - val_loss: 3318.5063\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 3222.8975 - val_loss: 3175.3394\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3092.5823 - val_loss: 3051.9492\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2980.6184 - val_loss: 2946.3352\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2884.6152 - val_loss: 2856.2112\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2802.9626 - val_loss: 2779.7922\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2734.3330 - val_loss: 2716.0103\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2677.3882 - val_loss: 2663.6333\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2630.9148 - val_loss: 2621.5144\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2594.2734 - val_loss: 2588.6763\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2566.0359 - val_loss: 2563.7952\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2545.2021 - val_loss: 2546.0369\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2530.5955 - val_loss: 2533.6653\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.9453 - val_loss: 2525.8921\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2514.9597 - val_loss: 2521.1360\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2511.6428 - val_loss: 2518.6077\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2509.9717 - val_loss: 2517.4548\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2509.2390 - val_loss: 2516.8181\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2508.9231 - val_loss: 2516.5642\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2508.8330 - val_loss: 2516.4153\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2508.7627 - val_loss: 2516.3347\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2508.7942 - val_loss: 2516.3579\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2508.7954 - val_loss: 2516.3677\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2508.7595 - val_loss: 2516.2249\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2508.7539 - val_loss: 2516.2180\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2508.7571 - val_loss: 2516.2292\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2508.7983 - val_loss: 2516.2061\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2508.7627 - val_loss: 2516.1858\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2508.8132 - val_loss: 2516.1003\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2509.1243 - val_loss: 2517.8979\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2509.0740 - val_loss: 2524.4849\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2510.3848 - val_loss: 2518.3403\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2509.1248 - val_loss: 2517.1938\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2506.1240 - val_loss: 2503.0986\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2490.8650 - val_loss: 2517.3936\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2474.9917 - val_loss: 2462.2542\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2424.6147 - val_loss: 2417.6538\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2376.1016 - val_loss: 2362.4888\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2325.2070 - val_loss: 2308.9155\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2252.9536 - val_loss: 2232.4648\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2181.6799 - val_loss: 2171.6626\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2126.2869 - val_loss: 2113.0054\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2048.6116 - val_loss: 2025.6731\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1972.1426 - val_loss: 1961.4595\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1896.1704 - val_loss: 1874.5433\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1805.7520 - val_loss: 1781.1953\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1712.6187 - val_loss: 1690.0410\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1621.7869 - val_loss: 1605.8046\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1550.6217 - val_loss: 1536.3427\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1485.1913 - val_loss: 1480.3173\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1419.0330 - val_loss: 1402.1100\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1352.4913 - val_loss: 1354.7090\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1282.4779 - val_loss: 1264.1687\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1218.0315 - val_loss: 1201.1680\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1161.4298 - val_loss: 1161.2070\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1096.6484 - val_loss: 1076.8881\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1036.9637 - val_loss: 1020.7810\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 982.6459 - val_loss: 975.3649\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.6135 - val_loss: 904.8303\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 873.6335 - val_loss: 857.7413\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 813.9663 - val_loss: 805.8372\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 765.4039 - val_loss: 741.1014\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 709.7237 - val_loss: 701.5756\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 662.6901 - val_loss: 651.8817\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 627.8571 - val_loss: 607.2033\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 580.1024 - val_loss: 563.6412\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 540.5044 - val_loss: 522.4738\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 500.2807 - val_loss: 481.8347\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 465.0614 - val_loss: 449.4059\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 430.8047 - val_loss: 410.9713\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 397.4752 - val_loss: 387.4107\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 365.6796 - val_loss: 355.5469\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 338.7920 - val_loss: 325.6660\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 313.8997 - val_loss: 305.0103\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 292.3294 - val_loss: 286.2246\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 269.2818 - val_loss: 259.7988\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 245.8403 - val_loss: 236.2305\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 225.7944 - val_loss: 217.0730\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 211.7085 - val_loss: 199.7910\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 193.3601 - val_loss: 185.4216\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 176.3596 - val_loss: 170.8334\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 162.7024 - val_loss: 159.3522\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 149.0907 - val_loss: 144.0121\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 140.1716 - val_loss: 134.4985\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 126.4487 - val_loss: 126.1168\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 117.7735 - val_loss: 118.0268\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 107.6449 - val_loss: 107.4990\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 99.4415 - val_loss: 98.9047\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 95.6409 - val_loss: 93.3795\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 84.2186 - val_loss: 83.7292\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 81.7372 - val_loss: 92.5415\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 79.0108 - val_loss: 77.3746\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 69.4627 - val_loss: 75.6626\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 69.6736 - val_loss: 78.9433\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 62.2126 - val_loss: 61.7956\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 58.4375 - val_loss: 64.3698\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 53.1044 - val_loss: 61.5901\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 53.5554 - val_loss: 53.7700\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 48.7329 - val_loss: 51.9942\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 44.7469 - val_loss: 52.1779\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 44.4095 - val_loss: 48.0946\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 44.2062 - val_loss: 42.5693\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 40.3307 - val_loss: 40.9317\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 43.8556 - val_loss: 46.2727\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 39.2913 - val_loss: 43.3271\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 34.5979 - val_loss: 38.4309\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 34.2882 - val_loss: 35.7780\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 31.5318 - val_loss: 41.2567\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 31.4265 - val_loss: 37.1667\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 33.2847 - val_loss: 36.1287\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 31.5787 - val_loss: 39.7651\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 30.6225 - val_loss: 38.4537\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 28.0541 - val_loss: 33.2558\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 29.4444 - val_loss: 35.9809\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 28.4522 - val_loss: 31.7012\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 26.1737 - val_loss: 31.4708\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 26.4560 - val_loss: 29.8351\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 27.3915 - val_loss: 29.6124\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 28.7327 - val_loss: 36.3361\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 26.1812 - val_loss: 27.3850\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 26.6705 - val_loss: 27.8638\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 21.4062 - val_loss: 29.5477\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 21.1450 - val_loss: 24.2884\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 25.6293 - val_loss: 25.2621\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 23.0040 - val_loss: 26.0195\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 19.5894 - val_loss: 33.0626\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 22.4562 - val_loss: 24.7241\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 25.1928 - val_loss: 26.2193\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 23.9262 - val_loss: 23.9870\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 20.2144 - val_loss: 43.7482\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 20.8981 - val_loss: 24.7354\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 16.9930 - val_loss: 28.4825\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 18.3382 - val_loss: 21.6557\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 22.9857 - val_loss: 24.9774\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 18.6638 - val_loss: 31.7551\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 18.4279 - val_loss: 22.1846\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 20.1486 - val_loss: 27.1349\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 21.7855 - val_loss: 24.1689\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 18.8750 - val_loss: 29.7250\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 18.6149 - val_loss: 26.0255\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 15.8986 - val_loss: 26.2857\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 24.0867 - val_loss: 20.8076\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 25.2166 - val_loss: 28.3729\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 15.0059 - val_loss: 27.0291\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 17.9868 - val_loss: 20.6293\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 15.4850 - val_loss: 20.6492\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 16.8195 - val_loss: 21.8295\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 17.9438 - val_loss: 21.7834\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 16.8312 - val_loss: 26.6840\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 15.0291 - val_loss: 21.1380\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 17.0853 - val_loss: 19.6476\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 16.9829 - val_loss: 20.6289\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 14.1972 - val_loss: 21.2199\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.0417 - val_loss: 30.3732\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 14.7468 - val_loss: 19.6940\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 17.7421 - val_loss: 22.5184\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 15.0854 - val_loss: 23.3468\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 17.3843 - val_loss: 21.5753\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 14.3931 - val_loss: 24.8813\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 14.6795 - val_loss: 21.4971\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 11.0150 - val_loss: 22.5301\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 17.0443 - val_loss: 41.7619\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 18.9663 - val_loss: 25.1563\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 13.5148 - val_loss: 18.9812\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 13.9226 - val_loss: 24.3287\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 18.8838 - val_loss: 26.4721\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 12.5936 - val_loss: 21.4360\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 13.8420 - val_loss: 16.6136\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 15.1388 - val_loss: 32.5525\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 15.0975 - val_loss: 51.0224\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 12.1112 - val_loss: 21.0271\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 10.5859 - val_loss: 19.4981\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 9.7953 - val_loss: 16.5499\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 10.1053 - val_loss: 23.6716\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 20.7608 - val_loss: 26.4050\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 14.2590 - val_loss: 15.9535\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 11.7215 - val_loss: 19.8195\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 11.9996 - val_loss: 18.4251\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 12.0697 - val_loss: 17.9184\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 12.5201 - val_loss: 19.4417\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 10.6761 - val_loss: 19.9235\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 12.0349 - val_loss: 20.9614\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 11.5982 - val_loss: 15.4312\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 11.0864 - val_loss: 24.4478\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 12.1725 - val_loss: 26.5666\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 21.7210 - val_loss: 28.0843\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 10.3757 - val_loss: 17.0383\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 12.0453 - val_loss: 18.2860\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 8.1386 - val_loss: 18.8146\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 9.9288 - val_loss: 17.4787\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 14.4777 - val_loss: 20.2504\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 12.2310 - val_loss: 17.2566\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 8.3685 - val_loss: 16.2392\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 12.1861 - val_loss: 27.7362\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 14.1129 - val_loss: 18.5350\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 12.0183 - val_loss: 24.7159\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 9.3915 - val_loss: 18.6069\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 18.606926834355892\n",
      "Mean Absolute Error (MAE): 2.540505461257032\n",
      "Root Mean Squared Error (RMSE): 4.31357471644527\n",
      "Time taken: 1257.0706655979156\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 15s 31ms/step - loss: 4057.4966 - val_loss: 3953.7456\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 3736.4749 - val_loss: 3729.1226\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 3529.6775 - val_loss: 3541.5225\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 3354.8040 - val_loss: 3381.2771\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 3204.0435 - val_loss: 3242.7615\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 3073.8965 - val_loss: 3123.9878\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2961.5420 - val_loss: 3021.2332\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2864.9126 - val_loss: 2933.9709\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2782.4407 - val_loss: 2859.9670\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2712.9177 - val_loss: 2797.9897\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 2655.3228 - val_loss: 2747.6577\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2608.3320 - val_loss: 2707.3967\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2571.2258 - val_loss: 2676.2900\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2542.6970 - val_loss: 2653.3474\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 2521.5598 - val_loss: 2636.8164\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2506.6555 - val_loss: 2625.9417\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2496.8760 - val_loss: 2619.3127\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2490.8613 - val_loss: 2615.5071\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2487.5574 - val_loss: 2613.8943\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2485.8555 - val_loss: 2612.9092\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2485.1282 - val_loss: 2612.8867\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2484.8342 - val_loss: 2613.1362\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 2484.6868 - val_loss: 2613.0156\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 2484.6677 - val_loss: 2613.2615\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2484.6567 - val_loss: 2613.2366\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2484.6636 - val_loss: 2613.2959\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2484.8879 - val_loss: 2614.5103\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2484.8481 - val_loss: 2614.0068\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2485.1770 - val_loss: 2614.0725\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2484.6924 - val_loss: 2613.7954\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2482.7852 - val_loss: 2596.7073\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2455.3152 - val_loss: 2572.6514\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2441.4463 - val_loss: 2569.3953\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2432.0339 - val_loss: 2565.3655\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2431.9929 - val_loss: 2561.5337\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2426.0815 - val_loss: 2560.5601\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2424.0669 - val_loss: 2556.4849\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2420.3459 - val_loss: 2554.4744\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2416.3298 - val_loss: 2556.9607\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2389.0833 - val_loss: 2495.0581\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2328.4456 - val_loss: 2417.2688\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2232.6333 - val_loss: 2303.8359\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 2120.1438 - val_loss: 2215.9312\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1996.3433 - val_loss: 2045.0607\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1879.4521 - val_loss: 1926.9860\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1782.1311 - val_loss: 1833.9991\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1687.3552 - val_loss: 1734.8964\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1597.6501 - val_loss: 1649.1865\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1515.2545 - val_loss: 1560.6902\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1436.6654 - val_loss: 1487.6421\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1362.2122 - val_loss: 1405.3333\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1282.7056 - val_loss: 1327.2139\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1212.9335 - val_loss: 1262.4745\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1141.0787 - val_loss: 1175.8589\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 1073.4736 - val_loss: 1114.8767\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1011.6592 - val_loss: 1046.1371\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 950.2029 - val_loss: 979.9058\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 888.8610 - val_loss: 923.2672\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 831.9885 - val_loss: 862.9638\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 772.6389 - val_loss: 791.6946\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 718.6413 - val_loss: 741.1087\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 667.1027 - val_loss: 688.0862\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 619.5127 - val_loss: 647.1716\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 578.0131 - val_loss: 618.4468\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 532.3159 - val_loss: 553.4521\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 487.5084 - val_loss: 517.5643\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 450.4121 - val_loss: 467.1822\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 415.0856 - val_loss: 436.5992\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 385.2279 - val_loss: 405.1299\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 356.6795 - val_loss: 376.0833\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 323.5918 - val_loss: 336.2812\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 301.8484 - val_loss: 317.1711\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 273.4480 - val_loss: 285.4824\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 250.0702 - val_loss: 269.6014\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 232.5681 - val_loss: 249.0463\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 29ms/step - loss: 210.6163 - val_loss: 221.4984\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 194.3982 - val_loss: 225.1832\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 178.8707 - val_loss: 188.7399\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 163.9102 - val_loss: 179.5853\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 148.0202 - val_loss: 164.5165\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 138.8400 - val_loss: 161.9824\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 132.2126 - val_loss: 131.1939\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 117.2651 - val_loss: 131.7499\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 106.8353 - val_loss: 125.2022\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 102.9000 - val_loss: 112.1683\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 95.6980 - val_loss: 108.3096\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 89.1056 - val_loss: 97.5556\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 83.9602 - val_loss: 93.9169\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 80.1861 - val_loss: 80.0402\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 72.1238 - val_loss: 91.5644\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 68.1886 - val_loss: 75.5386\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 65.4805 - val_loss: 70.0516\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 62.0767 - val_loss: 65.5080\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 60.6365 - val_loss: 70.7881\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 57.5612 - val_loss: 58.7030\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 52.1673 - val_loss: 54.9399\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 50.3497 - val_loss: 53.5714\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 50.3855 - val_loss: 49.7181\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 50.1880 - val_loss: 60.8889\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 47.0013 - val_loss: 61.5440\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 45.2417 - val_loss: 53.5317\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 47.0286 - val_loss: 51.1440\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 41.7967 - val_loss: 44.9428\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 40.6686 - val_loss: 42.7636\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 39.7164 - val_loss: 43.0623\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 39.3282 - val_loss: 37.7941\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 37.5188 - val_loss: 36.9329\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 39.2498 - val_loss: 48.0558\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 39.0612 - val_loss: 36.7068\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 35.2089 - val_loss: 84.5291\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 33.2701 - val_loss: 33.7680\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 36.7379 - val_loss: 51.2410\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 34.4496 - val_loss: 32.2820\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 34.6079 - val_loss: 30.3436\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 34.4147 - val_loss: 46.1974\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 30.3156 - val_loss: 32.0189\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 29.9900 - val_loss: 49.1313\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 30.6052 - val_loss: 31.2301\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 30.1082 - val_loss: 29.9760\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 29.3156 - val_loss: 36.3883\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 27.4182 - val_loss: 28.0391\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 28.4777 - val_loss: 31.1297\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 28.1967 - val_loss: 30.6187\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 26.6516 - val_loss: 30.3697\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 27.8365 - val_loss: 28.1610\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 26.9324 - val_loss: 27.7066\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 31.1336 - val_loss: 40.1078\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 27.0207 - val_loss: 35.0149\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 25.3935 - val_loss: 23.7962\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 24.6609 - val_loss: 26.6492\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 25.5279 - val_loss: 30.9908\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 27.2619 - val_loss: 33.1596\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 25.9553 - val_loss: 28.3103\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 25.0200 - val_loss: 27.9845\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 24.5511 - val_loss: 25.7709\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 22.8537 - val_loss: 23.6786\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 24.0859 - val_loss: 28.8625\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 23.1632 - val_loss: 25.8013\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 23.0812 - val_loss: 23.5526\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 22.5503 - val_loss: 24.4973\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 21.8841 - val_loss: 28.8825\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 21.3418 - val_loss: 24.8772\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 21.7578 - val_loss: 27.5534\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 21.0698 - val_loss: 20.8433\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 21.5068 - val_loss: 21.8230\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 23.5281 - val_loss: 25.5160\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 20.4612 - val_loss: 26.1435\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 22.5166 - val_loss: 27.3512\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 20.2711 - val_loss: 27.4925\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 19.2233 - val_loss: 24.8740\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 21.7690 - val_loss: 25.1399\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 29ms/step - loss: 19.6377 - val_loss: 21.1599\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 18.8623 - val_loss: 28.5717\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 17.4020 - val_loss: 19.8667\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 19.9487 - val_loss: 29.0938\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 20.7222 - val_loss: 26.7428\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 21.3509 - val_loss: 21.8442\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 23.6043 - val_loss: 22.9694\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 20.1735 - val_loss: 39.4450\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 19.1052 - val_loss: 20.4949\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 17.7406 - val_loss: 26.4740\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 19.0113 - val_loss: 21.9853\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 22.4632 - val_loss: 21.2469\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 15.7000 - val_loss: 20.9560\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 20.2950 - val_loss: 32.1492\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 19.9835 - val_loss: 21.5747\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 16.3290 - val_loss: 23.1969\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 19.0722 - val_loss: 20.3700\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 18.5727 - val_loss: 25.4323\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 14.7129 - val_loss: 22.4251\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 17.5994 - val_loss: 20.0328\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 18.7182 - val_loss: 49.2452\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 20.3410 - val_loss: 18.9936\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 22.1211 - val_loss: 28.1841\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 18.2405 - val_loss: 21.5924\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 13.7397 - val_loss: 19.8285\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 15.2455 - val_loss: 23.4470\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 18.4620 - val_loss: 20.9039\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 15.3996 - val_loss: 37.2780\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 15.9590 - val_loss: 24.1364\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 14.3699 - val_loss: 27.5704\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 15.6283 - val_loss: 21.9392\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 17.0807 - val_loss: 23.0968\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 16.9983 - val_loss: 18.2137\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 14.7250 - val_loss: 24.6842\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 16.4208 - val_loss: 29.3172\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 16.1613 - val_loss: 19.3373\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 13.2612 - val_loss: 17.0177\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 17.4973 - val_loss: 19.3963\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 17.4131 - val_loss: 25.2486\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 13.8663 - val_loss: 23.9933\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 14.4047 - val_loss: 25.5600\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 15.0105 - val_loss: 21.3615\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 17.3538 - val_loss: 16.6279\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 15.4184 - val_loss: 36.2409\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 17.9613 - val_loss: 21.7024\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 14.3446 - val_loss: 30.9262\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 14.5754 - val_loss: 20.7441\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 12.5433 - val_loss: 18.6371\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 13.1970 - val_loss: 18.0759\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 18.075913238973573\n",
      "Mean Absolute Error (MAE): 2.6447220335963326\n",
      "Root Mean Squared Error (RMSE): 4.251577735261766\n",
      "Time taken: 2301.85862326622\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 23ms/step - loss: 4061.1912 - val_loss: 3791.4004\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 3735.4680 - val_loss: 3564.8882\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 3533.7917 - val_loss: 3375.5396\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 3363.6863 - val_loss: 3213.9543\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 3217.3923 - val_loss: 3074.1902\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 3091.0793 - val_loss: 2953.6538\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2982.4785 - val_loss: 2849.7815\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2889.3779 - val_loss: 2760.9529\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2810.2356 - val_loss: 2685.6394\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2743.9065 - val_loss: 2622.5908\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2689.0510 - val_loss: 2570.6357\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2644.7056 - val_loss: 2529.0591\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2609.9397 - val_loss: 2496.6616\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2583.4741 - val_loss: 2472.2212\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2564.0376 - val_loss: 2454.3528\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 2550.6494 - val_loss: 2442.1484\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 2542.0210 - val_loss: 2434.2754\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 2536.9041 - val_loss: 2429.5400\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2534.0437 - val_loss: 2426.7681\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2532.6384 - val_loss: 2425.4128\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2532.0618 - val_loss: 2424.5918\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2531.8667 - val_loss: 2424.2671\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2533.2744 - val_loss: 2428.8516\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2533.0784 - val_loss: 2425.9380\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2532.0273 - val_loss: 2424.6182\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2530.1035 - val_loss: 2420.2229\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2489.3547 - val_loss: 2343.5764\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2424.8455 - val_loss: 2307.4929\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2390.0679 - val_loss: 2272.2551\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2355.8450 - val_loss: 2237.1975\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 2320.3840 - val_loss: 2210.7803\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2286.4705 - val_loss: 2171.8313\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2243.4570 - val_loss: 2124.5613\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2194.3408 - val_loss: 2073.8674\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2136.8755 - val_loss: 2020.8962\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2089.1223 - val_loss: 1975.8248\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 2036.5277 - val_loss: 1911.7751\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1975.2659 - val_loss: 1855.3589\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1911.2479 - val_loss: 1795.1348\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1845.8428 - val_loss: 1735.1859\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1786.0552 - val_loss: 1677.2340\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1725.4115 - val_loss: 1624.8319\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1661.5741 - val_loss: 1547.0139\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1599.4963 - val_loss: 1488.5056\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 1540.8381 - val_loss: 1430.6713\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 1480.4462 - val_loss: 1372.1337\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 1419.7837 - val_loss: 1313.0048\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1358.6036 - val_loss: 1249.3451\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1299.6650 - val_loss: 1197.2809\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1240.7974 - val_loss: 1150.6802\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1188.1060 - val_loss: 1107.0680\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1128.9655 - val_loss: 1044.5387\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1074.2430 - val_loss: 979.1038\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1016.9389 - val_loss: 923.4963\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 964.1848 - val_loss: 875.7849\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 910.8997 - val_loss: 841.6085\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 860.9025 - val_loss: 780.7546\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 809.5714 - val_loss: 732.9977\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 764.2780 - val_loss: 688.9928\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 718.6665 - val_loss: 644.0617\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 667.4261 - val_loss: 604.4126\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 621.2774 - val_loss: 554.9335\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 579.6122 - val_loss: 515.2935\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 538.7797 - val_loss: 480.0339\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 499.2793 - val_loss: 440.7231\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 464.5643 - val_loss: 425.2726\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 432.2398 - val_loss: 377.6401\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 399.5740 - val_loss: 352.9156\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 374.7816 - val_loss: 352.3356\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 345.5512 - val_loss: 303.7920\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 322.1009 - val_loss: 274.9415\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 294.3278 - val_loss: 253.7357\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 273.8623 - val_loss: 246.3572\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 251.7286 - val_loss: 212.3384\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 231.1387 - val_loss: 196.6709\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 213.0924 - val_loss: 187.6380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 199.0926 - val_loss: 173.5679\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 180.6990 - val_loss: 163.2933\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 165.3339 - val_loss: 141.3957\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 157.2645 - val_loss: 132.3612\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 141.6194 - val_loss: 120.2943\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 130.2433 - val_loss: 115.4037\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 121.9418 - val_loss: 101.5843\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 113.1241 - val_loss: 120.4519\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 102.8308 - val_loss: 94.4851\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 95.5063 - val_loss: 79.1137\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 88.2939 - val_loss: 77.9625\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 83.2936 - val_loss: 72.8504\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 74.7298 - val_loss: 71.3089\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 69.8419 - val_loss: 59.9256\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 66.3479 - val_loss: 66.8125\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 63.6760 - val_loss: 73.9346\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 58.6868 - val_loss: 51.1733\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 55.5398 - val_loss: 47.9731\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 51.6153 - val_loss: 53.2711\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 48.8835 - val_loss: 44.5073\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 46.1802 - val_loss: 58.4923\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 42.8230 - val_loss: 43.6258\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 41.5190 - val_loss: 52.5874\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 41.4371 - val_loss: 40.5070\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 37.7608 - val_loss: 36.5648\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 36.9082 - val_loss: 34.3301\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 33.7752 - val_loss: 33.5582\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 34.0561 - val_loss: 29.7264\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 32.8272 - val_loss: 42.4624\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 30.7469 - val_loss: 42.4953\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 33.6065 - val_loss: 29.3035\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 30.5509 - val_loss: 32.1509\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 29.1664 - val_loss: 33.0669\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 29.2261 - val_loss: 58.1019\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 28.7838 - val_loss: 35.7242\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 24.9608 - val_loss: 28.5451\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 24.1302 - val_loss: 29.5445\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 25.8919 - val_loss: 35.2463\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 23.1626 - val_loss: 31.8659\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 26.3780 - val_loss: 37.6982\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 22.7703 - val_loss: 32.3108\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 28.1765 - val_loss: 24.4597\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 22.3819 - val_loss: 24.6573\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 20.9437 - val_loss: 22.1716\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 20.5074 - val_loss: 30.5094\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 21.6472 - val_loss: 26.9368\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 21.3906 - val_loss: 21.9201\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 21.6353 - val_loss: 31.0746\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 20.3143 - val_loss: 21.9400\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 24.6366 - val_loss: 22.2055\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 19.0344 - val_loss: 21.8662\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 19.8908 - val_loss: 25.4516\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 21.2048 - val_loss: 20.2356\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 18.4191 - val_loss: 24.7940\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 17.9253 - val_loss: 23.0874\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 16.3411 - val_loss: 21.9008\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 20.1283 - val_loss: 23.1053\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 19.1039 - val_loss: 32.5383\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 17.1281 - val_loss: 24.8728\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 17.4096 - val_loss: 24.7603\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 17.1487 - val_loss: 21.0237\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 18.9545 - val_loss: 22.0416\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 17.0560 - val_loss: 20.6864\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 16.0606 - val_loss: 20.4085\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 15.5300 - val_loss: 113.7979\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 20.5707 - val_loss: 20.9081\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 15.8289 - val_loss: 28.5553\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 17.5308 - val_loss: 19.9951\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 16.9173 - val_loss: 61.9078\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 17.2413 - val_loss: 18.2772\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 15.3210 - val_loss: 21.8069\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 16.1206 - val_loss: 21.3756\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 14.6377 - val_loss: 22.5406\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 16.0719 - val_loss: 20.2650\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 16.1611 - val_loss: 19.1071\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 15.7679 - val_loss: 22.1311\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 14.4585 - val_loss: 22.4042\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 8s 21ms/step - loss: 13.7609 - val_loss: 16.5281\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 13.9463 - val_loss: 19.4500\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 12.7165 - val_loss: 21.2285\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 13.5171 - val_loss: 19.3951\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 15.6788 - val_loss: 26.3582\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 13.4935 - val_loss: 20.5050\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 14.4614 - val_loss: 23.6911\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 14.3621 - val_loss: 21.0095\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 15.3546 - val_loss: 30.3014\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 16.6462 - val_loss: 23.1849\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.9184 - val_loss: 16.1890\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 10.6873 - val_loss: 17.9211\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 12.1086 - val_loss: 17.0426\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 12.5393 - val_loss: 21.6352\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.9197 - val_loss: 17.8368\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 12.9975 - val_loss: 18.1568\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.2392 - val_loss: 14.7260\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.1725 - val_loss: 24.4354\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.1585 - val_loss: 16.9583\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 10.9727 - val_loss: 18.3736\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 12.8778 - val_loss: 15.9155\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 10.1525 - val_loss: 16.0300\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 15.3890 - val_loss: 35.1036\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 12.1300 - val_loss: 22.2571\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 13.4566 - val_loss: 19.7168\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 12.3252 - val_loss: 15.0020\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.9395 - val_loss: 21.1713\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.4973 - val_loss: 15.7693\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 9.6306 - val_loss: 18.8948\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 9.8577 - val_loss: 17.9579\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.0580 - val_loss: 14.7754\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.1922 - val_loss: 25.4262\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 13.5794 - val_loss: 25.9497\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.1346 - val_loss: 17.5436\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 8.7017 - val_loss: 15.4066\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 12.6979 - val_loss: 15.8500\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 12.1186 - val_loss: 18.9017\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.7407 - val_loss: 16.4336\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 9.9553 - val_loss: 16.5400\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 10.7189 - val_loss: 17.7561\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 10.8598 - val_loss: 31.9961\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.0925 - val_loss: 15.1013\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 10.6715 - val_loss: 20.4258\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 8.4689 - val_loss: 21.8182\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 11.1748 - val_loss: 15.1040\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 11.8377 - val_loss: 26.6257\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 11.1754 - val_loss: 22.7747\n",
      "16/16 [==============================] - 1s 16ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 22.774653779736237\n",
      "Mean Absolute Error (MAE): 2.8605563996714523\n",
      "Root Mean Squared Error (RMSE): 4.772279725638077\n",
      "Time taken: 1666.542846918106\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 15s 31ms/step - loss: 4071.6550 - val_loss: 3853.3076\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 3738.2964 - val_loss: 3628.7883\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 3533.7581 - val_loss: 3443.6604\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 3360.8914 - val_loss: 3284.4648\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 3212.2817 - val_loss: 3147.2117\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 3083.9678 - val_loss: 3028.2073\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2973.2805 - val_loss: 2925.8320\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2878.3687 - val_loss: 2838.3894\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2797.8271 - val_loss: 2764.2461\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2730.1621 - val_loss: 2702.2454\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2674.1323 - val_loss: 2651.3225\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2628.6365 - val_loss: 2610.4041\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2592.8982 - val_loss: 2578.6201\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2565.4011 - val_loss: 2554.5132\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2545.2708 - val_loss: 2537.0161\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2531.0908 - val_loss: 2525.1514\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2521.7646 - val_loss: 2517.4734\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2516.1296 - val_loss: 2512.9722\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2513.0632 - val_loss: 2510.5894\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2511.5544 - val_loss: 2509.4351\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.8264 - val_loss: 2508.9148\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.5830 - val_loss: 2508.6545\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4851 - val_loss: 2508.6287\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.5200 - val_loss: 2508.6455\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4080 - val_loss: 2508.6428\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4338 - val_loss: 2508.6091\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4297 - val_loss: 2508.6567\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4514 - val_loss: 2508.6394\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4387 - val_loss: 2508.7275\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.8472 - val_loss: 2508.8296\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.5605 - val_loss: 2508.7373\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4756 - val_loss: 2508.6699\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4932 - val_loss: 2508.6606\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4458 - val_loss: 2508.6741\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4780 - val_loss: 2508.6807\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4509 - val_loss: 2508.7107\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4624 - val_loss: 2508.6616\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4548 - val_loss: 2508.7036\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4558 - val_loss: 2508.6582\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4695 - val_loss: 2508.7429\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4453 - val_loss: 2508.7141\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4526 - val_loss: 2508.6936\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4790 - val_loss: 2508.8184\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4744 - val_loss: 2508.6917\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4712 - val_loss: 2508.7246\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.5056 - val_loss: 2508.7976\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4243 - val_loss: 2508.7471\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.5566 - val_loss: 2508.7241\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.5217 - val_loss: 2508.7324\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4744 - val_loss: 2508.7710\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.4548 - val_loss: 2508.7427\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.2896 - val_loss: 2508.6370\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.8218 - val_loss: 2508.0947\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2510.1929 - val_loss: 2500.0366\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2481.2039 - val_loss: 2469.0317\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2462.7937 - val_loss: 2451.5310\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2456.0571 - val_loss: 2444.9148\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2447.8086 - val_loss: 2430.8049\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2421.8416 - val_loss: 2380.8635\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2363.4641 - val_loss: 2327.7893\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2304.4141 - val_loss: 2261.4114\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2242.3535 - val_loss: 2195.7598\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2182.2229 - val_loss: 2147.1482\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2117.0962 - val_loss: 2065.1248\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 2036.7124 - val_loss: 1991.7882\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1954.2070 - val_loss: 1899.1256\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1863.9895 - val_loss: 1810.4111\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1782.6235 - val_loss: 1741.1316\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1702.6420 - val_loss: 1659.2450\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1630.5293 - val_loss: 1583.8165\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1546.0142 - val_loss: 1499.0983\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1469.2004 - val_loss: 1432.2406\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1399.9706 - val_loss: 1392.9174\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1331.6724 - val_loss: 1290.7671\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 28ms/step - loss: 1268.5074 - val_loss: 1232.3690\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1204.7590 - val_loss: 1167.5125\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1147.0215 - val_loss: 1119.4912\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1086.6425 - val_loss: 1052.8798\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1028.6746 - val_loss: 986.2470\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 967.9431 - val_loss: 932.5735\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 913.2631 - val_loss: 877.9012\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 857.3165 - val_loss: 824.0766\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 808.1686 - val_loss: 777.2722\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 755.2155 - val_loss: 729.9567\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 711.2877 - val_loss: 680.3216\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 663.7275 - val_loss: 649.2910\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 623.8908 - val_loss: 606.6127\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 582.8397 - val_loss: 557.6306\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 547.1878 - val_loss: 523.1882\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 512.9818 - val_loss: 488.9064\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 477.2499 - val_loss: 451.6155\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 443.2881 - val_loss: 431.3377\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 410.8815 - val_loss: 415.6987\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 384.4704 - val_loss: 368.6825\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 358.4279 - val_loss: 339.5123\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 328.2318 - val_loss: 318.6548\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 306.4778 - val_loss: 302.0027\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 285.5649 - val_loss: 278.3557\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 264.5417 - val_loss: 251.6891\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 244.3734 - val_loss: 232.3236\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 226.4645 - val_loss: 232.3688\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 213.8243 - val_loss: 195.7814\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 193.0569 - val_loss: 182.7711\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 178.3504 - val_loss: 173.3174\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 167.0070 - val_loss: 151.6175\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 152.6673 - val_loss: 145.8584\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 143.0490 - val_loss: 133.8960\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 130.0530 - val_loss: 126.9637\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 121.5735 - val_loss: 118.6062\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 113.5316 - val_loss: 108.5003\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 105.3746 - val_loss: 101.0647\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 98.3630 - val_loss: 90.1985\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 92.6435 - val_loss: 103.3535\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 85.3860 - val_loss: 76.3721\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 83.4887 - val_loss: 75.6052\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 73.1734 - val_loss: 68.3767\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 72.9894 - val_loss: 64.6662\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 67.2009 - val_loss: 60.3685\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 61.9654 - val_loss: 56.4775\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 62.2410 - val_loss: 57.9757\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 57.3541 - val_loss: 54.6129\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 53.6273 - val_loss: 47.0483\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 50.0769 - val_loss: 48.0685\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 49.2155 - val_loss: 52.0427\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 45.8219 - val_loss: 47.8679\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 44.8276 - val_loss: 45.2875\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 41.7993 - val_loss: 48.2540\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 39.4458 - val_loss: 39.0383\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 38.9577 - val_loss: 39.6196\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 39.4220 - val_loss: 42.5132\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 36.7379 - val_loss: 39.0420\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 34.4777 - val_loss: 38.2633\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 31.9371 - val_loss: 50.5955\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 32.7206 - val_loss: 26.9151\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 30.8295 - val_loss: 32.7534\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 30.1194 - val_loss: 27.3700\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 29.1116 - val_loss: 25.9560\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 27.1698 - val_loss: 34.1930\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 26.1161 - val_loss: 31.6840\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 29.5768 - val_loss: 34.7538\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 31.2058 - val_loss: 28.3587\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 23.8242 - val_loss: 23.2504\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 23.4010 - val_loss: 30.8142\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 23.2788 - val_loss: 31.0266\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 23.0537 - val_loss: 32.6460\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 24.2675 - val_loss: 24.7227\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 22.5743 - val_loss: 23.2172\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 20.3567 - val_loss: 25.0234\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 20.8526 - val_loss: 25.4274\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 22.2257 - val_loss: 24.0373\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 25ms/step - loss: 21.3352 - val_loss: 25.7235\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 21.9633 - val_loss: 20.9590\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 21.7667 - val_loss: 19.0537\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 17.9073 - val_loss: 20.7814\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 19.1899 - val_loss: 18.0977\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 19.2658 - val_loss: 24.9730\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 18.7836 - val_loss: 19.4440\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 16.4521 - val_loss: 22.6604\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 17.0817 - val_loss: 18.3719\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 16.2944 - val_loss: 18.9546\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 20.3835 - val_loss: 25.2818\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 18.1802 - val_loss: 15.9151\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 19.5249 - val_loss: 17.6340\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 15.9038 - val_loss: 18.9489\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 16.7833 - val_loss: 25.3225\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 16.8438 - val_loss: 17.0663\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 17.2646 - val_loss: 19.2107\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 14.1618 - val_loss: 16.6151\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 15.4653 - val_loss: 20.7125\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 15.9506 - val_loss: 17.5687\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 14.3188 - val_loss: 17.6443\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 15.9883 - val_loss: 16.4239\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 13.5774 - val_loss: 16.6559\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 16.6579 - val_loss: 14.2603\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 14.5715 - val_loss: 15.1258\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 15.7465 - val_loss: 52.7875\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 14.6942 - val_loss: 17.8459\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 14.4748 - val_loss: 13.8847\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 12.4018 - val_loss: 19.0500\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 13.2264 - val_loss: 17.2212\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 17.9705 - val_loss: 24.7287\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 12.4922 - val_loss: 15.3800\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 11.7514 - val_loss: 26.9394\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 15.4006 - val_loss: 16.3116\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 13.9437 - val_loss: 16.0691\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 12.7459 - val_loss: 17.1087\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 12.0454 - val_loss: 18.9277\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 13.8359 - val_loss: 26.6459\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 13.6557 - val_loss: 27.7338\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 14.4714 - val_loss: 15.4459\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 10.5717 - val_loss: 14.7226\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 11.5221 - val_loss: 29.2612\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 10.9978 - val_loss: 19.5124\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 13.4093 - val_loss: 20.1468\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 12.1587 - val_loss: 15.6469\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 14.2312 - val_loss: 13.4053\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 10.4908 - val_loss: 15.5862\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 11.3309 - val_loss: 21.5527\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 9.7986 - val_loss: 14.0582\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 13.2536 - val_loss: 17.7150\n",
      "16/16 [==============================] - 1s 19ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 17.714969945325315\n",
      "Mean Absolute Error (MAE): 2.6646723236048815\n",
      "Root Mean Squared Error (RMSE): 4.208915530790006\n",
      "Time taken: 2148.8539929389954\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 4061.4556 - val_loss: 3769.5906\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3738.1140 - val_loss: 3551.3462\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3530.5505 - val_loss: 3371.2954\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3356.8616 - val_loss: 3218.0762\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3207.7603 - val_loss: 3086.3997\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3079.2632 - val_loss: 2972.8191\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2969.1589 - val_loss: 2875.9409\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2874.8584 - val_loss: 2793.0674\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2794.7461 - val_loss: 2723.4097\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2727.7351 - val_loss: 2665.5769\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2672.4819 - val_loss: 2618.2681\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2627.7888 - val_loss: 2581.1453\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2592.7266 - val_loss: 2552.6204\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2566.1191 - val_loss: 2531.4946\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2546.7805 - val_loss: 2516.7227\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2533.1960 - val_loss: 2506.8076\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2524.4407 - val_loss: 2501.3247\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2519.1704 - val_loss: 2498.3533\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2516.3093 - val_loss: 2496.7549\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2514.8542 - val_loss: 2496.3745\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2514.2366 - val_loss: 2496.5176\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.9861 - val_loss: 2496.6675\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.9148 - val_loss: 2496.8364\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.8992 - val_loss: 2496.8572\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2513.8513 - val_loss: 2496.9966\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2513.8965 - val_loss: 2496.9333\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.8943 - val_loss: 2497.0308\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2513.8748 - val_loss: 2496.8762\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2513.8657 - val_loss: 2497.0178\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.8677 - val_loss: 2497.2510\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2513.8499 - val_loss: 2497.1377\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.8992 - val_loss: 2497.1096\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2513.9036 - val_loss: 2497.1204\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.8391 - val_loss: 2497.0010\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.9207 - val_loss: 2497.0024\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.9380 - val_loss: 2496.9500\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.9031 - val_loss: 2497.1155\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.9478 - val_loss: 2497.2227\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.9116 - val_loss: 2497.1777\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.8723 - val_loss: 2497.1890\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.8516 - val_loss: 2497.2271\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2513.9077 - val_loss: 2497.3052\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2710 - val_loss: 2496.0034\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2514.5476 - val_loss: 2495.4473\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2512.9309 - val_loss: 2490.4934\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2492.7283 - val_loss: 2465.2368\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2472.6616 - val_loss: 2446.7280\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2461.2524 - val_loss: 2432.6677\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2443.3669 - val_loss: 2403.9226\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2412.3398 - val_loss: 2368.1650\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2380.7280 - val_loss: 2342.6116\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2336.3015 - val_loss: 2277.3999\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2286.3064 - val_loss: 2235.2952\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2218.3647 - val_loss: 2134.1677\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2115.2847 - val_loss: 2040.9895\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2035.3022 - val_loss: 1969.6268\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1954.5006 - val_loss: 1886.0759\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1868.3893 - val_loss: 1813.4277\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1793.6785 - val_loss: 1728.7322\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1714.8102 - val_loss: 1657.1719\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1641.3907 - val_loss: 1583.3522\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1566.6674 - val_loss: 1507.8027\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1495.9363 - val_loss: 1448.0187\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1417.0621 - val_loss: 1367.2119\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1339.6437 - val_loss: 1296.1517\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1275.3352 - val_loss: 1322.2400\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1211.8223 - val_loss: 1167.3887\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1148.6337 - val_loss: 1111.9430\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1087.3394 - val_loss: 1049.6045\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1031.4325 - val_loss: 990.4052\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 974.7352 - val_loss: 941.1891\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 919.4883 - val_loss: 886.2357\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 870.3873 - val_loss: 836.4198\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 817.4683 - val_loss: 784.9086\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 770.5913 - val_loss: 754.4108\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 728.5485 - val_loss: 703.4914\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 679.5645 - val_loss: 662.0457\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 641.9915 - val_loss: 622.3527\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 603.0945 - val_loss: 578.2485\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 559.3953 - val_loss: 552.0114\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 523.0406 - val_loss: 504.4043\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 483.7787 - val_loss: 472.1126\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 457.8566 - val_loss: 440.6994\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 422.0373 - val_loss: 415.6221\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 392.8091 - val_loss: 377.6446\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 365.1956 - val_loss: 366.9656\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 338.3651 - val_loss: 338.9762\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 309.7932 - val_loss: 301.6140\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 287.4675 - val_loss: 279.0053\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 266.6114 - val_loss: 265.2593\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 246.1464 - val_loss: 244.5671\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 226.7061 - val_loss: 233.5771\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 215.0065 - val_loss: 229.2746\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 199.4658 - val_loss: 219.0908\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 180.7602 - val_loss: 183.5896\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 172.0278 - val_loss: 193.0677\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 156.5367 - val_loss: 155.6978\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 144.4069 - val_loss: 145.3669\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 134.0328 - val_loss: 138.3633\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 125.3056 - val_loss: 129.7137\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 114.5157 - val_loss: 115.8050\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 109.1611 - val_loss: 117.5691\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.3109 - val_loss: 105.0146\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 93.5215 - val_loss: 94.8659\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 85.0576 - val_loss: 102.4143\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 83.6987 - val_loss: 86.4676\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 76.2074 - val_loss: 88.2581\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 70.7742 - val_loss: 84.5650\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 68.3193 - val_loss: 70.8430\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 64.4299 - val_loss: 64.7307\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 60.3659 - val_loss: 73.5576\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 58.8388 - val_loss: 59.6631\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 58.1400 - val_loss: 66.0322\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 50.6807 - val_loss: 50.0624\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 51.4035 - val_loss: 55.8139\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 47.3228 - val_loss: 55.7275\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 42.3025 - val_loss: 53.2282\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 43.4295 - val_loss: 51.0062\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 40.3749 - val_loss: 52.5653\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 40.3887 - val_loss: 43.7457\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 41.1977 - val_loss: 80.8509\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 39.2364 - val_loss: 40.4921\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 31.5964 - val_loss: 49.3585\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 37.6152 - val_loss: 36.4367\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 31.9138 - val_loss: 37.2343\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 30.0869 - val_loss: 46.3217\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 31.6925 - val_loss: 35.4475\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 33.3201 - val_loss: 58.1806\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 33.4833 - val_loss: 42.7506\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 32.6291 - val_loss: 31.4379\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 27.4883 - val_loss: 42.2287\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 28.6046 - val_loss: 35.0238\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 29.0491 - val_loss: 40.8958\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 27.3094 - val_loss: 30.0041\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 25.2504 - val_loss: 35.3152\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 30.3142 - val_loss: 27.2207\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 25.5638 - val_loss: 28.9299\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 23.5608 - val_loss: 24.8709\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 25.3944 - val_loss: 27.4508\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 22.5768 - val_loss: 32.6519\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 24.3603 - val_loss: 31.4869\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 22.1017 - val_loss: 27.6217\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 25.3156 - val_loss: 43.9365\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 22.5728 - val_loss: 24.2297\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 26.5235 - val_loss: 28.9877\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 22.0289 - val_loss: 24.3243\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 19.3127 - val_loss: 24.5069\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 21.3644 - val_loss: 30.7089\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 22.0999 - val_loss: 27.4062\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 18.6926 - val_loss: 21.3564\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 20.9350 - val_loss: 32.0673\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 23.3725 - val_loss: 29.3998\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 18.1822 - val_loss: 44.3855\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 22.1491 - val_loss: 36.5856\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 19.5997 - val_loss: 41.0510\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 18.3929 - val_loss: 29.9213\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 20.0392 - val_loss: 26.3138\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 17.8273 - val_loss: 23.5384\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 25.0156 - val_loss: 21.6566\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 18.2186 - val_loss: 23.8121\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 17.0448 - val_loss: 19.6620\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 14.6612 - val_loss: 24.6253\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 14.7396 - val_loss: 23.6118\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 24.4064 - val_loss: 25.5756\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 17.9160 - val_loss: 32.3748\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 20.0862 - val_loss: 32.2489\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 17.7618 - val_loss: 22.7410\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 14.2109 - val_loss: 18.4437\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 21.6896 - val_loss: 27.5557\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 17.5186 - val_loss: 20.3412\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 17.8866 - val_loss: 19.3832\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 20.4686 - val_loss: 23.3471\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.4376 - val_loss: 28.9104\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 16.1552 - val_loss: 19.9501\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 14.1872 - val_loss: 18.2199\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 14.4466 - val_loss: 36.3370\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 13.3626 - val_loss: 18.5671\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 21.2500 - val_loss: 21.6840\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.1151 - val_loss: 25.7991\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 15.5140 - val_loss: 23.2380\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 15.1425 - val_loss: 19.2859\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 17.5853 - val_loss: 19.5384\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 14.2790 - val_loss: 16.5089\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 19.0612 - val_loss: 20.4225\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 18.9291 - val_loss: 20.1685\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 11.4774 - val_loss: 17.9545\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 14.4400 - val_loss: 25.1663\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 15.7254 - val_loss: 19.8713\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 17.7184 - val_loss: 18.4029\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 13.7785 - val_loss: 19.2762\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 20.9250 - val_loss: 19.4972\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.6543 - val_loss: 19.7479\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 11.9410 - val_loss: 24.3385\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 12.1643 - val_loss: 30.4383\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.2420 - val_loss: 43.9690\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 14.0594 - val_loss: 19.1954\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 14.3181 - val_loss: 37.9356\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 17.9763 - val_loss: 21.2160\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.7393 - val_loss: 18.6034\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.8830 - val_loss: 18.7872\n",
      "16/16 [==============================] - 1s 10ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 18.787185192030137\n",
      "Mean Absolute Error (MAE): 2.619755984536304\n",
      "Root Mean Squared Error (RMSE): 4.334418668291071\n",
      "Time taken: 1207.950902223587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 48, 512)           1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 48, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_8152\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold        MSE       MAE      RMSE   Time taken\n",
      "0        1  18.606927  2.540505  4.313575  1257.070666\n",
      "1        2  18.075913  2.644722  4.251578  2301.858623\n",
      "2        3  22.774654  2.860556  4.772280  1666.542847\n",
      "3        4  17.714970  2.664672  4.208916  2148.853993\n",
      "4        5  18.787185  2.619756  4.334419  1207.950902\n",
      "5  Average  19.191930  2.666042  4.376153  1716.455406\n",
      "Results saved to 'DL_Result_PL_model_1_Scattered_Reg3.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_1_Scattered_Reg3.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'DL_Result_PL_model_1_Scattered_Reg3.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
