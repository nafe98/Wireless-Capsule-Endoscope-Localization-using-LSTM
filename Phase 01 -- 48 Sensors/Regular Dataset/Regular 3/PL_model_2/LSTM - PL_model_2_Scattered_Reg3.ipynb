{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_2_Scattered_Reg3.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.790990</td>\n",
       "      <td>98.942547</td>\n",
       "      <td>66.852061</td>\n",
       "      <td>78.537710</td>\n",
       "      <td>72.380824</td>\n",
       "      <td>88.951092</td>\n",
       "      <td>90.918692</td>\n",
       "      <td>92.278454</td>\n",
       "      <td>95.010308</td>\n",
       "      <td>91.001789</td>\n",
       "      <td>...</td>\n",
       "      <td>89.761621</td>\n",
       "      <td>74.427330</td>\n",
       "      <td>100.513502</td>\n",
       "      <td>87.217017</td>\n",
       "      <td>80.749395</td>\n",
       "      <td>87.358951</td>\n",
       "      <td>85.650476</td>\n",
       "      <td>80.068792</td>\n",
       "      <td>70.987126</td>\n",
       "      <td>80.521285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.340619</td>\n",
       "      <td>90.423198</td>\n",
       "      <td>87.642409</td>\n",
       "      <td>76.630040</td>\n",
       "      <td>88.921830</td>\n",
       "      <td>97.253265</td>\n",
       "      <td>79.304423</td>\n",
       "      <td>98.406720</td>\n",
       "      <td>97.725501</td>\n",
       "      <td>92.447989</td>\n",
       "      <td>...</td>\n",
       "      <td>79.890950</td>\n",
       "      <td>83.426100</td>\n",
       "      <td>71.982395</td>\n",
       "      <td>77.217953</td>\n",
       "      <td>94.068811</td>\n",
       "      <td>84.359733</td>\n",
       "      <td>80.933342</td>\n",
       "      <td>75.148912</td>\n",
       "      <td>82.359444</td>\n",
       "      <td>90.743983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.585628</td>\n",
       "      <td>90.770939</td>\n",
       "      <td>87.347984</td>\n",
       "      <td>88.109083</td>\n",
       "      <td>89.558906</td>\n",
       "      <td>95.264726</td>\n",
       "      <td>79.142780</td>\n",
       "      <td>94.795926</td>\n",
       "      <td>80.983974</td>\n",
       "      <td>80.981781</td>\n",
       "      <td>...</td>\n",
       "      <td>85.152129</td>\n",
       "      <td>93.026783</td>\n",
       "      <td>100.161187</td>\n",
       "      <td>75.605136</td>\n",
       "      <td>84.857012</td>\n",
       "      <td>98.253237</td>\n",
       "      <td>79.653379</td>\n",
       "      <td>92.539654</td>\n",
       "      <td>102.217921</td>\n",
       "      <td>85.841926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.574467</td>\n",
       "      <td>80.281353</td>\n",
       "      <td>83.429868</td>\n",
       "      <td>94.266988</td>\n",
       "      <td>103.766700</td>\n",
       "      <td>89.221949</td>\n",
       "      <td>88.361743</td>\n",
       "      <td>102.614685</td>\n",
       "      <td>99.713954</td>\n",
       "      <td>93.260670</td>\n",
       "      <td>...</td>\n",
       "      <td>85.325950</td>\n",
       "      <td>80.537477</td>\n",
       "      <td>94.396560</td>\n",
       "      <td>82.269627</td>\n",
       "      <td>82.429383</td>\n",
       "      <td>80.173917</td>\n",
       "      <td>75.793891</td>\n",
       "      <td>101.563571</td>\n",
       "      <td>86.944513</td>\n",
       "      <td>91.575176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.736692</td>\n",
       "      <td>99.069960</td>\n",
       "      <td>78.459327</td>\n",
       "      <td>85.468961</td>\n",
       "      <td>93.727308</td>\n",
       "      <td>87.788715</td>\n",
       "      <td>85.554527</td>\n",
       "      <td>79.567194</td>\n",
       "      <td>86.725867</td>\n",
       "      <td>80.043688</td>\n",
       "      <td>...</td>\n",
       "      <td>68.876022</td>\n",
       "      <td>89.364210</td>\n",
       "      <td>82.782980</td>\n",
       "      <td>90.465916</td>\n",
       "      <td>83.111218</td>\n",
       "      <td>98.746243</td>\n",
       "      <td>89.322503</td>\n",
       "      <td>103.316556</td>\n",
       "      <td>66.082041</td>\n",
       "      <td>74.533889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>97.956169</td>\n",
       "      <td>95.527122</td>\n",
       "      <td>82.599286</td>\n",
       "      <td>81.825403</td>\n",
       "      <td>99.607106</td>\n",
       "      <td>79.993118</td>\n",
       "      <td>101.025214</td>\n",
       "      <td>95.664585</td>\n",
       "      <td>96.039527</td>\n",
       "      <td>89.015385</td>\n",
       "      <td>...</td>\n",
       "      <td>80.149358</td>\n",
       "      <td>102.984487</td>\n",
       "      <td>80.083995</td>\n",
       "      <td>88.586414</td>\n",
       "      <td>91.307511</td>\n",
       "      <td>95.327354</td>\n",
       "      <td>79.514761</td>\n",
       "      <td>75.111528</td>\n",
       "      <td>85.596108</td>\n",
       "      <td>87.116670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>83.530267</td>\n",
       "      <td>99.272592</td>\n",
       "      <td>88.012521</td>\n",
       "      <td>88.214706</td>\n",
       "      <td>93.137435</td>\n",
       "      <td>88.777329</td>\n",
       "      <td>80.989867</td>\n",
       "      <td>90.011529</td>\n",
       "      <td>86.195937</td>\n",
       "      <td>83.045404</td>\n",
       "      <td>...</td>\n",
       "      <td>80.998522</td>\n",
       "      <td>83.406136</td>\n",
       "      <td>80.599574</td>\n",
       "      <td>79.125240</td>\n",
       "      <td>86.045887</td>\n",
       "      <td>71.973222</td>\n",
       "      <td>81.306598</td>\n",
       "      <td>86.631450</td>\n",
       "      <td>70.973688</td>\n",
       "      <td>78.326997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>97.749384</td>\n",
       "      <td>88.461724</td>\n",
       "      <td>81.749940</td>\n",
       "      <td>83.120943</td>\n",
       "      <td>90.872430</td>\n",
       "      <td>90.740286</td>\n",
       "      <td>74.873689</td>\n",
       "      <td>82.490343</td>\n",
       "      <td>91.818896</td>\n",
       "      <td>98.934953</td>\n",
       "      <td>...</td>\n",
       "      <td>97.848848</td>\n",
       "      <td>83.749303</td>\n",
       "      <td>105.613048</td>\n",
       "      <td>67.985040</td>\n",
       "      <td>81.187445</td>\n",
       "      <td>91.825642</td>\n",
       "      <td>84.844603</td>\n",
       "      <td>77.509772</td>\n",
       "      <td>74.625785</td>\n",
       "      <td>88.986403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>91.721041</td>\n",
       "      <td>82.662321</td>\n",
       "      <td>78.148643</td>\n",
       "      <td>97.861113</td>\n",
       "      <td>91.111689</td>\n",
       "      <td>89.193802</td>\n",
       "      <td>92.662224</td>\n",
       "      <td>92.046467</td>\n",
       "      <td>90.960519</td>\n",
       "      <td>78.208066</td>\n",
       "      <td>...</td>\n",
       "      <td>94.036006</td>\n",
       "      <td>85.598085</td>\n",
       "      <td>87.757701</td>\n",
       "      <td>80.216331</td>\n",
       "      <td>98.069703</td>\n",
       "      <td>93.979685</td>\n",
       "      <td>103.198712</td>\n",
       "      <td>88.088120</td>\n",
       "      <td>75.949089</td>\n",
       "      <td>73.258968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>83.996569</td>\n",
       "      <td>82.181851</td>\n",
       "      <td>105.005366</td>\n",
       "      <td>89.794222</td>\n",
       "      <td>90.315036</td>\n",
       "      <td>96.690272</td>\n",
       "      <td>89.378480</td>\n",
       "      <td>96.499707</td>\n",
       "      <td>94.032005</td>\n",
       "      <td>91.797499</td>\n",
       "      <td>...</td>\n",
       "      <td>86.648738</td>\n",
       "      <td>81.697754</td>\n",
       "      <td>88.436257</td>\n",
       "      <td>84.215493</td>\n",
       "      <td>85.823238</td>\n",
       "      <td>82.540064</td>\n",
       "      <td>84.626611</td>\n",
       "      <td>91.986858</td>\n",
       "      <td>86.176124</td>\n",
       "      <td>71.070116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1           2          3           4          5   \\\n",
       "0     84.790990  98.942547   66.852061  78.537710   72.380824  88.951092   \n",
       "1     78.340619  90.423198   87.642409  76.630040   88.921830  97.253265   \n",
       "2     95.585628  90.770939   87.347984  88.109083   89.558906  95.264726   \n",
       "3     79.574467  80.281353   83.429868  94.266988  103.766700  89.221949   \n",
       "4     89.736692  99.069960   78.459327  85.468961   93.727308  87.788715   \n",
       "...         ...        ...         ...        ...         ...        ...   \n",
       "2438  97.956169  95.527122   82.599286  81.825403   99.607106  79.993118   \n",
       "2439  83.530267  99.272592   88.012521  88.214706   93.137435  88.777329   \n",
       "2440  97.749384  88.461724   81.749940  83.120943   90.872430  90.740286   \n",
       "2441  91.721041  82.662321   78.148643  97.861113   91.111689  89.193802   \n",
       "2442  83.996569  82.181851  105.005366  89.794222   90.315036  96.690272   \n",
       "\n",
       "              6           7          8          9   ...         38  \\\n",
       "0      90.918692   92.278454  95.010308  91.001789  ...  89.761621   \n",
       "1      79.304423   98.406720  97.725501  92.447989  ...  79.890950   \n",
       "2      79.142780   94.795926  80.983974  80.981781  ...  85.152129   \n",
       "3      88.361743  102.614685  99.713954  93.260670  ...  85.325950   \n",
       "4      85.554527   79.567194  86.725867  80.043688  ...  68.876022   \n",
       "...          ...         ...        ...        ...  ...        ...   \n",
       "2438  101.025214   95.664585  96.039527  89.015385  ...  80.149358   \n",
       "2439   80.989867   90.011529  86.195937  83.045404  ...  80.998522   \n",
       "2440   74.873689   82.490343  91.818896  98.934953  ...  97.848848   \n",
       "2441   92.662224   92.046467  90.960519  78.208066  ...  94.036006   \n",
       "2442   89.378480   96.499707  94.032005  91.797499  ...  86.648738   \n",
       "\n",
       "              39          40         41         42         43          44  \\\n",
       "0      74.427330  100.513502  87.217017  80.749395  87.358951   85.650476   \n",
       "1      83.426100   71.982395  77.217953  94.068811  84.359733   80.933342   \n",
       "2      93.026783  100.161187  75.605136  84.857012  98.253237   79.653379   \n",
       "3      80.537477   94.396560  82.269627  82.429383  80.173917   75.793891   \n",
       "4      89.364210   82.782980  90.465916  83.111218  98.746243   89.322503   \n",
       "...          ...         ...        ...        ...        ...         ...   \n",
       "2438  102.984487   80.083995  88.586414  91.307511  95.327354   79.514761   \n",
       "2439   83.406136   80.599574  79.125240  86.045887  71.973222   81.306598   \n",
       "2440   83.749303  105.613048  67.985040  81.187445  91.825642   84.844603   \n",
       "2441   85.598085   87.757701  80.216331  98.069703  93.979685  103.198712   \n",
       "2442   81.697754   88.436257  84.215493  85.823238  82.540064   84.626611   \n",
       "\n",
       "              45          46         47  \n",
       "0      80.068792   70.987126  80.521285  \n",
       "1      75.148912   82.359444  90.743983  \n",
       "2      92.539654  102.217921  85.841926  \n",
       "3     101.563571   86.944513  91.575176  \n",
       "4     103.316556   66.082041  74.533889  \n",
       "...          ...         ...        ...  \n",
       "2438   75.111528   85.596108  87.116670  \n",
       "2439   86.631450   70.973688  78.326997  \n",
       "2440   77.509772   74.625785  88.986403  \n",
       "2441   88.088120   75.949089  73.258968  \n",
       "2442   91.986858   86.176124  71.070116  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_Reg2_3.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.968791</td>\n",
       "      <td>60.239368</td>\n",
       "      <td>-105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-75.314716</td>\n",
       "      <td>60.181623</td>\n",
       "      <td>-104.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.653109</td>\n",
       "      <td>60.131806</td>\n",
       "      <td>-104.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.984037</td>\n",
       "      <td>60.089935</td>\n",
       "      <td>-104.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.307567</td>\n",
       "      <td>60.056029</td>\n",
       "      <td>-104.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-99.899763</td>\n",
       "      <td>81.788725</td>\n",
       "      <td>65.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-99.939531</td>\n",
       "      <td>81.389997</td>\n",
       "      <td>65.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-99.969304</td>\n",
       "      <td>80.990713</td>\n",
       "      <td>65.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-99.989081</td>\n",
       "      <td>80.591032</td>\n",
       "      <td>65.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-99.998859</td>\n",
       "      <td>80.191116</td>\n",
       "      <td>65.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1       2\n",
       "0    -75.968791  60.239368 -105.00\n",
       "1    -75.314716  60.181623 -104.93\n",
       "2    -74.653109  60.131806 -104.86\n",
       "3    -73.984037  60.089935 -104.79\n",
       "4    -73.307567  60.056029 -104.72\n",
       "...         ...        ...     ...\n",
       "2438 -99.899763  81.788725   65.66\n",
       "2439 -99.939531  81.389997   65.73\n",
       "2440 -99.969304  80.990713   65.80\n",
       "2441 -99.989081  80.591032   65.87\n",
       "2442 -99.998859  80.191116   65.94\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.790990</td>\n",
       "      <td>98.942547</td>\n",
       "      <td>66.852061</td>\n",
       "      <td>78.537710</td>\n",
       "      <td>72.380824</td>\n",
       "      <td>88.951092</td>\n",
       "      <td>90.918692</td>\n",
       "      <td>92.278454</td>\n",
       "      <td>95.010308</td>\n",
       "      <td>91.001789</td>\n",
       "      <td>...</td>\n",
       "      <td>89.761621</td>\n",
       "      <td>74.427330</td>\n",
       "      <td>100.513502</td>\n",
       "      <td>87.217017</td>\n",
       "      <td>80.749395</td>\n",
       "      <td>87.358951</td>\n",
       "      <td>85.650476</td>\n",
       "      <td>80.068792</td>\n",
       "      <td>70.987126</td>\n",
       "      <td>80.521285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.340619</td>\n",
       "      <td>90.423198</td>\n",
       "      <td>87.642409</td>\n",
       "      <td>76.630040</td>\n",
       "      <td>88.921830</td>\n",
       "      <td>97.253265</td>\n",
       "      <td>79.304423</td>\n",
       "      <td>98.406720</td>\n",
       "      <td>97.725501</td>\n",
       "      <td>92.447989</td>\n",
       "      <td>...</td>\n",
       "      <td>79.890950</td>\n",
       "      <td>83.426100</td>\n",
       "      <td>71.982395</td>\n",
       "      <td>77.217953</td>\n",
       "      <td>94.068811</td>\n",
       "      <td>84.359733</td>\n",
       "      <td>80.933342</td>\n",
       "      <td>75.148912</td>\n",
       "      <td>82.359444</td>\n",
       "      <td>90.743983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.585628</td>\n",
       "      <td>90.770939</td>\n",
       "      <td>87.347984</td>\n",
       "      <td>88.109083</td>\n",
       "      <td>89.558906</td>\n",
       "      <td>95.264726</td>\n",
       "      <td>79.142780</td>\n",
       "      <td>94.795926</td>\n",
       "      <td>80.983974</td>\n",
       "      <td>80.981781</td>\n",
       "      <td>...</td>\n",
       "      <td>85.152129</td>\n",
       "      <td>93.026783</td>\n",
       "      <td>100.161187</td>\n",
       "      <td>75.605136</td>\n",
       "      <td>84.857012</td>\n",
       "      <td>98.253237</td>\n",
       "      <td>79.653379</td>\n",
       "      <td>92.539654</td>\n",
       "      <td>102.217921</td>\n",
       "      <td>85.841926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.574467</td>\n",
       "      <td>80.281353</td>\n",
       "      <td>83.429868</td>\n",
       "      <td>94.266988</td>\n",
       "      <td>103.766700</td>\n",
       "      <td>89.221949</td>\n",
       "      <td>88.361743</td>\n",
       "      <td>102.614685</td>\n",
       "      <td>99.713954</td>\n",
       "      <td>93.260670</td>\n",
       "      <td>...</td>\n",
       "      <td>85.325950</td>\n",
       "      <td>80.537477</td>\n",
       "      <td>94.396560</td>\n",
       "      <td>82.269627</td>\n",
       "      <td>82.429383</td>\n",
       "      <td>80.173917</td>\n",
       "      <td>75.793891</td>\n",
       "      <td>101.563571</td>\n",
       "      <td>86.944513</td>\n",
       "      <td>91.575176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.736692</td>\n",
       "      <td>99.069960</td>\n",
       "      <td>78.459327</td>\n",
       "      <td>85.468961</td>\n",
       "      <td>93.727308</td>\n",
       "      <td>87.788715</td>\n",
       "      <td>85.554527</td>\n",
       "      <td>79.567194</td>\n",
       "      <td>86.725867</td>\n",
       "      <td>80.043688</td>\n",
       "      <td>...</td>\n",
       "      <td>68.876022</td>\n",
       "      <td>89.364210</td>\n",
       "      <td>82.782980</td>\n",
       "      <td>90.465916</td>\n",
       "      <td>83.111218</td>\n",
       "      <td>98.746243</td>\n",
       "      <td>89.322503</td>\n",
       "      <td>103.316556</td>\n",
       "      <td>66.082041</td>\n",
       "      <td>74.533889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>97.956169</td>\n",
       "      <td>95.527122</td>\n",
       "      <td>82.599286</td>\n",
       "      <td>81.825403</td>\n",
       "      <td>99.607106</td>\n",
       "      <td>79.993118</td>\n",
       "      <td>101.025214</td>\n",
       "      <td>95.664585</td>\n",
       "      <td>96.039527</td>\n",
       "      <td>89.015385</td>\n",
       "      <td>...</td>\n",
       "      <td>80.149358</td>\n",
       "      <td>102.984487</td>\n",
       "      <td>80.083995</td>\n",
       "      <td>88.586414</td>\n",
       "      <td>91.307511</td>\n",
       "      <td>95.327354</td>\n",
       "      <td>79.514761</td>\n",
       "      <td>75.111528</td>\n",
       "      <td>85.596108</td>\n",
       "      <td>87.116670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>83.530267</td>\n",
       "      <td>99.272592</td>\n",
       "      <td>88.012521</td>\n",
       "      <td>88.214706</td>\n",
       "      <td>93.137435</td>\n",
       "      <td>88.777329</td>\n",
       "      <td>80.989867</td>\n",
       "      <td>90.011529</td>\n",
       "      <td>86.195937</td>\n",
       "      <td>83.045404</td>\n",
       "      <td>...</td>\n",
       "      <td>80.998522</td>\n",
       "      <td>83.406136</td>\n",
       "      <td>80.599574</td>\n",
       "      <td>79.125240</td>\n",
       "      <td>86.045887</td>\n",
       "      <td>71.973222</td>\n",
       "      <td>81.306598</td>\n",
       "      <td>86.631450</td>\n",
       "      <td>70.973688</td>\n",
       "      <td>78.326997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>97.749384</td>\n",
       "      <td>88.461724</td>\n",
       "      <td>81.749940</td>\n",
       "      <td>83.120943</td>\n",
       "      <td>90.872430</td>\n",
       "      <td>90.740286</td>\n",
       "      <td>74.873689</td>\n",
       "      <td>82.490343</td>\n",
       "      <td>91.818896</td>\n",
       "      <td>98.934953</td>\n",
       "      <td>...</td>\n",
       "      <td>97.848848</td>\n",
       "      <td>83.749303</td>\n",
       "      <td>105.613048</td>\n",
       "      <td>67.985040</td>\n",
       "      <td>81.187445</td>\n",
       "      <td>91.825642</td>\n",
       "      <td>84.844603</td>\n",
       "      <td>77.509772</td>\n",
       "      <td>74.625785</td>\n",
       "      <td>88.986403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>91.721041</td>\n",
       "      <td>82.662321</td>\n",
       "      <td>78.148643</td>\n",
       "      <td>97.861113</td>\n",
       "      <td>91.111689</td>\n",
       "      <td>89.193802</td>\n",
       "      <td>92.662224</td>\n",
       "      <td>92.046467</td>\n",
       "      <td>90.960519</td>\n",
       "      <td>78.208066</td>\n",
       "      <td>...</td>\n",
       "      <td>94.036006</td>\n",
       "      <td>85.598085</td>\n",
       "      <td>87.757701</td>\n",
       "      <td>80.216331</td>\n",
       "      <td>98.069703</td>\n",
       "      <td>93.979685</td>\n",
       "      <td>103.198712</td>\n",
       "      <td>88.088120</td>\n",
       "      <td>75.949089</td>\n",
       "      <td>73.258968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>83.996569</td>\n",
       "      <td>82.181851</td>\n",
       "      <td>105.005366</td>\n",
       "      <td>89.794222</td>\n",
       "      <td>90.315036</td>\n",
       "      <td>96.690272</td>\n",
       "      <td>89.378480</td>\n",
       "      <td>96.499707</td>\n",
       "      <td>94.032005</td>\n",
       "      <td>91.797499</td>\n",
       "      <td>...</td>\n",
       "      <td>86.648738</td>\n",
       "      <td>81.697754</td>\n",
       "      <td>88.436257</td>\n",
       "      <td>84.215493</td>\n",
       "      <td>85.823238</td>\n",
       "      <td>82.540064</td>\n",
       "      <td>84.626611</td>\n",
       "      <td>91.986858</td>\n",
       "      <td>86.176124</td>\n",
       "      <td>71.070116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor1    sensor2     sensor3    sensor4     sensor5    sensor6  \\\n",
       "0     84.790990  98.942547   66.852061  78.537710   72.380824  88.951092   \n",
       "1     78.340619  90.423198   87.642409  76.630040   88.921830  97.253265   \n",
       "2     95.585628  90.770939   87.347984  88.109083   89.558906  95.264726   \n",
       "3     79.574467  80.281353   83.429868  94.266988  103.766700  89.221949   \n",
       "4     89.736692  99.069960   78.459327  85.468961   93.727308  87.788715   \n",
       "...         ...        ...         ...        ...         ...        ...   \n",
       "2438  97.956169  95.527122   82.599286  81.825403   99.607106  79.993118   \n",
       "2439  83.530267  99.272592   88.012521  88.214706   93.137435  88.777329   \n",
       "2440  97.749384  88.461724   81.749940  83.120943   90.872430  90.740286   \n",
       "2441  91.721041  82.662321   78.148643  97.861113   91.111689  89.193802   \n",
       "2442  83.996569  82.181851  105.005366  89.794222   90.315036  96.690272   \n",
       "\n",
       "         sensor7     sensor8    sensor9   sensor10  ...   sensor39  \\\n",
       "0      90.918692   92.278454  95.010308  91.001789  ...  89.761621   \n",
       "1      79.304423   98.406720  97.725501  92.447989  ...  79.890950   \n",
       "2      79.142780   94.795926  80.983974  80.981781  ...  85.152129   \n",
       "3      88.361743  102.614685  99.713954  93.260670  ...  85.325950   \n",
       "4      85.554527   79.567194  86.725867  80.043688  ...  68.876022   \n",
       "...          ...         ...        ...        ...  ...        ...   \n",
       "2438  101.025214   95.664585  96.039527  89.015385  ...  80.149358   \n",
       "2439   80.989867   90.011529  86.195937  83.045404  ...  80.998522   \n",
       "2440   74.873689   82.490343  91.818896  98.934953  ...  97.848848   \n",
       "2441   92.662224   92.046467  90.960519  78.208066  ...  94.036006   \n",
       "2442   89.378480   96.499707  94.032005  91.797499  ...  86.648738   \n",
       "\n",
       "        sensor40    sensor41   sensor42   sensor43   sensor44    sensor45  \\\n",
       "0      74.427330  100.513502  87.217017  80.749395  87.358951   85.650476   \n",
       "1      83.426100   71.982395  77.217953  94.068811  84.359733   80.933342   \n",
       "2      93.026783  100.161187  75.605136  84.857012  98.253237   79.653379   \n",
       "3      80.537477   94.396560  82.269627  82.429383  80.173917   75.793891   \n",
       "4      89.364210   82.782980  90.465916  83.111218  98.746243   89.322503   \n",
       "...          ...         ...        ...        ...        ...         ...   \n",
       "2438  102.984487   80.083995  88.586414  91.307511  95.327354   79.514761   \n",
       "2439   83.406136   80.599574  79.125240  86.045887  71.973222   81.306598   \n",
       "2440   83.749303  105.613048  67.985040  81.187445  91.825642   84.844603   \n",
       "2441   85.598085   87.757701  80.216331  98.069703  93.979685  103.198712   \n",
       "2442   81.697754   88.436257  84.215493  85.823238  82.540064   84.626611   \n",
       "\n",
       "        sensor46    sensor47   sensor48  \n",
       "0      80.068792   70.987126  80.521285  \n",
       "1      75.148912   82.359444  90.743983  \n",
       "2      92.539654  102.217921  85.841926  \n",
       "3     101.563571   86.944513  91.575176  \n",
       "4     103.316556   66.082041  74.533889  \n",
       "...          ...         ...        ...  \n",
       "2438   75.111528   85.596108  87.116670  \n",
       "2439   86.631450   70.973688  78.326997  \n",
       "2440   77.509772   74.625785  88.986403  \n",
       "2441   88.088120   75.949089  73.258968  \n",
       "2442   91.986858   86.176124  71.070116  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.968791</td>\n",
       "      <td>60.239368</td>\n",
       "      <td>-105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-75.314716</td>\n",
       "      <td>60.181623</td>\n",
       "      <td>-104.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.653109</td>\n",
       "      <td>60.131806</td>\n",
       "      <td>-104.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.984037</td>\n",
       "      <td>60.089935</td>\n",
       "      <td>-104.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.307567</td>\n",
       "      <td>60.056029</td>\n",
       "      <td>-104.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-99.899763</td>\n",
       "      <td>81.788725</td>\n",
       "      <td>65.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-99.939531</td>\n",
       "      <td>81.389997</td>\n",
       "      <td>65.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-99.969304</td>\n",
       "      <td>80.990713</td>\n",
       "      <td>65.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-99.989081</td>\n",
       "      <td>80.591032</td>\n",
       "      <td>65.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-99.998859</td>\n",
       "      <td>80.191116</td>\n",
       "      <td>65.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y   Pos Z\n",
       "0    -75.968791  60.239368 -105.00\n",
       "1    -75.314716  60.181623 -104.93\n",
       "2    -74.653109  60.131806 -104.86\n",
       "3    -73.984037  60.089935 -104.79\n",
       "4    -73.307567  60.056029 -104.72\n",
       "...         ...        ...     ...\n",
       "2438 -99.899763  81.788725   65.66\n",
       "2439 -99.939531  81.389997   65.73\n",
       "2440 -99.969304  80.990713   65.80\n",
       "2441 -99.989081  80.591032   65.87\n",
       "2442 -99.998859  80.191116   65.94\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 18s 20ms/step - loss: 4021.6602 - val_loss: 3920.1301\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3695.2437 - val_loss: 3692.8047\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3493.4624 - val_loss: 3499.8909\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 3321.0315 - val_loss: 3335.6992\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 3174.3220 - val_loss: 3194.6775\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3048.0928 - val_loss: 3073.1780\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2940.0483 - val_loss: 2968.9460\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2848.0647 - val_loss: 2880.1897\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2770.2529 - val_loss: 2805.3047\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2705.1270 - val_loss: 2742.6863\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2651.6980 - val_loss: 2691.4436\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2608.6648 - val_loss: 2650.0840\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 2575.0017 - val_loss: 2618.1436\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2549.4910 - val_loss: 2594.0234\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2531.1079 - val_loss: 2576.4900\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2518.5640 - val_loss: 2564.4111\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2510.5359 - val_loss: 2556.7261\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2505.7166 - val_loss: 2552.0908\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.1858 - val_loss: 2549.3462\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.9819 - val_loss: 2547.8608\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.4739 - val_loss: 2547.1370\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2507 - val_loss: 2546.7510\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2104 - val_loss: 2546.5168\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2202 - val_loss: 2546.4099\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1865 - val_loss: 2546.3110\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1877 - val_loss: 2546.2375\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.1741 - val_loss: 2546.2090\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1919 - val_loss: 2546.2136\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2605 - val_loss: 2546.2627\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2180 - val_loss: 2546.2075\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2571 - val_loss: 2546.1033\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1670 - val_loss: 2546.0605\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2501.1992 - val_loss: 2546.1931\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2283 - val_loss: 2546.1160\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1868 - val_loss: 2546.1882\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1912 - val_loss: 2546.0186\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1538 - val_loss: 2546.1096\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2622 - val_loss: 2546.1365\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2501.1946 - val_loss: 2546.2158\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2190 - val_loss: 2546.3296\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2002 - val_loss: 2546.2803\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1738 - val_loss: 2546.2244\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1680 - val_loss: 2546.1523\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2501.1807 - val_loss: 2546.2219\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2131 - val_loss: 2546.2454\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2524 - val_loss: 2546.2788\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1848 - val_loss: 2546.2173\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2339 - val_loss: 2546.2356\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2639 - val_loss: 2546.1316\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2000 - val_loss: 2546.1843\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2014 - val_loss: 2546.2727\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1987 - val_loss: 2546.2324\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1826 - val_loss: 2546.1382\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2646 - val_loss: 2546.1689\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2051 - val_loss: 2546.2212\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2332 - val_loss: 2546.2136\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2603 - val_loss: 2546.2336\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2246 - val_loss: 2546.1172\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2114 - val_loss: 2546.2275\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1858 - val_loss: 2546.0620\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1313 - val_loss: 2546.1560\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2073 - val_loss: 2546.2366\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.1853 - val_loss: 2546.2268\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2854 - val_loss: 2546.1799\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1948 - val_loss: 2546.2046\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2501.2405 - val_loss: 2546.1240\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.2249 - val_loss: 2546.1978\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2197 - val_loss: 2546.2576\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2649 - val_loss: 2546.2886\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2451 - val_loss: 2546.2178\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1819 - val_loss: 2546.1328\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1594 - val_loss: 2546.1252\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.2324 - val_loss: 2546.2705\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.2046 - val_loss: 2546.1809\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2505 - val_loss: 2546.1001\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2617 - val_loss: 2546.2185\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1987 - val_loss: 2546.2410\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2053 - val_loss: 2546.2292\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1289 - val_loss: 2546.2590\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2134 - val_loss: 2546.2600\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2446 - val_loss: 2546.3264\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1812 - val_loss: 2546.2791\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1406 - val_loss: 2546.3538\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2501.1997 - val_loss: 2546.3555\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1628 - val_loss: 2546.2786\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1814 - val_loss: 2546.2043\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1809 - val_loss: 2546.2117\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1882 - val_loss: 2546.1663\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2280 - val_loss: 2546.2053\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1558 - val_loss: 2546.2012\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1870 - val_loss: 2546.2559\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1860 - val_loss: 2546.2585\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1899 - val_loss: 2546.1807\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2366 - val_loss: 2546.2109\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1577 - val_loss: 2546.2087\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2346 - val_loss: 2546.1704\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2117 - val_loss: 2546.2068\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2117 - val_loss: 2546.1208\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1868 - val_loss: 2546.1497\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2222 - val_loss: 2546.1697\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2456 - val_loss: 2546.2830\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2322 - val_loss: 2546.1633\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2004 - val_loss: 2546.0154\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2501.1746 - val_loss: 2546.1121\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2144 - val_loss: 2546.1365\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2175 - val_loss: 2546.1807\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1982 - val_loss: 2546.1672\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2012 - val_loss: 2546.1211\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2144 - val_loss: 2546.1882\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1543 - val_loss: 2546.2375\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2273 - val_loss: 2546.1013\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2556 - val_loss: 2546.2295\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1692 - val_loss: 2546.1082\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1970 - val_loss: 2546.1741\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1777 - val_loss: 2546.2148\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2991 - val_loss: 2546.1982\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1975 - val_loss: 2546.1516\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1851 - val_loss: 2546.1306\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1760 - val_loss: 2546.1995\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.2385 - val_loss: 2546.1816\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.2114 - val_loss: 2546.1819\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1770 - val_loss: 2546.2083\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.1636 - val_loss: 2546.2197\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.2466 - val_loss: 2546.1558\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2501.2529 - val_loss: 2546.2405\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.1614 - val_loss: 2546.1238\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2501.1726 - val_loss: 2546.1714\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2501.1890 - val_loss: 2546.2163\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.2637 - val_loss: 2546.2566\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2131 - val_loss: 2546.2703\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1270 - val_loss: 2546.2976\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.2053 - val_loss: 2546.1870\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.2297 - val_loss: 2546.1389\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1760 - val_loss: 2546.1824\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1646 - val_loss: 2546.0815\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.2773 - val_loss: 2546.0872\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1794 - val_loss: 2546.1516\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2429 - val_loss: 2546.0940\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.1777 - val_loss: 2546.1848\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.1558 - val_loss: 2546.2002\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.1797 - val_loss: 2546.2590\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1777 - val_loss: 2546.2180\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2501.1831 - val_loss: 2546.1409\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1946 - val_loss: 2546.2598\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.1748 - val_loss: 2546.2644\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.1814 - val_loss: 2546.2141\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2501.1792 - val_loss: 2546.2285\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2158 - val_loss: 2546.2507\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2078 - val_loss: 2546.2402\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1711 - val_loss: 2546.2808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2266 - val_loss: 2546.2317\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2501.1460 - val_loss: 2546.2400\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1802 - val_loss: 2546.0557\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2046 - val_loss: 2546.0898\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2441 - val_loss: 2546.0139\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2878 - val_loss: 2546.0708\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2501.2107 - val_loss: 2546.1125\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.2131 - val_loss: 2546.1177\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.2227 - val_loss: 2546.1101\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1973 - val_loss: 2546.1262\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2501.2297 - val_loss: 2546.2026\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2432 - val_loss: 2546.2136\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1670 - val_loss: 2546.1743\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2615 - val_loss: 2546.1467\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2192 - val_loss: 2546.1890\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2039 - val_loss: 2546.2451\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1978 - val_loss: 2546.2273\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2100 - val_loss: 2546.2339\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1541 - val_loss: 2546.1460\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1904 - val_loss: 2546.2314\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1699 - val_loss: 2546.2209\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2588 - val_loss: 2546.1191\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2212 - val_loss: 2546.2463\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1443 - val_loss: 2546.3081\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1577 - val_loss: 2546.3020\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2146 - val_loss: 2546.2300\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1511 - val_loss: 2546.1917\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1917 - val_loss: 2546.2188\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1709 - val_loss: 2546.2227\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1880 - val_loss: 2546.2222\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2378 - val_loss: 2546.1436\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2024 - val_loss: 2546.2737\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2501.2180 - val_loss: 2546.1873\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2456 - val_loss: 2546.1802\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1812 - val_loss: 2546.2190\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2446 - val_loss: 2546.1624\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1792 - val_loss: 2546.1499\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2188 - val_loss: 2546.1572\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2046 - val_loss: 2546.2561\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1880 - val_loss: 2546.1704\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2290 - val_loss: 2546.2366\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2501.2358 - val_loss: 2546.2075\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2026 - val_loss: 2546.2195\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1956 - val_loss: 2546.1230\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.1799 - val_loss: 2546.1140\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.2046 - val_loss: 2546.1289\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.1907 - val_loss: 2546.0466\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2075 - val_loss: 2546.1565\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2278 - val_loss: 2546.1257\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2501.2305 - val_loss: 2545.9775\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 2545.977964238217\n",
      "Mean Absolute Error (MAE): 40.201286203374224\n",
      "Root Mean Squared Error (RMSE): 50.45768488781681\n",
      "Time taken: 1255.6512818336487\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 19ms/step - loss: 4029.3079 - val_loss: 3791.0554\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3714.1248 - val_loss: 3569.0415\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3513.7622 - val_loss: 3382.2754\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3341.6604 - val_loss: 3221.7688\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3194.9141 - val_loss: 3084.6257\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3069.2410 - val_loss: 2967.1172\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2961.2412 - val_loss: 2866.1848\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2868.8586 - val_loss: 2780.1995\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2790.8169 - val_loss: 2707.6460\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2725.5837 - val_loss: 2647.9929\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2672.0911 - val_loss: 2599.0059\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2628.9570 - val_loss: 2560.4238\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2595.1460 - val_loss: 2530.3057\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2569.5820 - val_loss: 2508.0193\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 2550.9783 - val_loss: 2492.2026\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 2538.4346 - val_loss: 2481.6340\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2530.3623 - val_loss: 2475.1484\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2525.4507 - val_loss: 2471.3889\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2522.9480 - val_loss: 2469.5176\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2521.7212 - val_loss: 2468.5945\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2521.1787 - val_loss: 2468.1045\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.9805 - val_loss: 2468.0620\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8564 - val_loss: 2467.8855\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8594 - val_loss: 2467.8103\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8274 - val_loss: 2467.8953\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8228 - val_loss: 2467.7212\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8110 - val_loss: 2467.8372\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8032 - val_loss: 2467.8237\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8572 - val_loss: 2467.7791\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8584 - val_loss: 2467.8948\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8535 - val_loss: 2467.7722\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8267 - val_loss: 2467.8650\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8809 - val_loss: 2467.8022\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8562 - val_loss: 2467.8853\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.7998 - val_loss: 2467.8281\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8916 - val_loss: 2467.8386\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8149 - val_loss: 2467.8408\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8257 - val_loss: 2467.7644\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8103 - val_loss: 2467.7786\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8718 - val_loss: 2467.6235\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2520.8423 - val_loss: 2467.6619\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8684 - val_loss: 2467.7437\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8528 - val_loss: 2467.7024\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8140 - val_loss: 2467.6643\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8196 - val_loss: 2467.7393\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8086 - val_loss: 2467.6289\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8416 - val_loss: 2467.7524\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8533 - val_loss: 2467.6472\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8142 - val_loss: 2467.6780\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8694 - val_loss: 2467.7229\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8706 - val_loss: 2467.7432\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8337 - val_loss: 2467.6235\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8086 - val_loss: 2467.6770\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8135 - val_loss: 2467.7727\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8428 - val_loss: 2467.7441\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.7822 - val_loss: 2467.6431\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2520.7932 - val_loss: 2467.7432\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8716 - val_loss: 2467.7351\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8467 - val_loss: 2467.7190\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8914 - val_loss: 2467.7622\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8198 - val_loss: 2467.7644\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8611 - val_loss: 2467.7959\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8726 - val_loss: 2467.8542\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8513 - val_loss: 2467.8350\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.7927 - val_loss: 2467.8154\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.7949 - val_loss: 2467.8630\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8003 - val_loss: 2467.7480\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8193 - val_loss: 2467.7346\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.9131 - val_loss: 2467.7671\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8792 - val_loss: 2467.7195\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.7642 - val_loss: 2467.7651\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8384 - val_loss: 2467.8101\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8191 - val_loss: 2467.7825\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8386 - val_loss: 2467.8755\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8140 - val_loss: 2467.7429\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.7866 - val_loss: 2467.7297\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8281 - val_loss: 2467.7139\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.7908 - val_loss: 2467.7749\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8594 - val_loss: 2467.8477\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8101 - val_loss: 2467.7942\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8633 - val_loss: 2467.8354\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8557 - val_loss: 2467.7468\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8525 - val_loss: 2467.7761\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8662 - val_loss: 2467.6702\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.7935 - val_loss: 2467.7188\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8284 - val_loss: 2467.7351\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8018 - val_loss: 2467.7498\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8105 - val_loss: 2467.7454\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.7937 - val_loss: 2467.7341\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8320 - val_loss: 2467.7114\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8369 - val_loss: 2467.7244\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.7852 - val_loss: 2467.6912\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8875 - val_loss: 2467.6357\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8240 - val_loss: 2467.7300\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8398 - val_loss: 2467.6589\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8572 - val_loss: 2467.7383\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8315 - val_loss: 2467.6589\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8408 - val_loss: 2467.7554\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.7812 - val_loss: 2467.7773\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.7874 - val_loss: 2467.7783\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8706 - val_loss: 2467.7322\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8289 - val_loss: 2467.7444\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8013 - val_loss: 2467.7544\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8853 - val_loss: 2467.6787\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8171 - val_loss: 2467.6465\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8542 - val_loss: 2467.7947\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8220 - val_loss: 2467.7891\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8628 - val_loss: 2467.7849\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.7830 - val_loss: 2467.7932\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8413 - val_loss: 2467.6521\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8669 - val_loss: 2467.7625\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.9148 - val_loss: 2467.8105\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.9314 - val_loss: 2467.7437\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8599 - val_loss: 2467.8462\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8115 - val_loss: 2467.7451\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8267 - val_loss: 2467.7778\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.7974 - val_loss: 2467.7119\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.7878 - val_loss: 2467.6824\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.9111 - val_loss: 2467.7773\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8799 - val_loss: 2467.7170\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8225 - val_loss: 2467.6370\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8220 - val_loss: 2467.6609\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8433 - val_loss: 2467.6572\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.7976 - val_loss: 2467.6541\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8347 - val_loss: 2467.6360\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8630 - val_loss: 2467.6934\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8176 - val_loss: 2467.5908\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.7927 - val_loss: 2467.7334\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8660 - val_loss: 2467.6401\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8337 - val_loss: 2467.6997\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8281 - val_loss: 2467.6350\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2520.8491 - val_loss: 2467.6643\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8682 - val_loss: 2467.6519\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2520.8503 - val_loss: 2467.6680\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2520.8252 - val_loss: 2467.6829\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2520.8564 - val_loss: 2467.7607\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2520.8542 - val_loss: 2467.8149\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8240 - val_loss: 2467.7131\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8254 - val_loss: 2467.8386\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8481 - val_loss: 2467.7407\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8506 - val_loss: 2467.8154\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8582 - val_loss: 2467.7788\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.9050 - val_loss: 2467.8843\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8315 - val_loss: 2467.8193\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8174 - val_loss: 2467.8481\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8413 - val_loss: 2467.8518\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8079 - val_loss: 2467.8242\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8354 - val_loss: 2467.8091\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8555 - val_loss: 2467.8118\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8748 - val_loss: 2467.7476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8044 - val_loss: 2467.7505\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8262 - val_loss: 2467.8782\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2520.8882 - val_loss: 2467.8567\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2520.7886 - val_loss: 2467.8311\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8293 - val_loss: 2467.8516\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8123 - val_loss: 2467.7913\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.8232 - val_loss: 2467.8684\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8167 - val_loss: 2467.7996\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8550 - val_loss: 2467.6978\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8340 - val_loss: 2467.7617\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8389 - val_loss: 2467.7610\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8826 - val_loss: 2467.7786\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8630 - val_loss: 2467.8108\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8547 - val_loss: 2467.7466\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8779 - val_loss: 2467.7173\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8352 - val_loss: 2467.7495\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8721 - val_loss: 2467.7920\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8228 - val_loss: 2467.7131\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8323 - val_loss: 2467.8032\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.9155 - val_loss: 2467.7612\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8467 - val_loss: 2467.7578\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8242 - val_loss: 2467.6714\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8347 - val_loss: 2467.7229\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8220 - val_loss: 2467.8022\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8586 - val_loss: 2467.7898\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8828 - val_loss: 2467.7466\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8413 - val_loss: 2467.8628\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8354 - val_loss: 2467.7251\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8706 - val_loss: 2467.7490\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2520.7717 - val_loss: 2467.7500\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.7744 - val_loss: 2467.7126\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8279 - val_loss: 2467.6982\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8340 - val_loss: 2467.6819\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8203 - val_loss: 2467.6499\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8083 - val_loss: 2467.6858\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8452 - val_loss: 2467.7393\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8821 - val_loss: 2467.6987\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.7915 - val_loss: 2467.6877\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8589 - val_loss: 2467.6917\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8418 - val_loss: 2467.6313\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8457 - val_loss: 2467.6797\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8467 - val_loss: 2467.7495\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2520.8252 - val_loss: 2467.7666\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8030 - val_loss: 2467.6760\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8501 - val_loss: 2467.8003\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.9065 - val_loss: 2467.6565\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.8225 - val_loss: 2467.7368\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2520.8230 - val_loss: 2467.7625\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2520.8186 - val_loss: 2467.6558\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.7944 - val_loss: 2467.8169\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 2467.8170058930386\n",
      "Mean Absolute Error (MAE): 38.76351483657107\n",
      "Root Mean Squared Error (RMSE): 49.67712759301848\n",
      "Time taken: 1246.5936291217804\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 4101.2310 - val_loss: 3856.6790\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3777.2844 - val_loss: 3634.5312\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3569.9097 - val_loss: 3451.5713\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3394.1428 - val_loss: 3294.6079\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3241.9690 - val_loss: 3158.2200\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3109.9478 - val_loss: 3040.6050\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2995.7056 - val_loss: 2939.1636\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2897.2986 - val_loss: 2852.7117\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2813.2292 - val_loss: 2779.4067\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2742.0544 - val_loss: 2718.1458\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2682.8555 - val_loss: 2668.3406\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2634.3948 - val_loss: 2628.4092\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2595.6477 - val_loss: 2597.3369\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2565.6753 - val_loss: 2574.2129\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2543.3132 - val_loss: 2557.9792\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2527.5127 - val_loss: 2547.2756\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.0969 - val_loss: 2541.0369\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2510.5925 - val_loss: 2537.6851\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2506.8579 - val_loss: 2536.3833\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2504.9873 - val_loss: 2536.0879\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2504.1411 - val_loss: 2536.0369\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.7488 - val_loss: 2536.3799\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6152 - val_loss: 2536.5488\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5527 - val_loss: 2536.6235\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5867 - val_loss: 2536.6465\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2503.5784 - val_loss: 2536.6851\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5713 - val_loss: 2536.7754\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2503.5615 - val_loss: 2536.9243\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5671 - val_loss: 2536.8796\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5208 - val_loss: 2536.8496\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5652 - val_loss: 2536.7747\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5725 - val_loss: 2536.9949\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2503.5481 - val_loss: 2536.8992\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6267 - val_loss: 2536.9214\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6309 - val_loss: 2536.9109\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5605 - val_loss: 2536.8413\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5598 - val_loss: 2536.9280\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5862 - val_loss: 2536.8499\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6609 - val_loss: 2536.7583\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5779 - val_loss: 2536.9565\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2503.5542 - val_loss: 2536.9033\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5510 - val_loss: 2537.0400\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5811 - val_loss: 2537.0781\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5764 - val_loss: 2537.0278\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.6077 - val_loss: 2536.8643\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5625 - val_loss: 2537.0020\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5078 - val_loss: 2536.9978\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.5645 - val_loss: 2537.0039\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.6211 - val_loss: 2536.9612\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5945 - val_loss: 2536.7905\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5957 - val_loss: 2536.7800\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5642 - val_loss: 2536.8486\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 2503.5969 - val_loss: 2536.8599\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.5884 - val_loss: 2536.8765\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5830 - val_loss: 2536.7971\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.5620 - val_loss: 2536.8918\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5891 - val_loss: 2536.9446\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5630 - val_loss: 2536.8323\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5491 - val_loss: 2536.9854\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5850 - val_loss: 2536.9021\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5806 - val_loss: 2537.0154\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2503.4946 - val_loss: 2536.9609\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.6147 - val_loss: 2537.0039\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.5635 - val_loss: 2537.0806\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5532 - val_loss: 2537.0547\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5144 - val_loss: 2536.8630\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5371 - val_loss: 2536.9568\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2503.5210 - val_loss: 2536.9829\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5911 - val_loss: 2537.0549\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.6167 - val_loss: 2537.1411\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5425 - val_loss: 2536.9451\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5750 - val_loss: 2537.0491\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5432 - val_loss: 2536.9900\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5828 - val_loss: 2536.9563\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5562 - val_loss: 2537.0930\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5669 - val_loss: 2537.0415\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5596 - val_loss: 2537.0674\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5469 - val_loss: 2536.9915\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5679 - val_loss: 2536.9690\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5759 - val_loss: 2536.7981\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5271 - val_loss: 2536.9246\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5291 - val_loss: 2536.9216\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 2503.5828 - val_loss: 2537.0662\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.6008 - val_loss: 2537.0830\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 2503.6489 - val_loss: 2537.0867\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 2503.5828 - val_loss: 2537.0793\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.5352 - val_loss: 2537.0293\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5415 - val_loss: 2536.9426\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5564 - val_loss: 2537.0588\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5542 - val_loss: 2536.9761\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.6145 - val_loss: 2536.9126\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5974 - val_loss: 2536.7632\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5420 - val_loss: 2536.8638\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5896 - val_loss: 2537.0732\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.6104 - val_loss: 2536.9788\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 2503.5596 - val_loss: 2536.9458\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5747 - val_loss: 2536.9807\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5532 - val_loss: 2536.9673\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5535 - val_loss: 2537.1787\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.6145 - val_loss: 2537.0073\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5476 - val_loss: 2536.9065\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6187 - val_loss: 2536.9897\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5889 - val_loss: 2536.9761\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 2503.5535 - val_loss: 2536.9233\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.6021 - val_loss: 2536.9663\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5510 - val_loss: 2536.9778\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.6184 - val_loss: 2536.9941\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5793 - val_loss: 2536.8513\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6077 - val_loss: 2536.9292\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5676 - val_loss: 2536.9214\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 2503.5579 - val_loss: 2536.9358\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5659 - val_loss: 2536.9905\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5417 - val_loss: 2536.9778\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5652 - val_loss: 2536.9148\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5413 - val_loss: 2537.0303\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5898 - val_loss: 2537.0205\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.4998 - val_loss: 2536.9536\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5632 - val_loss: 2537.0300\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2503.5256 - val_loss: 2537.0005\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.6106 - val_loss: 2536.8955\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6121 - val_loss: 2536.9456\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5496 - val_loss: 2536.9133\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5066 - val_loss: 2536.9958\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5959 - val_loss: 2537.0464\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5708 - val_loss: 2536.9556\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5698 - val_loss: 2536.8481\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6943 - val_loss: 2537.0061\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5408 - val_loss: 2537.0364\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5828 - val_loss: 2537.1396\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5981 - val_loss: 2536.9236\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5835 - val_loss: 2537.0000\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6245 - val_loss: 2536.8875\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5764 - val_loss: 2537.1150\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5369 - val_loss: 2536.9253\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.6277 - val_loss: 2537.0264\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5439 - val_loss: 2537.0659\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5781 - val_loss: 2536.9724\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5439 - val_loss: 2536.8738\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5430 - val_loss: 2536.8857\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5676 - val_loss: 2536.9854\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5916 - val_loss: 2537.0645\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5100 - val_loss: 2537.0146\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5425 - val_loss: 2537.0178\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5769 - val_loss: 2536.8552\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5925 - val_loss: 2536.9519\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5339 - val_loss: 2537.0020\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5469 - val_loss: 2536.8970\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5601 - val_loss: 2536.8936\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5994 - val_loss: 2536.8513\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5903 - val_loss: 2536.9678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5542 - val_loss: 2537.0471\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6018 - val_loss: 2537.0652\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5439 - val_loss: 2536.9102\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5884 - val_loss: 2536.9712\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5527 - val_loss: 2536.9797\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6270 - val_loss: 2536.9548\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5955 - val_loss: 2537.0125\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5732 - val_loss: 2536.9180\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5811 - val_loss: 2536.9597\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5354 - val_loss: 2536.9885\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5459 - val_loss: 2536.9819\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6052 - val_loss: 2536.9285\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5820 - val_loss: 2537.0815\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5486 - val_loss: 2537.0518\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5979 - val_loss: 2536.9441\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5527 - val_loss: 2537.0061\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6414 - val_loss: 2536.9221\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5171 - val_loss: 2537.0593\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5671 - val_loss: 2537.0320\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5547 - val_loss: 2536.9873\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5894 - val_loss: 2537.0383\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5386 - val_loss: 2537.1533\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5476 - val_loss: 2536.9199\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5488 - val_loss: 2537.1025\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6016 - val_loss: 2537.0383\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5610 - val_loss: 2537.0422\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2503.5820 - val_loss: 2537.0535\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2503.5286 - val_loss: 2537.0500\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.6252 - val_loss: 2537.0979\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6719 - val_loss: 2537.0171\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5286 - val_loss: 2537.0664\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5862 - val_loss: 2537.0613\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5903 - val_loss: 2537.1138\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.4961 - val_loss: 2537.0352\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5891 - val_loss: 2537.0049\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5232 - val_loss: 2537.0042\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5654 - val_loss: 2537.0542\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5781 - val_loss: 2537.0005\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.5642 - val_loss: 2536.9963\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6184 - val_loss: 2537.0061\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5676 - val_loss: 2537.0264\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5630 - val_loss: 2536.9922\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6011 - val_loss: 2537.0212\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6030 - val_loss: 2537.1670\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5686 - val_loss: 2537.0183\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5459 - val_loss: 2537.1382\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5747 - val_loss: 2536.9578\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.6233 - val_loss: 2537.1558\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5510 - val_loss: 2536.8716\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2503.5496 - val_loss: 2537.0256\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 2537.0252272546636\n",
      "Mean Absolute Error (MAE): 39.80292594638258\n",
      "Root Mean Squared Error (RMSE): 50.36889146342873\n",
      "Time taken: 1294.2195870876312\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 17ms/step - loss: 4029.6033 - val_loss: 3885.7070\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3712.2271 - val_loss: 3662.5532\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3509.3469 - val_loss: 3478.2644\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3338.7791 - val_loss: 3320.7341\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 3191.9966 - val_loss: 3184.2397\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3065.2043 - val_loss: 3067.0571\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2955.9856 - val_loss: 2966.0396\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2862.2222 - val_loss: 2879.5852\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2782.4646 - val_loss: 2806.5623\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2715.3250 - val_loss: 2745.6133\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2659.6628 - val_loss: 2695.6765\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2614.8081 - val_loss: 2655.8647\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2579.2190 - val_loss: 2624.8843\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2552.0464 - val_loss: 2601.5588\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.0125 - val_loss: 2585.0291\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2518.0669 - val_loss: 2573.8276\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2508.9067 - val_loss: 2566.7817\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2503.4309 - val_loss: 2562.8916\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2500.3440 - val_loss: 2560.7417\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2498.8108 - val_loss: 2559.8079\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2498.2251 - val_loss: 2559.4075\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.9739 - val_loss: 2559.2913\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8425 - val_loss: 2559.2827\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.9099 - val_loss: 2559.2742\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8220 - val_loss: 2559.2827\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8496 - val_loss: 2559.2397\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8250 - val_loss: 2559.2847\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8594 - val_loss: 2559.2852\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8113 - val_loss: 2559.2771\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8054 - val_loss: 2559.2869\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8220 - val_loss: 2559.2961\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7981 - val_loss: 2559.2749\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.7759 - val_loss: 2559.3054\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8291 - val_loss: 2559.2856\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8230 - val_loss: 2559.3413\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8357 - val_loss: 2559.2947\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7925 - val_loss: 2559.3337\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8157 - val_loss: 2559.2957\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8489 - val_loss: 2559.3191\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7979 - val_loss: 2559.3433\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8008 - val_loss: 2559.3384\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7820 - val_loss: 2559.3262\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8787 - val_loss: 2559.3049\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7830 - val_loss: 2559.3171\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8281 - val_loss: 2559.3083\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8342 - val_loss: 2559.3086\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7756 - val_loss: 2559.2886\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7815 - val_loss: 2559.2883\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8271 - val_loss: 2559.3186\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8879 - val_loss: 2559.3149\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7756 - val_loss: 2559.3372\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8059 - val_loss: 2559.3232\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.9087 - val_loss: 2559.2957\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8184 - val_loss: 2559.2944\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8525 - val_loss: 2559.2986\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8313 - val_loss: 2559.3123\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8015 - val_loss: 2559.2981\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8318 - val_loss: 2559.2957\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8281 - val_loss: 2559.2861\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7996 - val_loss: 2559.3149\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8440 - val_loss: 2559.3049\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8176 - val_loss: 2559.2651\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7776 - val_loss: 2559.2981\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8372 - val_loss: 2559.3206\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7900 - val_loss: 2559.3418\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8225 - val_loss: 2559.2812\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8701 - val_loss: 2559.3376\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8181 - val_loss: 2559.2883\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8301 - val_loss: 2559.3369\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8081 - val_loss: 2559.3223\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8049 - val_loss: 2559.2913\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8411 - val_loss: 2559.3318\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7754 - val_loss: 2559.3386\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8230 - val_loss: 2559.2957\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.7527 - val_loss: 2559.3040\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7737 - val_loss: 2559.3376\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8242 - val_loss: 2559.3005\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.7749 - val_loss: 2559.2954\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.7949 - val_loss: 2559.2825\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8135 - val_loss: 2559.2986\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8293 - val_loss: 2559.2651\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8298 - val_loss: 2559.2947\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8813 - val_loss: 2559.3142\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7583 - val_loss: 2559.2832\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8123 - val_loss: 2559.2754\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8472 - val_loss: 2559.2812\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7881 - val_loss: 2559.2988\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8250 - val_loss: 2559.3340\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8503 - val_loss: 2559.3059\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8442 - val_loss: 2559.2864\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8167 - val_loss: 2559.3064\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7988 - val_loss: 2559.2676\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8342 - val_loss: 2559.3269\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7429 - val_loss: 2559.2832\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8110 - val_loss: 2559.3027\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8750 - val_loss: 2559.2939\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8147 - val_loss: 2559.2949\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8303 - val_loss: 2559.2991\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8271 - val_loss: 2559.2634\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7566 - val_loss: 2559.3003\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8391 - val_loss: 2559.3389\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8325 - val_loss: 2559.3074\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7957 - val_loss: 2559.3223\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8943 - val_loss: 2559.2720\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7935 - val_loss: 2559.2927\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8042 - val_loss: 2559.3066\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8335 - val_loss: 2559.2773\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8254 - val_loss: 2559.2812\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.7878 - val_loss: 2559.2974\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.7864 - val_loss: 2559.2676\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7839 - val_loss: 2559.3008\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8083 - val_loss: 2559.2739\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7998 - val_loss: 2559.2668\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8064 - val_loss: 2559.2688\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8320 - val_loss: 2559.2568\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7979 - val_loss: 2559.3137\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8450 - val_loss: 2559.2903\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8464 - val_loss: 2559.3125\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8181 - val_loss: 2559.3103\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8401 - val_loss: 2559.2881\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8242 - val_loss: 2559.3276\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7690 - val_loss: 2559.2952\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8176 - val_loss: 2559.2966\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8013 - val_loss: 2559.3237\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7935 - val_loss: 2559.2705\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8152 - val_loss: 2559.2910\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8374 - val_loss: 2559.2986\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8523 - val_loss: 2559.2847\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8110 - val_loss: 2559.2842\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8186 - val_loss: 2559.2732\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8081 - val_loss: 2559.2791\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8838 - val_loss: 2559.3447\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7783 - val_loss: 2559.2998\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7842 - val_loss: 2559.3042\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8174 - val_loss: 2559.3162\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8066 - val_loss: 2559.3020\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.9341 - val_loss: 2559.2939\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8298 - val_loss: 2559.2727\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8650 - val_loss: 2559.3108\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.7810 - val_loss: 2559.3162\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7720 - val_loss: 2559.3213\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7700 - val_loss: 2559.2720\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8396 - val_loss: 2559.2756\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8894 - val_loss: 2559.2920\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8865 - val_loss: 2559.2446\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8713 - val_loss: 2559.2881\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8342 - val_loss: 2559.2661\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8103 - val_loss: 2559.2725\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8225 - val_loss: 2559.2866\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8113 - val_loss: 2559.2520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8428 - val_loss: 2559.2495\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8508 - val_loss: 2559.2561\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7666 - val_loss: 2559.2888\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8042 - val_loss: 2559.2454\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8357 - val_loss: 2559.2739\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8164 - val_loss: 2559.2893\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8259 - val_loss: 2559.2742\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8572 - val_loss: 2559.2449\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8340 - val_loss: 2559.2842\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8196 - val_loss: 2559.2595\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8691 - val_loss: 2559.2976\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7954 - val_loss: 2559.2747\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8208 - val_loss: 2559.2729\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7937 - val_loss: 2559.3037\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8506 - val_loss: 2559.2705\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8508 - val_loss: 2559.3096\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8677 - val_loss: 2559.3281\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7830 - val_loss: 2559.2639\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8245 - val_loss: 2559.3010\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7913 - val_loss: 2559.2935\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8342 - val_loss: 2559.2939\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8513 - val_loss: 2559.2698\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8269 - val_loss: 2559.2815\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7771 - val_loss: 2559.3320\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8018 - val_loss: 2559.2722\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8633 - val_loss: 2559.2966\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8367 - val_loss: 2559.2947\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8047 - val_loss: 2559.3135\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8149 - val_loss: 2559.2920\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8191 - val_loss: 2559.2498\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8562 - val_loss: 2559.2471\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8389 - val_loss: 2559.2712\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7844 - val_loss: 2559.2820\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8115 - val_loss: 2559.2573\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8071 - val_loss: 2559.2971\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7969 - val_loss: 2559.2639\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8225 - val_loss: 2559.2532\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.7957 - val_loss: 2559.2742\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.8240 - val_loss: 2559.2515\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8169 - val_loss: 2559.2976\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7964 - val_loss: 2559.2881\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8586 - val_loss: 2559.2957\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.7942 - val_loss: 2559.2827\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2497.8206 - val_loss: 2559.3191\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2497.7786 - val_loss: 2559.2800\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8113 - val_loss: 2559.3206\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.8125 - val_loss: 2559.3142\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8059 - val_loss: 2559.2974\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2497.8464 - val_loss: 2559.2910\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2497.7915 - val_loss: 2559.2908\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 2559.2905561972716\n",
      "Mean Absolute Error (MAE): 39.95631592896169\n",
      "Root Mean Squared Error (RMSE): 50.58943126975507\n",
      "Time taken: 1173.6400706768036\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 19ms/step - loss: 4033.6626 - val_loss: 3732.6438\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3715.7749 - val_loss: 3517.9404\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3515.0781 - val_loss: 3334.3279\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3344.3533 - val_loss: 3179.5735\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3199.4692 - val_loss: 3046.5627\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 3074.7368 - val_loss: 2932.2034\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2967.4592 - val_loss: 2833.8325\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2875.9211 - val_loss: 2750.0298\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2798.2671 - val_loss: 2679.5474\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2733.1833 - val_loss: 2620.4771\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2678.9023 - val_loss: 2570.6467\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2634.4988 - val_loss: 2532.3093\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2600.6421 - val_loss: 2502.9202\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2575.0706 - val_loss: 2481.3291\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2556.5793 - val_loss: 2465.9023\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2544.0049 - val_loss: 2455.9136\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2535.9458 - val_loss: 2449.8635\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2531.3074 - val_loss: 2446.3242\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2528.7927 - val_loss: 2444.5632\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2527.5144 - val_loss: 2443.8694\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2527.0193 - val_loss: 2443.5405\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2526.8169 - val_loss: 2443.4756\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7288 - val_loss: 2443.4548\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7144 - val_loss: 2443.4783\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7722 - val_loss: 2443.5508\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6899 - val_loss: 2443.5364\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7354 - val_loss: 2443.5916\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7505 - val_loss: 2443.5559\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7148 - val_loss: 2443.6011\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7588 - val_loss: 2443.6143\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7131 - val_loss: 2443.5957\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7168 - val_loss: 2443.5896\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7493 - val_loss: 2443.5869\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7986 - val_loss: 2443.6116\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7529 - val_loss: 2443.5654\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7119 - val_loss: 2443.5679\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6733 - val_loss: 2443.6116\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7432 - val_loss: 2443.6367\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7573 - val_loss: 2443.6472\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7188 - val_loss: 2443.6230\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2526.7275 - val_loss: 2443.6255\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2526.7419 - val_loss: 2443.5608\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7466 - val_loss: 2443.6614\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7163 - val_loss: 2443.6477\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7363 - val_loss: 2443.6431\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6890 - val_loss: 2443.6201\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7468 - val_loss: 2443.6494\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2526.7161 - val_loss: 2443.6990\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2526.7021 - val_loss: 2443.6052\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7014 - val_loss: 2443.5984\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6870 - val_loss: 2443.5378\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7148 - val_loss: 2443.6001\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2526.7581 - val_loss: 2443.5894\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6826 - val_loss: 2443.6089\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7502 - val_loss: 2443.5894\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6665 - val_loss: 2443.6042\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7620 - val_loss: 2443.6355\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7485 - val_loss: 2443.5820\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2526.6809 - val_loss: 2443.6270\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7729 - val_loss: 2443.5781\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7334 - val_loss: 2443.5823\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6775 - val_loss: 2443.6311\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6821 - val_loss: 2443.5935\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6907 - val_loss: 2443.5671\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7214 - val_loss: 2443.5979\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7451 - val_loss: 2443.6296\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7468 - val_loss: 2443.6357\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7896 - val_loss: 2443.6868\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7747 - val_loss: 2443.6509\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7188 - val_loss: 2443.6123\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7261 - val_loss: 2443.5940\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2526.7061 - val_loss: 2443.5615\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7915 - val_loss: 2443.6362\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2526.7156 - val_loss: 2443.5977\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7434 - val_loss: 2443.6174\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7087 - val_loss: 2443.5310\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7578 - val_loss: 2443.6206\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7000 - val_loss: 2443.6008\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2529.9968 - val_loss: 2443.4272\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2527.0400 - val_loss: 2443.1064\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7981 - val_loss: 2443.1370\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.8606 - val_loss: 2443.2520\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7312 - val_loss: 2443.3105\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7678 - val_loss: 2443.3582\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7354 - val_loss: 2443.3638\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7380 - val_loss: 2443.4758\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7791 - val_loss: 2443.5229\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7239 - val_loss: 2443.5386\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7122 - val_loss: 2443.5015\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2526.7354 - val_loss: 2443.5505\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7290 - val_loss: 2443.5388\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7139 - val_loss: 2443.6355\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6960 - val_loss: 2443.5918\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6624 - val_loss: 2443.5803\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2526.7622 - val_loss: 2443.5835\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7034 - val_loss: 2443.6106\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7053 - val_loss: 2443.6204\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7603 - val_loss: 2443.6348\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2526.7156 - val_loss: 2443.6265\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7095 - val_loss: 2443.5798\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2526.7634 - val_loss: 2443.5793\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2526.7493 - val_loss: 2443.5769\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7605 - val_loss: 2443.5793\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7449 - val_loss: 2443.6228\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.6982 - val_loss: 2443.6799\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7539 - val_loss: 2443.5581\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2527.5120 - val_loss: 2443.2234\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2527.1135 - val_loss: 2443.0039\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.9258 - val_loss: 2443.0076\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.8083 - val_loss: 2443.0972\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.8684 - val_loss: 2443.1750\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.7312 - val_loss: 2442.8420\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2526.1292 - val_loss: 2442.2085\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2525.4331 - val_loss: 2440.8699\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2525.3979 - val_loss: 2440.9226\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2523.9299 - val_loss: 2440.0154\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2521.9292 - val_loss: 2438.3394\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2520.2991 - val_loss: 2437.2424\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2518.3630 - val_loss: 2436.1025\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2514.4192 - val_loss: 2431.7124\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2513.5676 - val_loss: 2431.7747\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2509.2019 - val_loss: 2429.1809\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2504.8118 - val_loss: 2427.4761\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2516.8652 - val_loss: 2431.0989\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2506.1982 - val_loss: 2423.6082\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2502.5447 - val_loss: 2420.8396\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2498.2720 - val_loss: 2423.5835\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2493.4180 - val_loss: 2414.5527\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.1885 - val_loss: 2429.3096\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2488.5764 - val_loss: 2414.0220\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2482.3345 - val_loss: 2408.5457\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2476.4058 - val_loss: 2401.2605\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2473.2581 - val_loss: 2398.9070\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2469.4739 - val_loss: 2392.3711\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2462.7717 - val_loss: 2384.6125\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2455.1895 - val_loss: 2371.3853\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2441.6394 - val_loss: 2358.0396\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2430.4805 - val_loss: 2338.5515\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2418.8616 - val_loss: 2321.2568\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2406.1326 - val_loss: 2324.4585\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2391.6309 - val_loss: 2301.1213\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2386.5623 - val_loss: 2280.5288\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2357.9160 - val_loss: 2285.1152\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2353.7021 - val_loss: 2268.6765\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2338.6868 - val_loss: 2240.7156\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2319.7222 - val_loss: 2284.0945\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2317.8699 - val_loss: 2298.6150\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2305.5554 - val_loss: 2195.2197\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2301.5840 - val_loss: 2238.5283\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2306.7422 - val_loss: 2224.4351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2279.1289 - val_loss: 2205.1992\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2265.0281 - val_loss: 2158.1670\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2226.1218 - val_loss: 2160.9700\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2240.3972 - val_loss: 2170.6042\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2223.0962 - val_loss: 2128.9861\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2200.2380 - val_loss: 2162.0918\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2179.7361 - val_loss: 2101.5068\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2185.4541 - val_loss: 2088.9158\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2189.5605 - val_loss: 2094.3052\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2147.5310 - val_loss: 2042.9244\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2154.6177 - val_loss: 2051.9207\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2131.4827 - val_loss: 2037.0443\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2112.9963 - val_loss: 2087.3784\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2141.0046 - val_loss: 2178.6824\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2141.8384 - val_loss: 1986.2476\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2069.7817 - val_loss: 1992.6968\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2063.2295 - val_loss: 2008.2142\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2073.3118 - val_loss: 1998.8987\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2026.8097 - val_loss: 1958.5897\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2003.0272 - val_loss: 1969.7601\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1990.2986 - val_loss: 1923.6580\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1979.8074 - val_loss: 1934.5111\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2095.4529 - val_loss: 2358.9866\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2100.1018 - val_loss: 1931.2223\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2037.4753 - val_loss: 1930.1200\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 1952.5652 - val_loss: 2007.3182\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1950.9353 - val_loss: 1942.7153\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1945.4486 - val_loss: 2032.8501\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1944.4945 - val_loss: 1852.6978\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1904.5988 - val_loss: 1837.9282\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1893.0703 - val_loss: 1815.0165\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1875.6082 - val_loss: 1799.7816\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1865.7200 - val_loss: 1756.7108\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1892.7338 - val_loss: 1904.1144\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1845.6525 - val_loss: 1832.0428\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1857.3512 - val_loss: 1901.8953\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1858.4320 - val_loss: 1772.9774\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2046.5435 - val_loss: 2072.8120\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1967.9174 - val_loss: 1788.0587\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1821.2588 - val_loss: 1754.6653\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 1821.8516 - val_loss: 1685.0111\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1813.8158 - val_loss: 1986.4683\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1913.2854 - val_loss: 1711.2894\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1761.3354 - val_loss: 1613.2827\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1951.2322 - val_loss: 1723.2301\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1744.3218 - val_loss: 1614.3894\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1749.3506 - val_loss: 1584.3514\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1702.8260 - val_loss: 1551.5978\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1719.2988 - val_loss: 1570.8632\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1665.2649 - val_loss: 1556.5662\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 1556.5664014501654\n",
      "Mean Absolute Error (MAE): 30.972780040824006\n",
      "Root Mean Squared Error (RMSE): 39.45334461677698\n",
      "Time taken: 1184.0838747024536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 48, 512)           1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 48, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_1424\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold          MSE        MAE       RMSE   Time taken\n",
      "0        1  2545.977964  40.201286  50.457685  1255.651282\n",
      "1        2  2467.817006  38.763515  49.677128  1246.593629\n",
      "2        3  2537.025227  39.802926  50.368891  1294.219587\n",
      "3        4  2559.290556  39.956316  50.589431  1173.640071\n",
      "4        5  1556.566401  30.972780  39.453345  1184.083875\n",
      "5  Average  2333.335431  37.939365  48.109296  1230.837689\n",
      "Results saved to 'DL_Result_PL_model_2_Scattered_Reg3.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_2_Scattered_Reg3.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'DL_Result_PL_model_2_Scattered_Reg3.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
