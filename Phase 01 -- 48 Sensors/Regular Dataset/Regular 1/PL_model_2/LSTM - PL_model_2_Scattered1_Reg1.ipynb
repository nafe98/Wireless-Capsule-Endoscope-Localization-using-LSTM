{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_2_Scattered_Reg1.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.966458</td>\n",
       "      <td>76.691794</td>\n",
       "      <td>68.124658</td>\n",
       "      <td>69.178081</td>\n",
       "      <td>64.534165</td>\n",
       "      <td>76.817590</td>\n",
       "      <td>82.036444</td>\n",
       "      <td>63.012904</td>\n",
       "      <td>76.124602</td>\n",
       "      <td>66.512576</td>\n",
       "      <td>...</td>\n",
       "      <td>70.362393</td>\n",
       "      <td>59.270961</td>\n",
       "      <td>60.621590</td>\n",
       "      <td>54.192753</td>\n",
       "      <td>83.544496</td>\n",
       "      <td>57.301764</td>\n",
       "      <td>63.951668</td>\n",
       "      <td>83.072964</td>\n",
       "      <td>60.473752</td>\n",
       "      <td>72.292435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.692700</td>\n",
       "      <td>63.680076</td>\n",
       "      <td>63.407868</td>\n",
       "      <td>64.440492</td>\n",
       "      <td>69.481736</td>\n",
       "      <td>65.529803</td>\n",
       "      <td>64.520032</td>\n",
       "      <td>74.239935</td>\n",
       "      <td>65.563082</td>\n",
       "      <td>73.345285</td>\n",
       "      <td>...</td>\n",
       "      <td>75.015437</td>\n",
       "      <td>73.007565</td>\n",
       "      <td>59.834268</td>\n",
       "      <td>63.443141</td>\n",
       "      <td>81.114206</td>\n",
       "      <td>78.928829</td>\n",
       "      <td>64.997488</td>\n",
       "      <td>70.986068</td>\n",
       "      <td>67.150721</td>\n",
       "      <td>49.406450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.423386</td>\n",
       "      <td>68.207059</td>\n",
       "      <td>65.416411</td>\n",
       "      <td>81.006436</td>\n",
       "      <td>70.308422</td>\n",
       "      <td>93.886350</td>\n",
       "      <td>77.208542</td>\n",
       "      <td>79.014001</td>\n",
       "      <td>71.285041</td>\n",
       "      <td>64.713052</td>\n",
       "      <td>...</td>\n",
       "      <td>70.215749</td>\n",
       "      <td>66.022268</td>\n",
       "      <td>55.280539</td>\n",
       "      <td>71.956223</td>\n",
       "      <td>72.425614</td>\n",
       "      <td>58.764071</td>\n",
       "      <td>76.240297</td>\n",
       "      <td>89.828820</td>\n",
       "      <td>71.746000</td>\n",
       "      <td>73.450073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.604227</td>\n",
       "      <td>60.100769</td>\n",
       "      <td>78.108050</td>\n",
       "      <td>71.702062</td>\n",
       "      <td>76.073666</td>\n",
       "      <td>85.096470</td>\n",
       "      <td>64.170158</td>\n",
       "      <td>78.554347</td>\n",
       "      <td>61.627531</td>\n",
       "      <td>63.580600</td>\n",
       "      <td>...</td>\n",
       "      <td>56.684107</td>\n",
       "      <td>63.206736</td>\n",
       "      <td>75.628206</td>\n",
       "      <td>61.889875</td>\n",
       "      <td>70.740295</td>\n",
       "      <td>66.647134</td>\n",
       "      <td>70.709824</td>\n",
       "      <td>76.945843</td>\n",
       "      <td>58.398246</td>\n",
       "      <td>76.749932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.911221</td>\n",
       "      <td>67.146110</td>\n",
       "      <td>52.263216</td>\n",
       "      <td>77.054846</td>\n",
       "      <td>78.253807</td>\n",
       "      <td>78.206904</td>\n",
       "      <td>62.812263</td>\n",
       "      <td>66.284075</td>\n",
       "      <td>67.920070</td>\n",
       "      <td>74.997227</td>\n",
       "      <td>...</td>\n",
       "      <td>69.078210</td>\n",
       "      <td>65.429437</td>\n",
       "      <td>68.308554</td>\n",
       "      <td>64.388971</td>\n",
       "      <td>64.508250</td>\n",
       "      <td>61.106363</td>\n",
       "      <td>60.320194</td>\n",
       "      <td>63.822647</td>\n",
       "      <td>59.836285</td>\n",
       "      <td>68.951026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>77.635861</td>\n",
       "      <td>74.631760</td>\n",
       "      <td>58.895053</td>\n",
       "      <td>58.303407</td>\n",
       "      <td>79.082038</td>\n",
       "      <td>88.117920</td>\n",
       "      <td>72.722073</td>\n",
       "      <td>74.539170</td>\n",
       "      <td>76.658832</td>\n",
       "      <td>62.204263</td>\n",
       "      <td>...</td>\n",
       "      <td>61.566679</td>\n",
       "      <td>72.852155</td>\n",
       "      <td>55.812086</td>\n",
       "      <td>48.624382</td>\n",
       "      <td>69.453316</td>\n",
       "      <td>61.341108</td>\n",
       "      <td>79.265735</td>\n",
       "      <td>73.592422</td>\n",
       "      <td>82.282273</td>\n",
       "      <td>65.717778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>62.823602</td>\n",
       "      <td>72.690260</td>\n",
       "      <td>69.706508</td>\n",
       "      <td>56.995139</td>\n",
       "      <td>77.503766</td>\n",
       "      <td>74.898295</td>\n",
       "      <td>75.334289</td>\n",
       "      <td>72.963421</td>\n",
       "      <td>77.060024</td>\n",
       "      <td>80.256079</td>\n",
       "      <td>...</td>\n",
       "      <td>66.739113</td>\n",
       "      <td>61.633896</td>\n",
       "      <td>60.646570</td>\n",
       "      <td>58.331447</td>\n",
       "      <td>64.230697</td>\n",
       "      <td>75.307707</td>\n",
       "      <td>75.821711</td>\n",
       "      <td>74.601668</td>\n",
       "      <td>59.415883</td>\n",
       "      <td>67.166067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>81.389384</td>\n",
       "      <td>87.789650</td>\n",
       "      <td>67.253795</td>\n",
       "      <td>49.295169</td>\n",
       "      <td>63.452192</td>\n",
       "      <td>90.038200</td>\n",
       "      <td>83.933123</td>\n",
       "      <td>73.024195</td>\n",
       "      <td>70.681611</td>\n",
       "      <td>50.560766</td>\n",
       "      <td>...</td>\n",
       "      <td>50.103849</td>\n",
       "      <td>69.614166</td>\n",
       "      <td>46.320473</td>\n",
       "      <td>61.069086</td>\n",
       "      <td>78.216320</td>\n",
       "      <td>68.933371</td>\n",
       "      <td>76.296101</td>\n",
       "      <td>79.191328</td>\n",
       "      <td>78.368429</td>\n",
       "      <td>62.083876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>73.478893</td>\n",
       "      <td>74.239110</td>\n",
       "      <td>80.832142</td>\n",
       "      <td>57.894213</td>\n",
       "      <td>69.474806</td>\n",
       "      <td>73.222195</td>\n",
       "      <td>81.259577</td>\n",
       "      <td>52.787488</td>\n",
       "      <td>65.549878</td>\n",
       "      <td>67.340342</td>\n",
       "      <td>...</td>\n",
       "      <td>70.114742</td>\n",
       "      <td>67.666341</td>\n",
       "      <td>72.920214</td>\n",
       "      <td>48.609700</td>\n",
       "      <td>69.509795</td>\n",
       "      <td>71.538253</td>\n",
       "      <td>65.692645</td>\n",
       "      <td>72.449802</td>\n",
       "      <td>60.116178</td>\n",
       "      <td>81.836236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>80.366900</td>\n",
       "      <td>56.786580</td>\n",
       "      <td>78.892167</td>\n",
       "      <td>52.696707</td>\n",
       "      <td>73.300030</td>\n",
       "      <td>78.292661</td>\n",
       "      <td>57.602685</td>\n",
       "      <td>67.369970</td>\n",
       "      <td>68.721017</td>\n",
       "      <td>65.338030</td>\n",
       "      <td>...</td>\n",
       "      <td>81.834828</td>\n",
       "      <td>56.875920</td>\n",
       "      <td>70.828006</td>\n",
       "      <td>54.539941</td>\n",
       "      <td>68.782268</td>\n",
       "      <td>72.568965</td>\n",
       "      <td>79.268439</td>\n",
       "      <td>44.393526</td>\n",
       "      <td>61.642113</td>\n",
       "      <td>54.547595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5   \\\n",
       "0     64.966458  76.691794  68.124658  69.178081  64.534165  76.817590   \n",
       "1     73.692700  63.680076  63.407868  64.440492  69.481736  65.529803   \n",
       "2     77.423386  68.207059  65.416411  81.006436  70.308422  93.886350   \n",
       "3     79.604227  60.100769  78.108050  71.702062  76.073666  85.096470   \n",
       "4     68.911221  67.146110  52.263216  77.054846  78.253807  78.206904   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  77.635861  74.631760  58.895053  58.303407  79.082038  88.117920   \n",
       "2439  62.823602  72.690260  69.706508  56.995139  77.503766  74.898295   \n",
       "2440  81.389384  87.789650  67.253795  49.295169  63.452192  90.038200   \n",
       "2441  73.478893  74.239110  80.832142  57.894213  69.474806  73.222195   \n",
       "2442  80.366900  56.786580  78.892167  52.696707  73.300030  78.292661   \n",
       "\n",
       "             6          7          8          9   ...         38         39  \\\n",
       "0     82.036444  63.012904  76.124602  66.512576  ...  70.362393  59.270961   \n",
       "1     64.520032  74.239935  65.563082  73.345285  ...  75.015437  73.007565   \n",
       "2     77.208542  79.014001  71.285041  64.713052  ...  70.215749  66.022268   \n",
       "3     64.170158  78.554347  61.627531  63.580600  ...  56.684107  63.206736   \n",
       "4     62.812263  66.284075  67.920070  74.997227  ...  69.078210  65.429437   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  72.722073  74.539170  76.658832  62.204263  ...  61.566679  72.852155   \n",
       "2439  75.334289  72.963421  77.060024  80.256079  ...  66.739113  61.633896   \n",
       "2440  83.933123  73.024195  70.681611  50.560766  ...  50.103849  69.614166   \n",
       "2441  81.259577  52.787488  65.549878  67.340342  ...  70.114742  67.666341   \n",
       "2442  57.602685  67.369970  68.721017  65.338030  ...  81.834828  56.875920   \n",
       "\n",
       "             40         41         42         43         44         45  \\\n",
       "0     60.621590  54.192753  83.544496  57.301764  63.951668  83.072964   \n",
       "1     59.834268  63.443141  81.114206  78.928829  64.997488  70.986068   \n",
       "2     55.280539  71.956223  72.425614  58.764071  76.240297  89.828820   \n",
       "3     75.628206  61.889875  70.740295  66.647134  70.709824  76.945843   \n",
       "4     68.308554  64.388971  64.508250  61.106363  60.320194  63.822647   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  55.812086  48.624382  69.453316  61.341108  79.265735  73.592422   \n",
       "2439  60.646570  58.331447  64.230697  75.307707  75.821711  74.601668   \n",
       "2440  46.320473  61.069086  78.216320  68.933371  76.296101  79.191328   \n",
       "2441  72.920214  48.609700  69.509795  71.538253  65.692645  72.449802   \n",
       "2442  70.828006  54.539941  68.782268  72.568965  79.268439  44.393526   \n",
       "\n",
       "             46         47  \n",
       "0     60.473752  72.292435  \n",
       "1     67.150721  49.406450  \n",
       "2     71.746000  73.450073  \n",
       "3     58.398246  76.749932  \n",
       "4     59.836285  68.951026  \n",
       "...         ...        ...  \n",
       "2438  82.282273  65.717778  \n",
       "2439  59.415883  67.166067  \n",
       "2440  78.368429  62.083876  \n",
       "2441  60.116178  81.836236  \n",
       "2442  61.642113  54.547595  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_Reg1.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.966458</td>\n",
       "      <td>76.691794</td>\n",
       "      <td>68.124658</td>\n",
       "      <td>69.178081</td>\n",
       "      <td>64.534165</td>\n",
       "      <td>76.817590</td>\n",
       "      <td>82.036444</td>\n",
       "      <td>63.012904</td>\n",
       "      <td>76.124602</td>\n",
       "      <td>66.512576</td>\n",
       "      <td>...</td>\n",
       "      <td>70.362393</td>\n",
       "      <td>59.270961</td>\n",
       "      <td>60.621590</td>\n",
       "      <td>54.192753</td>\n",
       "      <td>83.544496</td>\n",
       "      <td>57.301764</td>\n",
       "      <td>63.951668</td>\n",
       "      <td>83.072964</td>\n",
       "      <td>60.473752</td>\n",
       "      <td>72.292435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.692700</td>\n",
       "      <td>63.680076</td>\n",
       "      <td>63.407868</td>\n",
       "      <td>64.440492</td>\n",
       "      <td>69.481736</td>\n",
       "      <td>65.529803</td>\n",
       "      <td>64.520032</td>\n",
       "      <td>74.239935</td>\n",
       "      <td>65.563082</td>\n",
       "      <td>73.345285</td>\n",
       "      <td>...</td>\n",
       "      <td>75.015437</td>\n",
       "      <td>73.007565</td>\n",
       "      <td>59.834268</td>\n",
       "      <td>63.443141</td>\n",
       "      <td>81.114206</td>\n",
       "      <td>78.928829</td>\n",
       "      <td>64.997488</td>\n",
       "      <td>70.986068</td>\n",
       "      <td>67.150721</td>\n",
       "      <td>49.406450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.423386</td>\n",
       "      <td>68.207059</td>\n",
       "      <td>65.416411</td>\n",
       "      <td>81.006436</td>\n",
       "      <td>70.308422</td>\n",
       "      <td>93.886350</td>\n",
       "      <td>77.208542</td>\n",
       "      <td>79.014001</td>\n",
       "      <td>71.285041</td>\n",
       "      <td>64.713052</td>\n",
       "      <td>...</td>\n",
       "      <td>70.215749</td>\n",
       "      <td>66.022268</td>\n",
       "      <td>55.280539</td>\n",
       "      <td>71.956223</td>\n",
       "      <td>72.425614</td>\n",
       "      <td>58.764071</td>\n",
       "      <td>76.240297</td>\n",
       "      <td>89.828820</td>\n",
       "      <td>71.746000</td>\n",
       "      <td>73.450073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.604227</td>\n",
       "      <td>60.100769</td>\n",
       "      <td>78.108050</td>\n",
       "      <td>71.702062</td>\n",
       "      <td>76.073666</td>\n",
       "      <td>85.096470</td>\n",
       "      <td>64.170158</td>\n",
       "      <td>78.554347</td>\n",
       "      <td>61.627531</td>\n",
       "      <td>63.580600</td>\n",
       "      <td>...</td>\n",
       "      <td>56.684107</td>\n",
       "      <td>63.206736</td>\n",
       "      <td>75.628206</td>\n",
       "      <td>61.889875</td>\n",
       "      <td>70.740295</td>\n",
       "      <td>66.647134</td>\n",
       "      <td>70.709824</td>\n",
       "      <td>76.945843</td>\n",
       "      <td>58.398246</td>\n",
       "      <td>76.749932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.911221</td>\n",
       "      <td>67.146110</td>\n",
       "      <td>52.263216</td>\n",
       "      <td>77.054846</td>\n",
       "      <td>78.253807</td>\n",
       "      <td>78.206904</td>\n",
       "      <td>62.812263</td>\n",
       "      <td>66.284075</td>\n",
       "      <td>67.920070</td>\n",
       "      <td>74.997227</td>\n",
       "      <td>...</td>\n",
       "      <td>69.078210</td>\n",
       "      <td>65.429437</td>\n",
       "      <td>68.308554</td>\n",
       "      <td>64.388971</td>\n",
       "      <td>64.508250</td>\n",
       "      <td>61.106363</td>\n",
       "      <td>60.320194</td>\n",
       "      <td>63.822647</td>\n",
       "      <td>59.836285</td>\n",
       "      <td>68.951026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>77.635861</td>\n",
       "      <td>74.631760</td>\n",
       "      <td>58.895053</td>\n",
       "      <td>58.303407</td>\n",
       "      <td>79.082038</td>\n",
       "      <td>88.117920</td>\n",
       "      <td>72.722073</td>\n",
       "      <td>74.539170</td>\n",
       "      <td>76.658832</td>\n",
       "      <td>62.204263</td>\n",
       "      <td>...</td>\n",
       "      <td>61.566679</td>\n",
       "      <td>72.852155</td>\n",
       "      <td>55.812086</td>\n",
       "      <td>48.624382</td>\n",
       "      <td>69.453316</td>\n",
       "      <td>61.341108</td>\n",
       "      <td>79.265735</td>\n",
       "      <td>73.592422</td>\n",
       "      <td>82.282273</td>\n",
       "      <td>65.717778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>62.823602</td>\n",
       "      <td>72.690260</td>\n",
       "      <td>69.706508</td>\n",
       "      <td>56.995139</td>\n",
       "      <td>77.503766</td>\n",
       "      <td>74.898295</td>\n",
       "      <td>75.334289</td>\n",
       "      <td>72.963421</td>\n",
       "      <td>77.060024</td>\n",
       "      <td>80.256079</td>\n",
       "      <td>...</td>\n",
       "      <td>66.739113</td>\n",
       "      <td>61.633896</td>\n",
       "      <td>60.646570</td>\n",
       "      <td>58.331447</td>\n",
       "      <td>64.230697</td>\n",
       "      <td>75.307707</td>\n",
       "      <td>75.821711</td>\n",
       "      <td>74.601668</td>\n",
       "      <td>59.415883</td>\n",
       "      <td>67.166067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>81.389384</td>\n",
       "      <td>87.789650</td>\n",
       "      <td>67.253795</td>\n",
       "      <td>49.295169</td>\n",
       "      <td>63.452192</td>\n",
       "      <td>90.038200</td>\n",
       "      <td>83.933123</td>\n",
       "      <td>73.024195</td>\n",
       "      <td>70.681611</td>\n",
       "      <td>50.560766</td>\n",
       "      <td>...</td>\n",
       "      <td>50.103849</td>\n",
       "      <td>69.614166</td>\n",
       "      <td>46.320473</td>\n",
       "      <td>61.069086</td>\n",
       "      <td>78.216320</td>\n",
       "      <td>68.933371</td>\n",
       "      <td>76.296101</td>\n",
       "      <td>79.191328</td>\n",
       "      <td>78.368429</td>\n",
       "      <td>62.083876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>73.478893</td>\n",
       "      <td>74.239110</td>\n",
       "      <td>80.832142</td>\n",
       "      <td>57.894213</td>\n",
       "      <td>69.474806</td>\n",
       "      <td>73.222195</td>\n",
       "      <td>81.259577</td>\n",
       "      <td>52.787488</td>\n",
       "      <td>65.549878</td>\n",
       "      <td>67.340342</td>\n",
       "      <td>...</td>\n",
       "      <td>70.114742</td>\n",
       "      <td>67.666341</td>\n",
       "      <td>72.920214</td>\n",
       "      <td>48.609700</td>\n",
       "      <td>69.509795</td>\n",
       "      <td>71.538253</td>\n",
       "      <td>65.692645</td>\n",
       "      <td>72.449802</td>\n",
       "      <td>60.116178</td>\n",
       "      <td>81.836236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>80.366900</td>\n",
       "      <td>56.786580</td>\n",
       "      <td>78.892167</td>\n",
       "      <td>52.696707</td>\n",
       "      <td>73.300030</td>\n",
       "      <td>78.292661</td>\n",
       "      <td>57.602685</td>\n",
       "      <td>67.369970</td>\n",
       "      <td>68.721017</td>\n",
       "      <td>65.338030</td>\n",
       "      <td>...</td>\n",
       "      <td>81.834828</td>\n",
       "      <td>56.875920</td>\n",
       "      <td>70.828006</td>\n",
       "      <td>54.539941</td>\n",
       "      <td>68.782268</td>\n",
       "      <td>72.568965</td>\n",
       "      <td>79.268439</td>\n",
       "      <td>44.393526</td>\n",
       "      <td>61.642113</td>\n",
       "      <td>54.547595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor1    sensor2    sensor3    sensor4    sensor5    sensor6  \\\n",
       "0     64.966458  76.691794  68.124658  69.178081  64.534165  76.817590   \n",
       "1     73.692700  63.680076  63.407868  64.440492  69.481736  65.529803   \n",
       "2     77.423386  68.207059  65.416411  81.006436  70.308422  93.886350   \n",
       "3     79.604227  60.100769  78.108050  71.702062  76.073666  85.096470   \n",
       "4     68.911221  67.146110  52.263216  77.054846  78.253807  78.206904   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  77.635861  74.631760  58.895053  58.303407  79.082038  88.117920   \n",
       "2439  62.823602  72.690260  69.706508  56.995139  77.503766  74.898295   \n",
       "2440  81.389384  87.789650  67.253795  49.295169  63.452192  90.038200   \n",
       "2441  73.478893  74.239110  80.832142  57.894213  69.474806  73.222195   \n",
       "2442  80.366900  56.786580  78.892167  52.696707  73.300030  78.292661   \n",
       "\n",
       "        sensor7    sensor8    sensor9   sensor10  ...   sensor39   sensor40  \\\n",
       "0     82.036444  63.012904  76.124602  66.512576  ...  70.362393  59.270961   \n",
       "1     64.520032  74.239935  65.563082  73.345285  ...  75.015437  73.007565   \n",
       "2     77.208542  79.014001  71.285041  64.713052  ...  70.215749  66.022268   \n",
       "3     64.170158  78.554347  61.627531  63.580600  ...  56.684107  63.206736   \n",
       "4     62.812263  66.284075  67.920070  74.997227  ...  69.078210  65.429437   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  72.722073  74.539170  76.658832  62.204263  ...  61.566679  72.852155   \n",
       "2439  75.334289  72.963421  77.060024  80.256079  ...  66.739113  61.633896   \n",
       "2440  83.933123  73.024195  70.681611  50.560766  ...  50.103849  69.614166   \n",
       "2441  81.259577  52.787488  65.549878  67.340342  ...  70.114742  67.666341   \n",
       "2442  57.602685  67.369970  68.721017  65.338030  ...  81.834828  56.875920   \n",
       "\n",
       "       sensor41   sensor42   sensor43   sensor44   sensor45   sensor46  \\\n",
       "0     60.621590  54.192753  83.544496  57.301764  63.951668  83.072964   \n",
       "1     59.834268  63.443141  81.114206  78.928829  64.997488  70.986068   \n",
       "2     55.280539  71.956223  72.425614  58.764071  76.240297  89.828820   \n",
       "3     75.628206  61.889875  70.740295  66.647134  70.709824  76.945843   \n",
       "4     68.308554  64.388971  64.508250  61.106363  60.320194  63.822647   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  55.812086  48.624382  69.453316  61.341108  79.265735  73.592422   \n",
       "2439  60.646570  58.331447  64.230697  75.307707  75.821711  74.601668   \n",
       "2440  46.320473  61.069086  78.216320  68.933371  76.296101  79.191328   \n",
       "2441  72.920214  48.609700  69.509795  71.538253  65.692645  72.449802   \n",
       "2442  70.828006  54.539941  68.782268  72.568965  79.268439  44.393526   \n",
       "\n",
       "       sensor47   sensor48  \n",
       "0     60.473752  72.292435  \n",
       "1     67.150721  49.406450  \n",
       "2     71.746000  73.450073  \n",
       "3     58.398246  76.749932  \n",
       "4     59.836285  68.951026  \n",
       "...         ...        ...  \n",
       "2438  82.282273  65.717778  \n",
       "2439  59.415883  67.166067  \n",
       "2440  78.368429  62.083876  \n",
       "2441  60.116178  81.836236  \n",
       "2442  61.642113  54.547595  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 16s 20ms/step - loss: 1413.2521 - val_loss: 1269.8562\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1249.7638 - val_loss: 1162.9574\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1155.5746 - val_loss: 1083.2125\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1085.6473 - val_loss: 1024.2413\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1033.9075 - val_loss: 981.4070\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 996.0420 - val_loss: 950.2610\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 968.4254 - val_loss: 929.3126\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 949.8751 - val_loss: 916.0420\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 938.0687 - val_loss: 908.2143\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 931.0492 - val_loss: 904.2026\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 927.1414 - val_loss: 902.3273\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.2667 - val_loss: 901.6881\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 924.4195 - val_loss: 901.6163\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.0831 - val_loss: 901.6521\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.9583 - val_loss: 901.6920\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 923.9216 - val_loss: 901.8006\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.9158 - val_loss: 901.8582\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 923.9432 - val_loss: 901.8296\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9017 - val_loss: 901.8719\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.9485 - val_loss: 901.9387\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9180 - val_loss: 901.7553\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9037 - val_loss: 901.7877\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9366 - val_loss: 901.7729\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.9524 - val_loss: 901.9130\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9056 - val_loss: 901.9702\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.9233 - val_loss: 901.7789\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.9213 - val_loss: 901.8479\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 923.9285 - val_loss: 901.8059\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9589 - val_loss: 901.8337\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.9564 - val_loss: 901.7578\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 923.9229 - val_loss: 901.8851\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9426 - val_loss: 901.8652\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.9332 - val_loss: 901.7802\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9458 - val_loss: 901.9330\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9022 - val_loss: 901.7572\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.9775 - val_loss: 900.5643\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.3310 - val_loss: 901.0779\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.9839 - val_loss: 901.2075\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.8746 - val_loss: 900.9081\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.4055 - val_loss: 884.9113\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 905.4099 - val_loss: 879.5804\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 898.7001 - val_loss: 874.0729\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 892.1850 - val_loss: 867.6215\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 884.7833 - val_loss: 860.3558\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 877.6702 - val_loss: 852.6407\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 869.5510 - val_loss: 843.5312\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 858.1340 - val_loss: 832.0927\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 843.9337 - val_loss: 825.8896\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 830.0706 - val_loss: 805.2072\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 815.8604 - val_loss: 790.0797\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 804.4704 - val_loss: 779.1144\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 788.2903 - val_loss: 768.4094\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 777.1300 - val_loss: 751.7550\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 756.0332 - val_loss: 738.6537\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 742.8195 - val_loss: 722.3729\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 727.3170 - val_loss: 709.0881\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 706.8522 - val_loss: 690.3401\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 686.3594 - val_loss: 672.3044\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 658.5861 - val_loss: 637.7617\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 632.1941 - val_loss: 623.2108\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 607.0247 - val_loss: 607.5043\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 584.4900 - val_loss: 574.1848\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 563.7302 - val_loss: 565.5716\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 546.8397 - val_loss: 570.2394\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 536.3991 - val_loss: 532.3089\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 516.6468 - val_loss: 541.2233\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 496.8921 - val_loss: 503.3086\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 481.9549 - val_loss: 486.2928\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 472.7895 - val_loss: 474.3918\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 456.1187 - val_loss: 478.6376\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 440.8160 - val_loss: 473.6588\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 425.8587 - val_loss: 452.9089\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 420.0032 - val_loss: 432.7216\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 408.8314 - val_loss: 452.2015\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 400.6052 - val_loss: 418.6701\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 384.1211 - val_loss: 399.4680\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 377.0351 - val_loss: 390.0047\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 369.3497 - val_loss: 378.4604\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 353.5440 - val_loss: 378.5988\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 344.3899 - val_loss: 358.7496\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 332.8198 - val_loss: 366.6968\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 328.4781 - val_loss: 382.8606\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 321.6992 - val_loss: 392.7947\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 313.9973 - val_loss: 338.0849\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 303.6071 - val_loss: 315.7528\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 291.8256 - val_loss: 314.1179\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 288.7850 - val_loss: 308.4116\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 281.4207 - val_loss: 291.9323\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 271.0937 - val_loss: 280.6554\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 264.7174 - val_loss: 296.0781\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 259.8454 - val_loss: 278.8015\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 256.9538 - val_loss: 274.2293\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 243.6649 - val_loss: 270.0766\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 240.7785 - val_loss: 278.3123\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 239.2085 - val_loss: 280.9877\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 232.9799 - val_loss: 238.3227\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 223.0302 - val_loss: 259.1694\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 216.7617 - val_loss: 246.5663\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 216.2932 - val_loss: 238.8441\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 213.1390 - val_loss: 241.3322\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 203.8675 - val_loss: 230.6422\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 203.9809 - val_loss: 230.5838\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 200.2117 - val_loss: 213.5038\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 193.6511 - val_loss: 230.7867\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 199.9072 - val_loss: 220.3890\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 190.3360 - val_loss: 219.4700\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 185.9043 - val_loss: 222.1961\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 185.7591 - val_loss: 209.6500\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 176.9525 - val_loss: 202.7741\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 179.1559 - val_loss: 209.0856\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 175.3955 - val_loss: 210.2689\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 172.3286 - val_loss: 205.3391\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 170.0444 - val_loss: 204.7541\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 169.4301 - val_loss: 200.5356\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 165.1907 - val_loss: 204.8607\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 162.2587 - val_loss: 221.8528\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 162.5987 - val_loss: 194.3958\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 158.7364 - val_loss: 207.6996\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 158.2655 - val_loss: 196.0130\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 158.0467 - val_loss: 216.8537\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 152.2121 - val_loss: 198.4924\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 150.3903 - val_loss: 204.5571\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 150.6658 - val_loss: 199.7517\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 148.1034 - val_loss: 191.6767\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 147.1951 - val_loss: 202.6519\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 145.4791 - val_loss: 192.2393\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 144.3524 - val_loss: 207.0365\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 141.0959 - val_loss: 202.0241\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 139.5315 - val_loss: 194.5976\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 137.0076 - val_loss: 194.3555\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 137.5746 - val_loss: 193.5092\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 135.0560 - val_loss: 193.9303\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 135.4643 - val_loss: 190.7994\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 133.4571 - val_loss: 190.6901\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 130.0350 - val_loss: 184.9025\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 130.1837 - val_loss: 188.8998\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 127.8751 - val_loss: 198.1483\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.5124 - val_loss: 193.1361\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 122.1458 - val_loss: 191.8005\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 122.9348 - val_loss: 185.9902\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 120.8116 - val_loss: 191.3285\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 118.5063 - val_loss: 185.5989\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 118.4228 - val_loss: 201.1008\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 116.7807 - val_loss: 183.0810\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 114.2406 - val_loss: 183.2582\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 115.4716 - val_loss: 197.0592\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 110.1533 - val_loss: 182.7595\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 111.8114 - val_loss: 186.4463\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 107.6932 - val_loss: 194.6904\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 109.3987 - val_loss: 186.1710\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 109.7358 - val_loss: 185.7081\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 102.3670 - val_loss: 183.8401\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 17ms/step - loss: 103.8724 - val_loss: 187.7546\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 102.8937 - val_loss: 190.8435\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 100.0638 - val_loss: 189.6190\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.8037 - val_loss: 182.4386\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 99.8105 - val_loss: 181.6170\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 97.9748 - val_loss: 198.5689\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 95.7439 - val_loss: 189.7612\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 96.3601 - val_loss: 190.1196\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 93.9645 - val_loss: 186.6311\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 92.8445 - val_loss: 190.4749\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 95.0098 - val_loss: 186.4564\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 91.3624 - val_loss: 195.5871\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 89.4211 - val_loss: 193.7748\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 86.5646 - val_loss: 196.4113\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 87.9467 - val_loss: 196.1648\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 88.4122 - val_loss: 210.2336\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 86.8435 - val_loss: 196.5851\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 80.1704 - val_loss: 194.9070\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 82.8776 - val_loss: 195.9124\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 80.5785 - val_loss: 196.0178\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 80.0475 - val_loss: 191.9030\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 77.4995 - val_loss: 192.4946\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 77.6612 - val_loss: 197.6695\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 77.3787 - val_loss: 192.4492\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 75.7223 - val_loss: 193.8260\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 74.2153 - val_loss: 197.5938\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 72.4542 - val_loss: 198.3439\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 70.9833 - val_loss: 202.8669\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 72.3960 - val_loss: 209.8448\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 71.7982 - val_loss: 204.3459\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 69.5953 - val_loss: 190.6614\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 69.3155 - val_loss: 201.3921\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 71.3984 - val_loss: 195.3212\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 66.9167 - val_loss: 199.0705\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 64.0255 - val_loss: 199.2777\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 65.1232 - val_loss: 194.6412\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 61.9489 - val_loss: 196.8159\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.1032 - val_loss: 197.5712\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 60.1050 - val_loss: 201.5725\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 61.4575 - val_loss: 200.7481\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 62.9096 - val_loss: 205.2013\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 58.8296 - val_loss: 200.1736\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.6559 - val_loss: 200.2602\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 58.6669 - val_loss: 199.0309\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.9207 - val_loss: 201.4411\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 57.4424 - val_loss: 200.4018\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 55.9295 - val_loss: 193.8809\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 51.6878 - val_loss: 219.7320\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 219.73180777446032\n",
      "Mean Absolute Error (MAE): 10.921935162456831\n",
      "Root Mean Squared Error (RMSE): 14.823353459135364\n",
      "Time taken: 1290.900950908661\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 20ms/step - loss: 1343.5823 - val_loss: 1310.8070\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1189.2941 - val_loss: 1213.9481\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1106.2615 - val_loss: 1142.6666\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1043.8519 - val_loss: 1088.7152\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 998.2390 - val_loss: 1049.6079\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 964.5662 - val_loss: 1020.7750\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 941.0941 - val_loss: 1001.5940\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.8299 - val_loss: 989.2209\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 916.3559 - val_loss: 981.8187\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 910.8961 - val_loss: 977.7365\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 908.0558 - val_loss: 975.6008\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 906.7974 - val_loss: 974.5457\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 906.2579 - val_loss: 974.1415\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0852 - val_loss: 973.9869\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0405 - val_loss: 973.9207\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0255 - val_loss: 973.8918\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0333 - val_loss: 973.9681\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 906.0412 - val_loss: 973.8964\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 905.9956 - val_loss: 973.9759\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0226 - val_loss: 973.9091\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0922 - val_loss: 973.8220\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0204 - val_loss: 974.0923\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0345 - val_loss: 973.8442\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 905.9993 - val_loss: 973.9434\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0447 - val_loss: 973.8224\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0300 - val_loss: 973.8752\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0627 - val_loss: 973.8511\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0075 - val_loss: 974.0467\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0203 - val_loss: 973.8371\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0212 - val_loss: 973.9304\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0213 - val_loss: 974.1035\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0385 - val_loss: 974.0187\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0518 - val_loss: 974.0311\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0402 - val_loss: 973.9551\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0385 - val_loss: 973.9969\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0300 - val_loss: 974.0372\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0453 - val_loss: 973.7900\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0023 - val_loss: 973.7503\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 906.0528 - val_loss: 973.7705\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0146 - val_loss: 973.9462\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.6380 - val_loss: 976.3256\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.2202 - val_loss: 975.2062\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.1321 - val_loss: 974.8270\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0394 - val_loss: 974.4802\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0462 - val_loss: 974.4008\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.0599 - val_loss: 974.3088\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 906.0708 - val_loss: 974.2869\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 905.9965 - val_loss: 974.1566\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 906.0250 - val_loss: 974.2074\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 906.0743 - val_loss: 974.2139\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 906.0199 - val_loss: 974.0040\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0272 - val_loss: 974.1286\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 905.9963 - val_loss: 978.1599\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 904.9661 - val_loss: 955.7631\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 891.6505 - val_loss: 950.2178\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 898.9088 - val_loss: 977.9006\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.4277 - val_loss: 975.6539\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 906.2663 - val_loss: 975.5048\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 906.1882 - val_loss: 974.4515\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.1070 - val_loss: 974.3762\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.1502 - val_loss: 973.8091\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0359 - val_loss: 973.7704\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 905.9937 - val_loss: 972.9120\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 900.8643 - val_loss: 954.8401\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 872.1484 - val_loss: 923.5720\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 847.9178 - val_loss: 910.7385\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 826.1620 - val_loss: 875.8940\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 793.0659 - val_loss: 848.5361\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 771.3858 - val_loss: 824.0113\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 743.5085 - val_loss: 795.5425\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 719.9311 - val_loss: 769.1096\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 697.0919 - val_loss: 743.3776\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 671.6989 - val_loss: 734.1922\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 650.4238 - val_loss: 691.6567\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 633.8240 - val_loss: 674.1041\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 612.4697 - val_loss: 649.0290\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 588.8558 - val_loss: 653.6035\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 573.2823 - val_loss: 611.4673\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 551.8893 - val_loss: 598.6750\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 540.2606 - val_loss: 578.3837\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 528.1016 - val_loss: 560.3693\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 504.4323 - val_loss: 548.1439\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 497.6294 - val_loss: 535.9496\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 479.5096 - val_loss: 520.0318\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 471.1851 - val_loss: 514.4486\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 460.9753 - val_loss: 492.7304\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 453.4579 - val_loss: 489.9431\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 439.8083 - val_loss: 472.7119\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 424.3069 - val_loss: 458.9986\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 414.9121 - val_loss: 449.5419\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 410.9432 - val_loss: 443.3438\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 400.1520 - val_loss: 429.5881\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 391.9478 - val_loss: 424.6234\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 387.8290 - val_loss: 418.9588\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 379.2471 - val_loss: 414.5366\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 375.9109 - val_loss: 423.6515\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 366.9180 - val_loss: 388.7865\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 361.3846 - val_loss: 393.3702\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 354.0560 - val_loss: 376.2018\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 350.1872 - val_loss: 371.0617\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 346.6478 - val_loss: 364.5460\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 339.2815 - val_loss: 372.9852\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 331.7649 - val_loss: 366.1676\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 328.2701 - val_loss: 351.7284\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 325.1609 - val_loss: 346.7237\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 324.5154 - val_loss: 363.2408\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 315.7727 - val_loss: 341.8474\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 310.9736 - val_loss: 338.7194\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 305.0689 - val_loss: 337.7139\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 296.2141 - val_loss: 327.7261\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 291.3222 - val_loss: 332.4263\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 288.5755 - val_loss: 324.7964\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 276.9986 - val_loss: 320.2249\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 269.4554 - val_loss: 313.5740\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 259.3447 - val_loss: 284.8264\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 255.8989 - val_loss: 287.4487\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 246.3527 - val_loss: 275.3997\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 238.7054 - val_loss: 269.4464\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 228.6393 - val_loss: 258.5820\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 222.4014 - val_loss: 249.9073\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 219.4006 - val_loss: 259.0737\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 211.3217 - val_loss: 241.4670\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 205.2110 - val_loss: 241.6161\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 197.9995 - val_loss: 237.9425\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 192.1131 - val_loss: 235.0052\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 188.0138 - val_loss: 235.4522\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 184.2460 - val_loss: 221.9044\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 181.8160 - val_loss: 217.6581\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 174.3794 - val_loss: 223.4537\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 170.3468 - val_loss: 218.3943\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 170.5140 - val_loss: 214.4859\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 166.4691 - val_loss: 207.5561\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 163.9139 - val_loss: 214.2916\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 158.8894 - val_loss: 214.1701\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 153.0783 - val_loss: 205.4399\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 152.2035 - val_loss: 206.8655\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 150.6203 - val_loss: 204.3801\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 149.7466 - val_loss: 210.1510\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 144.1320 - val_loss: 198.2105\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 142.6655 - val_loss: 213.4991\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 142.1335 - val_loss: 233.8075\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 139.4589 - val_loss: 200.2124\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 134.3188 - val_loss: 195.7563\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 136.2697 - val_loss: 200.4620\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 129.0907 - val_loss: 194.6192\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 128.5311 - val_loss: 200.8530\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.9986 - val_loss: 191.8513\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 124.7422 - val_loss: 200.2113\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 123.0471 - val_loss: 192.9424\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 117.7165 - val_loss: 194.1744\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 117.5815 - val_loss: 187.3140\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 115.6363 - val_loss: 196.2177\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 113.8978 - val_loss: 194.1636\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 112.7881 - val_loss: 211.7575\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 108.7968 - val_loss: 192.2414\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 111.1386 - val_loss: 195.3923\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 105.3738 - val_loss: 198.0247\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 105.2448 - val_loss: 198.8904\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.4660 - val_loss: 200.8344\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 102.2899 - val_loss: 198.2138\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 99.5531 - val_loss: 205.7198\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 101.4435 - val_loss: 197.6091\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 94.1794 - val_loss: 199.8945\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 97.6371 - val_loss: 206.9284\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 94.6960 - val_loss: 210.4379\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 93.3175 - val_loss: 211.6190\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 86.6545 - val_loss: 195.3340\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 90.3263 - val_loss: 197.2452\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 90.5426 - val_loss: 196.8499\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 85.6545 - val_loss: 193.7107\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 83.3967 - val_loss: 192.2537\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 82.2333 - val_loss: 191.6195\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 82.3764 - val_loss: 209.7119\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 81.0599 - val_loss: 211.1075\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 78.0500 - val_loss: 202.5882\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 75.5627 - val_loss: 199.8072\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 72.4880 - val_loss: 207.5331\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.5827 - val_loss: 202.4328\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.8782 - val_loss: 201.3107\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 69.7095 - val_loss: 206.0322\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 69.2037 - val_loss: 201.7055\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 67.7213 - val_loss: 204.4814\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 64.9461 - val_loss: 200.8162\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 66.5021 - val_loss: 202.2023\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 65.1998 - val_loss: 211.7047\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 62.9500 - val_loss: 202.0536\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 60.6536 - val_loss: 200.7440\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 57.4791 - val_loss: 201.4280\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.0605 - val_loss: 203.8225\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 57.6354 - val_loss: 202.6391\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 54.3174 - val_loss: 209.1799\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 54.1485 - val_loss: 202.4127\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 52.5726 - val_loss: 205.2284\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 51.3457 - val_loss: 209.7467\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 52.2815 - val_loss: 209.6266\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 49.1846 - val_loss: 221.1604\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 47.6333 - val_loss: 211.5797\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 45.0625 - val_loss: 214.4921\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 46.4880 - val_loss: 205.4039\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 49.3589 - val_loss: 214.3738\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 214.3737889801016\n",
      "Mean Absolute Error (MAE): 10.617937361033855\n",
      "Root Mean Squared Error (RMSE): 14.641509108698516\n",
      "Time taken: 1235.0915839672089\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 1390.5811 - val_loss: 1259.4608\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1230.3280 - val_loss: 1157.9426\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1141.4965 - val_loss: 1081.1367\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1074.6080 - val_loss: 1024.2911\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1025.4741 - val_loss: 982.4531\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 989.7122 - val_loss: 952.2744\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 964.3074 - val_loss: 931.2694\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 947.2405 - val_loss: 917.5718\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 936.4145 - val_loss: 909.0279\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 930.0552 - val_loss: 904.4084\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.7100 - val_loss: 901.9726\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.1160 - val_loss: 900.8516\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4571 - val_loss: 900.3710\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.1725 - val_loss: 900.2610\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 924.0947 - val_loss: 900.2487\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0748 - val_loss: 900.2189\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.1218 - val_loss: 900.1967\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1069 - val_loss: 900.2493\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.1267 - val_loss: 900.2260\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1185 - val_loss: 900.2211\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0850 - val_loss: 900.1962\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 924.1056 - val_loss: 900.2325\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.1048 - val_loss: 900.2228\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0675 - val_loss: 900.1934\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1099 - val_loss: 900.2622\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0647 - val_loss: 900.2292\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0726 - val_loss: 900.1866\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.0769 - val_loss: 900.2333\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1196 - val_loss: 900.1646\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0636 - val_loss: 900.2437\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.1041 - val_loss: 900.2352\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1188 - val_loss: 900.2226\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.1033 - val_loss: 900.2102\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 924.0770 - val_loss: 900.2286\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.0832 - val_loss: 900.1917\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0826 - val_loss: 900.1940\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0754 - val_loss: 900.1535\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 918.6957 - val_loss: 884.8397\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 906.5455 - val_loss: 880.9772\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 900.6852 - val_loss: 874.5475\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 894.6345 - val_loss: 867.2816\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 886.7420 - val_loss: 861.4358\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 878.3881 - val_loss: 854.2149\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 868.2156 - val_loss: 842.9590\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 856.2020 - val_loss: 828.4837\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 843.3248 - val_loss: 816.3692\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 829.1590 - val_loss: 800.5103\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 813.7639 - val_loss: 785.5580\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 795.1265 - val_loss: 763.0834\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 776.1329 - val_loss: 744.8536\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 754.0333 - val_loss: 719.1342\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 730.2782 - val_loss: 700.4529\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 707.4110 - val_loss: 679.7157\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 685.9354 - val_loss: 654.0760\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 665.6600 - val_loss: 634.8482\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 640.1166 - val_loss: 618.1097\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 625.1785 - val_loss: 605.9920\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 605.1064 - val_loss: 590.8914\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 589.8152 - val_loss: 560.8662\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 569.4369 - val_loss: 563.1630\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 553.8848 - val_loss: 534.9026\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 541.2173 - val_loss: 515.6049\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 527.4555 - val_loss: 542.9691\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 511.1940 - val_loss: 514.7263\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 499.3474 - val_loss: 476.5589\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 486.6119 - val_loss: 465.3007\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 473.1351 - val_loss: 448.7220\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 460.5984 - val_loss: 445.9477\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 451.0840 - val_loss: 432.6380\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 439.9082 - val_loss: 413.3151\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 419.2194 - val_loss: 399.7654\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 409.7894 - val_loss: 390.9317\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 401.6660 - val_loss: 389.8714\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 390.2469 - val_loss: 367.0506\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 376.6577 - val_loss: 354.6495\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 366.0470 - val_loss: 351.0861\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 354.8641 - val_loss: 346.7814\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 350.6114 - val_loss: 333.6234\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 348.3737 - val_loss: 331.6908\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 336.9487 - val_loss: 323.9344\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 325.1765 - val_loss: 321.9005\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 315.2839 - val_loss: 333.5014\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 311.6483 - val_loss: 305.8505\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 306.0531 - val_loss: 302.9438\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 296.3211 - val_loss: 294.6422\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 291.6480 - val_loss: 281.6762\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 290.4654 - val_loss: 294.2711\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 281.6686 - val_loss: 277.7178\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 272.8618 - val_loss: 268.9843\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 261.3322 - val_loss: 264.6836\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 255.9142 - val_loss: 261.5768\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 249.5439 - val_loss: 249.5261\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 244.4773 - val_loss: 265.6642\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 241.8664 - val_loss: 256.9684\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 236.0799 - val_loss: 248.4137\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 234.2109 - val_loss: 261.0827\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 234.4989 - val_loss: 244.7546\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 226.1136 - val_loss: 229.2014\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 220.1320 - val_loss: 250.3771\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 218.1852 - val_loss: 277.6637\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 216.4453 - val_loss: 239.7052\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 209.9798 - val_loss: 232.8051\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 205.6588 - val_loss: 219.8511\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 204.2123 - val_loss: 225.2711\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 199.8917 - val_loss: 216.0364\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 203.0797 - val_loss: 213.6563\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 195.2411 - val_loss: 205.8036\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 189.6069 - val_loss: 227.5095\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 193.5343 - val_loss: 218.7061\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 189.7075 - val_loss: 206.6327\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 184.2141 - val_loss: 232.2897\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 185.8611 - val_loss: 229.4920\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 183.6826 - val_loss: 206.7475\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 181.3720 - val_loss: 224.1380\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 184.6332 - val_loss: 208.3231\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 183.9781 - val_loss: 209.5455\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 176.7222 - val_loss: 209.7793\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 175.7159 - val_loss: 214.0575\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 172.8669 - val_loss: 204.2870\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 172.1120 - val_loss: 211.5916\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 171.4460 - val_loss: 206.0718\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 169.7631 - val_loss: 198.3408\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 166.6085 - val_loss: 199.3133\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 168.0173 - val_loss: 202.7655\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 166.5954 - val_loss: 199.9704\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 164.7390 - val_loss: 192.0961\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 158.9508 - val_loss: 208.6116\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 159.3070 - val_loss: 192.6582\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 160.0729 - val_loss: 214.2148\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 159.0875 - val_loss: 215.4201\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 160.3744 - val_loss: 214.6201\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 157.5868 - val_loss: 215.4926\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 156.3068 - val_loss: 199.6145\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 154.7451 - val_loss: 204.0548\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 153.3395 - val_loss: 202.0503\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 152.2054 - val_loss: 204.4154\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 153.0050 - val_loss: 199.9995\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 149.8006 - val_loss: 199.1236\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 149.4060 - val_loss: 184.9500\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 146.7157 - val_loss: 194.0220\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 149.8917 - val_loss: 201.9298\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 146.3616 - val_loss: 201.2502\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 147.7776 - val_loss: 191.4680\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 144.2598 - val_loss: 189.9378\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 143.5427 - val_loss: 195.3413\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 141.6629 - val_loss: 197.4366\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 141.5527 - val_loss: 188.5785\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 141.7680 - val_loss: 211.3386\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 138.7852 - val_loss: 191.9928\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 140.3824 - val_loss: 191.6397\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 138.8611 - val_loss: 196.2642\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 135.9330 - val_loss: 197.2069\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 137.9782 - val_loss: 224.6790\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 136.8904 - val_loss: 189.8305\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 135.3176 - val_loss: 222.6299\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 135.4006 - val_loss: 198.2410\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 134.9552 - val_loss: 191.2838\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 130.3942 - val_loss: 195.6648\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 134.3893 - val_loss: 190.3361\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 128.1758 - val_loss: 199.8189\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 131.8996 - val_loss: 191.6090\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 129.7575 - val_loss: 193.0840\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.9005 - val_loss: 183.0846\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 127.1787 - val_loss: 194.7904\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 129.0331 - val_loss: 192.9477\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 124.6404 - val_loss: 195.2480\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.3174 - val_loss: 194.6970\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 125.6647 - val_loss: 187.0126\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 123.1810 - val_loss: 187.5027\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 120.6596 - val_loss: 205.0577\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 121.2124 - val_loss: 201.8950\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 122.1341 - val_loss: 190.9921\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 121.0583 - val_loss: 190.6406\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 118.6331 - val_loss: 195.9303\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 117.0451 - val_loss: 196.4001\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 118.2103 - val_loss: 197.8796\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 118.0416 - val_loss: 192.5002\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 116.6140 - val_loss: 186.8410\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 113.8573 - val_loss: 187.9841\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 113.9789 - val_loss: 192.8875\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 114.2713 - val_loss: 193.7149\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 112.0969 - val_loss: 186.3110\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 108.7897 - val_loss: 187.9234\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 111.2874 - val_loss: 190.7059\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 110.3041 - val_loss: 200.4446\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 109.1421 - val_loss: 203.4900\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 113.5006 - val_loss: 208.1339\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 107.6706 - val_loss: 197.5061\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 107.3359 - val_loss: 189.5291\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 105.1747 - val_loss: 199.1386\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 104.9353 - val_loss: 196.5136\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.6942 - val_loss: 191.4379\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.3282 - val_loss: 202.1042\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 103.5677 - val_loss: 199.1494\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 102.4470 - val_loss: 194.6078\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.0328 - val_loss: 193.6197\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 101.2524 - val_loss: 194.6714\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 99.8592 - val_loss: 197.9050\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 99.5310 - val_loss: 194.8317\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.2038 - val_loss: 198.6427\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 198.64280201585154\n",
      "Mean Absolute Error (MAE): 10.52502126319974\n",
      "Root Mean Squared Error (RMSE): 14.094069746380978\n",
      "Time taken: 1222.277931213379\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 17ms/step - loss: 1382.5748 - val_loss: 1289.3496\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1220.6692 - val_loss: 1186.8958\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1132.8788 - val_loss: 1110.9490\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1067.6904 - val_loss: 1054.2660\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1019.1398 - val_loss: 1011.9124\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 983.4229 - val_loss: 981.0894\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 958.2203 - val_loss: 959.6760\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 941.0633 - val_loss: 945.3995\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 930.2231 - val_loss: 936.5000\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.7891 - val_loss: 931.3790\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.4122 - val_loss: 928.6344\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 918.7388 - val_loss: 927.2853\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 918.0406 - val_loss: 926.6411\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.7637 - val_loss: 926.5056\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6844 - val_loss: 926.3625\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6447 - val_loss: 926.2272\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6281 - val_loss: 926.2162\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6234 - val_loss: 926.2818\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6384 - val_loss: 926.2610\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6295 - val_loss: 926.2525\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6265 - val_loss: 926.2262\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6682 - val_loss: 926.1564\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6647 - val_loss: 926.1865\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 917.6259 - val_loss: 926.2424\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 917.6338 - val_loss: 926.2593\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6441 - val_loss: 926.2996\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6240 - val_loss: 926.1542\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.6245 - val_loss: 926.2476\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6669 - val_loss: 926.2411\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6486 - val_loss: 926.2515\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.6295 - val_loss: 926.2255\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6476 - val_loss: 926.2147\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6393 - val_loss: 926.1618\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6345 - val_loss: 926.2630\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6370 - val_loss: 926.2560\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6284 - val_loss: 926.2582\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6609 - val_loss: 926.1606\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6215 - val_loss: 926.2717\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6225 - val_loss: 926.1290\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6342 - val_loss: 926.2766\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6362 - val_loss: 926.2485\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6642 - val_loss: 926.1787\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 917.6473 - val_loss: 926.1516\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6260 - val_loss: 926.1598\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6815 - val_loss: 926.1250\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6506 - val_loss: 926.2277\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6692 - val_loss: 926.1317\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.6345 - val_loss: 926.2474\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.6204 - val_loss: 926.2352\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.6419 - val_loss: 926.2541\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.6382 - val_loss: 926.2703\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.6415 - val_loss: 926.2869\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6146 - val_loss: 926.2111\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6282 - val_loss: 926.2120\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6381 - val_loss: 926.2488\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6327 - val_loss: 926.1776\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6465 - val_loss: 926.2112\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.9333 - val_loss: 926.2502\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.7122 - val_loss: 926.0924\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6738 - val_loss: 926.1427\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6578 - val_loss: 926.2271\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.6393 - val_loss: 926.1970\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 917.6411 - val_loss: 926.2870\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 917.6579 - val_loss: 926.1815\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 917.4095 - val_loss: 925.5259\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 914.5992 - val_loss: 918.4367\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 903.7585 - val_loss: 909.2866\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 895.3402 - val_loss: 903.7776\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 889.6415 - val_loss: 898.3954\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 883.4413 - val_loss: 893.5024\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 876.5179 - val_loss: 885.0406\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 869.2164 - val_loss: 874.3234\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 856.8505 - val_loss: 860.0687\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 841.9231 - val_loss: 841.9442\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 829.2599 - val_loss: 828.9842\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 810.6686 - val_loss: 795.4500\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 780.7916 - val_loss: 765.3247\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 752.5618 - val_loss: 738.3505\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 725.4749 - val_loss: 702.4252\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 696.1443 - val_loss: 686.6566\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 674.1698 - val_loss: 662.0408\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 649.5400 - val_loss: 651.8575\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 627.8729 - val_loss: 607.6064\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 608.8741 - val_loss: 586.5287\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 586.6041 - val_loss: 575.0058\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 572.9454 - val_loss: 557.7529\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 552.1743 - val_loss: 533.4892\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 536.5351 - val_loss: 531.0606\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 519.7780 - val_loss: 501.0762\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 511.3939 - val_loss: 493.2660\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 495.8707 - val_loss: 481.7485\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 481.2420 - val_loss: 459.7174\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 469.8416 - val_loss: 457.2021\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 457.0095 - val_loss: 457.8007\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 447.1171 - val_loss: 428.1765\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 437.9430 - val_loss: 411.9364\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 425.0526 - val_loss: 409.6602\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 414.5787 - val_loss: 427.6178\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 407.7761 - val_loss: 399.7956\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 395.5226 - val_loss: 394.9930\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 392.0139 - val_loss: 376.7561\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 384.3498 - val_loss: 371.3129\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 374.4205 - val_loss: 355.1950\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 374.9536 - val_loss: 380.7688\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 367.9279 - val_loss: 354.3346\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 356.3494 - val_loss: 361.6027\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 353.5511 - val_loss: 338.4360\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 351.1019 - val_loss: 340.5493\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 341.4064 - val_loss: 341.3607\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 338.6029 - val_loss: 337.3081\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 333.6852 - val_loss: 330.6107\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 327.0377 - val_loss: 337.5477\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 317.6768 - val_loss: 315.9954\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 315.7928 - val_loss: 315.0947\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 310.5011 - val_loss: 313.4602\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 302.3442 - val_loss: 315.2456\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 302.5405 - val_loss: 299.0833\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 294.0616 - val_loss: 286.4659\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 289.6793 - val_loss: 292.8649\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 288.5089 - val_loss: 290.3765\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 287.1548 - val_loss: 300.8810\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 281.7626 - val_loss: 284.3175\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 272.9293 - val_loss: 283.6678\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 271.5554 - val_loss: 267.2583\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 268.1557 - val_loss: 271.5935\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 270.9547 - val_loss: 264.7088\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 270.9969 - val_loss: 273.4384\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 262.0833 - val_loss: 269.3721\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 263.5241 - val_loss: 254.2431\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 254.9237 - val_loss: 248.8062\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 255.4623 - val_loss: 269.1063\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 253.1045 - val_loss: 253.5085\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 243.8515 - val_loss: 263.4170\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 246.4717 - val_loss: 244.4882\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 239.0529 - val_loss: 248.7270\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 237.8964 - val_loss: 240.2083\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 233.0050 - val_loss: 248.3686\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 232.2797 - val_loss: 236.0937\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 229.1396 - val_loss: 232.1241\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 224.5435 - val_loss: 254.4624\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 223.9318 - val_loss: 224.2237\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 223.5631 - val_loss: 245.7963\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 218.7702 - val_loss: 264.0182\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 220.9517 - val_loss: 223.4697\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 219.5715 - val_loss: 250.7351\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 212.1214 - val_loss: 220.3793\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 210.7666 - val_loss: 218.5705\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 208.2904 - val_loss: 213.2585\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 207.9428 - val_loss: 217.5442\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 204.7876 - val_loss: 219.7723\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 208.2535 - val_loss: 222.8498\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 199.8933 - val_loss: 223.1726\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 204.9706 - val_loss: 241.4916\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 205.5924 - val_loss: 215.6324\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 203.1798 - val_loss: 203.9112\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 195.9127 - val_loss: 213.0293\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 189.6241 - val_loss: 198.1923\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 190.7800 - val_loss: 218.2778\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 195.4575 - val_loss: 205.1956\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 189.2091 - val_loss: 208.4814\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 184.2907 - val_loss: 211.6039\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 190.3855 - val_loss: 228.6167\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 187.5462 - val_loss: 230.7944\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 181.9483 - val_loss: 212.3086\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 185.1237 - val_loss: 204.7153\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 187.1617 - val_loss: 207.6981\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 179.4931 - val_loss: 205.0564\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 180.1794 - val_loss: 203.3211\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 177.1114 - val_loss: 201.6107\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 178.0230 - val_loss: 201.6758\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 177.1689 - val_loss: 201.9893\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 174.7505 - val_loss: 206.4317\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 166.1389 - val_loss: 218.0805\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 173.9583 - val_loss: 213.7880\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 169.4786 - val_loss: 191.4566\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 170.4418 - val_loss: 201.3785\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 166.6854 - val_loss: 197.7402\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 162.3585 - val_loss: 197.3334\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 167.4859 - val_loss: 197.0511\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 163.7606 - val_loss: 205.1048\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 159.1743 - val_loss: 199.7523\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 164.7495 - val_loss: 195.5669\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 162.0110 - val_loss: 203.1455\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 159.6563 - val_loss: 196.1053\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 154.9834 - val_loss: 205.0482\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 160.8577 - val_loss: 185.2402\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 154.5289 - val_loss: 199.5933\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 156.7157 - val_loss: 194.4749\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 151.8924 - val_loss: 201.7719\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 149.1704 - val_loss: 199.0523\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 147.7075 - val_loss: 185.9748\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 153.1178 - val_loss: 203.3472\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 152.9405 - val_loss: 184.3907\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 144.1149 - val_loss: 190.5860\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 148.0462 - val_loss: 196.2538\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 148.3264 - val_loss: 197.0942\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 143.8955 - val_loss: 187.2465\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 148.1543 - val_loss: 192.5643\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 143.2024 - val_loss: 184.0419\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 139.4057 - val_loss: 191.2721\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 191.27311359531834\n",
      "Mean Absolute Error (MAE): 10.51940216475605\n",
      "Root Mean Squared Error (RMSE): 13.830152334494308\n",
      "Time taken: 1185.9016501903534\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 1380.9352 - val_loss: 1257.3027\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1221.1593 - val_loss: 1157.1619\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1136.4159 - val_loss: 1083.3751\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1072.7490 - val_loss: 1027.2722\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1024.0715 - val_loss: 984.6575\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 988.6403 - val_loss: 954.0735\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 963.8544 - val_loss: 932.9815\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 947.0533 - val_loss: 919.0111\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 936.4135 - val_loss: 910.2452\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 930.1401 - val_loss: 905.0726\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.7159 - val_loss: 902.4695\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.1306 - val_loss: 901.1382\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4697 - val_loss: 900.6245\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.2365 - val_loss: 900.3621\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.1503 - val_loss: 900.1918\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0879 - val_loss: 900.1630\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0589 - val_loss: 900.1688\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1273 - val_loss: 900.1597\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0917 - val_loss: 900.1749\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0781 - val_loss: 900.2682\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1110 - val_loss: 900.2155\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0670 - val_loss: 900.2037\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1035 - val_loss: 900.1590\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0760 - val_loss: 900.2547\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0956 - val_loss: 900.2228\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0573 - val_loss: 900.2437\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1040 - val_loss: 900.2341\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0750 - val_loss: 900.1379\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0749 - val_loss: 900.2022\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.1031 - val_loss: 900.2070\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.0835 - val_loss: 900.2353\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.0818 - val_loss: 900.2528\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.0822 - val_loss: 900.1826\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.0458 - val_loss: 900.2187\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0659 - val_loss: 900.2161\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0583 - val_loss: 900.2418\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0947 - val_loss: 900.2428\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0942 - val_loss: 900.2041\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.0687 - val_loss: 900.2163\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.9722 - val_loss: 899.2318\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.4278 - val_loss: 890.0255\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 903.5528 - val_loss: 874.8073\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 896.9119 - val_loss: 870.8357\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 890.2113 - val_loss: 860.0459\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 882.6570 - val_loss: 853.9938\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 875.4682 - val_loss: 850.3862\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 866.2795 - val_loss: 835.2568\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 855.8970 - val_loss: 824.6292\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 843.7576 - val_loss: 813.8534\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 831.8568 - val_loss: 804.2519\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 815.1210 - val_loss: 794.4617\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 801.8829 - val_loss: 783.2292\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 788.7749 - val_loss: 773.3225\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 771.3866 - val_loss: 757.1922\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 753.3709 - val_loss: 736.9057\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 736.2104 - val_loss: 720.2730\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 718.4449 - val_loss: 703.8439\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 700.2108 - val_loss: 676.5733\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 677.0226 - val_loss: 658.8103\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 657.3379 - val_loss: 639.0635\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 636.5824 - val_loss: 617.8097\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 618.1066 - val_loss: 607.4617\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 594.0603 - val_loss: 580.1697\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 580.2602 - val_loss: 560.8735\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 563.9094 - val_loss: 551.7789\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 541.5774 - val_loss: 526.7454\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 521.9935 - val_loss: 520.7880\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 511.6067 - val_loss: 508.6867\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 489.2647 - val_loss: 479.7815\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 485.6371 - val_loss: 490.3904\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 461.5584 - val_loss: 473.9615\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 450.4716 - val_loss: 442.5019\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 440.1223 - val_loss: 437.2063\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 422.4537 - val_loss: 428.8326\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 414.9919 - val_loss: 432.8112\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 412.6424 - val_loss: 414.8417\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 392.1736 - val_loss: 399.0152\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 388.1382 - val_loss: 407.0841\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 374.6078 - val_loss: 392.2279\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 363.9277 - val_loss: 430.9668\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 357.0364 - val_loss: 370.9016\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 354.0956 - val_loss: 367.9714\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 344.0862 - val_loss: 388.5771\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 337.6365 - val_loss: 355.8651\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 328.7768 - val_loss: 367.9355\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 319.6046 - val_loss: 356.7262\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 317.4214 - val_loss: 343.5729\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 311.8950 - val_loss: 341.8420\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 303.5071 - val_loss: 336.3372\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 293.9910 - val_loss: 340.2755\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 293.8020 - val_loss: 328.7346\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 290.2591 - val_loss: 318.0406\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 278.9226 - val_loss: 343.1676\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 281.5843 - val_loss: 316.5450\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 272.8002 - val_loss: 312.3840\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 268.7223 - val_loss: 310.4812\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 262.3632 - val_loss: 304.9872\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 257.5679 - val_loss: 318.4416\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 258.4244 - val_loss: 292.7563\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 263.2119 - val_loss: 295.7787\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 251.5733 - val_loss: 309.1710\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 250.7016 - val_loss: 318.3258\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 244.5690 - val_loss: 295.1992\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 244.2377 - val_loss: 311.8675\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 237.9917 - val_loss: 284.1091\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 235.0710 - val_loss: 283.3502\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 231.8320 - val_loss: 282.2314\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 227.2077 - val_loss: 272.9142\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 225.2168 - val_loss: 266.3105\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 222.0213 - val_loss: 271.7879\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 218.6713 - val_loss: 293.2006\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 216.1376 - val_loss: 269.6707\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 214.9424 - val_loss: 264.0122\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 214.2811 - val_loss: 252.1994\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 207.1096 - val_loss: 259.9868\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 204.9231 - val_loss: 267.4499\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 207.9914 - val_loss: 263.9425\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 205.1705 - val_loss: 269.1813\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 198.7382 - val_loss: 250.5229\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 199.8645 - val_loss: 252.6848\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 198.0902 - val_loss: 248.3919\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 197.2761 - val_loss: 268.9219\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 195.5917 - val_loss: 234.7354\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 189.8563 - val_loss: 246.3042\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 188.7458 - val_loss: 234.6671\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 184.8142 - val_loss: 241.8206\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 187.4816 - val_loss: 237.4466\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 187.3617 - val_loss: 242.2820\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 184.4111 - val_loss: 242.5523\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 184.3374 - val_loss: 244.8158\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 179.4125 - val_loss: 242.4026\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 180.8378 - val_loss: 238.5053\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 176.8318 - val_loss: 231.3441\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 173.2482 - val_loss: 237.8668\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 174.9960 - val_loss: 244.3948\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 175.2946 - val_loss: 250.0903\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 172.9953 - val_loss: 230.0738\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 170.9786 - val_loss: 229.2431\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 169.7249 - val_loss: 231.9009\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 170.1643 - val_loss: 217.0872\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 166.1485 - val_loss: 224.3515\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 168.9575 - val_loss: 221.2819\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 163.0447 - val_loss: 218.8449\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 165.5699 - val_loss: 229.7165\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 160.0632 - val_loss: 220.1387\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 161.2562 - val_loss: 222.3633\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 157.9708 - val_loss: 218.1139\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 158.8551 - val_loss: 228.1273\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 154.9564 - val_loss: 222.6093\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 155.6853 - val_loss: 219.3552\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 155.6738 - val_loss: 229.5231\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 154.6010 - val_loss: 225.2067\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 152.4909 - val_loss: 226.6704\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 148.3448 - val_loss: 235.8567\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 151.2910 - val_loss: 229.4932\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 146.5708 - val_loss: 223.7990\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 147.6881 - val_loss: 251.3719\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 146.9018 - val_loss: 223.2004\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 146.3354 - val_loss: 219.5314\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 144.2560 - val_loss: 228.2948\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 141.8532 - val_loss: 234.3823\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 140.2659 - val_loss: 213.7030\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 141.6284 - val_loss: 215.5037\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 142.4919 - val_loss: 219.8322\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 140.9194 - val_loss: 212.3631\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 137.1904 - val_loss: 212.6794\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 136.6846 - val_loss: 216.6539\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 136.3341 - val_loss: 220.0602\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 138.0823 - val_loss: 221.9188\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 133.8277 - val_loss: 215.9668\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 131.5846 - val_loss: 218.1563\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 132.0235 - val_loss: 214.9450\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 129.1651 - val_loss: 222.5731\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 127.4250 - val_loss: 220.1120\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 130.4841 - val_loss: 214.0811\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 129.9534 - val_loss: 217.3433\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 128.5277 - val_loss: 227.5582\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.7564 - val_loss: 211.9917\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 124.2249 - val_loss: 216.4482\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 123.0230 - val_loss: 220.4407\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 125.3757 - val_loss: 239.6856\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 124.1721 - val_loss: 209.3020\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 122.6248 - val_loss: 218.5582\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 121.2673 - val_loss: 209.3082\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 118.6568 - val_loss: 212.0793\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 118.8248 - val_loss: 217.2496\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 121.9671 - val_loss: 218.7785\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 117.9760 - val_loss: 211.8523\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 115.8688 - val_loss: 218.0556\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 114.7228 - val_loss: 206.1752\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 118.3906 - val_loss: 217.2375\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 113.7915 - val_loss: 212.2205\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 116.1909 - val_loss: 218.9742\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 112.1350 - val_loss: 220.0344\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 113.7097 - val_loss: 216.7118\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 111.6422 - val_loss: 218.8941\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 107.7599 - val_loss: 215.3633\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 107.1892 - val_loss: 211.6882\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 107.7377 - val_loss: 217.8564\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 106.2183 - val_loss: 215.9301\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 215.92846675820024\n",
      "Mean Absolute Error (MAE): 11.159530256433627\n",
      "Root Mean Squared Error (RMSE): 14.694504644873206\n",
      "Time taken: 1190.876050710678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 48, 512)           1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 48, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_17368\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold         MSE        MAE       RMSE   Time taken\n",
      "0        1  219.731808  10.921935  14.823353  1290.900951\n",
      "1        2  214.373789  10.617937  14.641509  1235.091584\n",
      "2        3  198.642802  10.525021  14.094070  1222.277931\n",
      "3        4  191.273114  10.519402  13.830152  1185.901650\n",
      "4        5  215.928467  11.159530  14.694505  1190.876051\n",
      "5  Average  207.989996  10.748765  14.416718  1225.009633\n",
      "Results saved to 'DL_Result_PL_model_2_Scattered_Reg1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_2_Scattered_Reg1.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'DL_Result_PL_model_2_Scattered_Reg1.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
