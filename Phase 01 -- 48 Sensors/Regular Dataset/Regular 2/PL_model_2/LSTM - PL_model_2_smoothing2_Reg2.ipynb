{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_2_smoothing2_Reg2.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.632971</td>\n",
       "      <td>81.399266</td>\n",
       "      <td>77.250888</td>\n",
       "      <td>77.881737</td>\n",
       "      <td>87.606491</td>\n",
       "      <td>90.878011</td>\n",
       "      <td>83.683674</td>\n",
       "      <td>76.939886</td>\n",
       "      <td>77.811940</td>\n",
       "      <td>79.216417</td>\n",
       "      <td>...</td>\n",
       "      <td>80.122692</td>\n",
       "      <td>77.439776</td>\n",
       "      <td>80.094806</td>\n",
       "      <td>69.037217</td>\n",
       "      <td>92.465980</td>\n",
       "      <td>80.227891</td>\n",
       "      <td>82.639231</td>\n",
       "      <td>81.956382</td>\n",
       "      <td>68.796643</td>\n",
       "      <td>79.465122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.894162</td>\n",
       "      <td>81.456455</td>\n",
       "      <td>76.972121</td>\n",
       "      <td>77.906493</td>\n",
       "      <td>87.566765</td>\n",
       "      <td>90.759398</td>\n",
       "      <td>83.613337</td>\n",
       "      <td>77.200645</td>\n",
       "      <td>77.859044</td>\n",
       "      <td>79.324864</td>\n",
       "      <td>...</td>\n",
       "      <td>80.102728</td>\n",
       "      <td>77.443129</td>\n",
       "      <td>80.208063</td>\n",
       "      <td>69.342133</td>\n",
       "      <td>92.073577</td>\n",
       "      <td>80.326154</td>\n",
       "      <td>82.357046</td>\n",
       "      <td>81.884584</td>\n",
       "      <td>68.953000</td>\n",
       "      <td>79.397995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.147814</td>\n",
       "      <td>81.518846</td>\n",
       "      <td>76.695525</td>\n",
       "      <td>77.930667</td>\n",
       "      <td>87.527735</td>\n",
       "      <td>90.642030</td>\n",
       "      <td>83.540562</td>\n",
       "      <td>77.458909</td>\n",
       "      <td>77.911848</td>\n",
       "      <td>79.433134</td>\n",
       "      <td>...</td>\n",
       "      <td>80.082263</td>\n",
       "      <td>77.453403</td>\n",
       "      <td>80.322355</td>\n",
       "      <td>69.643368</td>\n",
       "      <td>91.684261</td>\n",
       "      <td>80.420395</td>\n",
       "      <td>82.077674</td>\n",
       "      <td>81.811890</td>\n",
       "      <td>69.101216</td>\n",
       "      <td>79.332075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.394387</td>\n",
       "      <td>81.586233</td>\n",
       "      <td>76.420343</td>\n",
       "      <td>77.954146</td>\n",
       "      <td>87.489211</td>\n",
       "      <td>90.526372</td>\n",
       "      <td>83.465142</td>\n",
       "      <td>77.714454</td>\n",
       "      <td>77.970389</td>\n",
       "      <td>79.541525</td>\n",
       "      <td>...</td>\n",
       "      <td>80.061302</td>\n",
       "      <td>77.470195</td>\n",
       "      <td>80.437383</td>\n",
       "      <td>69.941393</td>\n",
       "      <td>91.298301</td>\n",
       "      <td>80.510691</td>\n",
       "      <td>81.801362</td>\n",
       "      <td>81.738656</td>\n",
       "      <td>69.241014</td>\n",
       "      <td>79.267396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.634173</td>\n",
       "      <td>81.658761</td>\n",
       "      <td>76.145646</td>\n",
       "      <td>77.977021</td>\n",
       "      <td>87.451288</td>\n",
       "      <td>90.412748</td>\n",
       "      <td>83.387176</td>\n",
       "      <td>77.966851</td>\n",
       "      <td>78.034360</td>\n",
       "      <td>79.650200</td>\n",
       "      <td>...</td>\n",
       "      <td>80.040164</td>\n",
       "      <td>77.492911</td>\n",
       "      <td>80.552828</td>\n",
       "      <td>70.236678</td>\n",
       "      <td>90.915933</td>\n",
       "      <td>80.597446</td>\n",
       "      <td>81.528380</td>\n",
       "      <td>81.665320</td>\n",
       "      <td>69.371942</td>\n",
       "      <td>79.203816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>81.085500</td>\n",
       "      <td>83.269269</td>\n",
       "      <td>77.997856</td>\n",
       "      <td>67.669686</td>\n",
       "      <td>87.586293</td>\n",
       "      <td>86.693977</td>\n",
       "      <td>79.712469</td>\n",
       "      <td>83.950738</td>\n",
       "      <td>84.346201</td>\n",
       "      <td>78.132821</td>\n",
       "      <td>...</td>\n",
       "      <td>79.811065</td>\n",
       "      <td>81.004474</td>\n",
       "      <td>78.294866</td>\n",
       "      <td>67.316514</td>\n",
       "      <td>82.950869</td>\n",
       "      <td>80.483248</td>\n",
       "      <td>83.071120</td>\n",
       "      <td>81.965866</td>\n",
       "      <td>75.374322</td>\n",
       "      <td>65.513829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>80.871869</td>\n",
       "      <td>83.367393</td>\n",
       "      <td>78.059860</td>\n",
       "      <td>67.583630</td>\n",
       "      <td>87.631434</td>\n",
       "      <td>86.606911</td>\n",
       "      <td>79.477164</td>\n",
       "      <td>84.132178</td>\n",
       "      <td>84.549588</td>\n",
       "      <td>78.050669</td>\n",
       "      <td>...</td>\n",
       "      <td>79.786175</td>\n",
       "      <td>80.986456</td>\n",
       "      <td>78.193919</td>\n",
       "      <td>67.210842</td>\n",
       "      <td>82.792298</td>\n",
       "      <td>80.468536</td>\n",
       "      <td>83.056954</td>\n",
       "      <td>82.122991</td>\n",
       "      <td>75.464144</td>\n",
       "      <td>65.102826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>80.656301</td>\n",
       "      <td>83.466033</td>\n",
       "      <td>78.125031</td>\n",
       "      <td>67.499484</td>\n",
       "      <td>87.677524</td>\n",
       "      <td>86.518893</td>\n",
       "      <td>79.242501</td>\n",
       "      <td>84.317854</td>\n",
       "      <td>84.758155</td>\n",
       "      <td>77.968463</td>\n",
       "      <td>...</td>\n",
       "      <td>79.761260</td>\n",
       "      <td>80.965988</td>\n",
       "      <td>78.090956</td>\n",
       "      <td>67.102590</td>\n",
       "      <td>82.633703</td>\n",
       "      <td>80.454453</td>\n",
       "      <td>83.036478</td>\n",
       "      <td>82.281210</td>\n",
       "      <td>75.548762</td>\n",
       "      <td>64.685126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>80.439400</td>\n",
       "      <td>83.564900</td>\n",
       "      <td>78.192290</td>\n",
       "      <td>67.417331</td>\n",
       "      <td>87.723150</td>\n",
       "      <td>86.430248</td>\n",
       "      <td>79.008253</td>\n",
       "      <td>84.507677</td>\n",
       "      <td>84.972099</td>\n",
       "      <td>77.886868</td>\n",
       "      <td>...</td>\n",
       "      <td>79.737010</td>\n",
       "      <td>80.943514</td>\n",
       "      <td>77.985717</td>\n",
       "      <td>66.991973</td>\n",
       "      <td>82.475239</td>\n",
       "      <td>80.441972</td>\n",
       "      <td>83.009817</td>\n",
       "      <td>82.440347</td>\n",
       "      <td>75.628233</td>\n",
       "      <td>64.260938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>80.221609</td>\n",
       "      <td>83.663892</td>\n",
       "      <td>78.260620</td>\n",
       "      <td>67.337267</td>\n",
       "      <td>87.767240</td>\n",
       "      <td>86.341214</td>\n",
       "      <td>78.774122</td>\n",
       "      <td>84.701836</td>\n",
       "      <td>85.191428</td>\n",
       "      <td>77.806510</td>\n",
       "      <td>...</td>\n",
       "      <td>79.714033</td>\n",
       "      <td>80.919808</td>\n",
       "      <td>77.878151</td>\n",
       "      <td>66.879278</td>\n",
       "      <td>82.317245</td>\n",
       "      <td>80.431920</td>\n",
       "      <td>82.977138</td>\n",
       "      <td>82.600111</td>\n",
       "      <td>75.702741</td>\n",
       "      <td>63.830729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5   \\\n",
       "0     78.632971  81.399266  77.250888  77.881737  87.606491  90.878011   \n",
       "1     78.894162  81.456455  76.972121  77.906493  87.566765  90.759398   \n",
       "2     79.147814  81.518846  76.695525  77.930667  87.527735  90.642030   \n",
       "3     79.394387  81.586233  76.420343  77.954146  87.489211  90.526372   \n",
       "4     79.634173  81.658761  76.145646  77.977021  87.451288  90.412748   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  81.085500  83.269269  77.997856  67.669686  87.586293  86.693977   \n",
       "2439  80.871869  83.367393  78.059860  67.583630  87.631434  86.606911   \n",
       "2440  80.656301  83.466033  78.125031  67.499484  87.677524  86.518893   \n",
       "2441  80.439400  83.564900  78.192290  67.417331  87.723150  86.430248   \n",
       "2442  80.221609  83.663892  78.260620  67.337267  87.767240  86.341214   \n",
       "\n",
       "             6          7          8          9   ...         38         39  \\\n",
       "0     83.683674  76.939886  77.811940  79.216417  ...  80.122692  77.439776   \n",
       "1     83.613337  77.200645  77.859044  79.324864  ...  80.102728  77.443129   \n",
       "2     83.540562  77.458909  77.911848  79.433134  ...  80.082263  77.453403   \n",
       "3     83.465142  77.714454  77.970389  79.541525  ...  80.061302  77.470195   \n",
       "4     83.387176  77.966851  78.034360  79.650200  ...  80.040164  77.492911   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  79.712469  83.950738  84.346201  78.132821  ...  79.811065  81.004474   \n",
       "2439  79.477164  84.132178  84.549588  78.050669  ...  79.786175  80.986456   \n",
       "2440  79.242501  84.317854  84.758155  77.968463  ...  79.761260  80.965988   \n",
       "2441  79.008253  84.507677  84.972099  77.886868  ...  79.737010  80.943514   \n",
       "2442  78.774122  84.701836  85.191428  77.806510  ...  79.714033  80.919808   \n",
       "\n",
       "             40         41         42         43         44         45  \\\n",
       "0     80.094806  69.037217  92.465980  80.227891  82.639231  81.956382   \n",
       "1     80.208063  69.342133  92.073577  80.326154  82.357046  81.884584   \n",
       "2     80.322355  69.643368  91.684261  80.420395  82.077674  81.811890   \n",
       "3     80.437383  69.941393  91.298301  80.510691  81.801362  81.738656   \n",
       "4     80.552828  70.236678  90.915933  80.597446  81.528380  81.665320   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  78.294866  67.316514  82.950869  80.483248  83.071120  81.965866   \n",
       "2439  78.193919  67.210842  82.792298  80.468536  83.056954  82.122991   \n",
       "2440  78.090956  67.102590  82.633703  80.454453  83.036478  82.281210   \n",
       "2441  77.985717  66.991973  82.475239  80.441972  83.009817  82.440347   \n",
       "2442  77.878151  66.879278  82.317245  80.431920  82.977138  82.600111   \n",
       "\n",
       "             46         47  \n",
       "0     68.796643  79.465122  \n",
       "1     68.953000  79.397995  \n",
       "2     69.101216  79.332075  \n",
       "3     69.241014  79.267396  \n",
       "4     69.371942  79.203816  \n",
       "...         ...        ...  \n",
       "2438  75.374322  65.513829  \n",
       "2439  75.464144  65.102826  \n",
       "2440  75.548762  64.685126  \n",
       "2441  75.628233  64.260938  \n",
       "2442  75.702741  63.830729  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_Reg2_3.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.968791</td>\n",
       "      <td>60.239368</td>\n",
       "      <td>-105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-75.314716</td>\n",
       "      <td>60.181623</td>\n",
       "      <td>-104.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.653109</td>\n",
       "      <td>60.131806</td>\n",
       "      <td>-104.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.984037</td>\n",
       "      <td>60.089935</td>\n",
       "      <td>-104.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.307567</td>\n",
       "      <td>60.056029</td>\n",
       "      <td>-104.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-99.899763</td>\n",
       "      <td>81.788725</td>\n",
       "      <td>65.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-99.939531</td>\n",
       "      <td>81.389997</td>\n",
       "      <td>65.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-99.969304</td>\n",
       "      <td>80.990713</td>\n",
       "      <td>65.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-99.989081</td>\n",
       "      <td>80.591032</td>\n",
       "      <td>65.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-99.998859</td>\n",
       "      <td>80.191116</td>\n",
       "      <td>65.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1       2\n",
       "0    -75.968791  60.239368 -105.00\n",
       "1    -75.314716  60.181623 -104.93\n",
       "2    -74.653109  60.131806 -104.86\n",
       "3    -73.984037  60.089935 -104.79\n",
       "4    -73.307567  60.056029 -104.72\n",
       "...         ...        ...     ...\n",
       "2438 -99.899763  81.788725   65.66\n",
       "2439 -99.939531  81.389997   65.73\n",
       "2440 -99.969304  80.990713   65.80\n",
       "2441 -99.989081  80.591032   65.87\n",
       "2442 -99.998859  80.191116   65.94\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.632971</td>\n",
       "      <td>81.399266</td>\n",
       "      <td>77.250888</td>\n",
       "      <td>77.881737</td>\n",
       "      <td>87.606491</td>\n",
       "      <td>90.878011</td>\n",
       "      <td>83.683674</td>\n",
       "      <td>76.939886</td>\n",
       "      <td>77.811940</td>\n",
       "      <td>79.216417</td>\n",
       "      <td>...</td>\n",
       "      <td>80.122692</td>\n",
       "      <td>77.439776</td>\n",
       "      <td>80.094806</td>\n",
       "      <td>69.037217</td>\n",
       "      <td>92.465980</td>\n",
       "      <td>80.227891</td>\n",
       "      <td>82.639231</td>\n",
       "      <td>81.956382</td>\n",
       "      <td>68.796643</td>\n",
       "      <td>79.465122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.894162</td>\n",
       "      <td>81.456455</td>\n",
       "      <td>76.972121</td>\n",
       "      <td>77.906493</td>\n",
       "      <td>87.566765</td>\n",
       "      <td>90.759398</td>\n",
       "      <td>83.613337</td>\n",
       "      <td>77.200645</td>\n",
       "      <td>77.859044</td>\n",
       "      <td>79.324864</td>\n",
       "      <td>...</td>\n",
       "      <td>80.102728</td>\n",
       "      <td>77.443129</td>\n",
       "      <td>80.208063</td>\n",
       "      <td>69.342133</td>\n",
       "      <td>92.073577</td>\n",
       "      <td>80.326154</td>\n",
       "      <td>82.357046</td>\n",
       "      <td>81.884584</td>\n",
       "      <td>68.953000</td>\n",
       "      <td>79.397995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.147814</td>\n",
       "      <td>81.518846</td>\n",
       "      <td>76.695525</td>\n",
       "      <td>77.930667</td>\n",
       "      <td>87.527735</td>\n",
       "      <td>90.642030</td>\n",
       "      <td>83.540562</td>\n",
       "      <td>77.458909</td>\n",
       "      <td>77.911848</td>\n",
       "      <td>79.433134</td>\n",
       "      <td>...</td>\n",
       "      <td>80.082263</td>\n",
       "      <td>77.453403</td>\n",
       "      <td>80.322355</td>\n",
       "      <td>69.643368</td>\n",
       "      <td>91.684261</td>\n",
       "      <td>80.420395</td>\n",
       "      <td>82.077674</td>\n",
       "      <td>81.811890</td>\n",
       "      <td>69.101216</td>\n",
       "      <td>79.332075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.394387</td>\n",
       "      <td>81.586233</td>\n",
       "      <td>76.420343</td>\n",
       "      <td>77.954146</td>\n",
       "      <td>87.489211</td>\n",
       "      <td>90.526372</td>\n",
       "      <td>83.465142</td>\n",
       "      <td>77.714454</td>\n",
       "      <td>77.970389</td>\n",
       "      <td>79.541525</td>\n",
       "      <td>...</td>\n",
       "      <td>80.061302</td>\n",
       "      <td>77.470195</td>\n",
       "      <td>80.437383</td>\n",
       "      <td>69.941393</td>\n",
       "      <td>91.298301</td>\n",
       "      <td>80.510691</td>\n",
       "      <td>81.801362</td>\n",
       "      <td>81.738656</td>\n",
       "      <td>69.241014</td>\n",
       "      <td>79.267396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.634173</td>\n",
       "      <td>81.658761</td>\n",
       "      <td>76.145646</td>\n",
       "      <td>77.977021</td>\n",
       "      <td>87.451288</td>\n",
       "      <td>90.412748</td>\n",
       "      <td>83.387176</td>\n",
       "      <td>77.966851</td>\n",
       "      <td>78.034360</td>\n",
       "      <td>79.650200</td>\n",
       "      <td>...</td>\n",
       "      <td>80.040164</td>\n",
       "      <td>77.492911</td>\n",
       "      <td>80.552828</td>\n",
       "      <td>70.236678</td>\n",
       "      <td>90.915933</td>\n",
       "      <td>80.597446</td>\n",
       "      <td>81.528380</td>\n",
       "      <td>81.665320</td>\n",
       "      <td>69.371942</td>\n",
       "      <td>79.203816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>81.085500</td>\n",
       "      <td>83.269269</td>\n",
       "      <td>77.997856</td>\n",
       "      <td>67.669686</td>\n",
       "      <td>87.586293</td>\n",
       "      <td>86.693977</td>\n",
       "      <td>79.712469</td>\n",
       "      <td>83.950738</td>\n",
       "      <td>84.346201</td>\n",
       "      <td>78.132821</td>\n",
       "      <td>...</td>\n",
       "      <td>79.811065</td>\n",
       "      <td>81.004474</td>\n",
       "      <td>78.294866</td>\n",
       "      <td>67.316514</td>\n",
       "      <td>82.950869</td>\n",
       "      <td>80.483248</td>\n",
       "      <td>83.071120</td>\n",
       "      <td>81.965866</td>\n",
       "      <td>75.374322</td>\n",
       "      <td>65.513829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>80.871869</td>\n",
       "      <td>83.367393</td>\n",
       "      <td>78.059860</td>\n",
       "      <td>67.583630</td>\n",
       "      <td>87.631434</td>\n",
       "      <td>86.606911</td>\n",
       "      <td>79.477164</td>\n",
       "      <td>84.132178</td>\n",
       "      <td>84.549588</td>\n",
       "      <td>78.050669</td>\n",
       "      <td>...</td>\n",
       "      <td>79.786175</td>\n",
       "      <td>80.986456</td>\n",
       "      <td>78.193919</td>\n",
       "      <td>67.210842</td>\n",
       "      <td>82.792298</td>\n",
       "      <td>80.468536</td>\n",
       "      <td>83.056954</td>\n",
       "      <td>82.122991</td>\n",
       "      <td>75.464144</td>\n",
       "      <td>65.102826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>80.656301</td>\n",
       "      <td>83.466033</td>\n",
       "      <td>78.125031</td>\n",
       "      <td>67.499484</td>\n",
       "      <td>87.677524</td>\n",
       "      <td>86.518893</td>\n",
       "      <td>79.242501</td>\n",
       "      <td>84.317854</td>\n",
       "      <td>84.758155</td>\n",
       "      <td>77.968463</td>\n",
       "      <td>...</td>\n",
       "      <td>79.761260</td>\n",
       "      <td>80.965988</td>\n",
       "      <td>78.090956</td>\n",
       "      <td>67.102590</td>\n",
       "      <td>82.633703</td>\n",
       "      <td>80.454453</td>\n",
       "      <td>83.036478</td>\n",
       "      <td>82.281210</td>\n",
       "      <td>75.548762</td>\n",
       "      <td>64.685126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>80.439400</td>\n",
       "      <td>83.564900</td>\n",
       "      <td>78.192290</td>\n",
       "      <td>67.417331</td>\n",
       "      <td>87.723150</td>\n",
       "      <td>86.430248</td>\n",
       "      <td>79.008253</td>\n",
       "      <td>84.507677</td>\n",
       "      <td>84.972099</td>\n",
       "      <td>77.886868</td>\n",
       "      <td>...</td>\n",
       "      <td>79.737010</td>\n",
       "      <td>80.943514</td>\n",
       "      <td>77.985717</td>\n",
       "      <td>66.991973</td>\n",
       "      <td>82.475239</td>\n",
       "      <td>80.441972</td>\n",
       "      <td>83.009817</td>\n",
       "      <td>82.440347</td>\n",
       "      <td>75.628233</td>\n",
       "      <td>64.260938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>80.221609</td>\n",
       "      <td>83.663892</td>\n",
       "      <td>78.260620</td>\n",
       "      <td>67.337267</td>\n",
       "      <td>87.767240</td>\n",
       "      <td>86.341214</td>\n",
       "      <td>78.774122</td>\n",
       "      <td>84.701836</td>\n",
       "      <td>85.191428</td>\n",
       "      <td>77.806510</td>\n",
       "      <td>...</td>\n",
       "      <td>79.714033</td>\n",
       "      <td>80.919808</td>\n",
       "      <td>77.878151</td>\n",
       "      <td>66.879278</td>\n",
       "      <td>82.317245</td>\n",
       "      <td>80.431920</td>\n",
       "      <td>82.977138</td>\n",
       "      <td>82.600111</td>\n",
       "      <td>75.702741</td>\n",
       "      <td>63.830729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor1    sensor2    sensor3    sensor4    sensor5    sensor6  \\\n",
       "0     78.632971  81.399266  77.250888  77.881737  87.606491  90.878011   \n",
       "1     78.894162  81.456455  76.972121  77.906493  87.566765  90.759398   \n",
       "2     79.147814  81.518846  76.695525  77.930667  87.527735  90.642030   \n",
       "3     79.394387  81.586233  76.420343  77.954146  87.489211  90.526372   \n",
       "4     79.634173  81.658761  76.145646  77.977021  87.451288  90.412748   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  81.085500  83.269269  77.997856  67.669686  87.586293  86.693977   \n",
       "2439  80.871869  83.367393  78.059860  67.583630  87.631434  86.606911   \n",
       "2440  80.656301  83.466033  78.125031  67.499484  87.677524  86.518893   \n",
       "2441  80.439400  83.564900  78.192290  67.417331  87.723150  86.430248   \n",
       "2442  80.221609  83.663892  78.260620  67.337267  87.767240  86.341214   \n",
       "\n",
       "        sensor7    sensor8    sensor9   sensor10  ...   sensor39   sensor40  \\\n",
       "0     83.683674  76.939886  77.811940  79.216417  ...  80.122692  77.439776   \n",
       "1     83.613337  77.200645  77.859044  79.324864  ...  80.102728  77.443129   \n",
       "2     83.540562  77.458909  77.911848  79.433134  ...  80.082263  77.453403   \n",
       "3     83.465142  77.714454  77.970389  79.541525  ...  80.061302  77.470195   \n",
       "4     83.387176  77.966851  78.034360  79.650200  ...  80.040164  77.492911   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  79.712469  83.950738  84.346201  78.132821  ...  79.811065  81.004474   \n",
       "2439  79.477164  84.132178  84.549588  78.050669  ...  79.786175  80.986456   \n",
       "2440  79.242501  84.317854  84.758155  77.968463  ...  79.761260  80.965988   \n",
       "2441  79.008253  84.507677  84.972099  77.886868  ...  79.737010  80.943514   \n",
       "2442  78.774122  84.701836  85.191428  77.806510  ...  79.714033  80.919808   \n",
       "\n",
       "       sensor41   sensor42   sensor43   sensor44   sensor45   sensor46  \\\n",
       "0     80.094806  69.037217  92.465980  80.227891  82.639231  81.956382   \n",
       "1     80.208063  69.342133  92.073577  80.326154  82.357046  81.884584   \n",
       "2     80.322355  69.643368  91.684261  80.420395  82.077674  81.811890   \n",
       "3     80.437383  69.941393  91.298301  80.510691  81.801362  81.738656   \n",
       "4     80.552828  70.236678  90.915933  80.597446  81.528380  81.665320   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  78.294866  67.316514  82.950869  80.483248  83.071120  81.965866   \n",
       "2439  78.193919  67.210842  82.792298  80.468536  83.056954  82.122991   \n",
       "2440  78.090956  67.102590  82.633703  80.454453  83.036478  82.281210   \n",
       "2441  77.985717  66.991973  82.475239  80.441972  83.009817  82.440347   \n",
       "2442  77.878151  66.879278  82.317245  80.431920  82.977138  82.600111   \n",
       "\n",
       "       sensor47   sensor48  \n",
       "0     68.796643  79.465122  \n",
       "1     68.953000  79.397995  \n",
       "2     69.101216  79.332075  \n",
       "3     69.241014  79.267396  \n",
       "4     69.371942  79.203816  \n",
       "...         ...        ...  \n",
       "2438  75.374322  65.513829  \n",
       "2439  75.464144  65.102826  \n",
       "2440  75.548762  64.685126  \n",
       "2441  75.628233  64.260938  \n",
       "2442  75.702741  63.830729  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.968791</td>\n",
       "      <td>60.239368</td>\n",
       "      <td>-105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-75.314716</td>\n",
       "      <td>60.181623</td>\n",
       "      <td>-104.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.653109</td>\n",
       "      <td>60.131806</td>\n",
       "      <td>-104.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.984037</td>\n",
       "      <td>60.089935</td>\n",
       "      <td>-104.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.307567</td>\n",
       "      <td>60.056029</td>\n",
       "      <td>-104.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-99.899763</td>\n",
       "      <td>81.788725</td>\n",
       "      <td>65.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-99.939531</td>\n",
       "      <td>81.389997</td>\n",
       "      <td>65.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-99.969304</td>\n",
       "      <td>80.990713</td>\n",
       "      <td>65.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-99.989081</td>\n",
       "      <td>80.591032</td>\n",
       "      <td>65.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-99.998859</td>\n",
       "      <td>80.191116</td>\n",
       "      <td>65.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y   Pos Z\n",
       "0    -75.968791  60.239368 -105.00\n",
       "1    -75.314716  60.181623 -104.93\n",
       "2    -74.653109  60.131806 -104.86\n",
       "3    -73.984037  60.089935 -104.79\n",
       "4    -73.307567  60.056029 -104.72\n",
       "...         ...        ...     ...\n",
       "2438 -99.899763  81.788725   65.66\n",
       "2439 -99.939531  81.389997   65.73\n",
       "2440 -99.969304  80.990713   65.80\n",
       "2441 -99.989081  80.591032   65.87\n",
       "2442 -99.998859  80.191116   65.94\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 16s 20ms/step - loss: 4007.7109 - val_loss: 3865.1750\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3692.0391 - val_loss: 3646.7900\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3492.8752 - val_loss: 3461.5413\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 3320.5767 - val_loss: 3300.7336\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3172.6763 - val_loss: 3164.6128\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3046.4612 - val_loss: 3048.2090\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2938.3135 - val_loss: 2948.8250\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2846.0063 - val_loss: 2864.4045\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2767.7373 - val_loss: 2793.5950\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2702.3489 - val_loss: 2734.9990\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2648.5344 - val_loss: 2687.5696\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2605.3098 - val_loss: 2650.2771\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2571.5117 - val_loss: 2621.6611\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2545.8718 - val_loss: 2600.5583\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2527.1458 - val_loss: 2585.6572\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2514.3445 - val_loss: 2576.1492\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2506.3018 - val_loss: 2570.3218\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2501.3635 - val_loss: 2567.4126\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2498.8201 - val_loss: 2565.8325\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.4912 - val_loss: 2565.1965\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2497.0178 - val_loss: 2565.0850\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.8337 - val_loss: 2565.0261\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7483 - val_loss: 2564.9912\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7146 - val_loss: 2564.9683\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7053 - val_loss: 2565.0918\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7317 - val_loss: 2564.9326\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.8037 - val_loss: 2565.0549\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7458 - val_loss: 2565.0488\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.7395 - val_loss: 2564.9944\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7263 - val_loss: 2565.0286\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.7358 - val_loss: 2564.9431\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7334 - val_loss: 2564.9468\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.8074 - val_loss: 2564.8252\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.6975 - val_loss: 2564.8108\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6714 - val_loss: 2564.7615\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7183 - val_loss: 2564.8049\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7200 - val_loss: 2564.7319\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7104 - val_loss: 2564.7375\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7507 - val_loss: 2564.7788\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.6931 - val_loss: 2564.8350\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7695 - val_loss: 2564.8049\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7141 - val_loss: 2564.8540\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7126 - val_loss: 2564.8313\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7410 - val_loss: 2564.7861\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7334 - val_loss: 2564.8579\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7427 - val_loss: 2564.7969\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6743 - val_loss: 2564.7949\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7935 - val_loss: 2564.6238\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6934 - val_loss: 2564.7432\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.8130 - val_loss: 2564.7964\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2496.7659 - val_loss: 2564.6899\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7290 - val_loss: 2564.8809\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7456 - val_loss: 2564.8801\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7642 - val_loss: 2564.6365\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7444 - val_loss: 2565.0522\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7061 - val_loss: 2564.7129\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7556 - val_loss: 2564.9783\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7629 - val_loss: 2564.6941\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.8000 - val_loss: 2564.6155\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7107 - val_loss: 2564.7771\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7112 - val_loss: 2564.8630\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7488 - val_loss: 2564.6992\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7278 - val_loss: 2564.8296\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7083 - val_loss: 2564.7825\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7437 - val_loss: 2564.6338\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7351 - val_loss: 2564.7009\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7217 - val_loss: 2564.6211\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6846 - val_loss: 2564.6362\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7776 - val_loss: 2564.8169\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7405 - val_loss: 2564.5942\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.6926 - val_loss: 2564.8203\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6863 - val_loss: 2564.8491\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6731 - val_loss: 2564.7891\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7883 - val_loss: 2564.7507\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7122 - val_loss: 2564.8416\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7246 - val_loss: 2564.9131\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7087 - val_loss: 2564.9141\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7180 - val_loss: 2564.7371\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7539 - val_loss: 2564.7534\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7273 - val_loss: 2564.8208\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6890 - val_loss: 2564.8098\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7312 - val_loss: 2564.7524\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7649 - val_loss: 2564.8562\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7366 - val_loss: 2564.7368\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7441 - val_loss: 2564.9016\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7185 - val_loss: 2564.9468\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7163 - val_loss: 2564.7188\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2496.7903 - val_loss: 2564.7991\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7466 - val_loss: 2564.7571\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.7544 - val_loss: 2564.8799\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7151 - val_loss: 2564.7620\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7783 - val_loss: 2564.6438\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7537 - val_loss: 2564.7551\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7061 - val_loss: 2564.7739\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.7429 - val_loss: 2564.8752\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7219 - val_loss: 2564.7251\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7246 - val_loss: 2564.8335\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7231 - val_loss: 2564.7820\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2496.7432 - val_loss: 2564.7598\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.6758 - val_loss: 2564.7683\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7056 - val_loss: 2564.7742\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2496.7388 - val_loss: 2564.7717\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7253 - val_loss: 2564.7004\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7715 - val_loss: 2564.8003\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7380 - val_loss: 2564.6274\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7319 - val_loss: 2564.6917\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7053 - val_loss: 2564.7761\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7280 - val_loss: 2564.8223\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.7705 - val_loss: 2564.6201\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2496.7012 - val_loss: 2564.7407\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2496.7588 - val_loss: 2564.7495\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2496.7622 - val_loss: 2564.6016\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.7058 - val_loss: 2564.6877\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6594 - val_loss: 2564.7017\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7354 - val_loss: 2564.6682\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6919 - val_loss: 2564.7163\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7366 - val_loss: 2564.8364\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7769 - val_loss: 2564.6587\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7275 - val_loss: 2564.6812\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6982 - val_loss: 2564.7095\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7251 - val_loss: 2564.7285\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7415 - val_loss: 2564.8354\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7361 - val_loss: 2564.7224\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7046 - val_loss: 2564.6584\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7405 - val_loss: 2564.7686\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6931 - val_loss: 2564.7456\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.8191 - val_loss: 2564.6919\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7000 - val_loss: 2564.6472\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7441 - val_loss: 2564.6797\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.7451 - val_loss: 2564.7019\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7107 - val_loss: 2564.6667\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2496.7944 - val_loss: 2564.7874\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7131 - val_loss: 2564.7322\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7122 - val_loss: 2564.6902\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6863 - val_loss: 2564.6917\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6626 - val_loss: 2564.5554\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7087 - val_loss: 2564.6816\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7097 - val_loss: 2564.6643\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7690 - val_loss: 2564.8469\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6931 - val_loss: 2564.8977\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7717 - val_loss: 2564.7698\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7542 - val_loss: 2564.7095\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7405 - val_loss: 2564.6023\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7224 - val_loss: 2564.8628\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7236 - val_loss: 2564.7307\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7629 - val_loss: 2564.7590\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7615 - val_loss: 2564.7910\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7549 - val_loss: 2564.5383\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7385 - val_loss: 2564.7346\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7429 - val_loss: 2564.6519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7407 - val_loss: 2564.5078\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.6978 - val_loss: 2564.5090\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6799 - val_loss: 2564.5996\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6829 - val_loss: 2564.7227\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7117 - val_loss: 2564.7275\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7266 - val_loss: 2564.7144\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7468 - val_loss: 2564.6990\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7644 - val_loss: 2564.8035\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7734 - val_loss: 2564.7859\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7749 - val_loss: 2564.7891\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7607 - val_loss: 2564.7617\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7170 - val_loss: 2564.8750\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6799 - val_loss: 2564.9861\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2496.7144 - val_loss: 2564.8745\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7842 - val_loss: 2564.8799\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7273 - val_loss: 2565.0090\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7454 - val_loss: 2564.9749\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7483 - val_loss: 2564.7441\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7007 - val_loss: 2564.8750\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7791 - val_loss: 2564.7520\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7292 - val_loss: 2564.7498\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7637 - val_loss: 2564.6917\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7524 - val_loss: 2564.6270\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6904 - val_loss: 2564.7495\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7256 - val_loss: 2564.7793\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7026 - val_loss: 2564.7827\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7617 - val_loss: 2564.6672\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7346 - val_loss: 2564.6528\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7585 - val_loss: 2564.7817\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7100 - val_loss: 2564.6499\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7117 - val_loss: 2564.6235\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7336 - val_loss: 2564.5833\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6831 - val_loss: 2564.7012\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7297 - val_loss: 2564.7009\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6902 - val_loss: 2564.6760\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.8069 - val_loss: 2564.7493\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2496.7515 - val_loss: 2564.5803\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7109 - val_loss: 2564.7483\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7627 - val_loss: 2564.8083\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7017 - val_loss: 2564.7026\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2496.7720 - val_loss: 2564.6685\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7378 - val_loss: 2564.6753\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7009 - val_loss: 2564.5986\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7009 - val_loss: 2564.7668\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7063 - val_loss: 2564.8079\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7031 - val_loss: 2564.7029\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.6921 - val_loss: 2564.7686\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7690 - val_loss: 2565.0166\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2496.7742 - val_loss: 2564.8743\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2496.7083 - val_loss: 2564.8354\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 2564.834795798877\n",
      "Mean Absolute Error (MAE): 39.92720198294938\n",
      "Root Mean Squared Error (RMSE): 50.64419804675435\n",
      "Time taken: 1210.1208703517914\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 4067.4600 - val_loss: 3828.5486\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3748.4631 - val_loss: 3597.4817\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3541.6472 - val_loss: 3406.5579\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 3364.2583 - val_loss: 3246.7917\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3215.9250 - val_loss: 3110.6270\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3088.2656 - val_loss: 2992.6191\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2978.4888 - val_loss: 2891.3774\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2884.5288 - val_loss: 2804.8945\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2804.4905 - val_loss: 2731.5195\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2737.2034 - val_loss: 2670.3049\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2681.3774 - val_loss: 2619.9363\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2636.0396 - val_loss: 2579.4526\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2600.3076 - val_loss: 2547.8606\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2572.7283 - val_loss: 2523.8252\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2552.3694 - val_loss: 2506.8164\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2538.3210 - val_loss: 2495.1667\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2529.1013 - val_loss: 2487.9226\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2523.4644 - val_loss: 2483.6831\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2520.4685 - val_loss: 2481.3523\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2518.7297 - val_loss: 2480.3213\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2518.0986 - val_loss: 2479.8879\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.8562 - val_loss: 2479.6965\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2517.7446 - val_loss: 2479.6577\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7349 - val_loss: 2479.5549\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7610 - val_loss: 2479.6311\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7119 - val_loss: 2479.6873\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7512 - val_loss: 2479.5710\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7278 - val_loss: 2479.6211\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7776 - val_loss: 2479.6379\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7764 - val_loss: 2479.7185\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2517.7603 - val_loss: 2479.6560\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7251 - val_loss: 2479.6582\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7710 - val_loss: 2479.6714\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7751 - val_loss: 2479.7058\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.8066 - val_loss: 2479.6213\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7725 - val_loss: 2479.6482\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.6814 - val_loss: 2479.6289\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7510 - val_loss: 2479.6594\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2517.7979 - val_loss: 2479.6948\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7329 - val_loss: 2479.6802\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7441 - val_loss: 2479.6558\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7278 - val_loss: 2479.6777\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7068 - val_loss: 2479.6836\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7593 - val_loss: 2479.7280\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.6772 - val_loss: 2479.7124\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7073 - val_loss: 2479.7253\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7732 - val_loss: 2479.6499\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7390 - val_loss: 2479.7078\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7305 - val_loss: 2479.7737\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2517.7356 - val_loss: 2479.6858\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7830 - val_loss: 2479.6633\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7222 - val_loss: 2479.6833\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7605 - val_loss: 2479.7283\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7466 - val_loss: 2480.6321\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2518.0103 - val_loss: 2480.1082\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7891 - val_loss: 2479.9280\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7629 - val_loss: 2479.8647\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7874 - val_loss: 2479.8115\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7822 - val_loss: 2479.7971\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7449 - val_loss: 2479.7849\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7161 - val_loss: 2479.6755\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7324 - val_loss: 2479.7605\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7468 - val_loss: 2479.7712\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7114 - val_loss: 2479.7485\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7947 - val_loss: 2479.7559\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7375 - val_loss: 2479.6614\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7410 - val_loss: 2479.6575\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7085 - val_loss: 2479.7126\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7363 - val_loss: 2479.7441\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7246 - val_loss: 2479.7009\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7537 - val_loss: 2479.6384\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7390 - val_loss: 2479.6633\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7729 - val_loss: 2479.6667\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7463 - val_loss: 2479.6924\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.6919 - val_loss: 2479.6660\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 2517.7817 - val_loss: 2479.6033\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2517.7832 - val_loss: 2479.5950\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.8435 - val_loss: 2479.7080\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7427 - val_loss: 2479.6814\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.7280 - val_loss: 2479.6582\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2510.2871 - val_loss: 2428.9641\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2433.5378 - val_loss: 2375.6045\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2400.5366 - val_loss: 2352.9495\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2374.6084 - val_loss: 2327.7676\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2349.9927 - val_loss: 2304.8787\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2327.6982 - val_loss: 2282.0356\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2304.7983 - val_loss: 2264.3589\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2274.5142 - val_loss: 2215.1458\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2210.7480 - val_loss: 2153.9980\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2157.6660 - val_loss: 2108.2432\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2113.6099 - val_loss: 2065.6611\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2070.9292 - val_loss: 2024.6121\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2029.5391 - val_loss: 1985.8041\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1984.8088 - val_loss: 1928.0026\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1920.3370 - val_loss: 1864.7502\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1856.3416 - val_loss: 1797.1882\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1795.9000 - val_loss: 1737.1664\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1734.0917 - val_loss: 1678.0293\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1674.2189 - val_loss: 1617.5060\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1615.4965 - val_loss: 1561.0654\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1559.0378 - val_loss: 1509.0931\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1504.7617 - val_loss: 1457.6733\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1450.9067 - val_loss: 1397.4064\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1394.4595 - val_loss: 1337.8168\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1334.4861 - val_loss: 1285.1382\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1282.5044 - val_loss: 1231.3212\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1231.3361 - val_loss: 1182.0549\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 1183.6829 - val_loss: 1133.8000\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 1134.6199 - val_loss: 1088.4258\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1090.9530 - val_loss: 1045.6136\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1043.9452 - val_loss: 1000.7943\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1001.0593 - val_loss: 966.5955\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 962.1180 - val_loss: 915.3644\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 918.2379 - val_loss: 880.6590\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 877.9982 - val_loss: 840.4114\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 844.7726 - val_loss: 799.2585\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 805.3836 - val_loss: 774.3484\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 767.3214 - val_loss: 726.1044\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 730.4274 - val_loss: 702.9304\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 694.7156 - val_loss: 655.9540\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 660.5971 - val_loss: 627.7011\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 629.6591 - val_loss: 601.8107\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 596.3464 - val_loss: 560.9752\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 568.0226 - val_loss: 532.1344\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 538.9830 - val_loss: 506.8030\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 511.2759 - val_loss: 478.4637\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 482.9277 - val_loss: 452.4569\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 456.5962 - val_loss: 433.1711\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 430.6227 - val_loss: 404.6524\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 411.8967 - val_loss: 384.5725\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 385.9560 - val_loss: 360.7387\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 364.5185 - val_loss: 334.8531\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 342.4158 - val_loss: 316.3090\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 320.3990 - val_loss: 298.7708\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 304.6324 - val_loss: 284.7108\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 286.6644 - val_loss: 261.1755\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 280.1108 - val_loss: 252.7101\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 252.1840 - val_loss: 234.8396\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 236.9345 - val_loss: 220.8101\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 222.5983 - val_loss: 202.4896\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 213.2568 - val_loss: 194.7384\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 195.8887 - val_loss: 181.1035\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 185.8820 - val_loss: 168.7180\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 174.9415 - val_loss: 156.2341\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 162.3510 - val_loss: 145.2284\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 163.7598 - val_loss: 141.1588\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 140.4091 - val_loss: 127.1551\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 128.6441 - val_loss: 118.9726\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 119.2325 - val_loss: 112.9142\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 116.6350 - val_loss: 99.9583\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 107.9460 - val_loss: 92.5970\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 100.1121 - val_loss: 87.0100\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 88.5858 - val_loss: 79.7357\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 83.3843 - val_loss: 75.2313\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 76.3876 - val_loss: 69.9595\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 76.9972 - val_loss: 65.8175\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 67.7573 - val_loss: 57.2514\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 70.0794 - val_loss: 77.8317\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 71.0161 - val_loss: 52.8303\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 52.3027 - val_loss: 48.5648\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 48.0824 - val_loss: 43.3161\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 47.6464 - val_loss: 41.1159\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 42.7216 - val_loss: 38.3289\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 68.5947 - val_loss: 50.0288\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 45.6204 - val_loss: 32.5679\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 32.9922 - val_loss: 29.1694\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 31.4250 - val_loss: 27.8005\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 39.9245 - val_loss: 28.6174\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 28.3471 - val_loss: 24.5030\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 34.7350 - val_loss: 24.1899\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 24.6155 - val_loss: 20.8513\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 25.5529 - val_loss: 20.4256\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 20.9740 - val_loss: 18.1469\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 21.7388 - val_loss: 18.4014\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 29.9313 - val_loss: 20.2763\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 17.1771 - val_loss: 14.6188\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.4895 - val_loss: 20.2079\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 20.1695 - val_loss: 13.3013\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 14.7084 - val_loss: 13.1601\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 13.6559 - val_loss: 11.1202\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 13.9046 - val_loss: 11.6134\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 16.6335 - val_loss: 10.9174\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 11.6143 - val_loss: 11.7056\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 12.0276 - val_loss: 26.2806\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 18.1975 - val_loss: 7.7228\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 8.7899 - val_loss: 10.2218\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 8.6143 - val_loss: 10.7480\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 15.1159 - val_loss: 11.9919\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 8.0354 - val_loss: 7.1591\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 7.9457 - val_loss: 6.6974\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 7.7521 - val_loss: 6.5173\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 7.9243 - val_loss: 8.7748\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 8.1386 - val_loss: 5.3831\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 6.9476 - val_loss: 9.5311\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 41.8669 - val_loss: 15.7222\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 10.9167 - val_loss: 7.4462\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 7.3795 - val_loss: 6.4251\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 6.8437 - val_loss: 5.2164\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 5.7989 - val_loss: 5.9554\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 5.7598 - val_loss: 4.4763\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 4.4762552417753545\n",
      "Mean Absolute Error (MAE): 1.4571747721395152\n",
      "Root Mean Squared Error (RMSE): 2.115716247934811\n",
      "Time taken: 1203.0305080413818\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 9s 17ms/step - loss: 4051.8877 - val_loss: 3942.2236\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3730.6904 - val_loss: 3720.6167\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 3529.0791 - val_loss: 3535.5398\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3356.3757 - val_loss: 3373.3169\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 3205.0872 - val_loss: 3234.3794\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3075.1877 - val_loss: 3114.6611\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2963.2468 - val_loss: 3012.1946\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2867.0969 - val_loss: 2924.7429\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2785.1321 - val_loss: 2851.1448\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2716.0356 - val_loss: 2789.3000\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2658.5227 - val_loss: 2738.8970\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2611.6064 - val_loss: 2698.6843\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2574.3196 - val_loss: 2667.4141\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2545.6367 - val_loss: 2644.0642\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2524.5547 - val_loss: 2627.5503\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2509.6882 - val_loss: 2616.7207\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2499.7361 - val_loss: 2609.8948\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2493.6013 - val_loss: 2606.0947\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2490.0566 - val_loss: 2604.0593\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2488.3157 - val_loss: 2603.4937\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.5195 - val_loss: 2603.4587\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.2385 - val_loss: 2603.4905\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.1062 - val_loss: 2603.5374\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0305 - val_loss: 2603.4946\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0122 - val_loss: 2603.6052\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0608 - val_loss: 2603.5808\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2487.0569 - val_loss: 2603.5020\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0356 - val_loss: 2603.5681\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0828 - val_loss: 2603.5557\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0701 - val_loss: 2603.6753\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0291 - val_loss: 2603.5217\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0916 - val_loss: 2603.5803\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0090 - val_loss: 2603.5601\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0229 - val_loss: 2603.3552\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0122 - val_loss: 2603.5398\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0522 - val_loss: 2603.4910\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0486 - val_loss: 2603.6062\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2486.9810 - val_loss: 2603.6260\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0564 - val_loss: 2603.6797\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0369 - val_loss: 2603.7332\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.1086 - val_loss: 2603.6965\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2486.9668 - val_loss: 2603.6147\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0520 - val_loss: 2603.7012\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0295 - val_loss: 2603.6296\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0330 - val_loss: 2603.5422\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0652 - val_loss: 2603.6538\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2487.1130 - val_loss: 2603.5830\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2487.0295 - val_loss: 2603.7041\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0337 - val_loss: 2603.6431\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0427 - val_loss: 2603.6240\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0120 - val_loss: 2603.6465\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0767 - val_loss: 2603.5793\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0654 - val_loss: 2603.6694\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0544 - val_loss: 2603.5564\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0369 - val_loss: 2603.5386\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0234 - val_loss: 2603.5559\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0610 - val_loss: 2603.6355\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0938 - val_loss: 2603.6145\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0205 - val_loss: 2603.5510\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0063 - val_loss: 2603.5989\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0369 - val_loss: 2603.7231\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.1487 - val_loss: 2603.5334\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0688 - val_loss: 2603.5029\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2486.9875 - val_loss: 2603.5601\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0652 - val_loss: 2603.7102\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0046 - val_loss: 2603.4961\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0430 - val_loss: 2603.4141\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0439 - val_loss: 2603.5945\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.1274 - val_loss: 2603.6147\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0237 - val_loss: 2603.4697\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.1272 - val_loss: 2603.6279\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2486.9888 - val_loss: 2603.3860\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0247 - val_loss: 2603.5552\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2486.9951 - val_loss: 2603.5562\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0073 - val_loss: 2603.4834\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0432 - val_loss: 2603.3665\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0886 - val_loss: 2603.6475\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0129 - val_loss: 2603.2737\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0818 - val_loss: 2603.3921\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2486.9907 - val_loss: 2603.4666\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0312 - val_loss: 2603.4070\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0356 - val_loss: 2603.5957\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0850 - val_loss: 2603.4326\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0427 - val_loss: 2603.5759\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0056 - val_loss: 2603.4067\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0164 - val_loss: 2603.4961\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.1042 - val_loss: 2603.6082\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2486.9731 - val_loss: 2603.4727\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2487.0474 - val_loss: 2603.5637\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0083 - val_loss: 2603.5383\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0166 - val_loss: 2603.6360\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0974 - val_loss: 2603.5491\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0110 - val_loss: 2603.5806\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2486.9824 - val_loss: 2603.6562\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0127 - val_loss: 2603.5527\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0076 - val_loss: 2603.6021\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0159 - val_loss: 2603.5442\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2486.9849 - val_loss: 2603.5635\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0103 - val_loss: 2603.4236\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0430 - val_loss: 2603.6096\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0115 - val_loss: 2603.5659\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0054 - val_loss: 2603.6704\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0103 - val_loss: 2603.6221\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2486.9998 - val_loss: 2603.4883\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0212 - val_loss: 2603.5845\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2486.9966 - val_loss: 2603.4824\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2487.0354 - val_loss: 2603.6428\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0259 - val_loss: 2603.5566\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0249 - val_loss: 2603.6680\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0291 - val_loss: 2603.3899\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0098 - val_loss: 2603.5854\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0510 - val_loss: 2603.6323\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0300 - val_loss: 2603.5991\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0181 - val_loss: 2603.5630\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0483 - val_loss: 2603.4451\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2486.9988 - val_loss: 2603.5820\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0527 - val_loss: 2603.5156\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0439 - val_loss: 2603.4573\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0991 - val_loss: 2603.4216\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0049 - val_loss: 2603.4761\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0393 - val_loss: 2603.6133\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.1272 - val_loss: 2603.6042\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0676 - val_loss: 2603.7642\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0867 - val_loss: 2603.6914\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2487.0769 - val_loss: 2603.6240\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2487.0762 - val_loss: 2603.6738\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2487.0432 - val_loss: 2603.6282\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0432 - val_loss: 2603.4980\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0623 - val_loss: 2603.6531\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2487.0312 - val_loss: 2603.6719\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0234 - val_loss: 2603.7715\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2486.9983 - val_loss: 2603.7400\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0510 - val_loss: 2603.8406\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0056 - val_loss: 2603.7559\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0696 - val_loss: 2603.6699\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.1021 - val_loss: 2603.6702\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2487.0720 - val_loss: 2603.7676\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 2487.0640 - val_loss: 2603.5005\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0317 - val_loss: 2603.5459\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0220 - val_loss: 2603.6521\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0198 - val_loss: 2603.4502\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.1145 - val_loss: 2603.5178\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2487.0205 - val_loss: 2603.4731\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0276 - val_loss: 2603.6748\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.1064 - val_loss: 2603.5042\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0608 - val_loss: 2603.5454\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0615 - val_loss: 2603.4746\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0200 - val_loss: 2603.5002\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0029 - val_loss: 2603.3689\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.4861 - val_loss: 2604.5854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.5581 - val_loss: 2604.0251\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.1848 - val_loss: 2603.7766\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0618 - val_loss: 2603.7815\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0859 - val_loss: 2603.6655\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0476 - val_loss: 2603.7249\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2487.0808 - val_loss: 2603.6333\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0396 - val_loss: 2603.6106\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2487.0054 - val_loss: 2603.7725\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2486.9097 - val_loss: 2601.4871\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2474.9565 - val_loss: 2565.5801\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2400.6704 - val_loss: 2491.1838\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2362.9028 - val_loss: 2456.2537\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2391.8757 - val_loss: 2454.2288\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2424.3467 - val_loss: 2606.7891\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2445.4492 - val_loss: 2420.8838\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2304.8020 - val_loss: 2390.5161\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2274.3755 - val_loss: 2363.5852\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2248.9343 - val_loss: 2338.0981\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2226.5991 - val_loss: 2315.7397\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2207.9160 - val_loss: 2293.1428\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2187.0168 - val_loss: 2271.6772\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2167.9001 - val_loss: 2251.6018\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2150.4907 - val_loss: 2231.6279\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2133.5706 - val_loss: 2212.6035\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2144.3435 - val_loss: 2438.5171\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2331.9700 - val_loss: 2343.1587\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2331.8193 - val_loss: 2345.6719\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2160.0562 - val_loss: 2187.6389\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2084.3279 - val_loss: 2167.9829\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2049.9211 - val_loss: 2115.7241\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2035.7667 - val_loss: 2094.3835\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2036.3495 - val_loss: 2087.7908\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1974.4482 - val_loss: 2042.3942\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1947.5339 - val_loss: 1989.6519\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1904.2869 - val_loss: 1957.5818\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1860.1948 - val_loss: 1912.2898\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1815.2374 - val_loss: 1861.3629\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1762.2401 - val_loss: 1802.7307\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1742.3788 - val_loss: 1784.3728\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1681.6803 - val_loss: 1705.9438\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1614.6018 - val_loss: 1642.7749\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1547.0753 - val_loss: 1569.8065\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1485.3552 - val_loss: 1516.7942\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1430.9475 - val_loss: 1462.3910\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1373.6317 - val_loss: 1400.7548\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1310.8531 - val_loss: 1330.6412\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1246.1698 - val_loss: 1273.3479\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 1187.9396 - val_loss: 1215.7294\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1131.3662 - val_loss: 1159.6050\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1172.0402 - val_loss: 1238.0239\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 1238.024320216346\n",
      "Mean Absolute Error (MAE): 26.640931976171373\n",
      "Root Mean Squared Error (RMSE): 35.18556977251251\n",
      "Time taken: 1203.1218876838684\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 4055.2673 - val_loss: 3864.2246\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3728.9656 - val_loss: 3637.2788\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3525.8757 - val_loss: 3449.5732\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3355.3149 - val_loss: 3288.8682\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3208.5291 - val_loss: 3149.9910\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 3081.5925 - val_loss: 3029.3350\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2971.9790 - val_loss: 2925.0176\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2877.9319 - val_loss: 2835.6060\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2797.8835 - val_loss: 2759.4854\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2730.8135 - val_loss: 2695.9312\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2675.4595 - val_loss: 2643.8926\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2630.5652 - val_loss: 2601.1943\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2595.1245 - val_loss: 2568.4231\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2568.0959 - val_loss: 2542.8916\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2548.3750 - val_loss: 2524.4644\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2534.6846 - val_loss: 2511.7378\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2525.7095 - val_loss: 2503.6523\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2520.4236 - val_loss: 2498.5806\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2517.5864 - val_loss: 2495.3596\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2516.0823 - val_loss: 2494.0913\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.4946 - val_loss: 2493.2600\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2712 - val_loss: 2492.8147\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2048 - val_loss: 2492.6821\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1414 - val_loss: 2492.4495\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2026 - val_loss: 2492.4429\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1602 - val_loss: 2492.6987\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1917 - val_loss: 2492.5278\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1624 - val_loss: 2492.4224\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.2234 - val_loss: 2492.5178\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1116 - val_loss: 2492.5105\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2134 - val_loss: 2492.5674\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1936 - val_loss: 2492.7388\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1104 - val_loss: 2492.5620\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1443 - val_loss: 2492.6497\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1699 - val_loss: 2492.4163\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2036 - val_loss: 2492.7322\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1443 - val_loss: 2492.6152\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1531 - val_loss: 2492.5593\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2515.1125 - val_loss: 2492.4548\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1787 - val_loss: 2492.6887\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1799 - val_loss: 2492.4146\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2515.1584 - val_loss: 2492.6448\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1436 - val_loss: 2492.6292\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1304 - val_loss: 2492.4539\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1462 - val_loss: 2492.5010\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1814 - val_loss: 2492.5396\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1169 - val_loss: 2492.4575\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1099 - val_loss: 2492.5164\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1929 - val_loss: 2492.5298\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1914 - val_loss: 2492.4102\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1692 - val_loss: 2492.4468\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1328 - val_loss: 2492.4946\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1689 - val_loss: 2492.5593\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1511 - val_loss: 2492.4265\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1807 - val_loss: 2492.5591\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1523 - val_loss: 2492.3013\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1672 - val_loss: 2492.5603\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1948 - val_loss: 2492.4783\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1296 - val_loss: 2492.3330\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1824 - val_loss: 2492.4172\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1392 - val_loss: 2492.4241\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1626 - val_loss: 2492.5559\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1885 - val_loss: 2492.4587\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1453 - val_loss: 2492.5244\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1528 - val_loss: 2492.5630\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1711 - val_loss: 2492.4910\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1787 - val_loss: 2492.5627\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1609 - val_loss: 2492.7917\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1348 - val_loss: 2492.5757\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1633 - val_loss: 2492.2170\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1523 - val_loss: 2492.4031\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1868 - val_loss: 2492.7104\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1907 - val_loss: 2492.4473\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1787 - val_loss: 2492.4177\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1995 - val_loss: 2492.5178\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.0894 - val_loss: 2492.4785\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1899 - val_loss: 2492.3247\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1646 - val_loss: 2492.3940\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1858 - val_loss: 2492.1594\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1995 - val_loss: 2492.4998\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1199 - val_loss: 2492.4604\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2139 - val_loss: 2492.3525\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1772 - val_loss: 2492.4204\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1953 - val_loss: 2492.5112\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1272 - val_loss: 2492.4509\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1677 - val_loss: 2492.5928\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1013 - val_loss: 2492.4707\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1233 - val_loss: 2492.2324\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1760 - val_loss: 2492.4485\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1099 - val_loss: 2492.3208\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1860 - val_loss: 2492.2917\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1472 - val_loss: 2492.5449\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1853 - val_loss: 2492.2698\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1548 - val_loss: 2492.6057\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1775 - val_loss: 2492.4194\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1489 - val_loss: 2492.3882\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1094 - val_loss: 2492.6201\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1897 - val_loss: 2492.4968\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2371 - val_loss: 2492.5229\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1799 - val_loss: 2492.4563\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1699 - val_loss: 2492.5535\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1692 - val_loss: 2492.4570\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1057 - val_loss: 2492.5034\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1550 - val_loss: 2492.5146\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1704 - val_loss: 2492.3853\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1831 - val_loss: 2492.5146\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1873 - val_loss: 2492.3381\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1750 - val_loss: 2492.6362\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1753 - val_loss: 2492.4919\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1086 - val_loss: 2492.4697\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1135 - val_loss: 2492.6497\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2170 - val_loss: 2492.5356\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1824 - val_loss: 2492.5540\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1614 - val_loss: 2492.5852\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2173 - val_loss: 2492.2620\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1750 - val_loss: 2492.4038\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1602 - val_loss: 2492.4954\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1384 - val_loss: 2492.5002\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2515.1882 - val_loss: 2492.4248\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1387 - val_loss: 2492.3450\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2073 - val_loss: 2492.3755\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1060 - val_loss: 2492.3955\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1458 - val_loss: 2492.4680\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1438 - val_loss: 2492.4380\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2466 - val_loss: 2492.4912\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1204 - val_loss: 2492.4211\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.2104 - val_loss: 2492.5620\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.2375 - val_loss: 2492.3157\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1321 - val_loss: 2492.4827\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1987 - val_loss: 2492.3503\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.0955 - val_loss: 2492.4365\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1797 - val_loss: 2492.3701\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1470 - val_loss: 2492.3345\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2043 - val_loss: 2492.3069\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1191 - val_loss: 2492.2114\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1755 - val_loss: 2492.4092\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1216 - val_loss: 2492.4412\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1509 - val_loss: 2492.4612\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1509 - val_loss: 2492.3643\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1892 - val_loss: 2492.4963\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1199 - val_loss: 2492.4697\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1367 - val_loss: 2492.4915\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1819 - val_loss: 2492.3445\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2515.1550 - val_loss: 2492.3982\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1597 - val_loss: 2492.3604\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1692 - val_loss: 2492.2859\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1687 - val_loss: 2492.4353\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.2324 - val_loss: 2492.4360\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1975 - val_loss: 2492.2532\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1309 - val_loss: 2492.4487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1648 - val_loss: 2492.3481\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1697 - val_loss: 2492.3967\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1689 - val_loss: 2492.2971\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1914 - val_loss: 2492.3801\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1689 - val_loss: 2492.4395\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1995 - val_loss: 2492.3523\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1313 - val_loss: 2492.4409\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2515.1606 - val_loss: 2492.5923\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1638 - val_loss: 2492.5820\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1489 - val_loss: 2492.6145\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1814 - val_loss: 2492.3889\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1750 - val_loss: 2492.5354\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1582 - val_loss: 2492.5457\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1650 - val_loss: 2492.5398\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2341 - val_loss: 2492.4834\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1826 - val_loss: 2492.4202\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1599 - val_loss: 2492.4060\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1780 - val_loss: 2492.4470\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1829 - val_loss: 2492.2668\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2041 - val_loss: 2492.3816\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1965 - val_loss: 2492.3088\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1492 - val_loss: 2492.2761\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1980 - val_loss: 2492.2544\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1086 - val_loss: 2492.2493\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1333 - val_loss: 2492.2583\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2515.1726 - val_loss: 2492.2617\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1677 - val_loss: 2492.3845\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1460 - val_loss: 2492.2463\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1646 - val_loss: 2492.4878\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1782 - val_loss: 2492.3198\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2053 - val_loss: 2492.3184\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2515.2273 - val_loss: 2492.2188\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1584 - val_loss: 2492.2200\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1978 - val_loss: 2492.3130\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2515.1567 - val_loss: 2492.3450\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1309 - val_loss: 2492.3757\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1794 - val_loss: 2492.2849\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2019 - val_loss: 2492.2251\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1477 - val_loss: 2492.3455\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1465 - val_loss: 2492.3215\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.0908 - val_loss: 2492.2605\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1965 - val_loss: 2492.2537\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.2158 - val_loss: 2492.5149\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2515.1899 - val_loss: 2492.4282\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1501 - val_loss: 2492.4929\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1428 - val_loss: 2492.2141\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1523 - val_loss: 2492.2834\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1362 - val_loss: 2492.6550\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.1267 - val_loss: 2492.6440\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2515.2280 - val_loss: 2492.4949\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 2492.4948446599224\n",
      "Mean Absolute Error (MAE): 39.461583108813215\n",
      "Root Mean Squared Error (RMSE): 49.92489203453446\n",
      "Time taken: 1187.4799528121948\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 4038.5706 - val_loss: 3718.1243\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3718.3596 - val_loss: 3500.0930\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3519.1489 - val_loss: 3319.6609\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3351.1902 - val_loss: 3164.9924\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3206.8455 - val_loss: 3031.9009\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 3082.4321 - val_loss: 2916.7681\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2975.0896 - val_loss: 2817.8457\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2883.2678 - val_loss: 2733.5515\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2805.5178 - val_loss: 2662.0454\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2740.2683 - val_loss: 2602.7607\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2686.4951 - val_loss: 2554.3882\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2643.0122 - val_loss: 2515.4834\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2608.8679 - val_loss: 2485.5210\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2582.8596 - val_loss: 2463.0293\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2563.8994 - val_loss: 2446.7610\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2550.8010 - val_loss: 2436.0063\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2542.3289 - val_loss: 2429.1868\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2537.3228 - val_loss: 2425.6406\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2534.7048 - val_loss: 2423.5115\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2533.3633 - val_loss: 2422.6357\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.7874 - val_loss: 2422.1567\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5247 - val_loss: 2422.3242\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5256 - val_loss: 2422.1392\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4832 - val_loss: 2422.0510\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4468 - val_loss: 2422.1421\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2532.4773 - val_loss: 2422.2300\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 2532.5286 - val_loss: 2422.1912\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4458 - val_loss: 2422.3315\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4116 - val_loss: 2422.3396\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4631 - val_loss: 2422.2136\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4290 - val_loss: 2422.2756\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.3958 - val_loss: 2422.3503\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4229 - val_loss: 2422.3506\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4207 - val_loss: 2422.2471\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4495 - val_loss: 2422.1638\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4360 - val_loss: 2422.2646\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5334 - val_loss: 2422.2188\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5217 - val_loss: 2422.4180\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5105 - val_loss: 2422.1743\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4788 - val_loss: 2422.1707\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4309 - val_loss: 2422.3506\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4465 - val_loss: 2422.1362\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4236 - val_loss: 2422.3013\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4280 - val_loss: 2422.2070\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4893 - val_loss: 2422.3235\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.3870 - val_loss: 2422.4270\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4116 - val_loss: 2422.4165\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4192 - val_loss: 2422.4253\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4568 - val_loss: 2422.3335\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4333 - val_loss: 2422.3975\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4648 - val_loss: 2422.2825\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4438 - val_loss: 2422.4583\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4248 - val_loss: 2422.3271\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4080 - val_loss: 2422.3403\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4199 - val_loss: 2422.1809\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4712 - val_loss: 2422.3633\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5178 - val_loss: 2422.3350\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4561 - val_loss: 2422.3193\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.3914 - val_loss: 2422.2854\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4355 - val_loss: 2422.4136\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.3889 - val_loss: 2422.4431\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4519 - val_loss: 2422.3662\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4338 - val_loss: 2422.5115\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4409 - val_loss: 2422.4053\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4067 - val_loss: 2422.2927\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4421 - val_loss: 2422.3335\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4346 - val_loss: 2422.4592\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4460 - val_loss: 2422.3865\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4766 - val_loss: 2422.3652\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.8469 - val_loss: 2420.9094\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.8394 - val_loss: 2420.7739\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.6023 - val_loss: 2420.9729\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4851 - val_loss: 2421.1370\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 2532.5015 - val_loss: 2421.1519\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2532.4617 - val_loss: 2421.3333\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4653 - val_loss: 2421.5603\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4541 - val_loss: 2421.7092\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4673 - val_loss: 2421.6997\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4260 - val_loss: 2421.8765\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4941 - val_loss: 2422.0618\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4517 - val_loss: 2422.0085\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4875 - val_loss: 2421.9990\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4446 - val_loss: 2422.0972\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4141 - val_loss: 2422.1804\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4211 - val_loss: 2422.1414\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4529 - val_loss: 2422.2507\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4617 - val_loss: 2422.2820\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2532.4143 - val_loss: 2422.1611\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4143 - val_loss: 2422.2664\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4587 - val_loss: 2422.1538\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4497 - val_loss: 2422.3059\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4199 - val_loss: 2422.4062\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4863 - val_loss: 2422.3403\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5056 - val_loss: 2422.4385\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4844 - val_loss: 2422.1875\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4272 - val_loss: 2422.2832\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4199 - val_loss: 2422.3137\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5115 - val_loss: 2422.3076\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4788 - val_loss: 2422.3625\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4128 - val_loss: 2422.2241\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4438 - val_loss: 2422.2581\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4272 - val_loss: 2422.1982\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4678 - val_loss: 2422.2153\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4900 - val_loss: 2422.4573\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4424 - val_loss: 2422.2134\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4709 - val_loss: 2422.2771\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4785 - val_loss: 2422.3269\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4880 - val_loss: 2422.4946\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4590 - val_loss: 2422.4099\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4553 - val_loss: 2422.3599\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4526 - val_loss: 2422.2842\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4541 - val_loss: 2422.3169\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4414 - val_loss: 2422.3174\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4309 - val_loss: 2422.3572\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4421 - val_loss: 2422.2322\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4604 - val_loss: 2422.4541\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4875 - val_loss: 2422.3455\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4326 - val_loss: 2422.3870\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4165 - val_loss: 2422.2991\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4299 - val_loss: 2422.4890\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4265 - val_loss: 2422.2217\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2532.4246 - val_loss: 2422.1846\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4495 - val_loss: 2422.3237\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4727 - val_loss: 2422.3447\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4097 - val_loss: 2422.3059\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.5225 - val_loss: 2422.4087\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4807 - val_loss: 2422.4016\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4722 - val_loss: 2422.3618\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2532.4609 - val_loss: 2422.5613\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2522.1152 - val_loss: 2384.1633\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2445.0571 - val_loss: 2328.2981\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2413.4316 - val_loss: 2307.2207\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2387.6067 - val_loss: 2283.5359\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2359.0981 - val_loss: 2250.4668\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 2328.7441 - val_loss: 2227.8855\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2303.8618 - val_loss: 2209.1760\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2290.0234 - val_loss: 2210.8870\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2280.9834 - val_loss: 2195.3862\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2264.0610 - val_loss: 2180.6946\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2252.3997 - val_loss: 2172.7607\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2340.0449 - val_loss: 2430.3130\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2258.3787 - val_loss: 2115.7119\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2172.1279 - val_loss: 2076.0920\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2148.1594 - val_loss: 2058.5632\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2162.5493 - val_loss: 2200.5242\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2302.1150 - val_loss: 2187.6951\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2290.1714 - val_loss: 2177.7600\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2284.1650 - val_loss: 2173.4368\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 2277.2534 - val_loss: 2165.6038\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2270.3823 - val_loss: 2158.4592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2263.6296 - val_loss: 2147.5405\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2256.2166 - val_loss: 2138.4375\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2250.0334 - val_loss: 2130.7476\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2202.9390 - val_loss: 2045.0490\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2139.0122 - val_loss: 2364.2205\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2162.7148 - val_loss: 1965.6404\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2041.8274 - val_loss: 1936.1583\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 2010.1711 - val_loss: 1933.5712\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1983.1631 - val_loss: 1895.0349\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1958.0864 - val_loss: 1856.2518\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1927.4402 - val_loss: 1822.3846\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1885.5516 - val_loss: 1784.9807\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1833.6688 - val_loss: 1730.9417\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1770.1351 - val_loss: 1668.5438\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1696.7605 - val_loss: 1595.6105\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1632.7638 - val_loss: 1534.2794\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1567.3221 - val_loss: 1480.0979\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1494.3096 - val_loss: 1400.3022\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1428.8407 - val_loss: 1358.7363\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1375.4066 - val_loss: 1280.7544\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1301.3065 - val_loss: 1224.8979\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1238.1595 - val_loss: 1161.4462\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1179.4608 - val_loss: 1108.0281\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1124.8824 - val_loss: 1056.0084\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1070.2054 - val_loss: 1022.1618\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1022.7339 - val_loss: 954.9116\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 968.6013 - val_loss: 909.8515\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.3343 - val_loss: 871.1008\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 877.6372 - val_loss: 821.7081\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 828.9121 - val_loss: 777.7561\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 786.8130 - val_loss: 742.6764\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 738.2028 - val_loss: 698.3741\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 696.2504 - val_loss: 656.1672\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 658.2415 - val_loss: 626.9296\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 622.9421 - val_loss: 592.3910\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 607.0949 - val_loss: 558.9125\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 554.6237 - val_loss: 522.9417\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 518.5942 - val_loss: 492.6416\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 494.8558 - val_loss: 472.1628\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 456.9195 - val_loss: 452.7771\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 431.7336 - val_loss: 419.7102\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 421.6783 - val_loss: 396.7808\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 376.9465 - val_loss: 368.3576\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 351.0671 - val_loss: 337.0851\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 326.5056 - val_loss: 311.5265\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 316.4984 - val_loss: 296.4681\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 281.8015 - val_loss: 272.1135\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 274.4631 - val_loss: 256.9934\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 244.3864 - val_loss: 237.8780\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 231.0470 - val_loss: 262.0015\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 262.00163256267393\n",
      "Mean Absolute Error (MAE): 12.302892975533661\n",
      "Root Mean Squared Error (RMSE): 16.1864644861895\n",
      "Time taken: 1203.177899837494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 48, 512)           1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 48, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_3648\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold          MSE        MAE       RMSE   Time taken\n",
      "0        1  2564.834796  39.927202  50.644198  1210.120870\n",
      "1        2     4.476255   1.457175   2.115716  1203.030508\n",
      "2        3  1238.024320  26.640932  35.185570  1203.121888\n",
      "3        4  2492.494845  39.461583  49.924892  1187.479953\n",
      "4        5   262.001633  12.302893  16.186464  1203.177900\n",
      "5  Average  1312.366370  23.957957  30.811368  1201.386224\n",
      "Results saved to 'DL_Result_PL_model_2_smoothing2_Reg2.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_2_smoothing2_Reg2.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'DL_Result_PL_model_2_smoothing2_Reg2.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
