{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_2_Scattered_iReg_f_obese.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.088564</td>\n",
       "      <td>83.359765</td>\n",
       "      <td>72.810479</td>\n",
       "      <td>84.761720</td>\n",
       "      <td>88.208785</td>\n",
       "      <td>87.386594</td>\n",
       "      <td>87.989820</td>\n",
       "      <td>99.504084</td>\n",
       "      <td>81.894690</td>\n",
       "      <td>94.784763</td>\n",
       "      <td>...</td>\n",
       "      <td>90.665048</td>\n",
       "      <td>79.643971</td>\n",
       "      <td>86.568537</td>\n",
       "      <td>72.573973</td>\n",
       "      <td>91.979971</td>\n",
       "      <td>77.387958</td>\n",
       "      <td>78.648446</td>\n",
       "      <td>80.175763</td>\n",
       "      <td>63.904201</td>\n",
       "      <td>78.380726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.868410</td>\n",
       "      <td>111.937084</td>\n",
       "      <td>78.153044</td>\n",
       "      <td>92.303923</td>\n",
       "      <td>94.341940</td>\n",
       "      <td>92.319593</td>\n",
       "      <td>78.066890</td>\n",
       "      <td>92.297906</td>\n",
       "      <td>92.455897</td>\n",
       "      <td>86.193229</td>\n",
       "      <td>...</td>\n",
       "      <td>79.377154</td>\n",
       "      <td>77.396781</td>\n",
       "      <td>82.724989</td>\n",
       "      <td>88.498572</td>\n",
       "      <td>88.332868</td>\n",
       "      <td>90.186047</td>\n",
       "      <td>86.806692</td>\n",
       "      <td>90.319209</td>\n",
       "      <td>57.839702</td>\n",
       "      <td>92.809324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.271226</td>\n",
       "      <td>92.651651</td>\n",
       "      <td>79.332212</td>\n",
       "      <td>90.243722</td>\n",
       "      <td>80.139444</td>\n",
       "      <td>89.964565</td>\n",
       "      <td>93.238862</td>\n",
       "      <td>97.991677</td>\n",
       "      <td>77.338745</td>\n",
       "      <td>85.778575</td>\n",
       "      <td>...</td>\n",
       "      <td>75.651275</td>\n",
       "      <td>75.958278</td>\n",
       "      <td>75.016375</td>\n",
       "      <td>76.242293</td>\n",
       "      <td>94.704560</td>\n",
       "      <td>96.031670</td>\n",
       "      <td>89.006799</td>\n",
       "      <td>85.451401</td>\n",
       "      <td>66.047750</td>\n",
       "      <td>67.418762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.192718</td>\n",
       "      <td>80.990756</td>\n",
       "      <td>73.780143</td>\n",
       "      <td>83.066844</td>\n",
       "      <td>89.334711</td>\n",
       "      <td>91.637186</td>\n",
       "      <td>71.834202</td>\n",
       "      <td>91.042129</td>\n",
       "      <td>81.862654</td>\n",
       "      <td>90.149875</td>\n",
       "      <td>...</td>\n",
       "      <td>74.803915</td>\n",
       "      <td>72.575109</td>\n",
       "      <td>86.149110</td>\n",
       "      <td>75.991768</td>\n",
       "      <td>93.042742</td>\n",
       "      <td>86.486157</td>\n",
       "      <td>90.687198</td>\n",
       "      <td>82.083500</td>\n",
       "      <td>74.726898</td>\n",
       "      <td>72.413713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.514572</td>\n",
       "      <td>81.559072</td>\n",
       "      <td>83.554513</td>\n",
       "      <td>82.645536</td>\n",
       "      <td>95.813871</td>\n",
       "      <td>98.913757</td>\n",
       "      <td>80.297571</td>\n",
       "      <td>95.594679</td>\n",
       "      <td>85.057952</td>\n",
       "      <td>90.244208</td>\n",
       "      <td>...</td>\n",
       "      <td>90.404873</td>\n",
       "      <td>79.422422</td>\n",
       "      <td>85.761368</td>\n",
       "      <td>74.655615</td>\n",
       "      <td>79.752050</td>\n",
       "      <td>99.155365</td>\n",
       "      <td>76.191908</td>\n",
       "      <td>92.759031</td>\n",
       "      <td>69.506924</td>\n",
       "      <td>73.527862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>93.125727</td>\n",
       "      <td>83.439351</td>\n",
       "      <td>81.036755</td>\n",
       "      <td>79.950195</td>\n",
       "      <td>89.508754</td>\n",
       "      <td>88.075339</td>\n",
       "      <td>89.566627</td>\n",
       "      <td>73.291011</td>\n",
       "      <td>74.687521</td>\n",
       "      <td>86.785332</td>\n",
       "      <td>...</td>\n",
       "      <td>78.986972</td>\n",
       "      <td>79.081315</td>\n",
       "      <td>75.257006</td>\n",
       "      <td>86.757843</td>\n",
       "      <td>80.744253</td>\n",
       "      <td>93.724483</td>\n",
       "      <td>79.491578</td>\n",
       "      <td>87.111958</td>\n",
       "      <td>75.056999</td>\n",
       "      <td>68.620562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>95.122335</td>\n",
       "      <td>95.470826</td>\n",
       "      <td>74.574208</td>\n",
       "      <td>78.209233</td>\n",
       "      <td>96.168873</td>\n",
       "      <td>95.904205</td>\n",
       "      <td>85.508926</td>\n",
       "      <td>83.136386</td>\n",
       "      <td>78.046302</td>\n",
       "      <td>86.112204</td>\n",
       "      <td>...</td>\n",
       "      <td>69.609793</td>\n",
       "      <td>81.060281</td>\n",
       "      <td>88.396659</td>\n",
       "      <td>91.508618</td>\n",
       "      <td>100.856096</td>\n",
       "      <td>89.118431</td>\n",
       "      <td>94.460103</td>\n",
       "      <td>87.362282</td>\n",
       "      <td>73.265236</td>\n",
       "      <td>74.496222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>105.098298</td>\n",
       "      <td>83.753285</td>\n",
       "      <td>78.929067</td>\n",
       "      <td>82.837359</td>\n",
       "      <td>91.334365</td>\n",
       "      <td>89.632293</td>\n",
       "      <td>85.194372</td>\n",
       "      <td>93.269061</td>\n",
       "      <td>93.439580</td>\n",
       "      <td>91.731618</td>\n",
       "      <td>...</td>\n",
       "      <td>75.133868</td>\n",
       "      <td>90.784393</td>\n",
       "      <td>76.016950</td>\n",
       "      <td>78.457838</td>\n",
       "      <td>98.480802</td>\n",
       "      <td>89.874526</td>\n",
       "      <td>80.168132</td>\n",
       "      <td>86.960771</td>\n",
       "      <td>72.148560</td>\n",
       "      <td>70.064729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>87.920194</td>\n",
       "      <td>85.811942</td>\n",
       "      <td>85.571091</td>\n",
       "      <td>72.577148</td>\n",
       "      <td>90.818519</td>\n",
       "      <td>86.210765</td>\n",
       "      <td>92.646837</td>\n",
       "      <td>77.670349</td>\n",
       "      <td>88.168939</td>\n",
       "      <td>70.140442</td>\n",
       "      <td>...</td>\n",
       "      <td>90.002962</td>\n",
       "      <td>82.099037</td>\n",
       "      <td>90.125534</td>\n",
       "      <td>71.019561</td>\n",
       "      <td>91.216280</td>\n",
       "      <td>87.661533</td>\n",
       "      <td>82.934108</td>\n",
       "      <td>77.484567</td>\n",
       "      <td>76.379077</td>\n",
       "      <td>69.850290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>89.029709</td>\n",
       "      <td>86.057568</td>\n",
       "      <td>83.409416</td>\n",
       "      <td>76.863674</td>\n",
       "      <td>96.270619</td>\n",
       "      <td>102.584973</td>\n",
       "      <td>91.073276</td>\n",
       "      <td>87.657617</td>\n",
       "      <td>74.150701</td>\n",
       "      <td>75.710518</td>\n",
       "      <td>...</td>\n",
       "      <td>88.938976</td>\n",
       "      <td>58.724820</td>\n",
       "      <td>69.558923</td>\n",
       "      <td>76.672508</td>\n",
       "      <td>91.020093</td>\n",
       "      <td>88.143391</td>\n",
       "      <td>74.190097</td>\n",
       "      <td>81.803884</td>\n",
       "      <td>86.968580</td>\n",
       "      <td>76.800859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1          2          3          4           5   \\\n",
       "0      92.088564   83.359765  72.810479  84.761720  88.208785   87.386594   \n",
       "1      89.868410  111.937084  78.153044  92.303923  94.341940   92.319593   \n",
       "2      80.271226   92.651651  79.332212  90.243722  80.139444   89.964565   \n",
       "3      82.192718   80.990756  73.780143  83.066844  89.334711   91.637186   \n",
       "4      82.514572   81.559072  83.554513  82.645536  95.813871   98.913757   \n",
       "...          ...         ...        ...        ...        ...         ...   \n",
       "2438   93.125727   83.439351  81.036755  79.950195  89.508754   88.075339   \n",
       "2439   95.122335   95.470826  74.574208  78.209233  96.168873   95.904205   \n",
       "2440  105.098298   83.753285  78.929067  82.837359  91.334365   89.632293   \n",
       "2441   87.920194   85.811942  85.571091  72.577148  90.818519   86.210765   \n",
       "2442   89.029709   86.057568  83.409416  76.863674  96.270619  102.584973   \n",
       "\n",
       "             6          7          8          9   ...         38         39  \\\n",
       "0     87.989820  99.504084  81.894690  94.784763  ...  90.665048  79.643971   \n",
       "1     78.066890  92.297906  92.455897  86.193229  ...  79.377154  77.396781   \n",
       "2     93.238862  97.991677  77.338745  85.778575  ...  75.651275  75.958278   \n",
       "3     71.834202  91.042129  81.862654  90.149875  ...  74.803915  72.575109   \n",
       "4     80.297571  95.594679  85.057952  90.244208  ...  90.404873  79.422422   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  89.566627  73.291011  74.687521  86.785332  ...  78.986972  79.081315   \n",
       "2439  85.508926  83.136386  78.046302  86.112204  ...  69.609793  81.060281   \n",
       "2440  85.194372  93.269061  93.439580  91.731618  ...  75.133868  90.784393   \n",
       "2441  92.646837  77.670349  88.168939  70.140442  ...  90.002962  82.099037   \n",
       "2442  91.073276  87.657617  74.150701  75.710518  ...  88.938976  58.724820   \n",
       "\n",
       "             40         41          42         43         44         45  \\\n",
       "0     86.568537  72.573973   91.979971  77.387958  78.648446  80.175763   \n",
       "1     82.724989  88.498572   88.332868  90.186047  86.806692  90.319209   \n",
       "2     75.016375  76.242293   94.704560  96.031670  89.006799  85.451401   \n",
       "3     86.149110  75.991768   93.042742  86.486157  90.687198  82.083500   \n",
       "4     85.761368  74.655615   79.752050  99.155365  76.191908  92.759031   \n",
       "...         ...        ...         ...        ...        ...        ...   \n",
       "2438  75.257006  86.757843   80.744253  93.724483  79.491578  87.111958   \n",
       "2439  88.396659  91.508618  100.856096  89.118431  94.460103  87.362282   \n",
       "2440  76.016950  78.457838   98.480802  89.874526  80.168132  86.960771   \n",
       "2441  90.125534  71.019561   91.216280  87.661533  82.934108  77.484567   \n",
       "2442  69.558923  76.672508   91.020093  88.143391  74.190097  81.803884   \n",
       "\n",
       "             46         47  \n",
       "0     63.904201  78.380726  \n",
       "1     57.839702  92.809324  \n",
       "2     66.047750  67.418762  \n",
       "3     74.726898  72.413713  \n",
       "4     69.506924  73.527862  \n",
       "...         ...        ...  \n",
       "2438  75.056999  68.620562  \n",
       "2439  73.265236  74.496222  \n",
       "2440  72.148560  70.064729  \n",
       "2441  76.379077  69.850290  \n",
       "2442  86.968580  76.800859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.088564</td>\n",
       "      <td>83.359765</td>\n",
       "      <td>72.810479</td>\n",
       "      <td>84.761720</td>\n",
       "      <td>88.208785</td>\n",
       "      <td>87.386594</td>\n",
       "      <td>87.989820</td>\n",
       "      <td>99.504084</td>\n",
       "      <td>81.894690</td>\n",
       "      <td>94.784763</td>\n",
       "      <td>...</td>\n",
       "      <td>90.665048</td>\n",
       "      <td>79.643971</td>\n",
       "      <td>86.568537</td>\n",
       "      <td>72.573973</td>\n",
       "      <td>91.979971</td>\n",
       "      <td>77.387958</td>\n",
       "      <td>78.648446</td>\n",
       "      <td>80.175763</td>\n",
       "      <td>63.904201</td>\n",
       "      <td>78.380726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.868410</td>\n",
       "      <td>111.937084</td>\n",
       "      <td>78.153044</td>\n",
       "      <td>92.303923</td>\n",
       "      <td>94.341940</td>\n",
       "      <td>92.319593</td>\n",
       "      <td>78.066890</td>\n",
       "      <td>92.297906</td>\n",
       "      <td>92.455897</td>\n",
       "      <td>86.193229</td>\n",
       "      <td>...</td>\n",
       "      <td>79.377154</td>\n",
       "      <td>77.396781</td>\n",
       "      <td>82.724989</td>\n",
       "      <td>88.498572</td>\n",
       "      <td>88.332868</td>\n",
       "      <td>90.186047</td>\n",
       "      <td>86.806692</td>\n",
       "      <td>90.319209</td>\n",
       "      <td>57.839702</td>\n",
       "      <td>92.809324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.271226</td>\n",
       "      <td>92.651651</td>\n",
       "      <td>79.332212</td>\n",
       "      <td>90.243722</td>\n",
       "      <td>80.139444</td>\n",
       "      <td>89.964565</td>\n",
       "      <td>93.238862</td>\n",
       "      <td>97.991677</td>\n",
       "      <td>77.338745</td>\n",
       "      <td>85.778575</td>\n",
       "      <td>...</td>\n",
       "      <td>75.651275</td>\n",
       "      <td>75.958278</td>\n",
       "      <td>75.016375</td>\n",
       "      <td>76.242293</td>\n",
       "      <td>94.704560</td>\n",
       "      <td>96.031670</td>\n",
       "      <td>89.006799</td>\n",
       "      <td>85.451401</td>\n",
       "      <td>66.047750</td>\n",
       "      <td>67.418762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.192718</td>\n",
       "      <td>80.990756</td>\n",
       "      <td>73.780143</td>\n",
       "      <td>83.066844</td>\n",
       "      <td>89.334711</td>\n",
       "      <td>91.637186</td>\n",
       "      <td>71.834202</td>\n",
       "      <td>91.042129</td>\n",
       "      <td>81.862654</td>\n",
       "      <td>90.149875</td>\n",
       "      <td>...</td>\n",
       "      <td>74.803915</td>\n",
       "      <td>72.575109</td>\n",
       "      <td>86.149110</td>\n",
       "      <td>75.991768</td>\n",
       "      <td>93.042742</td>\n",
       "      <td>86.486157</td>\n",
       "      <td>90.687198</td>\n",
       "      <td>82.083500</td>\n",
       "      <td>74.726898</td>\n",
       "      <td>72.413713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.514572</td>\n",
       "      <td>81.559072</td>\n",
       "      <td>83.554513</td>\n",
       "      <td>82.645536</td>\n",
       "      <td>95.813871</td>\n",
       "      <td>98.913757</td>\n",
       "      <td>80.297571</td>\n",
       "      <td>95.594679</td>\n",
       "      <td>85.057952</td>\n",
       "      <td>90.244208</td>\n",
       "      <td>...</td>\n",
       "      <td>90.404873</td>\n",
       "      <td>79.422422</td>\n",
       "      <td>85.761368</td>\n",
       "      <td>74.655615</td>\n",
       "      <td>79.752050</td>\n",
       "      <td>99.155365</td>\n",
       "      <td>76.191908</td>\n",
       "      <td>92.759031</td>\n",
       "      <td>69.506924</td>\n",
       "      <td>73.527862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>93.125727</td>\n",
       "      <td>83.439351</td>\n",
       "      <td>81.036755</td>\n",
       "      <td>79.950195</td>\n",
       "      <td>89.508754</td>\n",
       "      <td>88.075339</td>\n",
       "      <td>89.566627</td>\n",
       "      <td>73.291011</td>\n",
       "      <td>74.687521</td>\n",
       "      <td>86.785332</td>\n",
       "      <td>...</td>\n",
       "      <td>78.986972</td>\n",
       "      <td>79.081315</td>\n",
       "      <td>75.257006</td>\n",
       "      <td>86.757843</td>\n",
       "      <td>80.744253</td>\n",
       "      <td>93.724483</td>\n",
       "      <td>79.491578</td>\n",
       "      <td>87.111958</td>\n",
       "      <td>75.056999</td>\n",
       "      <td>68.620562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>95.122335</td>\n",
       "      <td>95.470826</td>\n",
       "      <td>74.574208</td>\n",
       "      <td>78.209233</td>\n",
       "      <td>96.168873</td>\n",
       "      <td>95.904205</td>\n",
       "      <td>85.508926</td>\n",
       "      <td>83.136386</td>\n",
       "      <td>78.046302</td>\n",
       "      <td>86.112204</td>\n",
       "      <td>...</td>\n",
       "      <td>69.609793</td>\n",
       "      <td>81.060281</td>\n",
       "      <td>88.396659</td>\n",
       "      <td>91.508618</td>\n",
       "      <td>100.856096</td>\n",
       "      <td>89.118431</td>\n",
       "      <td>94.460103</td>\n",
       "      <td>87.362282</td>\n",
       "      <td>73.265236</td>\n",
       "      <td>74.496222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>105.098298</td>\n",
       "      <td>83.753285</td>\n",
       "      <td>78.929067</td>\n",
       "      <td>82.837359</td>\n",
       "      <td>91.334365</td>\n",
       "      <td>89.632293</td>\n",
       "      <td>85.194372</td>\n",
       "      <td>93.269061</td>\n",
       "      <td>93.439580</td>\n",
       "      <td>91.731618</td>\n",
       "      <td>...</td>\n",
       "      <td>75.133868</td>\n",
       "      <td>90.784393</td>\n",
       "      <td>76.016950</td>\n",
       "      <td>78.457838</td>\n",
       "      <td>98.480802</td>\n",
       "      <td>89.874526</td>\n",
       "      <td>80.168132</td>\n",
       "      <td>86.960771</td>\n",
       "      <td>72.148560</td>\n",
       "      <td>70.064729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>87.920194</td>\n",
       "      <td>85.811942</td>\n",
       "      <td>85.571091</td>\n",
       "      <td>72.577148</td>\n",
       "      <td>90.818519</td>\n",
       "      <td>86.210765</td>\n",
       "      <td>92.646837</td>\n",
       "      <td>77.670349</td>\n",
       "      <td>88.168939</td>\n",
       "      <td>70.140442</td>\n",
       "      <td>...</td>\n",
       "      <td>90.002962</td>\n",
       "      <td>82.099037</td>\n",
       "      <td>90.125534</td>\n",
       "      <td>71.019561</td>\n",
       "      <td>91.216280</td>\n",
       "      <td>87.661533</td>\n",
       "      <td>82.934108</td>\n",
       "      <td>77.484567</td>\n",
       "      <td>76.379077</td>\n",
       "      <td>69.850290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>89.029709</td>\n",
       "      <td>86.057568</td>\n",
       "      <td>83.409416</td>\n",
       "      <td>76.863674</td>\n",
       "      <td>96.270619</td>\n",
       "      <td>102.584973</td>\n",
       "      <td>91.073276</td>\n",
       "      <td>87.657617</td>\n",
       "      <td>74.150701</td>\n",
       "      <td>75.710518</td>\n",
       "      <td>...</td>\n",
       "      <td>88.938976</td>\n",
       "      <td>58.724820</td>\n",
       "      <td>69.558923</td>\n",
       "      <td>76.672508</td>\n",
       "      <td>91.020093</td>\n",
       "      <td>88.143391</td>\n",
       "      <td>74.190097</td>\n",
       "      <td>81.803884</td>\n",
       "      <td>86.968580</td>\n",
       "      <td>76.800859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2    sensor3    sensor4    sensor5     sensor6  \\\n",
       "0      92.088564   83.359765  72.810479  84.761720  88.208785   87.386594   \n",
       "1      89.868410  111.937084  78.153044  92.303923  94.341940   92.319593   \n",
       "2      80.271226   92.651651  79.332212  90.243722  80.139444   89.964565   \n",
       "3      82.192718   80.990756  73.780143  83.066844  89.334711   91.637186   \n",
       "4      82.514572   81.559072  83.554513  82.645536  95.813871   98.913757   \n",
       "...          ...         ...        ...        ...        ...         ...   \n",
       "2438   93.125727   83.439351  81.036755  79.950195  89.508754   88.075339   \n",
       "2439   95.122335   95.470826  74.574208  78.209233  96.168873   95.904205   \n",
       "2440  105.098298   83.753285  78.929067  82.837359  91.334365   89.632293   \n",
       "2441   87.920194   85.811942  85.571091  72.577148  90.818519   86.210765   \n",
       "2442   89.029709   86.057568  83.409416  76.863674  96.270619  102.584973   \n",
       "\n",
       "        sensor7    sensor8    sensor9   sensor10  ...   sensor39   sensor40  \\\n",
       "0     87.989820  99.504084  81.894690  94.784763  ...  90.665048  79.643971   \n",
       "1     78.066890  92.297906  92.455897  86.193229  ...  79.377154  77.396781   \n",
       "2     93.238862  97.991677  77.338745  85.778575  ...  75.651275  75.958278   \n",
       "3     71.834202  91.042129  81.862654  90.149875  ...  74.803915  72.575109   \n",
       "4     80.297571  95.594679  85.057952  90.244208  ...  90.404873  79.422422   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  89.566627  73.291011  74.687521  86.785332  ...  78.986972  79.081315   \n",
       "2439  85.508926  83.136386  78.046302  86.112204  ...  69.609793  81.060281   \n",
       "2440  85.194372  93.269061  93.439580  91.731618  ...  75.133868  90.784393   \n",
       "2441  92.646837  77.670349  88.168939  70.140442  ...  90.002962  82.099037   \n",
       "2442  91.073276  87.657617  74.150701  75.710518  ...  88.938976  58.724820   \n",
       "\n",
       "       sensor41   sensor42    sensor43   sensor44   sensor45   sensor46  \\\n",
       "0     86.568537  72.573973   91.979971  77.387958  78.648446  80.175763   \n",
       "1     82.724989  88.498572   88.332868  90.186047  86.806692  90.319209   \n",
       "2     75.016375  76.242293   94.704560  96.031670  89.006799  85.451401   \n",
       "3     86.149110  75.991768   93.042742  86.486157  90.687198  82.083500   \n",
       "4     85.761368  74.655615   79.752050  99.155365  76.191908  92.759031   \n",
       "...         ...        ...         ...        ...        ...        ...   \n",
       "2438  75.257006  86.757843   80.744253  93.724483  79.491578  87.111958   \n",
       "2439  88.396659  91.508618  100.856096  89.118431  94.460103  87.362282   \n",
       "2440  76.016950  78.457838   98.480802  89.874526  80.168132  86.960771   \n",
       "2441  90.125534  71.019561   91.216280  87.661533  82.934108  77.484567   \n",
       "2442  69.558923  76.672508   91.020093  88.143391  74.190097  81.803884   \n",
       "\n",
       "       sensor47   sensor48  \n",
       "0     63.904201  78.380726  \n",
       "1     57.839702  92.809324  \n",
       "2     66.047750  67.418762  \n",
       "3     74.726898  72.413713  \n",
       "4     69.506924  73.527862  \n",
       "...         ...        ...  \n",
       "2438  75.056999  68.620562  \n",
       "2439  73.265236  74.496222  \n",
       "2440  72.148560  70.064729  \n",
       "2441  76.379077  69.850290  \n",
       "2442  86.968580  76.800859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 15s 20ms/step - loss: 1403.3567 - val_loss: 1274.4550\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1242.1056 - val_loss: 1168.0586\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1151.1224 - val_loss: 1089.6881\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1084.0795 - val_loss: 1030.5481\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1033.6439 - val_loss: 985.5026\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 996.3500 - val_loss: 952.9229\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 969.8130 - val_loss: 929.6093\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 951.6473 - val_loss: 913.9601\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 939.9573 - val_loss: 903.9518\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 933.0225 - val_loss: 898.0770\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 929.2496 - val_loss: 894.7835\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 927.4473 - val_loss: 893.1881\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.6042 - val_loss: 892.3778\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.3127 - val_loss: 892.0541\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2476 - val_loss: 891.8661\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1742 - val_loss: 891.7820\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1894 - val_loss: 891.8220\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1772 - val_loss: 891.8795\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 926.1766 - val_loss: 891.7955\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1700 - val_loss: 891.8288\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2103 - val_loss: 891.8002\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1734 - val_loss: 891.8372\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1747 - val_loss: 891.7852\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1619 - val_loss: 891.7739\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1864 - val_loss: 891.7728\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1938 - val_loss: 891.7924\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1739 - val_loss: 891.8413\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1730 - val_loss: 891.8080\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1883 - val_loss: 891.7905\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1849 - val_loss: 891.7899\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1698 - val_loss: 891.8386\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1719 - val_loss: 891.8235\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1799 - val_loss: 891.7788\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1790 - val_loss: 891.8385\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 926.1622 - val_loss: 891.8253\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1878 - val_loss: 891.8456\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1963 - val_loss: 891.8253\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2177 - val_loss: 891.8463\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 926.1780 - val_loss: 891.8650\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1790 - val_loss: 891.8842\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1920 - val_loss: 891.8734\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1755 - val_loss: 891.8448\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1763 - val_loss: 891.8898\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2173 - val_loss: 891.8701\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2031 - val_loss: 891.8176\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1707 - val_loss: 891.8295\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1560 - val_loss: 891.7740\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1740 - val_loss: 891.8288\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1606 - val_loss: 891.8369\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1975 - val_loss: 891.8459\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2361 - val_loss: 891.8259\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1879 - val_loss: 891.8185\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2020 - val_loss: 891.8185\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1584 - val_loss: 891.8781\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1736 - val_loss: 891.8074\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1864 - val_loss: 891.8290\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1824 - val_loss: 891.8332\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1772 - val_loss: 891.8365\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1901 - val_loss: 891.8412\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1877 - val_loss: 891.8993\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 926.1473 - val_loss: 891.9053\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1982 - val_loss: 891.8844\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2159 - val_loss: 891.8474\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1505 - val_loss: 891.9074\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1699 - val_loss: 891.8966\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 926.1789 - val_loss: 891.8374\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 926.1984 - val_loss: 891.8271\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2200 - val_loss: 891.8577\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1697 - val_loss: 891.9292\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 926.2104 - val_loss: 891.8779\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1635 - val_loss: 891.8298\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 926.1885 - val_loss: 891.9056\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 926.1687 - val_loss: 891.8768\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2025 - val_loss: 891.8918\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1879 - val_loss: 891.8001\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1613 - val_loss: 891.8011\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1771 - val_loss: 891.8594\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1617 - val_loss: 891.8779\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1743 - val_loss: 891.8071\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1786 - val_loss: 891.8365\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2183 - val_loss: 891.8063\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1987 - val_loss: 891.7825\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1998 - val_loss: 891.8141\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2321 - val_loss: 891.8369\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2079 - val_loss: 891.8517\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1946 - val_loss: 891.8779\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1718 - val_loss: 891.8786\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1756 - val_loss: 891.8149\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1556 - val_loss: 891.8427\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1635 - val_loss: 891.8782\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2074 - val_loss: 891.9040\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1708 - val_loss: 891.8301\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1644 - val_loss: 891.8234\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1785 - val_loss: 891.8762\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1440 - val_loss: 891.8413\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1817 - val_loss: 891.8008\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2032 - val_loss: 891.8302\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 926.1640 - val_loss: 891.8396\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 926.1772 - val_loss: 891.8297\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1558 - val_loss: 891.8571\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1692 - val_loss: 891.8094\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 926.1725 - val_loss: 891.8376\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1589 - val_loss: 891.8154\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2158 - val_loss: 891.8982\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1617 - val_loss: 891.8718\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1978 - val_loss: 891.9445\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1859 - val_loss: 891.8491\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1835 - val_loss: 891.8494\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1735 - val_loss: 891.8240\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2089 - val_loss: 891.8616\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1766 - val_loss: 891.8537\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1658 - val_loss: 891.8543\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 926.2054 - val_loss: 891.8044\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2192 - val_loss: 891.7924\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1936 - val_loss: 891.8323\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2315 - val_loss: 891.8107\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2037 - val_loss: 891.7980\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1962 - val_loss: 891.8167\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1741 - val_loss: 891.8080\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2164 - val_loss: 891.8293\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1779 - val_loss: 891.8524\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1845 - val_loss: 891.8441\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2242 - val_loss: 891.8900\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 926.1564 - val_loss: 891.8806\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2179 - val_loss: 891.8914\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 926.1929 - val_loss: 891.8051\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 926.1779 - val_loss: 891.8238\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1359 - val_loss: 891.8391\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1956 - val_loss: 891.8644\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1779 - val_loss: 891.8836\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.2072 - val_loss: 891.8505\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2332 - val_loss: 891.8110\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1969 - val_loss: 891.8046\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2078 - val_loss: 891.7659\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1793 - val_loss: 891.8288\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1973 - val_loss: 891.7804\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1907 - val_loss: 891.8508\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1530 - val_loss: 891.8151\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1448 - val_loss: 891.8881\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1586 - val_loss: 891.9179\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.1806 - val_loss: 891.8860\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.2200 - val_loss: 891.8983\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.1926 - val_loss: 891.9119\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 926.2283 - val_loss: 891.8204\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 926.6115 - val_loss: 892.3882\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 926.1188 - val_loss: 892.0901\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 924.8691 - val_loss: 890.4417\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.9772 - val_loss: 886.4210\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 919.7355 - val_loss: 884.7172\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.9879 - val_loss: 883.0406\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 916.7073 - val_loss: 881.4988\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.2566 - val_loss: 880.0755\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 914.2654 - val_loss: 879.5513\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 913.0646 - val_loss: 877.8051\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.7947 - val_loss: 876.9747\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 910.9742 - val_loss: 876.0737\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 909.6788 - val_loss: 874.6513\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 908.3267 - val_loss: 872.9852\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.3790 - val_loss: 871.1169\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 904.5319 - val_loss: 869.2253\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 902.8736 - val_loss: 868.7336\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 901.8368 - val_loss: 866.3396\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 899.9987 - val_loss: 865.1179\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 898.4449 - val_loss: 863.8564\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 897.4922 - val_loss: 863.6635\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 896.4643 - val_loss: 863.7772\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 894.1734 - val_loss: 858.9179\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 893.1424 - val_loss: 858.5468\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 891.8505 - val_loss: 857.7780\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 890.2016 - val_loss: 857.4549\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 888.5064 - val_loss: 853.3268\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 886.0049 - val_loss: 850.9448\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 884.5872 - val_loss: 851.1451\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 883.1038 - val_loss: 848.6644\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 881.4540 - val_loss: 847.6085\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 880.1102 - val_loss: 845.8090\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 879.3870 - val_loss: 846.2008\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 877.7556 - val_loss: 848.3687\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 877.4463 - val_loss: 842.7856\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 875.8645 - val_loss: 841.8040\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 874.5248 - val_loss: 841.9918\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 874.2820 - val_loss: 840.4731\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 872.8702 - val_loss: 840.5449\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 871.5651 - val_loss: 840.1244\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 870.2953 - val_loss: 838.3264\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 869.1238 - val_loss: 837.3802\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 866.4719 - val_loss: 836.2310\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 864.5614 - val_loss: 832.2908\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 860.6245 - val_loss: 831.4140\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 858.9445 - val_loss: 826.2468\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 856.0648 - val_loss: 823.2719\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 850.5230 - val_loss: 819.5391\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 849.7719 - val_loss: 816.3561\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 843.6829 - val_loss: 807.0059\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 834.8106 - val_loss: 822.3851\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 822.5706 - val_loss: 802.9883\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 804.7077 - val_loss: 773.4924\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 810.6927 - val_loss: 779.0500\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 801.0726 - val_loss: 754.6912\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 775.1797 - val_loss: 748.3541\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 748.3542750629232\n",
      "Mean Absolute Error (MAE): 22.363772792656675\n",
      "Root Mean Squared Error (RMSE): 27.356064685237957\n",
      "Time taken: 1235.9265370368958\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 18ms/step - loss: 1398.3119 - val_loss: 1244.5179\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1228.5592 - val_loss: 1140.5544\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1137.6083 - val_loss: 1067.6322\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1071.3606 - val_loss: 1014.3895\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1022.3408 - val_loss: 975.9239\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 986.6068 - val_loss: 948.8510\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 961.0334 - val_loss: 930.5887\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 944.0342 - val_loss: 919.6193\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 933.5125 - val_loss: 913.7513\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 927.2984 - val_loss: 910.8434\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.0828 - val_loss: 909.8423\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 922.5800 - val_loss: 909.7646\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.8719 - val_loss: 909.9598\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.6203 - val_loss: 910.2446\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5504 - val_loss: 910.4180\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5596 - val_loss: 910.4348\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5226 - val_loss: 910.4778\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5092 - val_loss: 910.5099\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5004 - val_loss: 910.5883\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5215 - val_loss: 910.5197\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5309 - val_loss: 910.5853\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5263 - val_loss: 910.5581\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5172 - val_loss: 910.6277\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5504 - val_loss: 910.6351\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5441 - val_loss: 910.6278\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5543 - val_loss: 910.5923\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 921.5342 - val_loss: 910.4424\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 921.5667 - val_loss: 910.5576\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5159 - val_loss: 910.5938\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5356 - val_loss: 910.5292\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5181 - val_loss: 910.4431\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5219 - val_loss: 910.4372\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5546 - val_loss: 910.4683\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 921.5383 - val_loss: 910.5470\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5309 - val_loss: 910.5452\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5460 - val_loss: 910.4601\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5463 - val_loss: 910.4907\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5226 - val_loss: 910.5084\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5389 - val_loss: 910.4968\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5128 - val_loss: 910.5597\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5186 - val_loss: 910.4739\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5091 - val_loss: 910.5507\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5583 - val_loss: 910.5606\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.4998 - val_loss: 910.5493\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5281 - val_loss: 910.4720\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5576 - val_loss: 910.5534\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5563 - val_loss: 910.5613\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5084 - val_loss: 910.5098\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 921.5276 - val_loss: 910.4598\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5229 - val_loss: 910.4342\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5247 - val_loss: 910.5639\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5343 - val_loss: 910.5081\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5317 - val_loss: 910.5746\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5200 - val_loss: 910.4880\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 921.5211 - val_loss: 910.4582\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.4869 - val_loss: 910.5159\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5269 - val_loss: 910.5312\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.5137 - val_loss: 910.5710\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5355 - val_loss: 910.5681\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.5412 - val_loss: 910.5740\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.4394 - val_loss: 909.5433\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.9692 - val_loss: 907.7650\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 919.2526 - val_loss: 905.3011\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 918.0850 - val_loss: 904.3063\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.6574 - val_loss: 901.5628\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 914.5400 - val_loss: 901.1423\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 912.4373 - val_loss: 898.3348\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 908.9838 - val_loss: 893.3757\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 903.5267 - val_loss: 887.9875\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 898.3843 - val_loss: 882.5250\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 894.2239 - val_loss: 879.0162\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 891.9359 - val_loss: 876.9227\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 887.8061 - val_loss: 874.5464\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 885.5041 - val_loss: 870.7117\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 883.4666 - val_loss: 867.8325\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 881.1047 - val_loss: 866.1553\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 878.6981 - val_loss: 864.2544\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 876.7136 - val_loss: 861.5274\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 876.1905 - val_loss: 868.4310\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 874.2908 - val_loss: 858.3021\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 872.2126 - val_loss: 857.4136\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 870.2349 - val_loss: 856.1016\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 869.0743 - val_loss: 857.5745\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 867.1625 - val_loss: 853.9100\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 862.2468 - val_loss: 849.6161\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 859.1605 - val_loss: 847.3752\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 854.9694 - val_loss: 853.3043\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 850.0038 - val_loss: 850.4905\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 849.3017 - val_loss: 869.3450\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 860.9610 - val_loss: 818.6161\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 829.5563 - val_loss: 797.6337\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 816.1169 - val_loss: 790.1692\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 800.0958 - val_loss: 773.0555\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 787.3212 - val_loss: 753.7805\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 780.0061 - val_loss: 769.5464\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 768.2192 - val_loss: 742.1245\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 756.6412 - val_loss: 719.3380\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 738.7485 - val_loss: 702.3046\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 721.6317 - val_loss: 697.6594\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 717.1227 - val_loss: 700.7473\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 694.9835 - val_loss: 692.5978\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 689.6857 - val_loss: 703.1831\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 668.3257 - val_loss: 642.1707\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 665.1736 - val_loss: 666.2325\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 650.9044 - val_loss: 605.5459\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 631.0192 - val_loss: 600.9116\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 619.2731 - val_loss: 595.2688\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 611.4437 - val_loss: 579.3948\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 588.4182 - val_loss: 577.6326\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 595.6414 - val_loss: 584.6559\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 577.2378 - val_loss: 597.2188\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 564.3724 - val_loss: 554.3411\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 547.0749 - val_loss: 568.7153\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 561.1022 - val_loss: 527.3118\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 537.9811 - val_loss: 507.9207\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 528.9795 - val_loss: 501.2947\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 515.7687 - val_loss: 645.2162\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 527.1428 - val_loss: 489.9662\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 499.4580 - val_loss: 475.2538\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 518.4250 - val_loss: 482.7784\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 501.3933 - val_loss: 477.7855\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 484.1076 - val_loss: 498.7529\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 479.1165 - val_loss: 458.1533\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 477.0062 - val_loss: 472.2336\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 474.6072 - val_loss: 464.0811\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 468.2632 - val_loss: 453.4484\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 455.9165 - val_loss: 444.2708\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 463.7804 - val_loss: 441.3094\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 451.4926 - val_loss: 446.0484\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 460.2039 - val_loss: 435.0847\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 452.0732 - val_loss: 425.5885\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 439.9808 - val_loss: 427.0401\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 437.5055 - val_loss: 431.0082\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 434.0121 - val_loss: 425.2614\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 435.6603 - val_loss: 432.1093\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 432.9696 - val_loss: 423.2504\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 428.7827 - val_loss: 416.7120\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 420.2280 - val_loss: 413.3073\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 420.7609 - val_loss: 403.4106\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 419.4036 - val_loss: 427.7699\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 420.6054 - val_loss: 413.9551\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 407.1920 - val_loss: 415.8900\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 406.7113 - val_loss: 402.8115\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 407.9636 - val_loss: 406.6218\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 403.9572 - val_loss: 435.4680\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 403.7852 - val_loss: 395.8556\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 399.8706 - val_loss: 387.8661\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 402.6988 - val_loss: 410.6987\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 397.1511 - val_loss: 382.5800\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 394.4347 - val_loss: 411.7764\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 393.9179 - val_loss: 425.9200\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 388.9963 - val_loss: 407.1380\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 17ms/step - loss: 393.5516 - val_loss: 384.3516\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 384.5904 - val_loss: 395.3887\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 385.3193 - val_loss: 406.7729\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 383.0305 - val_loss: 381.7071\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 378.3504 - val_loss: 384.8957\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 371.9338 - val_loss: 376.3431\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 376.5247 - val_loss: 383.2269\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 369.2075 - val_loss: 380.2304\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 370.9605 - val_loss: 374.1647\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 368.6345 - val_loss: 384.7973\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 375.5108 - val_loss: 385.9382\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 381.1934 - val_loss: 404.5878\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 372.7392 - val_loss: 364.8867\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 366.8217 - val_loss: 368.7827\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 369.2791 - val_loss: 374.8138\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 361.0912 - val_loss: 377.5799\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 364.0032 - val_loss: 371.5362\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 359.3930 - val_loss: 363.7320\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 360.0193 - val_loss: 367.9314\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 354.7846 - val_loss: 407.3757\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 359.6572 - val_loss: 363.6282\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 359.0424 - val_loss: 363.3824\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 356.6494 - val_loss: 367.8542\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 354.8475 - val_loss: 369.0727\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 352.5445 - val_loss: 377.1068\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 354.2567 - val_loss: 371.9231\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 348.9994 - val_loss: 369.7290\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 352.1932 - val_loss: 394.5752\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 350.7935 - val_loss: 360.5530\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 342.8465 - val_loss: 356.9323\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 359.5630 - val_loss: 376.0748\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 347.6976 - val_loss: 357.3913\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 342.2147 - val_loss: 378.2825\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 346.8022 - val_loss: 362.9520\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 343.1107 - val_loss: 366.5882\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 338.3178 - val_loss: 369.5726\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 340.3520 - val_loss: 366.4811\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 335.8465 - val_loss: 367.8166\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 337.4765 - val_loss: 374.5943\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 337.0070 - val_loss: 364.3127\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 329.9414 - val_loss: 359.6651\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 328.5244 - val_loss: 357.8356\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 328.0510 - val_loss: 353.2169\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 330.0824 - val_loss: 356.4277\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 335.1759 - val_loss: 370.8465\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 325.8752 - val_loss: 345.9323\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 321.3572 - val_loss: 358.0956\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 322.4218 - val_loss: 376.1552\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 376.15527737865233\n",
      "Mean Absolute Error (MAE): 15.600469648092663\n",
      "Root Mean Squared Error (RMSE): 19.394722926060386\n",
      "Time taken: 1221.3904476165771\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 9s 18ms/step - loss: 1363.4430 - val_loss: 1293.7325\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1204.2112 - val_loss: 1194.5566\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1118.9735 - val_loss: 1121.3007\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1054.8259 - val_loss: 1066.7933\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1007.3848 - val_loss: 1026.7119\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 972.8646 - val_loss: 998.1908\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 948.7449 - val_loss: 978.7841\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 932.6168 - val_loss: 966.3317\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 922.5586 - val_loss: 958.9224\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 916.6265 - val_loss: 954.8123\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 913.5252 - val_loss: 952.8765\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 912.1125 - val_loss: 952.1233\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.4947 - val_loss: 951.8841\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2806 - val_loss: 951.7950\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2179 - val_loss: 951.7711\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1916 - val_loss: 951.8032\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1774 - val_loss: 951.8310\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2078 - val_loss: 951.8007\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1568 - val_loss: 951.8112\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1946 - val_loss: 951.8511\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1500 - val_loss: 951.8286\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 911.2218 - val_loss: 951.7858\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1708 - val_loss: 951.7670\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2255 - val_loss: 951.7787\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2031 - val_loss: 951.8068\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1780 - val_loss: 951.7878\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1638 - val_loss: 951.7470\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1491 - val_loss: 951.8036\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 911.2052 - val_loss: 951.7972\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1758 - val_loss: 951.7980\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1807 - val_loss: 951.7866\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2200 - val_loss: 951.7697\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2019 - val_loss: 951.8488\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 911.1539 - val_loss: 951.7196\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 911.1959 - val_loss: 951.7552\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2004 - val_loss: 951.7804\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 911.1843 - val_loss: 951.7701\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 911.1647 - val_loss: 951.7482\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.1803 - val_loss: 951.7709\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 911.1561 - val_loss: 951.8308\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 911.1884 - val_loss: 951.7928\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 912.0381 - val_loss: 956.0461\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 912.2701 - val_loss: 952.9370\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.4849 - val_loss: 952.4021\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.2588 - val_loss: 952.1799\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 911.1979 - val_loss: 952.1069\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 910.5171 - val_loss: 949.2886\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 903.2571 - val_loss: 943.0817\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 898.3518 - val_loss: 940.2416\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 894.3987 - val_loss: 937.5798\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 891.7369 - val_loss: 935.5253\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 890.0022 - val_loss: 932.8125\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 887.6012 - val_loss: 931.5962\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 884.4675 - val_loss: 927.3086\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 882.4363 - val_loss: 926.1779\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 878.8226 - val_loss: 921.9506\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 876.6667 - val_loss: 920.1004\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 874.1268 - val_loss: 916.4981\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 868.4542 - val_loss: 919.0280\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 866.1508 - val_loss: 908.0792\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 858.4042 - val_loss: 907.4633\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 851.7442 - val_loss: 881.7105\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 839.5726 - val_loss: 870.4059\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 827.0341 - val_loss: 852.0780\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 809.2670 - val_loss: 858.3182\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 794.2822 - val_loss: 819.3195\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 782.5611 - val_loss: 798.5568\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 768.4434 - val_loss: 782.8888\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 754.5664 - val_loss: 769.6613\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 742.8793 - val_loss: 756.7721\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 734.4977 - val_loss: 740.3458\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 719.7078 - val_loss: 730.1927\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 713.3602 - val_loss: 721.4839\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 707.6990 - val_loss: 719.1512\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 693.6821 - val_loss: 701.5123\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 685.2905 - val_loss: 691.5048\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 666.7857 - val_loss: 679.8103\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 658.5029 - val_loss: 673.1186\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 660.4302 - val_loss: 682.9074\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 648.8748 - val_loss: 628.8129\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 634.6552 - val_loss: 632.8945\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 617.1265 - val_loss: 604.6423\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 600.5858 - val_loss: 625.8168\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 590.5336 - val_loss: 588.8599\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 567.1281 - val_loss: 590.9901\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 555.1420 - val_loss: 546.1951\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 545.9458 - val_loss: 537.3181\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 533.6833 - val_loss: 541.7433\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 536.5085 - val_loss: 571.1127\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 522.2535 - val_loss: 520.9035\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 517.3514 - val_loss: 518.4099\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 515.9966 - val_loss: 532.9363\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 505.1166 - val_loss: 521.0065\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 498.1357 - val_loss: 511.0214\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 487.0943 - val_loss: 496.0373\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 490.9865 - val_loss: 492.9935\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 486.7092 - val_loss: 489.6789\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 475.9739 - val_loss: 499.3541\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 479.4646 - val_loss: 484.0598\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 471.8055 - val_loss: 473.7939\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 462.4643 - val_loss: 482.3692\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 451.3682 - val_loss: 465.4270\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 457.1967 - val_loss: 468.7118\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 442.3577 - val_loss: 497.7940\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 443.5068 - val_loss: 473.3053\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 435.5618 - val_loss: 457.7949\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 436.8168 - val_loss: 447.1421\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 426.7260 - val_loss: 442.1673\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 426.1276 - val_loss: 436.0937\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 424.4931 - val_loss: 431.8671\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 417.7731 - val_loss: 439.1063\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 414.2651 - val_loss: 437.7267\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 409.6663 - val_loss: 422.5077\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 404.0892 - val_loss: 448.8677\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 400.0082 - val_loss: 423.0945\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 407.1846 - val_loss: 424.6406\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 399.2270 - val_loss: 416.1276\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 402.5790 - val_loss: 424.7074\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 393.0686 - val_loss: 410.5109\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 389.7618 - val_loss: 424.3184\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 385.1637 - val_loss: 423.8121\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 380.7722 - val_loss: 415.8954\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 382.4890 - val_loss: 450.7810\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 381.5851 - val_loss: 412.6325\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 378.9731 - val_loss: 448.9327\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 380.9698 - val_loss: 386.0698\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 371.1968 - val_loss: 409.7190\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 375.2056 - val_loss: 395.9656\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 369.5075 - val_loss: 408.7390\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 369.3045 - val_loss: 388.0158\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 371.5612 - val_loss: 389.8102\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 368.9027 - val_loss: 408.7735\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 366.3789 - val_loss: 399.0619\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 370.1613 - val_loss: 393.3650\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 360.4820 - val_loss: 399.4986\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 366.1240 - val_loss: 408.6864\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 364.9562 - val_loss: 393.4132\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 361.4491 - val_loss: 383.8685\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 365.0088 - val_loss: 403.3223\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 364.8976 - val_loss: 393.1447\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 360.1846 - val_loss: 391.5356\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 357.2691 - val_loss: 392.6952\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 354.4780 - val_loss: 453.9659\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 359.0978 - val_loss: 390.0073\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 358.2901 - val_loss: 388.7838\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 355.7788 - val_loss: 398.7622\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 354.1024 - val_loss: 414.5569\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 352.7232 - val_loss: 386.2168\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 357.0585 - val_loss: 397.1243\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 353.3882 - val_loss: 383.0471\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 347.7914 - val_loss: 390.5942\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 350.0862 - val_loss: 414.3408\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 352.7574 - val_loss: 395.6295\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 357.2331 - val_loss: 382.6708\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 353.4984 - val_loss: 385.2093\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 348.5723 - val_loss: 389.9497\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 344.8659 - val_loss: 377.1636\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 342.7764 - val_loss: 385.3856\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 345.4082 - val_loss: 406.2995\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 345.6863 - val_loss: 394.5561\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 343.4562 - val_loss: 391.8064\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 346.3287 - val_loss: 375.3178\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 343.8481 - val_loss: 401.1836\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 344.6914 - val_loss: 382.1998\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 337.3827 - val_loss: 387.2792\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 340.5065 - val_loss: 390.4427\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 342.8959 - val_loss: 376.2025\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 339.2509 - val_loss: 374.3905\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 339.6956 - val_loss: 380.1916\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 338.6487 - val_loss: 376.2195\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 338.5573 - val_loss: 379.6489\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 341.7648 - val_loss: 403.9746\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 334.8196 - val_loss: 381.8140\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 342.3583 - val_loss: 398.5280\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 335.8260 - val_loss: 395.3056\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 340.0118 - val_loss: 380.6426\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 336.3245 - val_loss: 377.2439\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 333.7626 - val_loss: 385.1078\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 333.7853 - val_loss: 374.3677\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 331.9101 - val_loss: 376.9121\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 336.9471 - val_loss: 381.9001\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 329.2759 - val_loss: 421.6213\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 331.9366 - val_loss: 380.7131\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 325.0727 - val_loss: 383.7893\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 331.2494 - val_loss: 382.2669\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 326.2224 - val_loss: 402.1534\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 329.9616 - val_loss: 407.9970\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 330.3757 - val_loss: 378.1508\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 326.6174 - val_loss: 390.5736\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 324.9430 - val_loss: 410.0484\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 327.5691 - val_loss: 376.3364\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 325.2676 - val_loss: 381.4873\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 322.4557 - val_loss: 397.9361\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 319.9302 - val_loss: 399.3677\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 326.0120 - val_loss: 379.5998\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 320.3763 - val_loss: 385.1077\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 318.4156 - val_loss: 388.5183\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 320.6182 - val_loss: 378.5888\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 317.4893 - val_loss: 375.6522\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 323.2486 - val_loss: 377.4228\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 377.4225672763796\n",
      "Mean Absolute Error (MAE): 15.545129915492817\n",
      "Root Mean Squared Error (RMSE): 19.427366452413967\n",
      "Time taken: 1251.2706940174103\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 1365.0485 - val_loss: 1285.0292\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1202.4707 - val_loss: 1184.9944\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1117.4235 - val_loss: 1112.0461\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1054.1832 - val_loss: 1056.0259\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1006.6376 - val_loss: 1015.0127\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 973.1786 - val_loss: 985.9191\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 950.0598 - val_loss: 965.9487\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 934.9008 - val_loss: 952.7930\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.4727 - val_loss: 944.7409\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.1240 - val_loss: 940.2180\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.3967 - val_loss: 937.6726\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 916.1573 - val_loss: 936.5424\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.6769 - val_loss: 935.9713\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4338 - val_loss: 935.6678\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4050 - val_loss: 935.6070\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3751 - val_loss: 935.6002\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3607 - val_loss: 935.5740\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3920 - val_loss: 935.5758\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4177 - val_loss: 935.4384\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 915.4019 - val_loss: 935.5659\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.3930 - val_loss: 935.5004\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4055 - val_loss: 935.7000\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3467 - val_loss: 935.5096\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3467 - val_loss: 935.4489\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3981 - val_loss: 935.4209\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3748 - val_loss: 935.4955\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3828 - val_loss: 935.5360\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3869 - val_loss: 935.4254\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3812 - val_loss: 935.3893\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.4172 - val_loss: 935.4805\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4032 - val_loss: 935.4510\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3756 - val_loss: 935.4617\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4111 - val_loss: 935.4510\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4208 - val_loss: 935.4200\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 915.4184 - val_loss: 935.4395\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4351 - val_loss: 935.4076\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4407 - val_loss: 935.5270\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4186 - val_loss: 935.3233\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3752 - val_loss: 935.4366\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.3699 - val_loss: 935.4835\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.3724 - val_loss: 935.4406\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.4109 - val_loss: 935.4190\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4002 - val_loss: 935.4136\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4059 - val_loss: 935.4169\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3784 - val_loss: 935.4929\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.4984 - val_loss: 935.4796\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.3980 - val_loss: 935.4517\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.3834 - val_loss: 935.5242\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3900 - val_loss: 935.4935\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4119 - val_loss: 935.4838\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3779 - val_loss: 935.5447\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 915.3870 - val_loss: 935.5900\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3685 - val_loss: 935.4833\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4299 - val_loss: 935.3713\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3944 - val_loss: 935.4617\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3629 - val_loss: 935.4546\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3754 - val_loss: 935.3908\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4000 - val_loss: 935.4877\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 915.4008 - val_loss: 935.6216\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3979 - val_loss: 935.4585\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3885 - val_loss: 935.4871\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4102 - val_loss: 935.4285\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3817 - val_loss: 935.5354\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 915.3682 - val_loss: 935.3917\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3765 - val_loss: 935.4437\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3942 - val_loss: 935.4070\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 915.3647 - val_loss: 935.3638\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3680 - val_loss: 935.4410\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4033 - val_loss: 935.5506\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 915.4092 - val_loss: 935.5115\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4006 - val_loss: 935.5153\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4544 - val_loss: 935.4210\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3858 - val_loss: 935.5506\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3696 - val_loss: 935.6367\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4140 - val_loss: 935.5465\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3989 - val_loss: 935.5118\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 14ms/step - loss: 916.1035 - val_loss: 936.7308\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.6010 - val_loss: 936.0967\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4377 - val_loss: 935.9045\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.4086 - val_loss: 935.8016\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 915.4818 - val_loss: 935.7422\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.4105 - val_loss: 935.7110\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3466 - val_loss: 935.5991\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3747 - val_loss: 935.4425\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.3630 - val_loss: 935.4554\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 914.7761 - val_loss: 934.3834\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.0228 - val_loss: 932.1415\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 911.2896 - val_loss: 930.3964\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 909.6790 - val_loss: 929.4586\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 909.0823 - val_loss: 927.7119\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.6479 - val_loss: 925.9445\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.7541 - val_loss: 926.5029\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 905.4186 - val_loss: 924.2061\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 904.3517 - val_loss: 922.1079\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 902.8373 - val_loss: 921.3132\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 900.9504 - val_loss: 920.5506\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 899.5839 - val_loss: 919.4364\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 897.6492 - val_loss: 914.7413\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 894.6822 - val_loss: 908.5713\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 888.4333 - val_loss: 898.1078\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 886.1432 - val_loss: 907.1672\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 886.9735 - val_loss: 905.8420\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 883.0295 - val_loss: 900.5378\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 877.8631 - val_loss: 894.4607\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 868.8888 - val_loss: 881.5140\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 854.1490 - val_loss: 845.0627\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 819.8627 - val_loss: 827.0656\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 802.3267 - val_loss: 828.0246\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 776.7951 - val_loss: 782.7374\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 760.7919 - val_loss: 772.2076\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 743.8343 - val_loss: 744.7683\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 723.6976 - val_loss: 753.5536\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 716.6705 - val_loss: 738.1874\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 703.4055 - val_loss: 706.7828\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 688.2656 - val_loss: 697.5894\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 665.3776 - val_loss: 688.7198\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 655.8638 - val_loss: 672.9170\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 634.2097 - val_loss: 660.4199\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 619.4352 - val_loss: 648.1414\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 619.0511 - val_loss: 630.0760\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 607.6208 - val_loss: 622.7922\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 599.8720 - val_loss: 619.6781\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 591.9803 - val_loss: 600.6979\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 586.8533 - val_loss: 600.9026\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 582.0167 - val_loss: 631.6569\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 565.0815 - val_loss: 629.4131\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 568.6351 - val_loss: 585.5272\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 547.5915 - val_loss: 576.4709\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 541.3925 - val_loss: 558.1602\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 534.9822 - val_loss: 565.8239\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 522.4250 - val_loss: 552.4218\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 524.1343 - val_loss: 545.5640\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 512.4302 - val_loss: 555.8200\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 507.8564 - val_loss: 530.1026\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 505.8225 - val_loss: 525.1446\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 497.8141 - val_loss: 532.7485\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 496.7971 - val_loss: 524.7847\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 492.6095 - val_loss: 509.8329\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 516.2893 - val_loss: 512.8539\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 485.3217 - val_loss: 512.8459\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 484.5622 - val_loss: 507.5008\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 468.5116 - val_loss: 513.3630\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 470.5316 - val_loss: 493.0798\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 467.6548 - val_loss: 483.4283\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 462.6584 - val_loss: 484.7076\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 463.6143 - val_loss: 482.8665\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 455.2299 - val_loss: 487.3203\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 444.6578 - val_loss: 472.3705\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 444.6212 - val_loss: 480.4980\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 449.3947 - val_loss: 456.7656\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 444.7315 - val_loss: 488.2910\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 444.9809 - val_loss: 459.5471\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 431.5721 - val_loss: 449.2022\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 432.3777 - val_loss: 472.3024\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 438.3862 - val_loss: 480.6089\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 431.1333 - val_loss: 456.1831\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 420.4057 - val_loss: 463.8372\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 419.4051 - val_loss: 438.6779\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 423.2397 - val_loss: 461.5160\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 424.3990 - val_loss: 491.5095\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 414.9334 - val_loss: 439.7115\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 411.8156 - val_loss: 444.9467\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 407.4094 - val_loss: 449.5057\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 408.1974 - val_loss: 433.0930\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 408.9060 - val_loss: 434.7200\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 403.4511 - val_loss: 431.6732\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 400.4132 - val_loss: 417.6794\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 404.3187 - val_loss: 433.3609\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 401.2848 - val_loss: 434.5399\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 395.7560 - val_loss: 456.7485\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 405.8645 - val_loss: 416.0524\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 397.6705 - val_loss: 417.0865\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 397.8059 - val_loss: 444.9213\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 397.9816 - val_loss: 448.3285\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 400.8912 - val_loss: 418.2370\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 408.5435 - val_loss: 412.3074\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 400.4174 - val_loss: 455.3185\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 387.5156 - val_loss: 410.0864\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 383.4789 - val_loss: 410.4904\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 386.7047 - val_loss: 417.1411\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 383.9503 - val_loss: 412.5349\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 378.6893 - val_loss: 413.6698\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 383.7625 - val_loss: 414.2534\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 384.6479 - val_loss: 425.0620\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 383.8978 - val_loss: 400.0021\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 373.2420 - val_loss: 404.3187\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 381.4121 - val_loss: 417.2875\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 372.7805 - val_loss: 415.3024\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 372.0088 - val_loss: 397.9611\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 368.4531 - val_loss: 399.0352\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 369.0331 - val_loss: 399.4688\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 367.2178 - val_loss: 412.4216\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 370.9965 - val_loss: 397.6817\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 368.4833 - val_loss: 400.8088\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 364.4776 - val_loss: 408.0540\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 360.3871 - val_loss: 418.7895\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 361.7085 - val_loss: 410.3120\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 363.0749 - val_loss: 389.1665\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 365.3992 - val_loss: 384.3622\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 355.5191 - val_loss: 412.6404\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 412.6360909331304\n",
      "Mean Absolute Error (MAE): 16.437418329103004\n",
      "Root Mean Squared Error (RMSE): 20.313446062476213\n",
      "Time taken: 1166.5530831813812\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 1378.3340 - val_loss: 1266.9503\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 1218.4102 - val_loss: 1164.2845\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1131.3987 - val_loss: 1087.6635\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1067.0648 - val_loss: 1031.7853\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1019.6624 - val_loss: 990.2849\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 985.0020 - val_loss: 960.4966\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 960.5283 - val_loss: 939.8542\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 943.9255 - val_loss: 926.1853\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 933.4493 - val_loss: 917.8374\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 927.4088 - val_loss: 913.3699\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.2675 - val_loss: 911.1023\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 922.8099 - val_loss: 909.9206\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 922.1823 - val_loss: 909.4385\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.9315 - val_loss: 909.3553\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.9183 - val_loss: 909.2872\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.8483 - val_loss: 909.2379\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8576 - val_loss: 909.2666\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8658 - val_loss: 909.2339\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8550 - val_loss: 909.3732\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8802 - val_loss: 909.4274\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8727 - val_loss: 909.2903\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8463 - val_loss: 909.2577\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8754 - val_loss: 909.3066\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.8795 - val_loss: 909.3032\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.9072 - val_loss: 909.2609\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8307 - val_loss: 909.2895\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8912 - val_loss: 909.2000\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8484 - val_loss: 909.3071\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.8955 - val_loss: 906.5399\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.5317 - val_loss: 900.8049\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 906.0702 - val_loss: 888.3212\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 895.2434 - val_loss: 880.1331\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 885.5664 - val_loss: 875.9944\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 878.1053 - val_loss: 876.3037\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 873.1207 - val_loss: 861.5329\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 864.0245 - val_loss: 852.4537\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 857.1400 - val_loss: 843.6788\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 850.5164 - val_loss: 836.0125\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 864.9215 - val_loss: 924.0809\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 885.5200 - val_loss: 848.9686\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 857.7258 - val_loss: 837.3026\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 850.4053 - val_loss: 858.1996\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 840.8922 - val_loss: 815.3565\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 833.2283 - val_loss: 806.1157\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 826.3806 - val_loss: 804.2329\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 820.7446 - val_loss: 802.5457\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 821.8410 - val_loss: 792.6153\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 814.5093 - val_loss: 803.8962\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 803.7268 - val_loss: 781.2071\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 799.0657 - val_loss: 772.9584\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 796.0822 - val_loss: 765.1257\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 789.6492 - val_loss: 762.0181\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 778.4137 - val_loss: 755.6415\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 782.4289 - val_loss: 741.9016\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 776.1165 - val_loss: 726.2789\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 756.9777 - val_loss: 725.9012\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 753.1677 - val_loss: 719.1097\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 756.4501 - val_loss: 705.3309\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 747.8173 - val_loss: 731.6795\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 731.0960 - val_loss: 770.7571\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 732.1661 - val_loss: 712.3681\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 730.4692 - val_loss: 671.2656\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 717.5327 - val_loss: 668.1487\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 713.2997 - val_loss: 658.3778\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 715.7831 - val_loss: 684.2137\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 703.6452 - val_loss: 693.4781\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 708.9385 - val_loss: 698.7199\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 697.6243 - val_loss: 696.8347\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 679.1764 - val_loss: 658.0859\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 674.3610 - val_loss: 648.2331\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 667.6991 - val_loss: 623.1664\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 670.5209 - val_loss: 645.0903\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 663.4327 - val_loss: 609.8151\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 664.1265 - val_loss: 612.0718\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 645.2545 - val_loss: 599.3819\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 647.1915 - val_loss: 609.7720\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 620.7896 - val_loss: 580.7062\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 610.8771 - val_loss: 582.1646\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 605.1622 - val_loss: 629.4551\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 600.1804 - val_loss: 556.5982\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 605.0444 - val_loss: 625.7137\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 594.7662 - val_loss: 553.7477\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 578.3979 - val_loss: 621.3585\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 590.9439 - val_loss: 583.4556\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 560.9610 - val_loss: 531.9994\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 561.7426 - val_loss: 549.1667\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 544.6129 - val_loss: 523.7594\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 542.6450 - val_loss: 509.3372\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 533.3746 - val_loss: 498.4803\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 523.7053 - val_loss: 495.1907\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 517.2424 - val_loss: 528.6689\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 512.9185 - val_loss: 516.0363\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 513.3182 - val_loss: 501.8428\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 506.3508 - val_loss: 474.0247\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 498.8128 - val_loss: 525.7994\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 482.8240 - val_loss: 496.3260\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 486.0278 - val_loss: 617.9467\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 473.3100 - val_loss: 436.5292\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 476.3317 - val_loss: 490.7964\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 458.3040 - val_loss: 448.4458\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 452.7827 - val_loss: 527.9526\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 460.0160 - val_loss: 417.7147\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 457.8801 - val_loss: 428.3413\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 448.5689 - val_loss: 412.9513\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 439.5878 - val_loss: 426.9507\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 435.6896 - val_loss: 403.0413\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 430.5387 - val_loss: 414.2421\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 430.4339 - val_loss: 442.1731\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 428.3185 - val_loss: 405.5141\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 422.1695 - val_loss: 404.1116\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 419.3777 - val_loss: 406.7044\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 412.0503 - val_loss: 387.6330\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 409.4716 - val_loss: 388.9382\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 417.0533 - val_loss: 388.8284\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 409.2660 - val_loss: 407.8479\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 414.3702 - val_loss: 388.0489\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 412.4830 - val_loss: 387.6863\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 396.7493 - val_loss: 395.8716\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 396.8975 - val_loss: 391.0687\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 403.7359 - val_loss: 401.1494\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 395.7944 - val_loss: 388.3185\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 395.8745 - val_loss: 373.9988\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 391.4852 - val_loss: 376.3728\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 391.6492 - val_loss: 394.7041\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 386.3799 - val_loss: 387.5675\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 388.6169 - val_loss: 389.2726\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 386.1590 - val_loss: 399.3838\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 383.1477 - val_loss: 426.0161\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 380.1307 - val_loss: 373.0360\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 391.6386 - val_loss: 374.0792\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 379.5211 - val_loss: 362.2794\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 384.4132 - val_loss: 374.4695\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 379.0236 - val_loss: 371.2466\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 374.7867 - val_loss: 363.7250\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 379.1437 - val_loss: 377.8131\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 371.5605 - val_loss: 364.5416\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 376.8608 - val_loss: 364.7318\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 371.2410 - val_loss: 364.0772\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 370.0037 - val_loss: 360.2218\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 368.4682 - val_loss: 393.4624\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 365.9249 - val_loss: 371.5645\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 370.2837 - val_loss: 410.0844\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 368.0363 - val_loss: 372.5907\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 368.3017 - val_loss: 422.2672\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 365.8068 - val_loss: 356.8634\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 364.3372 - val_loss: 382.0875\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 367.6064 - val_loss: 386.5273\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 364.1656 - val_loss: 379.8298\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 361.2073 - val_loss: 393.1884\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 356.6764 - val_loss: 369.3723\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 359.7606 - val_loss: 355.7147\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 353.0991 - val_loss: 364.0006\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 356.4956 - val_loss: 353.6773\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 352.0736 - val_loss: 367.6545\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 354.3866 - val_loss: 408.2828\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 352.8796 - val_loss: 371.4535\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 352.4834 - val_loss: 357.2089\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 353.3590 - val_loss: 360.1823\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 348.4621 - val_loss: 352.0825\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 349.3128 - val_loss: 354.3257\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 347.1221 - val_loss: 372.3503\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 345.7179 - val_loss: 364.6233\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 346.1100 - val_loss: 349.2450\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 342.4107 - val_loss: 351.5567\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 341.3149 - val_loss: 348.2373\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 333.3074 - val_loss: 353.8132\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 340.4820 - val_loss: 357.5578\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 338.2556 - val_loss: 353.2161\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 337.4577 - val_loss: 344.7257\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 338.7855 - val_loss: 357.6008\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 333.7895 - val_loss: 352.1185\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 332.3994 - val_loss: 370.0483\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 334.0327 - val_loss: 479.1799\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 335.0797 - val_loss: 351.6613\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 327.4736 - val_loss: 345.1831\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 330.1776 - val_loss: 351.8136\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 332.6719 - val_loss: 347.4703\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 328.0054 - val_loss: 343.6375\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 324.5318 - val_loss: 342.3277\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 326.1653 - val_loss: 353.4224\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 323.0815 - val_loss: 350.4256\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 320.0443 - val_loss: 354.3488\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 319.9477 - val_loss: 400.8584\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 321.2504 - val_loss: 363.2551\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 318.0685 - val_loss: 364.1337\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 318.1392 - val_loss: 341.4577\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 321.8218 - val_loss: 343.0424\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 317.4550 - val_loss: 336.5899\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 318.8591 - val_loss: 344.4879\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 311.9812 - val_loss: 356.4620\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 312.6530 - val_loss: 343.1353\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 312.4376 - val_loss: 354.2123\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 310.4849 - val_loss: 351.0937\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 312.2303 - val_loss: 356.4271\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 311.1302 - val_loss: 351.8814\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 304.9635 - val_loss: 348.8385\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 309.8046 - val_loss: 341.0119\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 303.3331 - val_loss: 366.9115\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 303.8523 - val_loss: 352.3488\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 305.6942 - val_loss: 335.1957\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 335.194129704692\n",
      "Mean Absolute Error (MAE): 14.663093046871888\n",
      "Root Mean Squared Error (RMSE): 18.30830766905265\n",
      "Time taken: 1192.627272605896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 48, 512)           1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 48, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_8924\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold         MSE        MAE       RMSE   Time taken\n",
      "0        1  748.354275  22.363773  27.356065  1235.926537\n",
      "1        2  376.155277  15.600470  19.394723  1221.390448\n",
      "2        3  377.422567  15.545130  19.427366  1251.270694\n",
      "3        4  412.636091  16.437418  20.313446  1166.553083\n",
      "4        5  335.194130  14.663093  18.308308  1192.627273\n",
      "5  Average  449.952468  16.921977  20.959982  1213.553607\n",
      "Results saved to 'DL_Result_PL_model_2_Scattered_iReg_f_obese.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_2_Scattered_iReg_f_obese.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'DL_Result_PL_model_2_Scattered_iReg_f_obese.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAADnXklEQVR4nOzdeXxU1d3H8c+dyUZ2IJAFAgQIqwqKirsoKIi1LrhTlxa1LmitWrW1+oi1+ri1bq1Lfdxa1y5aVxQVRRHZNwElQNgTIIQkJCHb3Pv8McwkQxJIcrLcCd/368WLmTt3Zs753kmYH+eecy3HcRxEREREREQMeDq6ASIiIiIiEv5UWIiIiIiIiDEVFiIiIiIiYkyFhYiIiIiIGFNhISIiIiIixlRYiIiIiIiIMRUWIiIiIiJiTIWFiIiIiIgYU2EhIiIiIiLGVFiIiIiIiIgxFRYiIgehl19+GcuyWLBgQUc3pUmWLFnCz372MzIzM4mOjqZbt26MGzeOl156CZ/P19HNExERIKKjGyAiIrI/L7zwAtdeey2pqalcdtllZGdns3v3bj7//HOmTJlCXl4ev/vd7zq6mSIiBz0VFiIi4lrfffcd1157LcceeywfffQRCQkJwcduvvlmFixYwPfff98q71VWVkZcXFyrvJaIyMFIp0KJiEijFi9ezBlnnEFiYiLx8fGMHTuW7777LmSf6upqpk2bRnZ2NjExMXTv3p0TTjiBGTNmBPfJz8/n5z//Ob179yY6Opr09HTOPvts1q9fv9/3nzZtGpZl8dprr4UUFQFHHnkkV155JQBffvkllmXx5Zdfhuyzfv16LMvi5ZdfDm678soriY+PZ+3atUycOJGEhAQmT57M1KlTiY+Pp7y8vN57XXLJJaSlpYWcevXxxx9z4oknEhcXR0JCAmeeeSYrVqzYb59ERDorFRYiItKgFStWcOKJJ7J06VJuv/127r77bnJzcxkzZgxz584N7nfvvfcybdo0TjnlFJ5++mnuuusu+vTpw6JFi4L7TJo0iXfeeYef//zn/PWvf+Wmm25i9+7dbNy4sdH3Ly8v5/PPP+ekk06iT58+rd6/mpoaxo8fT8+ePXn00UeZNGkSF110EWVlZXz44Yf12vL+++9z/vnn4/V6Afj73//OmWeeSXx8PA899BB33303K1eu5IQTTjhgwSQi0hnpVCgREWnQ73//e6qrq/nmm2/o378/AJdffjmDBw/m9ttv56uvvgLgww8/ZOLEiTz//PMNvk5RURHffvstjzzyCLfddltw+29/+9v9vv+aNWuorq7m0EMPbaUehaqsrOSCCy7gwQcfDG5zHIdevXrx1ltvccEFFwS3f/jhh5SVlXHRRRcBUFpayk033cRVV10V0u8rrriCwYMH88ADDzSah4hIZ6URCxERqcfn8/Hpp59yzjnnBIsKgPT0dC699FK++eYbSkpKAEhOTmbFihXk5OQ0+FpdunQhKiqKL7/8kl27djW5DYHXb+gUqNZy3XXXhdy3LIsLLriAjz76iNLS0uD2t956i169enHCCScAMGPGDIqKirjkkksoKCgI/vF6vYwePZqZM2e2WZtFRNxKhYWIiNSzY8cOysvLGTx4cL3Hhg4dim3bbNq0CYD77ruPoqIiBg0axKGHHspvfvMbli1bFtw/Ojqahx56iI8//pjU1FROOukkHn74YfLz8/fbhsTERAB2797dij2rFRERQe/evettv+iii9izZw/vvfce4B+d+Oijj7jggguwLAsgWESdeuqp9OjRI+TPp59+yvbt29ukzSIibqbCQkREjJx00kmsXbuWF198kUMOOYQXXniBI444ghdeeCG4z80338zq1at58MEHiYmJ4e6772bo0KEsXry40dcdOHAgERERLF++vEntCHzp31dj17mIjo7G46n/z+AxxxxDv379ePvttwF4//332bNnT/A0KADbtgH/PIsZM2bU+/Pf//63SW0WEelMVFiIiEg9PXr0IDY2lh9//LHeYz/88AMej4fMzMzgtm7duvHzn/+cN954g02bNnHYYYdx7733hjxvwIAB3HrrrXz66ad8//33VFVV8dhjjzXahtjYWE499VRmzZoVHB3Zn65duwL+OR11bdiw4YDP3deFF17I9OnTKSkp4a233qJfv34cc8wxIX0B6NmzJ+PGjav3Z8yYMc1+TxGRcKfCQkRE6vF6vZx++un897//DVnhaNu2bbz++uuccMIJwVOVdu7cGfLc+Ph4Bg4cSGVlJeBfUamioiJknwEDBpCQkBDcpzH/8z//g+M4XHbZZSFzHgIWLlzIK6+8AkDfvn3xer3MmjUrZJ+//vWvTet0HRdddBGVlZW88sorTJ8+nQsvvDDk8fHjx5OYmMgDDzxAdXV1vefv2LGj2e8pIhLutCqUiMhB7MUXX2T69On1tv/qV7/i/vvvZ8aMGZxwwglcf/31RERE8Nxzz1FZWcnDDz8c3HfYsGGMGTOGUaNG0a1bNxYsWMC//vUvpk6dCsDq1asZO3YsF154IcOGDSMiIoJ33nmHbdu2cfHFF++3fccddxx/+ctfuP766xkyZEjIlbe//PJL3nvvPe6//34AkpKSuOCCC3jqqaewLIsBAwbwwQcftGi+wxFHHMHAgQO56667qKysDDkNCvzzP5555hkuu+wyjjjiCC6++GJ69OjBxo0b+fDDDzn++ON5+umnm/2+IiJhzRERkYPOSy+95ACN/tm0aZPjOI6zaNEiZ/z48U58fLwTGxvrnHLKKc63334b8lr333+/c/TRRzvJyclOly5dnCFDhjh//OMfnaqqKsdxHKegoMC54YYbnCFDhjhxcXFOUlKSM3r0aOftt99ucnsXLlzoXHrppU5GRoYTGRnpdO3a1Rk7dqzzyiuvOD6fL7jfjh07nEmTJjmxsbFO165dnV/+8pfO999/7wDOSy+9FNzviiuucOLi4vb7nnfddZcDOAMHDmx0n5kzZzrjx493kpKSnJiYGGfAgAHOlVde6SxYsKDJfRMR6Swsx3GcDqtqRERERESkU9AcCxERERERMabCQkREREREjKmwEBERERERYyosRERERETEmAoLERERERExpsJCRERERESM6QJ5TWDbNlu3biUhIQHLsjq6OSIiIiIi7cJxHHbv3k1GRgYez/7HJFRYNMHWrVvJzMzs6GaIiIiIiHSITZs20bt37/3uo8KiCRISEgB/oImJie3+/j6fj7Vr1zJgwAC8Xm+7v39noAzNKUMzys+cMjSj/MwpQ3PK0ExH5FdSUkJmZmbw+/D+qLBogsDpT4mJiR1WWMTHx5OYmKgfwhZShuaUoRnlZ04ZmlF+5pShOWVopiPza8p0AE3eFhERERERYyoswsSBJsvIgSlDc8rQjPIzpwzNKD9zytCcMjTj5vwsx3Gcjm6E25WUlJCUlERxcXGHnAolIiIiItIRmvM9WHMswoDjOJSVlREXF6flbltIGZpThmaUnzllaEb5mevoDG3bpqqqqt3ftzU5jkN5eTmxsbH6HLZAW+QXGRnZavM1VFiEAdu22bx5M9nZ2Zro1ELK0JwyNKP8zClDM8rPXEdmWFVVRW5uLrZtt+v7tjbHcaipqSEiIkKFRQu0VX7JycmkpaUZv6YKCxEREREXcxyHvLw8vF4vmZmZrj7H/kAcx6GyspLo6GgVFi3Q2vkFRkC2b98OQHp6utHrqbAQERERcbGamhrKy8vJyMggNja2o5tjJDC1NyYmRoVFC7RFfl26dAFg+/bt9OzZ02g0rkNL3lmzZnHWWWeRkZGBZVm8++67je577bXXYlkWjz/+eMj2wsJCJk+eTGJiIsnJyUyZMoXS0tKQfZYtW8aJJ55ITEwMmZmZPPzww23Qm7ZjWRZRUVH6ATSgDM0pQzPKz5wyNKP8zHVUhj6fD4CoqKh2fd+2Es4jLm7QFvkFCtbq6mqj1+nQI1tWVsaIESP4y1/+st/93nnnHb777jsyMjLqPTZ58mRWrFjBjBkz+OCDD5g1axbXXHNN8PGSkhJOP/10+vbty8KFC3nkkUe49957ef7551u9P23F4/HQv39//SAaUIbmlKEZ5WdOGZpRfuY6OsPOUBRalqXToAy0VX6t9XodeirUGWecwRlnnLHffbZs2cKNN97IJ598wplnnhny2KpVq5g+fTrz58/nyCOPBOCpp55i4sSJPProo2RkZPDaa69RVVXFiy++SFRUFMOHD2fJkiX86U9/CilA3MxxHIqLi0lKStIPYgspQ3PK0IzyM6cMzSg/c8rQnOM4+Hw+vF6vMmwBt+fn6jkWtm1z2WWX8Zvf/Ibhw4fXe3zOnDkkJycHiwqAcePG4fF4mDt3Lueeey5z5szhpJNOChk+HD9+PA899BC7du2ia9eu9V63srKSysrK4P2SkhLAPxQZGI60LAuPx4Nt29S9FEhj2z0eD5ZlNbo98Lp1twcy8Pl8bN26ldjYWCIjI4Pb6/J6vTiOE7I90JbGtje17W3Rp6Zsb80+1dTUBDMM/DCGe5/a+zgFJg8GMuwMfWrP4xT4OY6LiyMyMrJT9OlA21u7T9XV1SE/x52hT+15nGzbJj8/n7i4uJD/cQ/nPrX3cQr8HCckJATftz36VLe9DV1+zLKsBrc3R2Ov0drbHcehuro6mG1zXycrK4tf/epX3HzzzU3q08yZMzn11FMpLCwkOTm5Tfpkur256ubXWm0JHBug3meyOW12dWHx0EMPERERwU033dTg4/n5+fTs2TNkW0REBN26dSM/Pz+4T1ZWVsg+qampwccaKiwefPBBpk2bVm/72rVriY+PByApKYn09HS2bdtGcXFxcJ+UlBRSUlLYsmULZWVlwe1paWkkJyezfv36kDWoe/fuTXx8PGvXrg35RZSVlUVERAQ5OTnYtk1hYSFr1qxh8ODB1NTUkJubG9zX4/EwaNAgysrK2Lx5c3B7VFQU/fv3p7i4OJgHQFxcHJmZmRQWFlJQUBDc3p59qis7O7vN+7R9+/Zghh6Pp1P0qb2PU//+/fH5fMEMO0Of2vM4BX6OCwsLSU1N7RR9au/jtHbt2uDPcURERKfoU3sep8C/d1u3bmXPnj2dok/tfZxs22bXrl0A7dqnul/0qqqqQtoeFRWF1+ulsrIy5Atg4HSZioqKkD7FxMQEVxYKsCyLmJiYetfJ8Hg8REdH4/P5Qs6993q9REVFUVNTQ01NTb3t1dXVREdHsz+/+93vmDZtGhEREc3q07x58/B6vSH92l+fjjnmGNatW0d0dDQVFRVGfapb4EVERBAZGRncPmvWLCZMmMCOHTtISUlps+MUHR1db3tr9KmysjLY3n1/npqzYIBrrrxtWRbvvPMO55xzDgALFy7kzDPPZNGiRcG5Ff369ePmm28OVqkPPPAAr7zyCj/++GPIa/Xs2ZNp06Zx3XXXcfrpp5OVlcVzzz0XfHzlypUMHz6clStXMnTo0HptaWjEIvBLIXDFwfYesVizZg0DBw7UiEUL+1RdXU1OTg4DBw7UiEUL++Q4Djk5OQwYMEAjFi0csVizZg3Z2dkasTAYsQj8LtSIRctGLNauXcuAAQM0YmEwYhH4T772HLGoqKhg48aNZGVlNfiF3Y0jFnWLq7feeov/+Z//4Ycffgh+Ke7evTsJCQnB4+Tz+YiIiDjg63dkn/a3/csvvwyOjHTt2rVNRywqKirqzbMw7VNFRQW5ubn079+fqKiokMdKS0tJTk5u0pW3XTuD6+uvv2b79u306dOHiIgIIiIi2LBhA7feeiv9+vUD/P8jEVh3N6CmpobCwkLS0tKC+2zbti1kn8D9wD77io6OJjExMeQPEPyHzOv1hvyPbVO2Bw5+Y9vrbgtstywLr9dLREQECQkJwYuhBLbX/QPU2153mNGk7W3Rp6Zsb80+eb3eYIadpU/tfZw8Hg/x8fHBDDtDn9rzOAV+jgOv3xn61N7Hqe7vws7Sp/Y8Tl6vl7i4uAbbEq59au/jFPgMNrR/W/cpIPDedf80tr05f5r72gfanp6eHvyTnJwcsm3NmjUkJSUxffp0Ro0aRUxMDLNnz2bdunWcc845pKWlER8fz9FHH83nn38e8vpZWVk88cQTwfsej4f/+7//47zzziMuLo5Bgwbx/vvvB9vy1Vdf4fF4KC4uxrIsXnnlFZKTk/n0008ZNmwYCQkJnHHGGcFCyLL8heevfvUrunbtSkpKCnfccQdXXnkl55577n4zCNxvKJuioiIuv/xyunXrRlxcHBMnTmTNmjXBxzdu3MhPf/pTunXrRnx8PIcccggff/xx8Lk/+9nP6NmzJ7GxsRx66KG8/PLLbXb8Gvu5aQrXFhaXXXYZy5YtY8mSJcE/GRkZ/OY3v+GTTz4B4Nhjj6WoqIiFCxcGn/fFF19g2zajR48O7jNr1qyQoaEZM2YwePDgBk+DciOPxxP2F8TpaMrQnDI0o/zMKUMzys+cMjRnWVbw7Is777yT//3f/2XVqlUcdthhlJaWMnHiRD7//HMWL17MhAkTOOuss9i4ceN+X3PatGlceOGFLFu2jIkTJzJ58mQKCwsb3b+8vJxHH32Uv//978yaNYuNGzdy2223BR9/6KGHeO2113jppZeYPXs2JSUl+70kQlNceeWVLFiwgPfee485c+bgOA4TJ04Mfj+94YYbqKysZNasWSxfvpyHHnooePr93XffzcqVK/n4449ZtWoVzz77LD169DBqT1vp0DkWpaWlrFmzJng/NzeXJUuW0K1bN/r06UP37t1D9o+MjCQtLY3BgwcDMHToUCZMmMDVV1/Ns88+S3V1NVOnTuXiiy8Onj516aWXMm3aNKZMmcIdd9zB999/zxNPPMGf//zn9uuoocC52d26ddMvsxZShuaUoRnlZ04ZmlF+5tyU4VlPfcOO3ZUH3rGV9UiI5v0bT2jx8x3HCZ7vf99993HaaacFH+vWrRsjRowI3v/DH/7AO++8w3vvvcfUqVMbfc0rr7ySSy65BPCfJv/kk08yb948JkyY0OD+1dXVPPvsswwYMACAqVOnct999wUff+qpp/jtb3/LueeeC8DTTz/NRx991MIeQ05ODu+99x6zZ8/muOOOA+C1114jMzOTd999lwsuuICNGzcyadIkDj30UMA/rzFg48aNHH744Rx55JE4jkOvXr1CThtzkw5t1YIFCzjllFOC92+55RYArrjiCl5++eUmvcZrr73G1KlTGTt2LB6Ph0mTJvHkk08GH09KSuLTTz/lhhtuYNSoUaSkpHDPPfeEzVKz4P8hLCgoCJsRFjdShuaUoRnlZ04ZmlF+5tyU4Y7dleSXVBx4RxcKzHGpu6on+P/D+d577+XDDz8kLy+Pmpoa9uzZc8ARi8MOOyx4Oy4ujsTExHqnytcVGxsbLCqA4CIvAMXFxWzbto2jjz46+LjX62XUqFH15uA01apVq4iIiAieTQPQvXt3Bg8ezKpVqwC46aabuO666/j0008ZN24ckyZNCvbruuuuY9KkSSxatIjTTjuNiRMnMmbMmBa1pa11aGExZsyYZk1iWb9+fb1t3bp14/XXX9/v8w477DC+/vrr5jZPRERExJV6JOx/1aVweN+4uLiQ+7fddhszZszg0UcfZeDAgXTp0oXzzz8/ZKWqhgROrQqwLGu/RUBD+3f0WkZXXXUV48eP58MPP+TTTz/lwQcf5LHHHuPGG2/kjDPOYMOGDXz00UfMmDGDiRMncv311/PYY491aJsb4s5xFAlRUFpJ3u5qIneWMaDn/mfji4iISOdncjqSW82ePTs4SRr8IxgN/adyW0pKSiI1NZX58+dz0kknAf4RlkWLFjFy5MgWvebQoUOpqalh7ty5wVOhdu7cyY8//siwYcOC+2VmZnLttddy7bXX8tvf/pa//e1v3HjjjQD06NGDK664gssvv5zRo0dz1113qbCQljnlsVmUV/kY1LOQT285uaObE5Ysy9KVUg0pQzPKz5wyNKP8zCnD1tHY/JTs7Gz+85//cNZZZ2FZFnfffXeLTz8yceONN/Lggw8ycOBAhgwZwlNPPcWuXbuadNyXL19OQkJC8L5lWYwYMYKzzz6bq6++mueee46EhATuvPNOevXqxdlnnw3AzTffzBlnnMGgQYPYtWsXM2fODF4S4Z577mHUqFEMHz6ciooKpk+f3uDlEtxAhUUYiI2KoLzKR1mV78A7S4M8Hg/p6ekd3YywpgzNKD9zytCM8jOnDM3VXRVqX3/605/4xS9+wXHHHRdc5rWkpKSdWwh33HEH+fn5XH755Xi9Xq655hrGjx8fsuxvYwKjHAFer5eamhpeeuklfvWrX/GTn/yEqqoqTjrpJD766KNgFj6fjxtuuIHNmzeTmJjIhAkTggsNRUVF8dvf/pb169fTpUsXTjzxRN58883W73grcM0F8tyspKSEpKSkJl0YpC2c/PBMNhSW0zU2ksX3nN7u798Z2LbNtm3bSE1N7fCVPMKVMjSj/MwpQzPKz1xHZRi4eFlWVhYxMTHt9r5twXEcqquriYyMDJuRH9u2GTp0KBdeeCF/+MMfOrQtbZXf/j5jzfkerN8sYSAu2l8ha8Si5RzHobi4uMMnZ4UzZWhG+ZlThmaUnzll2Dr2vfK522zYsIG//e1vrF69muXLl3PdddeRm5vLpZde2tFNA9ydnwqLMBAb5T9jrarGptrX/ucaioiIiBwsPB4PL7/8MkcddRTHH388y5cv57PPPnPtvAY30RyLMBAbVXtOX3mVj6QuqgdFRERE2kJmZiazZ8/u6GaEJX1DDQNx0bX1X1llTQe2JHxZlkVKSkrYnM/pRsrQjPIzpwzNKD9zyrB1uPWq0eHCzfm5t2USVLewKK9SYdESHo+HlJSUjm5GWFOGZpSfOWVoRvmZU4bm9rcqlByY2/PTiEUYiI2sPRWqrNK9E3bczLZtNm3a1CHrYXcWytCM8jOnDM0oP3PK0JzjOFRVVWkCfAu5PT8VFmEgNqr2MJVpxKJFHMehrKzMtT+I4UAZmlF+5pShGeVnThm2DjevahQO3JyfCoswEFgVCqBcIxYiIiIi4kIqLMJAbHSdU6E0YiEiIiIiLqTCIgzER9dO0inXRfJaxOPxkJaWpqvNGlCGZpSfOWVoRvmZU4atozmTj8eMGcPNN98cvN+vXz8ef/zx/T7HsizefffdljWuDV6ntWnythjRcrPmLMsiOTlZSwQaUIZmlJ85ZWhG+ZlThk131llnMWHChHrbLctizpw5eDweli1b1uzXnT9/Ptdcc01rNDHo3nvvZeTIkfW25+XlccYZZ7Tqe+3r5ZdfJjk5ucn7W5ZFRESEaz+DKizCQN3J2xqxaBnbtlm3bp1W8jCgDM0oP3PK0IzyM6cMm27KlCnMmDGDzZs3h2x3HIcXXniBI488ksMOO6zZr9ujRw9iY2Nbq5n7lZaWRnR0dLu8V1M5jkNlZaVrFxBQYREGQpab1RyLFnH78mzhQBmaUX7mlKEZ5WdOGTbdT37yE3r06MHLL78csr20tJT//Oc//OIXv2Dnzp1ccskl9OrVi9jYWA499FDeeOON/b7uvqdC5eTkcNJJJxETE8OwYcOYMWNGvefccccdDBo0iNjYWPr378/dd99NdXU14B8xmDZtGkuXLsWyLCzLCrZ531Ohli9fzqmnnkqXLl3o3r0711xzDaWlpcHHr7zySs455xweffRR0tPT6d69OzfccEPwvVpi48aNnH322cTHx5OYmMhFF11EXl5e8PGlS5dyyimnkJCQQGJiIqNGjWLBggUAbNiwgbPOOouuXbsSFxfH8OHD+eijj1rclqbQBfLCQGxU3etYqLAQERERd4uIiODyyy/n5Zdf5q677gqeuvPPf/4Tn8/HJZdcQllZGaNGjeKOO+4gMTGRDz/8kMsuu4wBAwZw9NFHH/A9bNvmvPPOIzU1lblz51JcXBwyHyMgISGBl19+mYyMDJYvX87VV19NQkICt99+OxdddBHff/8906dP57PPPgMgKSmp3muUlZUxfvx4jj32WObPn8/27du56qqrmDp1akjxNHPmTNLT05k5cyZr1qzhoosuYuTIkVx99dXNztC27WBR8dVXX1FTU8MNN9zA5ZdfzldffQXA5MmTOfzww3nmmWfwer0sWbIkOAfjhhtuoKqqilmzZhEXF8fKlSuJj49vdjuaQ4VFGAi58raWmxUREZHnTobS7e3/vvE94ZdfNWnXX/ziFzzyyCN89dVXjBkzBvCPEJxzzjkkJSWRnJzMbbfdFtz/xhtv5JNPPuHtt99uUmHx2Wef8cMPP/DJJ5+QkZEBwAMPPFBvXsTvf//74O1+/fpx22238eabb3L77bfTpUsX4uPjiYiIIC0trdH3ev3116moqODVV18lLi4OgKeffpqzzjqLhx56iNTUVAC6du3K008/jdfrZciQIZx55pl8/vnnLSosPv/8c5YvX05ubi6ZmZkAvPLKKxxyyCHMnz+fo48+mo0bN/Kb3/yGIUOGAJCdnR18/saNG5k0aRKHHnooAP379292G5pLhUUYiI+pnf2vU6FaxuPx0Lt3b63kYUAZmlF+5pShGeVnzlUZlm6H3Vs7uhX7NWTIEI477jhefPFFxowZw5o1a/j666+DIwM+n48HHniAt99+my1btlBVVUVlZWWT51CsWrWKzMzMYFEBcOyxx9bb76233uLJJ59k7dq1lJaWUlNTQ2JiYrP6smrVKkaMGBEsKgCOP/54bNvmxx9/DBYWw4cPx+utPdMkPT2d5cuXN+u96r5nZmZmsKgAGDZsGMnJyaxatYqjjz6aW265hauuuoq///3vjBs3jgsuuIABAwYAcNNNN3Hdddfx6aefMm7cOCZNmtSieS3N4YKfDDmQkBELTd5uEcuyiI+Pd+0qCuFAGZpRfuaUoRnlZ85VGcb3hISM9v8T37NZzZwyZQr//ve/2b17Ny+99BIDBgzg1FNPxbIsHnnkEZ544gnuuOMOZs6cyZIlSxg/fjxVVVWtFtOcOXOYPHkyEydO5IMPPmDx4sXcddddrfoede27FKxlWa062T/w2Qv8fe+997JixQrOPPNMvvjiC4YNG8Y777wDwFVXXcW6deu47LLLWL58OUceeSRPPfVUq7WlIRqxCAPR3tpfYJpj0TI+n4+1a9cyYMCAkP9JkKZThmaUnzllaEb5mXNVhk08HamjXXjhhfzqV7/i9ddf59VXX+Xaa6+lsrKS6OhoZs+ezdlnn83PfvYzwD+nYPXq1QwbNqxJrz106FA2bdpEXl4e6enpAHz33Xch+3z77bf07duXu+66K7htw4YNIftERUXh8+3/P26HDh3Kyy+/TFlZWXDUYvbs2Xg8HgYPHtyk9jZXoH+bNm0KjlqsWLGCoqIihg4dGtxv0KBBDBo0iF//+tdccsklvPTSS5x77rkAZGZmcu2113Lttdfy29/+lr/97W/ceOONbdJe0IhFWPB6rGBxoRGLltPygOaUoRnlZ04ZmlF+5pRh88THx3PRRRfx29/+lry8PK688srgqlrZ2dnMmDGDb7/9llWrVvHLX/6Sbdu2Nfm1x40bx6BBg7jiiitYunQpX3/9dUgBEXiPjRs38uabb7J27VqefPLJ4P/oB/Tr14/c3FyWLFlCQUEBlZWV9d5r8uTJxMTEcMUVV/D9998zc+ZMbrzxRi677LLgaVAt5fP5WLJkScifVatWMW7cOA499FAmT57MokWLmDdvHldccQUnnngiRx55JHv27GHq1Kl8+eWXbNiwgdmzZzN//vxg0XHzzTfzySefkJuby6JFi5g5c2ZIQdIWVFiEiZhIf2GhORYiIiISTqZMmcKuXbsYP358yHyI3//+9xxxxBGMHz+eMWPGkJaWxjnnnNPk1/V4PLzzzjvs2bOHo48+mquuuoo//vGPIfv89Kc/5de//jVTp05l5MiRfPvtt9x9990h+0yaNIkJEyZwyimn0KNHjwaXvI2NjeWTTz6hsLCQo446ivPPP5+xY8fy9NNPNy+MBpSWlnL44YeH/DnrrLOwLIv//ve/dO3alZNOOolx48bRv39/Xn31VQC8Xi87d+7k8ssvZ9CgQVx44YWcccYZTJs2DfAXLDfccANDhw5lwoQJDBo0iL/+9a/G7d0fy9FizAdUUlJCUlISxcXFzZ7s0xp8Ph/HP/gZ+aU1dI+LYuHdp7V7G8Kdz+cjJyeH7Ozsjh++DlPK0IzyM6cMzSg/cx2VYUVFBbm5uWRlZRETE9Nu79sWHMehoqKCmJgYd8xVCTNtld/+PmPN+R6sEYsw4PF4SIzzH2SNWLSMx+MhKyvLHSt5hCllaEb5mVOGZpSfOWXYOtx2Netw4+b89JMRJuL3rgxVUW3jszXI1BIREVqrwJQyNKP8zClDM8rPnDI0p5EKM27OT4VFGLBtG2pqJxJp1KL5bNsmJydHk+4MKEMzys+cMjSj/Mwpw9ZRUVHR0U0Ia27OT4VFmOgSWXuodPVtEREREXEbFRZhoktEnWtZaMRCRERERFxGhUWYiNGIhYiIyEFNC3lKW2mt0/s0AykMeDweMnp0hx9KAI1YtITH4yE7O1sreRhQhmaUnzllaEb5meuoDCMjI7Esix07dtCjRw9XT949kEBxVFFREdb96CitnZ/jOFRVVbFjxw48Hg9RUVFGr6fCIkzE1DkVqlyFRYvU1NQY/8Ac7JShGeVnThmaUX7mOiJDr9dL79692bx5M+vXr2/X924LjuOoqDDQFvnFxsbSp08f46JZhUUYsG2bitLi4P0ynQrVbLZtk5ubqwtDGVCGZpSfOWVoRvmZ68gM4+Pjyc7Oprq6ul3ft7X5fD42bNhAnz599DlsgbbIz+v1EhER0SrFigqLMBGyKpRGLERERA46Xq837L+M+3w+PB4PMTExYd+XjuD2/HSiZZioeyqURixERERExG1UWISJ2KjaqlQjFi2jCYvmlKEZ5WdOGZpRfuaUoTllaMbN+elUqDDg9XoZlNUXyAOgVCMWzeb1ehk0aFBHNyOsKUMzys+cMjSj/MwpQ3PK0Izb83NvySNBjuNg+aqC9zVi0XyO41BaWqo1wA0oQzPKz5wyNKP8zClDc8rQjNvzU2ERBmzbZnfhjuB9zbFoPtu22bx5c6tdAOZgpAzNKD9zytCM8jOnDM0pQzNuz0+FRZiI0apQIiIiIuJiKizCRJe6q0JVacRCRERERNxFhUUYsCyLxLiY4P3ySo1YNJdlWURFRelKnwaUoRnlZ04ZmlF+5pShOWVoxu35WY5bZ3+4SElJCUlJSRQXF5OYmNhh7Rj0+4+pqrEZmp7Ix786scPaISIiIiIHh+Z8D9aIRRhwHIeioiLi9l7LQnMsmi+QoerollOGZpSfOWVoRvmZU4bmlKEZt+enwiIM2LZNfn5+8CJ5WhWq+QIZunUVhXCgDM0oP3PK0IzyM6cMzSlDM27PT4VFGImN8l/PsExzLERERETEZVRYhJH4aP+IxZ5qHz7bnUNgIiIiInJwiujoBsgBOA6eGXeTWbCJKXuimMp5gL+4iI/W4Wsqy7KIi4tz7SoK4UAZmlF+5pShGeVnThmaU4Zm3J6fVoVqgg5fFerBTKgsIT+yN8fsfhiAeb8bS8/EmAM8UURERESk5bQqVCfjdOkKQLxdEtymi+Q1j23bFBQUuHayUzhQhmaUnzllaEb5mVOG5pShGbfnp8IiHHTpBkCsrxQL/wdJE7ibx3EcCgoKXLs8WzhQhmaUnzllaEb5mVOG5pShGbfnp8IiHMT6Ryw82CRQDkC5RixERERExEVUWIQBZ++IBUBXqxSAMl0kT0RERERcRIVFGLD2zrEA6Iq/sCjXRfKaxbIskpKSXLuKQjhQhmaUnzllaEb5mVOG5pShGbfnp/VKw4AV2z14O9naDY5GLJrL4/GQnp7e0c0Ia8rQjPIzpwzNKD9zytCcMjTj9vw0YhEG7AZGLDR5u3ls2yYvL8+1qyiEA2VoRvmZU4ZmlJ85ZWhOGZpxe34qLMJBTJ3CYu8cC03ebh7HcSguLnbtKgrhQBmaUX7mlKEZ5WdOGZpThmbcnp8KizDgxNYWFkmWRixERERExH1UWISDuqtCoRELEREREXEfFRZhoO7k7a7WbkAjFs1lWRYpKSmuXUUhHChDM8rPnDI0o/zMKUNzytCM2/PTqlBhwBNXO2KRrBGLFvF4PKSkpHR0M8KaMjSj/MwpQzPKz5wyNKcMzbg9P41YhAE7Mh7H8teAukBey9i2zaZNm1y7ikI4UIZmlJ85ZWhG+ZlThuaUoRm356fCIgw4gC8qAYBkSxfIawnHcSgrK3PtKgrhQBmaUX7mlKEZ5WdOGZpThmbcnp8KizDhi04CoCt751hoxEJEREREXESFRZjwRfkLizirkiiqNcdCRERERFxFhUUY8Hg8RCamBu8nUUqpVoVqFo/HQ1paGh6PPvItpQzNKD9zytCM8jOnDM0pQzNuz0+rQoUBy7KITOoZvN/VKmWLCotmsSyL5OTkjm5GWFOGZpSfOWVoRvmZU4bmlKEZt+fnznJHQti2TVFl7aHqSinl1T5s250Td9zItm3WrVvn2lUUwoEyNKP8zClDM8rPnDI0pwzNuD0/FRZhwHEcqiLig/eTrd04DlTUaJ5FUzmOQ1VVlWtXUQgHytCM8jOnDM0oP3PK0JwyNOP2/FRYhInAqlBQey2L3RU6HUpERERE3EGFRZgIrAoFtVffLiyr6qjmiIiIiIiEUGERBjweD916DwzeD1wkr6C0sqOaFHY8Hg+9e/d27SoK4UAZmlF+5pShGeVnThmaU4Zm3J6fVoUKA5ZlEdutV/B+170jFjtLNWLRVJZlER8ff+AdpVHK0IzyM6cMzSg/c8rQnDI04/b8OrTcmTVrFmeddRYZGRlYlsW7774bfKy6upo77riDQw89lLi4ODIyMrj88svZunVryGsUFhYyefJkEhMTSU5OZsqUKZSWlobss2zZMk488URiYmLIzMzk4Ycfbo/utRqfz8favF3B+10t/9W3NWLRdD6fj9WrV+PzacJ7SylDM8rPnDI0o/zMKUNzytCM2/Pr0MKirKyMESNG8Je//KXeY+Xl5SxatIi7776bRYsW8Z///Icff/yRn/70pyH7TZ48mRUrVjBjxgw++OADZs2axTXXXBN8vKSkhNNPP52+ffuycOFCHnnkEe69916ef/75Nu9fa6qJTAjeDpwKtVNzLJrFrUuzhRNlaEb5mVOGZpSfOWVoThmacXN+HXoq1BlnnMEZZ5zR4GNJSUnMmDEjZNvTTz/N0UcfzcaNG+nTpw+rVq1i+vTpzJ8/nyOPPBKAp556iokTJ/Loo4+SkZHBa6+9RlVVFS+++CJRUVEMHz6cJUuW8Kc//SmkAHE7xxuFExmHVV0WPBWqYLdGLERERETEHcJqjkVxcXHIFQfnzJlDcnJysKgAGDduHB6Ph7lz53LuuecyZ84cTjrpJKKiooL7jB8/noceeohdu3bRtWvXeu9TWVlJZWXtl/aSkhLAP/wUGHqyLAuPx4Nt2yFrCTe23ePxYFlWo9v3HdIKTMqxbRufz+evTrt0heoykuucChV4ntfrxXGckCo20JbGtje17W3Rp6Zsb+0+BbLsTH1qz+PkOA6O49TbP5z71J7HKfBzbNs2Xq+3U/TpQNtbu0+BDPV7r2VtDzy3obaEa5/a+zgF/z2GTtOngPY6TnV/jjtLn9rzOAH1/i1u6z4155oZYVNYVFRUcMcdd3DJJZeQmJgIQH5+Pj179gzZLyIigm7dupGfnx/cJysrK2Sf1NTU4GMNFRYPPvgg06ZNq7d97dq1wQkzSUlJpKens23bNoqLi4P7pKSkkJKSwpYtWygrKwtuT0tLIzk5mfXr11NVVXsKU+/evYmPj2ft2rUhH4asrCwiIiLIyckJflAqPbHEAMmUAQ5bdpaQk5ODx+Nh0KBBlJWVsXnz5uBrREVF0b9/f4qLi4N5AMTFxZGZmUlhYSEFBQXB7e3Zp7qys7OpqakhNzc3uK21+1RQUIBt26xduxbLsjpFn9r7OA0cOJBevXoFM+wMfWrP4xT4OS4qKqJHjx6dok/tfZwCV5tdu3YtXq+3U/SpPY9T9+7dycrKIi8vj/Ly8k7Rp/Y+ToEvWB6Pp9P0KdCf9jpOpaWlwZ/j9PT0TtGn9jxO2dnZpKamhvxb3NZ9io2NpaksxyWX7rMsi3feeYdzzjmn3mPV1dVMmjSJzZs38+WXXwYLiwceeIBXXnmFH3/8MWT/nj17Mm3aNK677jpOP/10srKyeO6554KPr1y5kuHDh7Ny5UqGDh1a7/0aGrEIHJjAe7dnBRv4QhLxxvl4cr8C4JCKF0hK7sas34wBOmdV3pp9Cow2BdrWGfrU3scp8BqB252hT+15nALP83q9GrEwHLEIPL8z9Kk9j1NjwrlP7X2cAu2NjIyst3+49imgvY5T4I/H48Hr9XaKPrXncQp8pwm0oT36VFpaSnJyMsXFxcHvwY1x/YhFdXU1F154IRs2bOCLL74I6VBaWhrbt28P2b+mpobCwkLS0tKC+2zbti1kn8D9wD77io6OJjo6ut72wBeCugIHfl/N3b7v69bd7vP5WLduHYO6dAtuT7ZK2VEaH/ygAsF/aPfV2PbWantL+tTU7a3VJ4B169aRnZ0d8rxw7lN7Hyefz8eaNWvqZQjh26f9bW/tPgV+jrOzs5u0v0nbG9se7sfJsqx6P8fh3qf2PE4+n4+cnJwGf4b39zpu7lNLt7e0T3V/jhv6TgDh16e62uM4OY4TzLDu6Ldp2xvb3lk+ewEt+bfYtO11/zPxQNx5dY29AkVFTk4On332Gd27dw95/Nhjj6WoqIiFCxcGt33xxRfYts3o0aOD+8yaNYvq6urgPjNmzGDw4MENngblal1q29uVUiprbMqq3LncmIiIiIgcXDq0sCgtLWXJkiUsWbIEgNzcXJYsWcLGjRuprq7m/PPPZ8GCBbz22mv4fD7y8/PJz88PnrM2dOhQJkyYwNVXX828efOYPXs2U6dO5eKLLyYjIwOASy+9lKioKKZMmcKKFSt46623eOKJJ7jllls6qtstV7ew2DuBe6euZSEiIiIiLtChp0ItWLCAU045JXg/8GX/iiuu4N577+W9994DYOTIkSHPmzlzJmPGjAHgtddeY+rUqYwdOxaPx8OkSZN48skng/smJSXx6aefcsMNNzBq1ChSUlK45557wmqp2aDYOqdCBZacLa2ib/e4jmqRiIiIiAjgosnbblZSUkJSUlKTJq20hcBkHM/yt7HevRaAe6qv4FXfeJ6/bBSnD294rojUCmZYZ06KNI8yNKP8zClDM8rPnDI0pwzNdER+zfke7Oo5FlKrpqYmZMSia50RC2mampqajm5C2FOGZpSfOWVoRvmZU4bmlKEZN+enwiIM2LZNbm4udkxycFuy5S8sNMeiaYIZ7rNsmzSdMjSj/MwpQzPKz5wyNKcMzbg9PxUW4aTOcrPBydtlGrEQERERkY6nwiKc7LPcLECBRixERERExAVUWIQJj8cDMUlg+Q9Z4FQoFRZNt7+L50nTKEMzys+cMjSj/MwpQ3PK0Iyb89OqUE3Q0atChXgoC/YUstHpyUmVj5PdM54Zt5zcsW0SERERkU5Jq0J1Mo7jUFpaiuM4wZWhugYmb2uORZOEZCgtogzNKD9zytCM8jOnDM0pQzNuz0+FRRiwbZvNmzf7VwDYO4E7gXK8+NhVXkWNz50rA7hJSIbSIsrQjPIzpwzNKD9zytCcMjTj9vxUWISbfa5l4ThQWK5RCxERERHpWCoswk18z+DNntYuAHbqInkiIiIi0sFUWIQBy7KIioryX7o9Pi24vadVBKiwaIqQDKVFlKEZ5WdOGZpRfuaUoTllaMbt+UV0dAPkwDweD/379/ffSUgNbu8RKCzKtOTsgYRkKC2iDM0oP3PK0IzyM6cMzSlDM27PTyMWYcBxHIqKivwrACSkB7f3pAiAAo1YHFBIhtIiytCM8jOnDM0oP3PK0JwyNOP2/FRYhAHbtsnPz/evAFDnVKjUvXMsdJG8AwvJUFpEGZpRfuaUoRnlZ04ZmlOGZtyenwqLcFPnVKjaORYqLERERESkY6mwCDdxWhVKRERERNxHhUUYsCyLuLg4/woAEVEQmwLUjlgU6OrbBxSSobSIMjSj/MwpQzPKz5wyNKcMzbg9P60KFQY8Hg+ZmZm1GxLSoLxgb2HhULBbp0IdSL0MpdmUoRnlZ04ZmlF+5pShOWVoxu35acQiDNi2TUFBQe1EnXj/PIsoakimlJ1lla5dHcAt6mUozaYMzSg/c8rQjPIzpwzNKUMzbs9PhUUYcByHgoKC2uIhIfQieRXVNuVVvg5qXXiol6E0mzI0o/zMKUMzys+cMjSnDM24PT8VFuEovqGVoTTPQkREREQ6jgqLcFTnInmp+FeG2qElZ0VERESkA6mwCAOWZZGUlFS7AkAD17LYoQnc+1UvQ2k2ZWhG+ZlThmaUnzllaE4ZmnF7floVKgx4PB7S02tHKepefTtwLYv84j3t3aywUi9DaTZlaEb5mVOGZpSfOWVoThmacXt+GrEIA7Ztk5eXV7sCQJ0Rix57Ryy2Fld0QMvCR70MpdmUoRnlZ04ZmlF+5pShOWVoxu35qbAIA47jUFxcXLsCQJ0Ri9S9IxZbijRisT/1MpRmU4ZmlJ85ZWhG+ZlThuaUoRm356fCIhxFxkBMMgA9KQJgqwoLEREREelAKizC1d5rWaR6igBHhYWIiIiIdCgVFmHAsixSUlJCVwDYey2LGKpIYA/bd1dSVePO8+3coMEMpVmUoRnlZ04ZmlF+5pShOWVoxu35qbAIAx6Ph5SUFDyeOoerzrUselq7cBzI1wTuRjWYoTSLMjSj/MwpQzPKz5wyNKcMzbg9P3e2SkLYts2mTZtCVwBo4FoWmsDduAYzlGZRhmaUnzllaEb5mVOG5pShGbfnp8IiDDiOQ1lZWegKAHWvZbH36tuaZ9G4BjOUZlGGZpSfOWVoRvmZU4bmlKEZt+enwiJcNTBiocJCRERERDqKCotwFTLHogiArbr6toiIiIh0EBUWYcDj8ZCWlhY6USe+dsSi9iJ5mrzdmAYzlGZRhmaUnzllaEb5mVOG5pShGbfnF9HRDZADsyyL5OTk0I0JtXMs0jxFgE6F2p8GM5RmUYZmlJ85ZWhG+ZlThuaUoRm35+fOckdC2LbNunXrQlcAiIqDqAQA0j3FgL+wcOtkno7WYIbSLMrQjPIzpwzNKD9zytCcMjTj9vxUWIQBx3GoqqqqXzTsHbVIoQiA8iofxXuq27l14aHRDKXJlKEZ5WdOGZpRfuaUoTllaMbt+amwCGd7C4suTjmx+OdX6FoWIiIiItIRVFiEs/i6S84GrmWhCdwiIiIi0v5UWIQBj8dD7969668AkFD3InlFAGzZVd6OLQsfjWYoTaYMzSg/c8rQjPIzpwzNKUMzbs9Pq0KFAcuyiI+Pr/9AnWtZZFg7wYGtxRqxaEijGUqTKUMzys+cMjSj/MwpQ3PK0Izb83NnuSMhfD4fq1evxufzhT7QtV/wZh9rO6A5Fo1pNENpMmVoRvmZU4ZmlJ85ZWhOGZpxe34qLMJEg8uKdcsK3uzr2QboWhb749al2cKJMjSj/MwpQzPKz5wyNKcMzbg5PxUW4Sy5b/Bmf28BoMJCRERERDqGCotwFh0PcT2B2hGL7bsrqapxbyUrIiIiIp2TCosw4PF4yMrKangFgL2nQ3WzC4mhEseBbSWawL2v/WYoTaIMzSg/c8rQjPIzpwzNKUMzbs/Pna2SeiIiGlnAq84E7kxrB6AJ3I1pNENpMmVoRvmZU4ZmlJ85ZWhOGZpxc34qLMKAbdvk5OQ0PFmna50J3JYmcDdmvxlKkyhDM8rPnDI0o/zMKUNzytCM2/NTYRHu6oxYBAqLLbtUWIiIiIhI+1JhEe7qLDmbufdaFrk7yzqqNSIiIiJykFJhEe4aOBVq7fbSjmqNiIiIiBykLMdxnI5uhNuVlJSQlJREcXExiYmJ7f7+juNg2zYejwfLsvZ9EB7IgOpyNloZnLTnUeKjI1h+7+n19z2I7TdDaRJlaEb5mVOGZpSfOWVoThma6Yj8mvM9WCMWYaKmpqbhBywrOM8i3dmBB5vSyhq2lVS2X+PCRKMZSpMpQzPKz5wyNKP8zClDc8rQjJvzU2ERBmzbJjc3t/EVAPYWFpFUk0YhAGt0OlSIA2YoB6QMzSg/c8rQjPIzpwzNKUMzbs9PhUVnUGeeRR+PfwL3mu27O6o1IiIiInIQUmHRGdRZGarP3gnca3ZoxEJERERE2o8KizCx30u3N3Ati7XbteTsvvaboTSJMjSj/MwpQzPKz5wyNKcMzbg5P60K1QQdvSrUARWsgadHAfCJdRy/3DOVHgnRzL9rXAc3TERERETCmVaF6mQcx6G0tJRGa8DkPoB/ybEBETsA2LG7kuI91e3UQvc7YIZyQMrQjPIzpwzNKD9zytCcMjTj9vxUWIQB27bZvHlz4ysARERBUm8AMuz84GatDFXrgBnKASlDM8rPnDI0o/zMKUNzytCM2/NTYdFZ7J1nEevbTSL+gkJX4BYRERGR9qLCorOoM4G7j+VfcnatVoYSERERkXaiwiIMWJZFVFTU/i/dXmfJ2b5W4FoWKiwCmpSh7JcyNKP8zClDM8rPnDI0pwzNuD2/iI5ugByYx+Ohf//++9+pzkXyBkZshypdy6KuJmUo+6UMzSg/c8rQjPIzpwzNKUMzbs9PIxZhwHEcioqK9r8CQPcBwZsjY/zXsthUWE5Fta+tmxcWmpSh7JcyNKP8zClDM8rPnDI0pwzNuD0/FRZhwLZt8vPz978CQMpgsLwADLI2+p/nwPqdulAeNDFD2S9laEb5mVOGZpSfOWVoThmacXt+Kiw6i8gYSBkEQFrVBiKpATTPQkRERETahwqLziTtEAC8Tg0DrK2ACgsRERERaR8qLMKAZVnExcUdeAWA1OHBm0OtDYAKi4AmZyiNUoZmlJ85ZWhG+ZlThuaUoRm356fCIgx4PB4yMzPxeA5wuFIPDd48xOufZ7Eyr6QtmxY2mpyhNEoZmlF+5pShGeVnThmaU4Zm3J6fO1slIWzbpqCg4MATdeqMWIyK8Z8KtW5HGUXlVW3ZvLDQ5AylUcrQjPIzpwzNKD9zytCcMjTj9vxUWIQBx3EoKCg48NJiCWkQ2x2Agc764OYlm4rarnFhoskZSqOUoRnlZ04ZmlF+5pShOWVoxu35qbDoTCwLUv0TuONrdpFCMaDCQkRERETaXocWFrNmzeKss84iIyMDy7J49913Qx53HId77rmH9PR0unTpwrhx48jJyQnZp7CwkMmTJ5OYmEhycjJTpkyhtDR0wvKyZcs48cQTiYmJITMzk4cffritu9Zx9hYWAEM9/gncizcWdVBjRERERORg0aGFRVlZGSNGjOAvf/lLg48//PDDPPnkkzz77LPMnTuXuLg4xo8fT0VFRXCfyZMns2LFCmbMmMEHH3zArFmzuOaaa4KPl5SUcPrpp9O3b18WLlzII488wr333svzzz/f5v1rLZZlkZSU1LQVANJqC4tRMVsA/4iFbbtzyKy9NCtDaZAyNKP8zClDM8rPnDI0pwzNuD0/y3HJSVqWZfHOO+9wzjnnAP7RioyMDG699VZuu+02AIqLi0lNTeXll1/m4osvZtWqVQwbNoz58+dz5JFHAjB9+nQmTpzI5s2bycjI4JlnnuGuu+4iPz+fqKgoAO68807effddfvjhhya1raSkhKSkJIqLi0lMTGz9zremvGXw3IkAzIkbxyU7fwHA57eezIAe8R3ZMhEREREJM835HuzaORa5ubnk5+czbty44LakpCRGjx7NnDlzAJgzZw7JycnBogJg3LhxeDwe5s6dG9znpJNOChYVAOPHj+fHH39k165d7dQbM7Ztk5eX17QVAHoMBk8EANmsD24+2E+HalaG0iBlaEb5mVOGZpSfOWVoThmacXt+ER3dgMbk5+cDkJqaGrI9NTU1+Fh+fj49e/YMeTwiIoJu3bqF7JOVlVXvNQKPde3atd57V1ZWUllZGbxfUuK/FoTP58Pn8wH+ERaPx4Nt2yEz8xvb7vF4sCyr0e2B1627HfwfIJ/Px65du+jevTuRkZHB7XV5vV4cx8G2IvB0z8basYpu5euJpIZqIli0oZBzR6a3qO1t0aembA/2qc72QFsa295Y2+tm6PV6O0Wf2vs4OY5DUVFRMMPO0Kf2PE6Bz2BKSkqn6dOBtrd2n2pqakJ+jjtDn9rzONm2TXFxMSkpKZ2mT+19nAI/xz179uw0fQpor+NU9+c4MjKyU/SpPY8TUO/f4rbuU3NObnJtYdGRHnzwQaZNm1Zv+9q1a4mP959OlJSURHp6Otu2baO4uDi4T0pKCikpKWzZsoWysrLg9rS0NJKTk1m/fj1VVbXXlejduzfx8fGsXbs25MOQlZVFREQEOTk52LZNYWEha9asYfDgwdTU1JCbmxvc1+PxMGjQIMrKyti8eTPpsX1JYhUep4ZszxZW2n2Zu2YbOTn+UZu4uDgyMzMpLCykoKAg+Drt2ae6srOzD9ingKioKPr3709xcXGweGxKn7Zv3x7M0OPxdIo+tfdx6t+/Pz6fL5hhZ+hTex6nwM9xYWEhqampnaJP7X2c1q5dG/w5joiI6BR9as/jFPiPtK1bt7Jnz55O0af2Pk62bQfPdugsfYL2PU67d+8O/hxnZGR0ij6153EaMGAA1dXVIf8Wt3WfYmNjaSrXzrFYt24dAwYMYPHixYwcOTK438knn8zIkSN54oknePHFF7n11ltDTmmqqakhJiaGf/7zn5x77rlcfvnllJSUhKw4NXPmTE499VQKCwubPGIRODCBc8vae8RizZo1DBw48MAjFraN9e2TeD6/F4BHYn/NXwqPwuuxWHL3WGKjIsKmKm/N/2morq4mJyeHgQMHasSihX1yHIecnBwGDBigEYsWjlisWbOG7OxsIiMjO0WfDrS9tfsU+Mc08HPcGfrU3iMWa9euZcCAAcH3D/c+dcSIReA/+QLvG+59CmjPEYu632k6Q5/ae8Ri9erVIf8Wt3WfSktLSU5ObtIcC9eOWGRlZZGWlsbnn38eLCxKSkqYO3cu1113HQDHHnssRUVFLFy4kFGjRgHwxRdfYNs2o0ePDu5z1113UV1dHfxSPmPGDAYPHtxgUQEQHR1NdHR0ve2Bf8jqqvvL2WT7vq9bd7tlWfTs2ZOICH9R0Nj+lmX5t6cfGtw2OjaPvxSCz3ZYmVfK6P7dW73tLelTU7cH+9TE7ftrSyDDff9BbUg49Km9j5Nt2/To0aNehhC+fdrf9tbuU+DnOPDcztAn0+3N7VNERES9n+Nw71N7HifLskhJScHr9Tb4nHDsU0u3t7RPgZ9jy7I6TZ/qao8+1f05DnynCfc+NWe7aZ9a8m+xadsDx6kpOnTydmlpKUuWLGHJkiWAf8L2kiVL2LhxI5ZlcfPNN3P//ffz3nvvsXz5ci6//HIyMjKCoxpDhw5lwoQJXH311cybN4/Zs2czdepULr74YjIyMgC49NJLiYqKYsqUKaxYsYK33nqLJ554gltuuaWDet18Ho8neF52k9S5lsVgp3YIbfFBfKG8Zmco9ShDM8rPnDI0o/zMKUNzytCM2/Pr0FYtWLCAww8/nMMPPxyAW265hcMPP5x77rkHgNtvv50bb7yRa665hqOOOorS0lKmT59OTExM8DVee+01hgwZwtixY5k4cSInnHBCyDUqkpKS+PTTT8nNzWXUqFHceuut3HPPPSHXunA727bZtGlTg8NhDYpPhcTeAPQoXkoU1QAs3hgeq2C1hWZnKPUoQzPKz5wyNKP8zClDc8rQjNvz69BTocaMGbPfmeaWZXHfffdx3333NbpPt27deP311/f7Pocddhhff/11i9vZ0RzHoaysrOmz8i0Lsk6EpW/gqang2Oj1fFWZzaKNRTiO06whrc6i2RlKPcrQjPIzpwzNKD9zytCcMjTj9vzcOY4i5vqdGLx5dvJaAHbsrmTF1pKOapGIiIiIdGIqLDqrficEbx7nWRm8PWPlto5ojYiIiIh0cioswoDH4yEtLa15E3W69oXkPgCkliwnGv9aygdrYdGiDCWEMjSj/MwpQzPKz5wyNKcMzbg9P3e2SkJYlkVycnLz50b0O8n/fF8lk3puBWBlXgmbd5W3dhNdr8UZSpAyNKP8zClDM8rPnDI0pwzNuD0/FRZhwLZt1q1b1/wVALLqzLNIWhe8/dlBOGrR4gwlSBmaUX7mlKEZ5WdOGZpThmbcnp8KizDgOA5VVVXNXwGgzgTuQ6uXBm/PWHXwFRYtzlCClKEZ5WdOGZpRfuaUoTllaMbt+amw6MySekG3/gB02b6EAcn+wz13XSHFe6o7smUiIiIi0smosOjs9o5aWHY1P8/0j1TU2A5f/ri9I1slIiIiIp2MCosw4PF46N27d8tWAMg6KXhzTPQPwdufHmTzLIwyFEAZmlJ+5pShGeVnThmaU4Zm3J6fO1slISzLIj4+vmUrANS5nkWvXQtIjo0E4Ksfd1BZ42utJrqeUYYCKENTys+cMjSj/MwpQ3PK0Izb81NhEQZ8Ph+rV6/G52tBIZCQBimDALC2LuTsAV4ASitr+Hh5fms209WMMhRAGZpSfuaUoRnlZ04ZmlOGZtyenwqLMGG0rNjQs/x/OzY/T1oY3Pz8rHWuXVWgLbh1abZwogzNKD9zytCM8jOnDM0pQzNuzk+FxcHgsIuDN/tufo8RvZMA/8XyZq/Z2VGtEhEREZFORIXFwaDHIOg1CgArfzm3jKgJPvT81+sae5aIiIiISJOpsAgDHo+HrKwssxUARlwSvHli+WdkdusCwKzVO1iVV2LaRNdrlQwPcsrQjPIzpwzNKD9zytCcMjTj9vzc2SqpJyIiwuwFhp8HHv9reL7/F1cd1yf40N8OklEL4wxFGRpSfuaUoRnlZ04ZmlOGZtycnwqLMGDbNjk5OWaTdeK6Q/Z4/+3deVyYkktSF//Ss+8t2Upe8Z5WaKl7tUqGBzllaEb5mVOGZpSfOWVoThmacXt+KiwOJiNqJ3F3WflPLjumL+C/Evfv/rP8oFohSkRERERalwqLg8mg8RCT7L+96n2mHNWdlPhoAGb+uIOXZq/vsKaJiIiISHhTYXEwiYiGQyb5b1eX03XxMzx24Yjgw//78Q+s2FrcQY0TERERkXBmOTr/5YBKSkpISkqiuLiYxMTEdn9/x3GwbRuPx2N+CffCXHj6KLCrIaIL3LiQ+78u5oVvcgEY0COOD248kS5R3lZouXu0aoYHKWVoRvmZU4ZmlJ85ZWhOGZrpiPya8z1YIxZhoqam5sA7NUW3LBj9y70vugdm/pHfTBjM8Az/B2XtjjKueGkeBaWVrfN+LtJqGR7ElKEZ5WdOGZpRfuaUoTllaMbN+amwCAO2bZObm9t6KwCceCvE+K++zZLXiS5YyZOXHE7s3lGKebmF/PSpb1i2uah13s8FWj3Dg5AyNKP8zClDM8rPnDI0pwzNuD0/FRYHo9hucNLte+848OnvGZASxz+uGk3PBP9k7q3FFZz/7Bwe/2w123dXdFxbRURERCQsqLA4WB19NST7l5tl3Zew9E2O6NOVD248gVF9uwJQVWPz+Gc5HPfgF0x9fREfLc9j485yLUvblvKWwvZVHd0KERERkWZz76X7JESrX7o9IhrG3Qv/+rn//ntTIb4HPQeO442rj+H+D1fy9+824Dj+61x8sCyPD5blAZAQE0H/lDi6xUXRPT6axJhIIr0WXo9FhNdDhMd/O9JrYeGfWLTv/CLLCjxS+5hV57HWZts2BQUlpBRsqJelx2ORlhhD765d6N21Cwkxka3+/k2ycS68eDpgwQ1zocfgjmnHfrT65/Ago/zMKUMzys+cMjSnDM24OT+tCtUEHb0qVJtxHPjwFljwov9+ZBxc8T70HgXApsJyXp+3kbfmb6KwrKoDG9q+jh/Ynf897zAyu8W27xvPehS++IP/9pl/gqOmtO/7i4iIiOxDq0J1Mo7jUFpa2vqnIFkWTHwUhp7lv19dBq9fAJsXAJDZLZY7Jgxhzm9P5W+XH8lNpw5k7JCepCXG1BuB6Exmr9nJGU98zX8WbW7f077KCmpvl25rv/dtojb7HB4klJ85ZWhG+ZlThuaUoRm356dTocKAbdts3ryZ7OxsvN5Wvr6ExwvnvQD/mAQbvoHynfDCWDj8ZzD2XojvQXSEl9OGpXLasNTg03y2w67yKgrLqthdUU2Nz8FnO1TbDj7bptrnUOPzf+gd9v5d52cgcHPfH4y2+jmxbZv8/HzS0tLqDSFW1djkFVewaVc5c9buZEvRHkora7jl7aV8tXoHD59/GNER7XBdj7Idtbd357X9+zVTm34ODwLKz5wyNKP8zClDc8rQjNvzU2EhEBkDl7wOr54DWxf5ty3+B6x8H0ZeCoMnQN/jwVs798DrsUiJjyYlPrpj2txMPp+PnJwysrMz9vuDuLuimnvfW8m/F20G4L9LthIbFcGD5x3a9o0MKSzy2/79RERERFqRCgvxi0mCKZ/CvL/Blw9CZQlUFsPcZ/x/ohOh1yhIyYaUQZDU2/+cmGSIigXL4/+D5T/FKnjbU+c+DT8GYPvA8fn/tn1g1/jvY/lHVSzv3r89tX8HhAxzOA1vt208VSWwpwi8+5wB6ImE6HgAEmIieezCEYwZ3IPb/rmUyhqbN+Zt5NBeSVw6uk9rJN24uqdCuXDEQkRERGR/VFiEAcuyiIqKavtLt3sj4djr4dDz4bNpsOxN/xd88Bca62b6/4QhLzBofzukj4QRl8AhkyC+B2eNyKDaZ3PL20sB+J/3vmdwWkJwKd42ETJi4b45Fu32OeyklJ85ZWhG+ZlThuaUoRm356dVoZqg064KdSB7imDNZ7B6Oqz9wj//orOzvHDYRXDGQxCTyLT3V/DS7PUA9EyI5oMbT6BnYkzrv69twx9S9o7SAFhw946Q089ERERE2ltzvgersGiCji4sHMehuLiYpKSkjqtQHcdfWBSs9v8p3QEVRf4/VeWA49/Hsevcdvbetht4zK59DGpPdfJE7L3t8f+Ns/c0Kdv/J3DKlGNTe+WLveplU3vfAWpqaoiIjKyzde+t3fmwbXnoU7sNgAtfpbrHMH72wlzm5hYCcGJ2Cq/8/Gg8nlY+DuWF8HBW6LZfr4SkXq37PgZc8TkMY8rPnDI0o/zMKUNzytBMR+TXnO/BOhUqDARWNEpISOi4FQAsC+JS/H/6HtcxbTBg+3yszclpfBWF7atg6Zv+a3pUlkDhWnhhLJFnPsZfJl/AmU9+zbaSSr7OKeDVOeu58vis+q9hou5pUAG7811VWLjicxjGlJ85ZWhG+ZlThuaUoRm356frWIgA9BwKp02DX34FaYf5t9VUwH9vIGXLFzx6wYjgrg9+/AM523a37vs3WFhoAreIiIiEDxUWInV16w9TZsCon9du++h2Tuwbx5XH9QOgssbm5reWUFVjt977NlRYlGrJWREREQkfKizCgGVZxMXF6VxEA83KMDIGfvJn6D/Gf794I3z9GHeeMYSBPf3L0q7YWsJjM35svQbWXWo2wGXXstDn0IzyM6cMzSg/c8rQnDI04/b8VFiEAY/HQ2ZmZr0rRkvTNTtDy4KJj/qvcQHw7ZPEFOfy+EUjidg7cfu5r9bxyYpW+vIfBqdC6XNoRvmZU4ZmlJ85ZWhOGZpxe37ubJWEsG2bgoICbLsVT705yLQow5RsOO5G/21fFXx0G4dkJHLnGUOCu9z29lJyC8rMG9jY5G0X0efQjPIzpwzNKD9zytCcMjTj9vxUWIQBx3EoKChAKwO3XIszPOk2SMr03143Exb/gyknZHHmYekA7K6s4dq/L6S8qsasgQ0WFu66SJ4+h2aUnzllaEb5mVOG5pShGbfnp8JCZH+i4mDC/9bef/9XWDmf8tCkw4LzLX7ctpvf/HMZPtvgh7zuHIu4ngDsLtjExCe+Zs32Vl6BSkRERKQNqLAQOZAhZ8JRV/tvOz54+3Li8+fx7M9GERflX0P6w+V53Pr2Emp8LRyaDIxYRCdC174AJPiKyMkr5K8z15r2QERERKTNqbAIA5Zl6QqVhowytCw442E4ZJL/fk0FvH4RA/cs48lLDg9O5n53yVZ+/fbSlhUXgcIiLgUS0oKbe1DErBx3DHnqc2hG+ZlThmaUnzllaE4ZmnF7fioswoDH4yE9Pd21KwCEA+MMPR4451kYMNZ/v7IEXjqDsctu45WzuxPp9f+Av790K1NfX0xJRXXTX7umCiqK/bfjelDZpWfwoZ5WEQWllfyQ3/GnQ+lzaEb5mVOGZpSfOWVoThmacXt+7myVhLBtm7y8PNeuABAOWiXDiCi46O/Q57jabave4/hPJvJ9wq9YFn0VP0ZfzuTVN/HTP81g5o/bm/a65XXnV/Rg5e644N1UaxcA3+Q0cJ2LdqbPoRnlZ04ZmlF+5pShOWVoxu35qbAIA47jUFxc7IrTYcJVq2UYFQdXvO+/gN7eSdbYNURXbCfRKifaquFE7/ecXvYeP39pPre+vZSKat/+X7PuilBxKXyT7w3e7bm3sJiV08CqUe1Mn0Mzys+cMjSj/MwpQ3PK0Izb81NhIdJc3gg48hdw02I4+U7o2g8Se0PKIBz8p0RdG/E+cezh34s2c+s/l+7/F0CdwmKXlcy8ndHB+wNi/KdAzcstPHCBIiIiItKBVFiItFR0PJzyW/jVUrhlBUydj3XoBQB0s0q5JupTAD5clseTn69p/HXqLDW7eKeXbU7X4P1hCXsAqKyxWbB+Vxt0QkRERKR1qLAIA5ZlkZKS4toVAMJBu2U45k6w/KcyXR/9MYmW/6rcf/5sNR8uy2v4OXVGLL7cTEhh0S+qJHj76w4+HUqfQzPKz5wyNKP8zClDc8rQjNvza1FhsWnTJjZv3hy8P2/ePG6++Waef/75VmuY1PJ4PKSkpLh2BYBw0G4Zdh8AIy4BILK6hJcGzQs+dOs/l7B4YwOjDnUKi5yyGIqJo4pIALrZhQR+d8zq4Anc+hyaUX7mlKEZ5WdOGZpThmbcnl+LWnXppZcyc+ZMAPLz8znttNOYN28ed911F/fdd1+rNlD8KwBs2rTJtSsAhIN2zfDk34AnAoAj8t7kssP8qzxVVNtMfmEuX63eZ+ShzqlQO51EwKI61j8xPKIsn+EZiQCsyithx+7Ktm9/I/Q5NKP8zClDM8rPnDI0pwzNuD2/FhUW33//PUcffTQAb7/9Nocccgjffvstr732Gi+//HJrtk/wrwBQVlbm2hUAwkG7Zti1Hxz+MwCsqt3c63uK47KSACiv8jHl5fn8e2HtiF/dEYudTiJ9u8fSpVsv/4Y9hYwZkBR8fPaaArB9kL8catq3yNDn0IzyM6cMzSg/c8rQnDI04/b8WlRYVFdXEx3tX7nms88+46c//SkAQ4YMIS+vkfPIRQ4mJ98BMckAeNd+xqu9/suE4f4ratfYDrf+cyl//XINjuPg7C0sbMdiFwncctogPInpwZc6pVftL48PluXhfH4fPHsCvDQRXPqLRURERA4+LSoshg8fzrPPPsvXX3/NjBkzmDBhAgBbt26le/furdpAkbCUmAEX/QM8/rkSEQue56+DFnL5sX2Duzw8/UfufW8FFUXbACgkgUFpSZx1WAbEpwX3OzSpnIRo/6lV36zaSNWc5/wPbFkAJVvbqUMiIiIi+9eiwuKhhx7iueeeY8yYMVxyySWMGDECgPfeey94ipS0Ho/HQ1pammsn6oSDDskw60Q46/HaNky/k2nD8vnN+MHBba/MWY+1d8Rip5PIracPxuOxIKG2sIgq38595wzHsuA0z0Ki7T2177F9ZZt3I9h+fQ6NKD9zytCM8jOnDM0pQzNuzy+iJU8aM2YMBQUFlJSU0LVr7dKY11xzDbGxsa3WOPGzLIvk5OSObkZY67AMD/8ZFKyG2U+A48P618+5YcqnpCaO4M5/LyPKriDGqgagKrob44buvZp3Qu2pUOzO59zRvbGwSPrPwyEv72xbgZV9Wrt0RZ9DM8rPnDI0o/zMKUNzytCM2/NrUbmzZ88eKisrg0XFhg0bePzxx/nxxx/p2bNnqzZQ/CsArFu3zrUrAISDDs1w7L0w5Cf+25Ul8PqFnD84mheuOJLeUaXB3dIzMmvXpU5IrX3+Tv/F9c7JjuTkiOUhL71m+Tzaiz6HZpSfOWVoRvmZU4bmlKEZt+fXosLi7LPP5tVXXwWgqKiI0aNH89hjj3HOOefwzDPPtGoDxb8CQFVVlWtXAAgHHZqhxwPnPQ/p/lMGKdoIb17KmP6JPHNOn+BuKam9a5/TcxhYe388F74MO1bD9//B4/hCXromb7l/pah2oM+hGeVnThmaUX7mlKE5ZWjG7fm1qLBYtGgRJ554IgD/+te/SE1NZcOGDbz66qs8+eSTrdpAkU4hKg4ueQsSMvz3N8+Dd37JgJjdtfvE9ai9nZAGx93ov+2rgvemwtI3gg/vifBf22KAtYWbX5vH5l3lbd0DERERkf1qUWFRXl5OQkICAJ9++innnXceHo+HY445hg0bNrRqA0U6jcR0uPRNiNw7D2nluzD9ztrH41JC9x/zW+jW339701zIW+K/nXYY0YP98yqiLB/JFZu49h8LKa2sadPmi4iIiOxPiwqLgQMH8u6777Jp0yY++eQTTj/9dAC2b99OYmJiqzZQ/CsA9O7d27UrAIQD12SYPgIufDW4DC0lW2ofqztiARDZBX76VP3XGHExntRhwbtDrI18v6WEn780j7I2LC5ck2GYUn7mlKEZ5WdOGZpThmbcnl+LWnXPPfdw22230a9fP44++miOPfZYwD96cfjhh7dqA8W/AkB8fHztxF5pNldlmH0aXPT32uIiYN/CAqDfCXDkL2rvWx445HxIHR7cNCLKX5zMX7+Ln788n/KqtikuXJVhGFJ+5pShGeVnThmaU4Zm3J5fiwqL888/n40bN7JgwQI++eST4PaxY8fy5z//udUaJ34+n4/Vq1fj8/kOvLM0yHUZDj4DLngJPHVWfK5z7YoQ46ZB8t5J3sPO8a8Y1bN2xOLCPrtJjPG/zrzcQqa8vKBNigvXZRhmlJ85ZWhG+ZlThuaUoRm359ficZS0tDQOP/xwtm7dyubNmwE4+uijGTJkSKs1Tmq5dVmxcOK6DIee5T8tqtsA/6hE174N7xeTCFd/CRe8UntqVHIfiPLPc0osWc0/rhpNwt7iYs66nUx+YS67yqpavcmuyzDMKD9zytCM8jOnDM0pQzNuzq9FhYVt29x3330kJSXRt29f+vbtS3JyMn/4wx9c3VkR1xlyJty0CH5ygJG+uO4w/ByIjvfftyzoOdR/u2gjh6V4ePUXR5MQ7S8uFm8s4vxnv2VL0Z6GX09ERESklbWosLjrrrt4+umn+d///V8WL17M4sWLeeCBB3jqqae4++67W7uNItKQOhO42b6Kw/t05a1fHkuPhGgA1u4oY9Jfv2XF1uIOaqCIiIgcTCynBVfYyMjI4Nlnn+WnP/1pyPb//ve/XH/99WzZsqWRZ4ankpISkpKSKC4u7pBVrwIXQ4mKinLtZB2365QZzn0ePv6N//ZP/hyc5L2psJzL/m8u63f6r20RFeHhnp8MY/LoPkZ975QZtiPlZ04ZmlF+5pShOWVopiPya8734Ij9PtqIwsLCBudSDBkyhMLCwpa8pBxARESLDpXU0ekyrDtisW1l8GZmt1j+dd1xTHl5Pks3F1NVY/P7d79nztqdjMxMZl1BGVuK9jA6qxvXnTwAj6fpv5g6XYbtTPmZU4ZmlJ85ZWhOGZpxc34tOhVqxIgRPP300/W2P/300xx22GHGjZJQtm2Tk5Oj+SsGOmWGPeueCrUy5KGU+GjevvZYrji2dkL4h8vz+ONHq3hj3kZmrd7BI5/8yO/eWY5tN23QslNm2I6UnzllaEb5mVOG5pShGbfn16KS5+GHH+bMM8/ks88+C17DYs6cOWzatImPPvqoVRsoIo2I7QYJGbB7K2xbAY7jn9S9V3SEl2lnH8Ix/btz+7+Xsbui/hK0b87fRFWNzcPnH0aE150X2xEREZHw0KJvEieffDKrV6/m3HPPpaioiKKiIs477zxWrFjB3//+99Zuo4g0JnA6VEURFG9qcJczDk3n01+fxB/PPYQ/XzSCd64/jj9dOALv3lOg/rN4Cze/tYQanzv/90NERETCQ4tP0srIyOCPf/xjyLalS5fyf//3fzz//PPGDRORJkgfAWs+899+7yaY/C/w1v+xTk/qwuTRtadFHd6nK3HREUx9fRHVPocPluWR3TOBX43Lbq+Wi4iISCfTolWhGrN06VKOOOII114NsKXcsCqUbdt4PB6toNBCnTbD4i3w3ElQXuC/f8wNMOGBJj995g/buerVBfhsB6/H4t/XHcfIzOQG9+20GbYT5WdOGZpRfuaUoTllaKYj8mvO92BXn1Tt8/m4++67ycrKokuXLgwYMIA//OEP1K2FHMfhnnvuIT09nS5dujBu3DhycnJCXqewsJDJkyeTmJhIcnIyU6ZMobS0tL27Y6Smpv758dI8nTLDpF5w0d/Bs3eU4ru/wOLXmvz0U4b0ZOopAwHw2Q6/fmsJ5VWN59QpM2xHys+cMjSj/MwpQ3PK0Iyb83N1YfHQQw/xzDPP8PTTT7Nq1SoeeughHn74YZ566qngPg8//DBPPvkkzz77LHPnziUuLo7x48dTUVER3Gfy5MmsWLGCGTNm8MEHHzBr1iyuueaajuhSi9i2TW5urmtXAAgHnTrDvsfBxEdq7793I7x4Bnw2DXJmQMX+L5A39eS+jOidBEBuQRn3f7iqwf06dYbtQPmZU4ZmlJ85ZWhOGZpxe37NmmNx3nnn7ffxoqIik7bU8+2333L22Wdz5plnAtCvXz/eeOMN5s2bB/hHKx5//HF+//vfc/bZZwPw6quvkpqayrvvvsvFF1/MqlWrmD59OvPnz+fII48E4KmnnmLixIk8+uijZGRktGqbRTrEkb/wrww1/wVwfLDxW/+fb/4EWJB6CPQ9Fo67EZL71D4v/3si/zGJf2MxNvIeNlQn8frcjaQlxnDtyQOIinD1/z2IiIiIizTrW0NSUtJ+//Tt25fLL7+81Rp33HHH8fnnn7N69WrAP4fjm2++4YwzzgAgNzeX/Px8xo0bF9LG0aNHM2fOHMC/DG5ycnKwqAAYN24cHo+HuXPntlpbRTrchP+FE2+Drv32ecCBbcth3vPwt7GwO9+/uaYS/nMNlOYTUZrH04MWB5/xpxmrmfjk13y3bme7NV9ERETCW7NGLF566aW2akeD7rzzTkpKShgyZAherxefz8cf//hHJk+eDEB+vv8LUmpqasjzUlNTg4/l5+fTs2fPkMcjIiLo1q1bcJ99VVZWUllZGbxfUlIC+Od8BCamW5aFx+PBtu2QOR+NbQ9Msmls+74T3j0ef81n23bwMZ/PF7K9Lq/XG5zQs29bGtve1La3RZ+asr21+xTIsDP1KXS7F8/Yu7FPuQunZCvWxu9g01ysTXOw8r8HHCjbjvOvX2D/7B08sx7G2r4i+PxDir7gupN+znNf52I7sGZ7KRc//x0nDOzORUdmMnZIjwYz0GevaW0PtMm2bbxeb6fo04G2t3af6v4u7Cx9as/jFJjw2VBbwrVP7X2c6j6vs/QpoL2O077faTpDn9rzOAXeu+7rtHWfmrPOk3uvCQ68/fbbvPbaa7z++usMHz6cJUuWcPPNN5ORkcEVV1zRZu/74IMPMm3atHrb165dS3x8POAfGUlPT2fbtm0UF9eew56SkkJKSgpbtmyhrKwsuD0tLY3k5GTWr19PVVVVcHvv3r2Jj49n7dq1IR+GrKwsIiIiQiair1u3juzsbGpqasjNzQ1u93g8DBo0iLKyMjZv3hzcHhUVRf/+/SkuLg4pouLi4sjMzKSwsJCCgoLg9o7oE9AufQpsW7duXafp0wGPU9QhMOAQ0o6/i2TPHmqePYmI8u1YG2ZT9uqlJGyeGdJma+caLjxqHaf/cjT3fvAjSzf7X/ubNTv5Zs1OusVF8csT+mLba4MrUeiz1/w+FRcXd7o+tfdxWrduXafrE7TPcRo0aBCbNm3qVH3qiOPk9XopLS3tVH1q7+O0bt26TtcnaJ/j1KtXr+D3mfboU2xsLE3VqsvNtrbMzEzuvPNObrjhhuC2+++/n3/84x/88MMPrFu3jgEDBrB48WJGjhwZ3Ofkk09m5MiRPPHEE7z44ovceuut7Nq1K/h4TU0NMTEx/POf/+Tcc8+t974NjVgEDkxgma32rGAdx6G8vJzY2Fi8Xm9we12dsSpvzT75fD7KysqIjY3FsqxO0admH6f1s7FeOQvLCe2D02MI1o4f/O098TasU3+Pz3Z4Y94Gnp+Vy6Zde0L2P+/wDO4/5xCi986/0GevaW0P/BzHxcVpxMJgxCLwu9CyrE7Rp/Y8TgB79uyhS5cu9doSrn1q7+MU+DlOSEiot3+49imgvY6Tbdsh32k6Q5/a8zh5PB5KS0vp0qVL8D/52rpPpaWlJCcnN2m5WVePWJSXlweDDQj8gwz+Ki8tLY3PP/88WFiUlJQwd+5crrvuOgCOPfZYioqKWLhwIaNGjQLgiy++wLZtRo8e3eD7RkdHEx0dXW+71+sNfrEP2Ld9Ld2+7+vW3e7z+di6dSvZ2dnBD1FD+wf+oW3q9tZqe0v61NTtrdUnIJhh3eeFc5+avb3f8TDuXphxd+3G9BFYF70Gjx8KOHhW/hdO/T0RXg+XHZvF5NH9+HbtTt6Yt5EPl+cB8J/FW9m8q4LnLhtF17ioju1TGB2nuj/HTdnfpO2NbQ/342RZVr2f43DvU3seJ5/Px+bNm+v9HjzQ67i5Ty3d3tI+1f05bug7AYRfn+pqj+PkOE697zTh3qfmbDftk8/nY8uWLQ3+HLdVnwLHqSlcveTLWWedxR//+Ec+/PBD1q9fzzvvvMOf/vSn4CiDZVncfPPN3H///bz33nssX76cyy+/nIyMDM455xwAhg4dyoQJE7j66quZN28es2fPZurUqVx88cVaEUoOPsfdCIP9q6zhjYKz/wrJmdDnWP+2nTmwfWVwd4/H4oTsFP4y+QievmQkUV7/L5d56wuZ9My3FJdXt3cPRERExKVcPWLx1FNPcffdd3P99dezfft2MjIy+OUvf8k999wT3Of222+nrKyMa665hqKiIk444QSmT59OTExMcJ/XXnuNqVOnMnbsWDweD5MmTeLJJ5/siC6JdCzLggteguX/9C9Bm3aIf/vwc/3L0wKseBdSh9d76hmHpOEr2cEfvtpBQWkV6wrKmPb+Cv500ch2a76IiIi4l6vnWLhFcy5l3hZs22b9+vX069dvv6f6SOOU4QHszofHhgAOpAyCG+b5i5A6Ahl6E3vyk6dns7vCf+XP5y8bxenD0zqg0eFFn0FzytCM8jOnDM0pQzMdkV9zvgersGiCji4sRNrFi2fUjlpc922DoxYB/1q4mdv+uRSAlPhoZvz6JPJLKnj8s9X8kL+bG0/N5vxRvduj1SIiItKGmvM9WKViGHAch6KiomatIyyhlGETDK+zQtpXD8E+K1HUzXDSEb0YN9R/fZiC0krO/stsJj75NZ+s2MaGneXc9s+lPPDRKny28g7QZ9CcMjSj/MwpQ3PK0Izb81NhEQZs2yY/P7/ekmPSdMqwCYafA5Fx/tsr/wvT74A6v7jqZmhZFg+ceyhJXSIB2FhYzr6/456ftY5rXl3A7gpN8AZ9BluDMjSj/MwpQ3PK0Izb81NhISJ+8T3h/BfB2rtU3bzn4auHG929Z2IM951de7pU19hIfn/mUO47ezhej39+xuc/bOeG1xe3abNFRETEHVy9KpSItLPBE+Dsv8C71/rvf/kAxHaDo69ucPezR/YiLiqCHaWV/OSwdBJi/CMYA3rEc90/FlJSUcOs1Tv4Ib+EIWmanyQiItKZacQiDFiWRVxcXLMuUCKhlGEzjLwETv9j7f2PboPF/2g0w3HDUrnk6D7BogLg+IEp3Hr64OD9N+dtan47cmb4L9z32bTmP9eF9Bk0pwzNKD9zytCcMjTj9vy0KlQTaFUoOSh9fh98/djeOxZMegEOPb/JTy/eU83Rf/yMyhqbxJgI5t01jpjIhq8s2qAXToPN8/zvfcd66JLcjMaLiIhIa9CqUJ2MbdsUFBS4dqJOOFCGLXDq3TD6ur13HJz/XMPur/6CXV3ZpKcndYnkzMPSASipqOHj7/Oa/t6+GshfHnxvdq1v+nNdSp9Bc8rQjPIzpwzNKUMzbs9PhUUYcByHgoIC1y4tFg6UYQtYFkx4EEb93H/X8ZEw83dYTxwGX/wRSg5cKFxydJ/g7TeaczrUzhyo2VN7v2hD05/rUvoMmlOGZpSfOWVoThmacXt+KixEpHGWBWf+CQ7/We2m0nyY9TA8NQp++Gi/Tz+yb1cG9owHYF5uIWu2lzbtffOWhd7fFf6FhYiISGenwkJE9s/jgZ8+je9n77C79xicwHK01WXw5qXw7VPUu4jFXpZlcfFRmcH7b83f2LT3zFsaer8TjFiIiIh0dioswoBlWSQlJbl2BYBwoAwNWRZW/zGUnvkszq+WwfDz9j7gwKe/h/dv8s+LaMB5R/Qmyuv/VfPm/E28NX8j1T4bx3H4dk0B17+2kAufm8OKrcW1T8rvfCMW+gyaU4ZmlJ85ZWhOGZpxe35aFaoJtCqUyD4cB756CL58sHbb2HvgxFsb3P1Xby7mv0u2Bu/36RZLbJSXH/J3B7elxEfxzvXHk9m1C/xvX6isU2ikDIKp81u9GyIiIrJ/WhWqk7Ftm7y8PNeuABAOlKG5kAwtC8bcCZP+D6y9v0a+/jOU7mjwudN+OpyTB/UI3t9YWB5SVAAUlFZxxUvzKMnLCS0qwD9iEebHTp9Bc8rQjPIzpwzNKUMzbs9PhUUYcByH4uJi164AEA6UobkGMzz0fDjicv/tqt3+Sd0NSI6N4pVfHM2/rzuWE7NTgtsP75PMYxeMYECPOADW7Sjjb2+/U/8FfJVQuq3V+tIR9Bk0pwzNKD9zytCcMjTj9vwiOroBIhLmxvwOlv3TP5l7wYtw9C8hZWCDu47q242/TxnNqrwSAIam+4dUj87qxrl//ZaC0kqiC1bU/mZK7A0lm/23izZAYnpb90ZERERaSCMWImImIRWOu9F/266Bz+894FOGpicGiwqAzG6xvHjlkXSJ9HKItb7OjmfV3u4EE7hFREQ6MxUWYcCyLFJSUly7AkA4UIbm9pvhcTdCfKr/9qr3YeN3zX79w3onc9UJ/RjuyQVgjzcR+h1fu0OYLzmrz6A5ZWhG+ZlThuaUoRm356fCIgx4PB5SUlLweHS4WkoZmttvhtHxMOa3tfc//0OL3uPKw7rQw/KfJrW0pi9lsb1qHwzzEQt9Bs0pQzPKz5wyNKcMzbg9P3e2SkLYts2mTZtcuwJAOFCG5g6Y4eGXQbcB/tsbvoENc5r9Ht13/xC8vcTXl3+t89Y+GOYjFvoMmlOGZpSfOWVoThmacXt+KizCgOM4lJWVuXYFgHCgDM0dMENvROh1LL5+tPlvUueK2yvtfjw/dydOl67+DWE+YqHPoDllaEb5mVOG5pShGbfnp8JCRFrPYRdCUh//7TWfwZZFzXt+ncLie6cfW4r2UBCRBoBdvJnXvl3Dyq0l+Gx3/kIVERE5mKmwEJHW442EE26uvf/1Y817/t7CwhcRS67jLyjmFSUA4MHmufdnMfHJrzns3k+46pUFFJRWtkarRUREpBWosAgDHo+HtLQ0107UCQfK0FyTMxw5GRL2Xm/ihw9g28qmvUHhOije5H+vXiM5tLf/FKhNTs/gLpnWdgDKqnx8tmob973fxNd2AX0GzSlDM8rPnDI0pwzNuD0/d7ZKQliWRXJysmuXFgsHytBckzOMjIHjbqq9//wYeCQbnjwCPr0baqoafl7OZ7XvNXAcf75oJGePzKBn5qDg9msPi+DMQ9OJjfJP6n5v6Vbm5Ra2tEvtSp9Bc8rQjPIzpwzNKUMzbs9PhUUYsG2bdevWuXYFgHCgDM01K8NRV0Jsiv+2rxLKtkPhWvj2SXj9Aqgoqf+cnE9rb2efzoAe8Txx8eGcd2rttSxOTCnjL5OP4K4zhwa33fveirCYc6HPoDllaEb5mVOG5pShGbfnp8IiDDiOQ1VVlWtXAAgHytBcszKMioVJf4O+J0CPoZCUCZ4I/2PrvoSXz4Td22r3r94D67/2305Ih9RDah/r2rf29t4lZy8+qg/D9l65e2VeCW/O32jQs/ahz6A5ZWhG+ZlThuaUoRm356fCQkTaxoBT4ecfwg3fwa+/hys/gsDSsfnL4P9Og9Id/vvrZ0NNhf/2wHFQd4g3KbP29t4lZ70ei3t/Ojy4+dFPfqS4vLoteyMiIiIHoMJCRNpHn9Hwi08gsbf/ftEGmHm//3bIaVCnhT4vMqZ2Mnidi+QdndWNn47IAGBXeTUX/+07vl1TAPj/R2dVXgkvfpPLwg3hMQdDREQk3FmOW8dSXKSkpISkpCSKi4tJTExs9/cPXAwlLi7OtZN13E4Zmmu1DIs3w1+OgardYHng+u/gjYv9q0J5IuD2dRCTFPqcFyfAxr1X8v7tFoiOByCveA/jHvuKsipfcNfjB3Zna1EFuQVlAER4LN694XgO6bXPa7YzfQbNKUMzys+cMjSnDM10RH7N+R6sEYswYFkW8fHx+gE0oAzNtVqGSb3hhF/5bzs2/Ocaf1EBkHlM/aICILnuPIva+RTpSV147epjGJ5R+4tu9pqdwaICoMZ2+N07yzt8grc+g+aUoRnlZ04ZmlOGZtyenwqLMODz+Vi9ejU+n+/AO0uDlKG5Vs3wmBtqT2/KW1K7fd/ToAK69qu9vTMn5KGRmcm8P/UEHr1gBGmJMQB4LDimfzf6do8FYNnmYv7xnf80Ksdx+Gh5Hs98uZbyqhrzvjSRPoPmlKEZ5WdOGZpThmbcnl9ERzdAmsaty4qFE2VortUyjIqFU+6C96aGbm+ssEgdVnt72woYdnbIwx6PxfmjenPmoeks3LCLwWkJ9EiIZv76Qi541n8K1SOf/Miovl157NMfmfmjf9L4gvWFvHDFke32Pz/6DJpThmaUnzllaE4ZmnFzfhqxEJGOMfJS6FmnYEjsFXq/rrrLz+Yvb/Qlu0R5OSE7hR4J0QAc1a8bFx/lX1WqtLKGnzz1TbCoAPj8h+38Z9GWlvdBREREglRYiEjH8HjhtPtq7w8+I3SZ2bq6ZkGUf8I2+d83623uPGMI3eOiQrYldYkM3p72/gq2lVQ06zVFRESkPhUWYcDj8ZCVlYXHo8PVUsrQXJtkmH0anPUkHHU1nHr3/t4cUvdet6J4I+wpavJbJMdGcc9ZtSMhpw9LZeYNI7huSDkR1FBSUcNv/7O8zS82pM+gOWVoRvmZU4bmlKEZt+enORZhIiJCh8qUMjTXJhmOuqJp+6UeApvm+m9vWwH9jm/yW5w9she9u3bBth2OLJmB9bfzuKOymBtjYpjvG8S3OcN5b24cZx/TyKlYrUSfQXPK0IzyM6cMzSlDM27Oz53ljoSwbZucnBxXT9ZxO2VorsMzTKszz2Jb806HAhjVA46afwvWO7+EymIAYqngZO8yfhv5Bt0+vZEaX9v1rcPz6wSUoRnlZ04ZmlOGZtyenwoLEQkPqYfW3t7PBO4GFayBZ46Dle/WbutzLMSnBe8e4VvOzFX5Zm0UERE5iKmwEJHwkDoM2Du5uzkjFhXF/it7787z3+/SFS54GX4xHW79gR29xgEQZ1Xy+exvW7XJIiIiBxMVFiISHqLioFt//+3tq8DXhIvb2T7499W1F9XrMRSumwPDz/Xftyy6DzomuPuejYvYuLO8lRsuIiJycFBhEQY8Hg/Z2dmuXQEgHChDc67IMDDPoqYCCtceeP8v/gA5n/hvd+kKl7wBiekhu3gyRgZvD7fW89q8Da3U2FCuyC/MKUMzys+cMjSnDM24PT93tkrqqalpwv/Oyn4pQ3MdnmFz5ln88BF882f/bcvrP/2pW1b9/dJHBG8eYuXyzwWbqazxmbe1AR2eXyegDM0oP3PK0JwyNOPm/FRYhAHbtsnNzXXtCgDhQBmac0WGaU27AjcA856rvT3+Aeg/puH94ntCgn8U4xDPegrLKpn+fetP4nZFfmFOGZpRfuaUoTllaMbt+amwEJHwkdrEJWcrd8P62f7bSZkw+pf7f929oxaJVjmZ1naen7WOwrIqw8aKiIgcXFRYiEj4SOoNMUn+2/n7KSzWfQV2tf929ulgWft/3ZDTodazYmsJYx/7kv8s2tzmV+QWERHpLFRYhAm3TtIJJ8rQXIdnaFm18yxK86GsoOH9AhO2AQaNP/Dr1iksRkX5J2/vKq/mlreX8vOX51NcXt3SFofo8Pw6AWVoRvmZU4bmlKEZN+fn3pZJkNfrZdCgQXi93o5uSthShuZck2HdeRZbFtV/3HEgZ4b/dkQM9DvxwK9Zp7C4rF8xZx5Wu3LUlz/uYNKz37J5V+0ytOVVNWzYWdasZrsmvzCmDM0oP3PK0JwyNOP2/FRYhAHHcSgtLdUpGQaUoTnXZJhWZ2WoNy+Bf15ZO58CIH9Z7cXwsk6CqNgDv2ZiL4jtDkD09uX85ZLDeeHyI+keFwXAmu2lnPfXb3l38RZufXspR97/GSc/8iW3vr2UGl/TJtC5Jr8wpgzNKD9zytCcMjTj9vxUWIQB27bZvHmza1cACAfK0JxrMhxwKkQl7G1UDax4B16eCJ/f59+2+tPafbNPb9prWlbtqEV5AezOY9ywVP5z/XFkpcQBsH13JTe/tYR/L9pMeZV/Odp/L9rMda8toqL6wMvTuia/MKYMzSg/c8rQnDI04/b8VFiISHhJzIAbvoMTboHYlNrtXz8GK96FnBYUFhByOhR5SwHo2z2Of193HIf3SQ7ZNSEmgiiv/9fnjJXb+MXL85n5w3beXrCJv81ax5JNRc3rk4iISCcQ0dENEBFptqTeMO5/YMyd8O2T8MX9/u3/vQGq9s596DEEuvZt+mvuW1gMPgOAbnFRvH7VMTz66Y/kF1cw4ZA0ThuWyoL1u7jm7wsor/Lx7dqdfLt2Z/Dp0REePr/1ZHp3bcJpWCIiIp2ERizCgGVZREVFYR1oyUxplDI058oMI6LhxNvg0Av896tKgb3nnTZntAIaHLEI6BLl5e6fDOMvk4/grBEZxER6OSE7hb9PGU1iTP3/n6mssXlz3qaQba7ML8woQzPKz5wyNKcMzbg9P8tx6+wPFykpKSEpKYni4mISExM7ujkisq+qMvjbWNixqnbblR9CvxOa/hq2DQ/1hcoSSMiAW1Ye+PoXwNodpbw5byNdoiJI7hLJAx+tosZ26JkQzew7TyXSq/+/ERGR8NWc78H6Fy8MOI5DUVGRa1cACAfK0JyrM4yKg4v+DlHx/vtdukHm6Oa9hsdTO2qxeyvMfa5JTxvQI567zhzGLacN4hcnZDFuaCrgn+z9+artwf1cnV+YUIZmlJ85ZWhOGZpxe34qLMKAbdvk5+e7dgWAcKAMzbk+w5RsuOwdOOR8OP9F8EY2/zWOu7H29qd3waZ5zX6JS0f3Cd5+Y97G4G3X5xcGlKEZ5WdOGZpThmbcnp8KCxHpPDKPhvP/Dwac0rLnDxoPx93kv23X+K+R0djVvRtxwsAUenftAsCsnB1sKiw/wDNEREQ6BxUWIiJ1jf0f6Hu8/3bJFvj3Vf75F03k8VhccrR/1MJx4K35/kncm3eVs7WkutWbKyIi4hYqLMKAZVnExcW5dgWAcKAMzR00GXoj/KdSxfX03183E9Z9EbrP7m2w5jOoqWrwJS44sjcRHn9Or8xZz4kPf8HJj87iF//ZyH+XbG3L1ndqB81nsI0oP3PK0JwyNOP2/FRYhAGPx0NmZiYejw5XSylDcwdVhglpcMb/1t7/4aPa2zWV8OLp8I9J8MV9DT69Z0JMcBL37ooaNhXuCT7297kbG3yOHNhB9RlsA8rPnDI0pwzNuD0/d7ZKQti2TUFBgWsn6oQDZWjuoMswezx4o/y3V3/iP68JYO0XsGu9//YPHzb69KtP6h8ctYiK8BAb5QVgyaYiCssaHumQ/TvoPoOtTPmZU4bmlKEZt+enwiIMOI5DQUGBa5cWCwfK0NxBl2F0PGSd5L9dshnyl/tvf//v2n0K10F5YYNPH9W3K9NvPpG3f3ksy/7ndCaPrp138XXOjrZsead10H0GW5nyM6cMzSlDM27PT4WFiEhjBk2ovb16OlSVh54WBbBlYaNPH9gzgaOzuhET6eXkQSnB7V/+qMJCREQ6HxUWIiKNqVtY/Pixv7ioLgvdZ/OCJr3UqD5diY30nxr11eod2LY7/7dJRESkpVRYhAHLskhKSnLtCgDhQBmaOygzTM6E1EP9t7cugu+eqb/PlqYVFtGRXo7qkwhAYVkVy7YUt1YrDxoH5WewFSk/c8rQnDI04/b8VFiEAY/HQ3p6umtXAAgHytDcQZvh4DqjFpv3Xok7rifE7j21acvC2ond++HxeJgwovaq3F/+uL3+TlXl8MldMPvJJr3mweag/Qy2EuVnThmaU4Zm3J6fO1slIWzbJi8vz7UrAIQDZWjuoM1w8Bn1tw0/F3of6b+9Z5d/EvcB2LbNsOTaYqHBeRaLXoE5T8OMuxs+xaqmsqmt7pQO2s9gK1F+5pShOWVoxu35qbAIA47jUFxc7NoVAMKBMjR30GaYfjjEp4ZuO2QS9Dqy9v5+JnAHOI5DtL2HwanxACzdXMTO0n0KhS2Lam8X/Bj62L+mwIO9YembzWl9p3LQfgZbifIzpwzNKUMzbs9PhYWIyP54PDBofO39pEzofRT0OqJ2WxMncAOcPKgHEFh2tiD0wbrFREle7e3yQvj+X+CrgoUv13/RXRugqqz+dhERkXakwkJE5ECG/KT29iGT/MVGr1G125o4gRsIWXb2s1Xbah+wbSjIqb2/u05hUby59nbJltAX/P4/8MRh8JfRKi5ERKRDqbAIA5ZlkZKS4toVAMKBMjR3UGeYfTqceCuMuAROvMW/rUsydM/2385ffsD5D4H8juzXjYSYCAA+WJbHFz/sLS5KNkN1ee0T6hYWJVvrbM8PndgduPp38SbYMKcFnesAFSXw7vX+ierNOE/4oP4MtgLlZ04ZmlOGZtyenwqLMODxeEhJSXHtCgDhQBmaO6gztCwYew+c+yzEJNVuD0zg9lXVXpm7EYH8oiMj+NXY7OD2X7+1lM27ymHH6tAnhBQWdUYpfFWhV/uu+1je4qb2qGMtewuWvOafqL7x2yY/7aD+DLYC5WdOGZpThmbcnp87WyUhbNtm06ZNrl0BIBwoQ3PKsAF1T4favABqqmDrYijbWW/XuvlNOSGL04f5J4QX76nmhtcXU7P9h9AnlDQyYgGwu8794jqFxdYlLexIO6tbDO3Ob/LT9Bk0o/zMKUNzytCM2/NTYREGHMehrKzMtSsAhANlaE4ZNqBuYTH7cXi4Pzw/Bp45rt4XZqe8kJotS3BsG8uyeOSCEfTpFgvA0k1FLFw4N/S1y7aDr8Z/e9/CIlB02HZokZG31LxP7aGizsUBmzEvRJ9BM8rPnDI0pwzNuD0/FRYiIi2Vegh4o/23d+dB1W7/7dJ8mPE/tfvtWo/nmWPImv4zrCX/ACCpSyR/nXwEURF7fw0X7HMqlGP7iwsILR7q3i/bDnZN7fbiTQ2OlrhO3cKiek/HtUNERFqV6wuLLVu28LOf/Yzu3bvTpUsXDj30UBYsqF2BxXEc7rnnHtLT0+nSpQvjxo0jJycn5DUKCwuZPHkyiYmJJCcnM2XKFEpLS9u7KyLS2UREQf+Ta+936QpR/utUsOxN/2RqXzX8+yqsMv8F8QKFBcAhvZJ48NxD8Vgw0NpntSeoHZlobMRi3xWiIDzmWYQUFlrJSkSks3B1YbFr1y6OP/54IiMj+fjjj1m5ciWPPfYYXbt2De7z8MMP8+STT/Lss88yd+5c4uLiGD9+PBUVFcF9Jk+ezIoVK5gxYwYffPABs2bN4pprrumILrWIx+MhLS3NtRN1woEyNKcMG3Huc3DWE/Dz6XDbGhh3b+1jH90GX/wBNs+v3bZlEVTuDt6dNKo3/7xsEN2t2m0Blbu24Ng2Nbs2hT4QGLEobqCwCId5FiGnQpU3vt8+9Bk0o/zMKUNzytCM2/OL6OgG7M9DDz1EZmYmL730UnBbVlZW8LbjODz++OP8/ve/5+yzzwbg1VdfJTU1lXfffZeLL76YVatWMX36dObPn8+RR/pXcHnqqaeYOHEijz76KBkZGe3bqRawLIvk5OSObkZYU4bmlGEjYrvBqCtr7x/5C1j0KuQvg23f+//UYTk+2PBtyEX3RsXtCN4ucbqQaPlPD/rr+1+zck48f/OFni6UvzmXNKg/kgGQt8SwQ+2ghadC6TNoRvmZU4bmlKEZt+fn6sLivffeY/z48VxwwQV89dVX9OrVi+uvv56rr74agNzcXPLz8xk3blzwOUlJSYwePZo5c+Zw8cUXM2fOHJKTk4NFBcC4cePweDzMnTuXc889t977VlZWUllZuyZ9SUkJAD6fD5/PB/gPrMfjwbbtkAk0jW33eDxYltXo9sDr1t0O/tn/tm2zYcMG+vbtS0RERHB7XV6vF8dxQrYH2tLY9qa2vS361JTtrdmnmpoa1q9fT9++fYPtC/c+tfdxAli/fj19+vQJ+Z+ScO5Tmx2nCQ/hffmMkNe0+56AZ8M3/ju5s7AHnhbc39q+Kjh8XNjjaBILvgIgsnwb63NzIDrkpSjatoGy7bvpX7yZfVcyd7YugX3a2Cp9asH2Ro9TRXGw3XZVKc7e43Wg41RTUxP8XejxeNzVJ7d89vaz3XEcNm7cSJ8+fULWwA/nPrX3cQr8e9y/f//g64d7nwLa6zj5fL6Q7zSdoU/teZwsyyI3Nzfk3+K27lNzJoq7urBYt24dzzzzDLfccgu/+93vmD9/PjfddBNRUVFcccUV5Of7V11JTU0NeV5qamrwsfz8fHr27BnyeEREBN26dQvus68HH3yQadOm1du+du1a4uP9508nJSWRnp7Otm3bKC6u/d+3lJQUUlJS2LJlC2VltecOp6WlkZyczPr166mqqgpu7927N/Hx8axduzbkw5CVlUVERAQ5OTnYtk1hYSFVVVUMHjyYmpoacnNzg/t6PB4GDRpEWVkZmzfXXqE3KiqK/v37U1xcHNLXuLg4MjMzKSwspKCgILi9PftUV3Z2drv0KT8/n6qqquAa0J2hT+15nPr378+ePXvIyckJ/jIL9z613XHqRp9B5xC7+l0AylKPZvPIuxi0YSIWDqz7KqRPPXPm0W3vM+OzRsPewiLN2kW6VX8ydk8K+dkbi3kvbXPwl3h1TAqRFQVYxZuoLMond1ttjm47ToPrjFjs3rmNvL3H5UDHae3atcHfhREREa7qk3s+e433qWvXrlRVVbFlyxb27KkdKQrnPrX3cbJtm127dpGVlUV5eXmn6BO073HavXt38Oc4IyOjU/SpPY/TgAEDKCsrC/m3uK37FBsbS1NZjlvXq8If1JFHHsm339ZeQOmmm25i/vz5zJkzh2+//Zbjjz+erVu3kp6eHtznwgsvxLIs3nrrLR544AFeeeUVfvzxx5DX7tmzJ9OmTeO6666r974NjVgEDkxiYiLQvhWsz+djzZo1DBw4kMjIyOD2ujpjVd6afaquriYnJ4eBAwfi9Xo7RZ/a+zg5jkNOTg4DBgzA6/V2ij616XHaswvPu9fi2D7ss/+Kr0t3fM+cQJdd/t9F9m1rcLr4ywnP6+djrf3Cv/26OXieORaAbSnH8kPKaZz8w33sa1DFK3zW/TH6lC3zP++IK/AsegUA52f/wc4a0/p9ao3jVFOB98HaU1CdwT/BvvDV4P7Q+HGqrq4O/i70er3u6RMu++w1st22bdauXcuAAQOC7x/ufWrv4xT493jw4MHB9w33PgW013GqqakJ+U7TGfrUnscJYPXq1SH/Frd1n0pLS0lOTqa4uDj4Pbgxrh6xSE9PZ9iwYSHbhg4dyr///W/AXxUCbNu2LaSw2LZtGyNHjgzus3379pDXqKmpobCwMPj8fUVHRxMdHV1ve+Afsrrq/nI22b7v6+673ePxBL8QN7a/ZVnN2t5abW9pn5qyvTX7FMiw7vPCvU+tsb2pbff5fME27vtYuPZpf9uN+xSfAj/7FxbgBfD52J16VLCw8Gz4BobvPRWzYO//VEUn4ek5FCJioKaCVGsXqWnVELh2XmRccBWlntYuvKVbwQK6dMPT9zjYW1iUrV9A/MCxrd+n1ti+J3QVKKumvN577+847ftz7Io+NbHtTd3eHn1qzuuES5+as92kT4HX7Ex9Cmivz96+32nCvU/N2W7ap5b8W2za9sBxagp3Tinf6/jjj6830rB69Wr69u0L+IeP0tLS+Pzzz4OPl5SUMHfuXI491v8/fsceeyxFRUUsXLgwuM8XX3yBbduMHj26HXphzuPx0Lt370Y/AHJgytCcMjTj8XiIHT6hdkPuLP/flaX+608A9BgElgUJe/+jpCQvdEnZXkcEb2awk57s8t9J6gXpI4OPfTPrM1bllbRBL1pBxT7tauaqUPoMtpzyM6cMzSlDM27Pz52t2uvXv/413333HQ888ABr1qzh9ddf5/nnn+eGG24A/BXUzTffzP333897773H8uXLufzyy8nIyOCcc84B/CMcEyZM4Oqrr2bevHnMnj2bqVOncvHFF4fFilDg72d8fHyzKkYJpQzNKUMzlmXRZfCp4Nk7ULzOP4+CnXXOq00Z7P87UFhUFkPBmtrH6xQWh0duINLyD6lXxWVQ3XUAe4gBYDi5vLO4gaVo3aDuilAA1U0vLPQZNKP8zClDc8rQjNvzc3VhcdRRR/HOO+/wxhtvcMghh/CHP/yBxx9/nMmTJwf3uf3227nxxhu55pprOOqooygtLWX69OnExMQE93nttdcYMmQIY8eOZeLEiZxwwgk8//zzHdGlFvH5fKxevbreeXnSdMrQnDI04/P5WL1+C06vvSvUFa6F4s2wo84Vt1Oy/X8n1p7aGVw+1hvtv9L3Xmd1ry0cfihP4JXvNvG93QeATM8Ovs+pnfDnKhVFofebUVjoM2hG+ZlThuaUoRm35+fqORYAP/nJT/jJT37S6OOWZXHfffdx3331JzcGdOvWjddff70tmtduGpq8I82jDM0pQzO2beNknYS16Tv/hmVvw446p3v22GfEAmq/eCdmhGwf4qstSL7Kj+K5rTncYvfnKI9/e8S2ZRTvOY2kLpFt0pcW23fEohmnQoE+g6aUnzllaE4ZmnFzfq4esRAR6WycrJNr73w+DZa9WXs/ZZD/77qFRUBiL39xsVdESe3VuNdVJlFaWcP3dr/gtmxrI/NzC1ur2a3H4FQoERFxNxUWIiLtqdcoiIqvvz3tUOia5b+d2FBhkdFwwQHk0R2AHdF9gtuyrHy+W1f/GhgdToWFiEin5fpTocS/AkBWVpZrVwAIB8rQnDI0E8wvMgp+8mf47q8Qnwbph0HaYTBwLASybXDEIgOiYiEmqd6X862Ov7A4d+xJ8Jl/W5aVzxvhUFj4qsBXA94D/3Okz6AZ5WdOGZpThmbcnp8KizAREaFDZUoZmlOGZoL5HXah/09jGjsVCiAho96X8wH9sxmf0Z1zjhsKs7vBnkKyPHmszCuhuLyapFgXzbPYt7AA/6iFd/8XXQrQZ9CM8jOnDM0pQzNuzs+d5Y6EsG2bnJwcV0/WcTtlaE4ZmmlWfgkNXLwzML9i39OkYlN46eoTuevMYXg8FnQfCECGVUi0U8ncXJeNWjRWWDSBPoNmlJ85ZWhOGZpxe34qLERE3CayC3TpGrotUFgk7HP9naReofe7Dwje7GdtY47bTodqqLCoKqu/TUREwo4KCxERN9r3dKjAqVD7jlgk7q+wyOe7dS5bGarBEYs97d8OERFpdSosRETcqG5h4YmAuB71t0P9wqJbbWHR38pjVV4Ju8qq2qiRLWBwKpSIiLibe2d/SJDH4yE7O9u1KwCEA2VoThmaaXZ+dUcmEjJqV4xK3OdUqH3v751jAZBl5QFw05uLAaistrn+lAGMGdyzWW1vVZUl9bc18VQofQbNKD9zytCcMjTj9vzc2Sqpp6ampqObEPaUoTllaKZZ+dUdmahbPOw7sTupd+j9bv2DN/t58gH4OqeAr3MKmLe+kFveXkpFta/p7WhthqdC6TNoRvmZU4bmlKEZN+enwiIM2LZNbm6ua1cACAfK0JwyNNPs/BotLPYdsdjnVKjo+OBzB+4tLOoqLKvi3cVbmtaG1lZT1fBpT81YFUqfwZZTfuaUoTllaMbt+amwEBFxo7rFRN3bcT38cy4aeixg7+lQXSnh7SuG8cnNJ/H6VaODD784OxfHcVq7xQfW0GlQoFWhREQ6CRUWIiJu1O9ESOoDkbFwyHm12z0e/xW7AxoqLOqcDnV0YiGD0xI4bmAKR/b1L2G7elspX+cUtFXLG1f3NCjLW3tbq0KJiHQKKizChFsn6YQTZWhOGZppVn7R8XDTIrhtNfQaFfpY1kn+v/scBxHR9Z9bZwI3O9f6/y7byV19V5FIKeAftWh3FUW1t+vOFalu+oiFPoNmlJ85ZWhOGZpxc35aFSoMeL1eBg0a1NHNCGvK0JwyNNOi/LyR/j/7+smf4dDzofeRDT+vzrUs2LkWbB+8ejaHb1vOM7GjmFx+K1/+uIM123czsGdC89pkou6IRUI6lOyd61HVtDkW+gyaUX7mlKE5ZWjG7fm5t+SRIMdxKC0t7ZhzojsJZWhOGZpp1fwiY2DgWIhJavjxkBGLNbB6OmxbDsBx9iJS8H/Bf/yzHHbsrjRvT1OFFBZ1RyyadiqUPoNmlJ85ZWhOGZpxe34qLMKAbdts3rzZtSsAhANlaE4ZmmnX/Lr2A2vvr/fCtTDnr8GHLBzGRy0D4INleRz1x88Y/+dZPPfVWnx2G/9DVbewqDs3pImnQukzaEb5mVOG5pShGbfnp8JCRKSziYiGpEz/7fzlsOGbkIevSPkx5P6P23bz4Mc/8Phnq9u2XfueChXQxFOhRETE3VRYiIh0RoHToez6F1LKLp3HG784nOvHDGBEZjKW5d/+1BdrmP59/WtftJrGCosmXsdCRETcTYVFGLAsi6ioKKzAv/7SbMrQnDI00+751Z3ADRCTDEN/6m9LVSnHen/g9glD+O8Nx3PXxKHB3W59ewlrtu9umzY1OseiaYWFPoNmlJ85ZWhOGZpxe34qLMKAx+Ohf//+rl5ezO2UoTllaKbd86s7gRtg1JWh18NY/Unw5pQTsvjpCP+ch7IqH9e8upCSiurWb1OjcyyaNnlbn0Ezys+cMjSnDM24PT93tkpCOI5DUVGRa1cACAfK0JwyNNPu+XWrM2JheeHoa2DAqbVX7f7xY9jbFsuyeGjSYQxNTwRgXUEZv35zCXZrT+auqHPl7diU2rY08crb+gyaUX7mlKE5ZWjG7fmpsAgDtm2Tn5/v2hUAwoEyNKcMzbR7fmmH1F7d+pDzIKmXf3navsf5txVtgILaydpdorw8f9kokmP91834/IftPPF5Tu3rbVsJ790E60MngjdL3RGLmESIjPPfbsqpULYPe83n7MyZr89gC+ln2JwyNKcMzbg9PxUWIiKdUUIanP9/cOxUmPhI7fZBE2pvr54e8pTMbrE8dcnhePaeuvvE5znMWLnNf+f9X8GiV+Afk2DX+qa1oXgLLHgJdu99jUBhERnnv/BfVKz/flNOhVr8D7yvTaLfJ5fDnqKmvb+IiLQrFRYiIp3V8HNh/B+hS9fabSGFxSf1nnJido//b+++w6Mq0wYO/85MekI6KUDoEHqXIghSFBA7dlSwF+yry+ra+6e7uusullUUCzYUG2KhC9JL6DWEngSSkF5nzvn+eJMpaSSckMzAc19Xrpw2M+95cmZynnkb08Z1caw//FUSyYdT4cg6tcFWDL8+UbfX//pmmPsQzLldrVckFhUT+/kGqt91aQp1YAUAVlshHN9Rt9cXQgjRqCSx8AKaphEcHOyxIwB4A4mheRJDczwmflEdIKqTWj64ErJSqhxy5/D2TOilhoPNL7Hx2odfgOFS7b7rZ9gzv/bXKSuGI+vVcsoyKMyqJrGoR1OofOcwuFpx9smPF1V4zDXoxSSG5kkMzfH0+Eli4QUsFgsJCQkeOwKAN5AYmicxNMej4tfzavXb0GHJq1V2a5rG61f1olt5Z+5OJdurPscvfwVbSc2vcSIFqOhcaEDKUucM2xWJRUVTKHsp2KvOt+Em/5hj0SKJxSnxqGvQS0kMzZMYmuPp8fPMUgk3uq6TkZHhsR11vIHE0DyJoTkeFb/B9zibR23+Co5VbVoU5OfDF3cOZmjHKPpbnJ28MwLaqIWsfbDirZpfIzPZfX3HXOdygEpYHE2h4OS1FvnpjkW98ETtx4pqedQ16KUkhuZJDM3x9PhJYuEFDMMgIyPDY4cW8wYSQ/MkhuZ4VPwCQmHYI+UrBix6sdrDwgJ9mTllAIN9VZJw3AhlUs492Mr/dRh//JOs1BT2ZxRQXGZ3f3DmXvd11/4clZtCQe2Jha0UCjOd60WSWJwKj7oGvZTE0DyJoTmeHj9JLIQQ4mw08A5opvpRsHOusz9EJb4nkgnU8wHYZHRml9GaT2wXAqDZivht+sOc/48lnPPSAn7dmup8YFalGotSl9m8KzeFgtoTi4Lj7uvSFEoIITySJBZCCHE28g2E4Y851xe+UP1xh1Y7FvsPG8vY7rH823YluYZKCq6xLqGDdoS8Yhv3ztrAV2sPqoMz99X82pVHhQIorSWxcGkGBUiNhRBCeChJLLyApmmEhYV57AgA3kBiaJ7E0ByPjF/fmyCirVretxh2/lz1GJfEIiLxPN67aQDv3D6aBZHXAWDVDF4K/QEA3YBp327h3aXJVZtCuapvU6hKiYXmOtGeqDOPvAa9jMTQPImhOZ4eP0ksvIDFYiE+Pt5jRwDwBhJD8ySG5nhk/Hz8YNRTzvUfH3AbfQmAQ2vUb4sPtOgDwLkdo7nynhchOAaAwSXLebKvc5K7t35Jcg4PG9cTLL7uz1nfplCVEwupsTglHnkNehmJoXkSQ3M8PX6eWSrhRtd1UlNTPXYEAG8gMTRPYmiOx8avx0RInKCWCzNUclHRKbAwCzLKR4SK7+3edMkvGEb81bF6W/HHPHZhZwDaas45J4y4ntDqHPfXrHdTKPdkx5A+FqfEY69BLyIxNE9iaI6nx08SCy9gGAY5OTkeOwKAN5AYmicxNMdj46dpcMm/Ibi5Wt/9C2z4RC0fXuc8LmFQ1cf2nwIR7dTTpPzB1HZpPHdpd9q5JBbLMsMw2g5zf1x9m0LlpbmvS43FKfHYa9CLSAzNkxia4+nxk8RCCCHOdiHN4dL/ONd/fRw2fQn7/3BuSxhY9XFWXxgxzbm+cy6Tz23L7d2c36R9kezH9zkd3R9nsikUxTngod/WCSHE2UwSCyGEEJA4HvpNVstlBfDdXbDCJdloVU1iAdDlItCsajl5EQB9g7Mcu/cbcTy1PhDDJ8D5mIBw9dvXJbGox6hQmqFDSW5tZyOEEKIJSGLhBTRNIzo62mNHAPAGEkPzJIbmeEX8xr4M7c+vuj20FYS1rP4xAWHQaoBaztgNOYfdRoTab8SSb7NyILiX2qBZIChKLbsmFmUFNZerco0FSHOoU+AV16CHkxiaJzE0x9PjJ4mFF7BYLERHR3vsCADeQGJonsTQHK+In38I3PQ93PobdLtMJQEAXS+u/XHtRzqXkxc7Jsezh8Rjs6oO2n/NvhJbq8Ew+mkIDFfHunbeLisfVSp1M/z5b8gvnxTPMKqOVAUySd4p8Ipr0MNJDM2TGJrj6fHzzFIJN7quc+jQIY8dAcAbSAzNkxia4zXx0zRoPRiu+QQe2qISjQtfqv0xHUY5l7d9B4WZAFijO3Jl31YArClpzf86TodhDzuP9XPpvF1aCHYbzLoa5j8Nv/5NbS/OAVtx1deUGot685pr0INJDM2TGJrj6fGTxMILGIZBQUGBx44A4A0khuZJDM3xyviFtYIOI8HqU/txLfuDf6haTl7o3B7ZnrtGtKeixv7D5SkUl9nJKijlyzUHWXvUJWEoK4Dcw875Lw78qX5XV1sBUJRd79M523nlNehhJIbmSQzN8fT4neS/hRBCCHESVh9oNxx2znXfHtWR9s1DuKhHPD9vSSUjv5RJH6xmy5EcSm067bRUFvuXH1tWBFn7nI/NS1XzaLj0rzACI9GKyjuGS42FEEJ4HKmxEEIIYV6HkVW3RXUA4J7zOzg2rT9wglKbqsIvNPydx5YWuCcWAOnb3DtuN090LksfCyGE8DiSWHgBi8VCXFycx3bU8QYSQ/Mkhuac8fFrX01iEakSih4twxiZ2NyxuVmAD22jgijCJbEoK4SsFPfHV0ksujiXpcai3s74a7ARSAxrYCuBldNhyzcnPVRiaI6nx0+aQnkBTdMIDw9v6mJ4NYmheRJDc874+EW2h/A2kH2gfIMGke0cu/91bV9mLN9Hi/BALu3TgqPZRVzyr8WO/cWF+QRUSSy2QlCkY1VzrbGQPhb1dsZfg41AYliDLbPhtyfUckw3iO1W46ESQ3M8PX6eme4IN7qus2/fPo8dAcAbSAzNkxiac8bHT9Pcm0OFJ4CPs0YiLMiXRy5M5LqBrQny86FjTDNuGtaJMkNNrnf0eCaHkre6P+ex7ZDnrLHQozo790mNRb2d8ddgI5AY1uDYDudyxu5aD5UYmuPp8ZPEwgsYhkFpaanHjgDgDSSG5kkMzTkr4uc67Gxkh5qPK/fA6E4Ua+XJR2kB0WWpbvuN9O2qE3fFerRLYlGcY6qoZ6Oz4ho8zSSGNXCtQSzJrfVQiaE5nh4/SSyEEEI0jPYjIbi8L4VrklGDEH8ffAPUXBattOMEaqVu+zVbERzZoFasftAsHt3ip9alxkIIz+E6mEJx7YmFOLNJHwshhBANIyAU7lgMmXvV8LN14B/UDIqP46fZHdtshgUfrbyavzRP/Q6JBU3D7heKpThDEgshPInr+1FqE89qUmPhBSwWC61atfLYEQC8gcTQPImhOWdN/MITVF8Li7VOh2u+wVW27Q3sVfXAkFgsFguW4PLO3NJ5u97OmmvwNJIY1sA1sThJUyiJoTmeHj/PLJVwo2kaISEhaBXT14p6kxiaJzE0R+JXA9/AKpv8elxa9biQWDRNwxocpdbLCsBWWvU4USO5Bs2TGNbArcai9sRCYmiOp8dPEgsvYLfb2b17N3a7/eQHi2pJDM2TGJoj8auBX1CVTe0GXeI+xwVASAx2u518u7MF7/wNu8gqkOSiruQaNE9iWIN6dN6WGJrj6fGTPhZewlOHFfMmEkPzJIbmSPyqUbkplGZFi2xHfmgnAnNdhp9tFgeAzbeZY9Or361k33cH6dUqnAu6xnDrsHYE+cm/tdrINWiexLCSsiKwFTnX69DHQmJojifHT2oshBBCNJ3KTaHCE8DqS1jb3m6bZ+8sJb/ExuYTfo5tYRRgGLDpUDb/+H03t3+8jjK75/7DFeKMVLm/00lqLMSZTRILIYQQTadyU6gINVu3Xwv3Dty/HzQY/vpS1mY4ayTGtvejS5yzBmNFciYvzN1++soqhKjKdahZkFGhznKSWHgBi8VCu3btPHYEAG8gMTRPYmiOxK8GlZtCRbZXv2O7u20+ZoSTU1RGDs7j7xoYxa8PDeerOwfja1UdGT9ZeYDPVh04rUX2VnINmicxrEbloZ9P0nlbYmiOp8fPM0slqvDxkXbDZkkMzZMYmiPxq0blplA1JBZRcQkA5BLi3Fh+QzOofRQvX9HTsfnZH7exIjmj4ct6BpBr0DyJYSWVE4uSXDjJrNASQ3M8OX6SWHgBXdfZs2ePR3fW8XQSQ/MkhuZI/GpQuSlUpGoKRVAkNIt3bH73rvG8fUNfJg1q6zzWpW331QMSuH2YeqxNN7h31gYOZBacpkJ7J7kGzZMYVqNyYqHbVIfuGkgMzfH0+EliIYQQounU1BQKoNvl6ne74fgFBDK2eyzNoyKd+yvd0Dx+UVdGdG4OQHZhGbd/vI684rLTUGghhEN1k1VKB+6zliQWQgghmk7lplARbZ3LY1+Cu/6ASd86Ntn9Qp37KyUWVovGf27oS4fmKlnZcyyfB79Mwq7X3iyDjZ/Bp1fAobWncgZCnN0q11iAdOA+i0liIYQQoun4udRYNGvhnmhYrBDfG3ycQ8zqrolF5dFogNAAXz6YfA5hgb4ALNp5jKd+2EpBia361y/Khp8eguRF8PuTp34eQpytqk0spMbibCWJhRewWCx06tTJY0cA8AYSQ/MkhuZI/Grg69LHwrUZVDUsFgvtu/V1bqjuhgZoFx3M25P6YbWokaI+X32Q815bzAfL9lFcVmm22v3LQC9vLnV0I9jO3Jm85Ro0T2JYjerehyU111hIDM3x9Ph5ZqlEFTZbDd+2iTqTGJonMTRH4lcN1xqKyLYnPdymg+FfXmtRXdvuckM7RvPS5T0cyUVWQSkv/ryDkf9YwtLdx50HJi92LttL4PiOehTe+8g1aJ7EsJJqag5PVmMhMTTHk+MniYUX0HWdlJQUjx0BwBtIDM2TGJoj8atBfG/wCVDLHcfUemhFDAkMVxtqqLGocN3A1sx/eDiX9m6BpvILUnOKmfzhGv7+3RbVPCp5kfuDjmw4hZPwDnINmicxrEa1NRY1JxYSQ3M8PX6SWAghhGg6wdEwdTXc+rtzFKiTCQhXv4uzTzpefvvmIbx1fV9+efA8hnWMdmyftfog17z6BZxIcTs+dceKqs2lhBA1kz4WwoUkFkIIIZpWRFtoPQhHtcLJBEao37pNfTP681/g3WFVaxsMQ20rzKJLXCif3jaQFy7vQaCvFYBepRurPPWJPavp8/zvvDxvB2V2z/xGUAiPUl2TRBkV6qwliYWX8NROOt5EYmiexNAciZ95FosFo6LGAmDh87D2A0jbAj/eD67NAxa/BO+PhBkXQlkxmqZx0+A2/PrQeYzuEsMo362OQwsNfwA6a4cwyor53x/7uGnGarIKzqzO3NVeg1kp8N4I+OY29/iJasn72IVudyYRmtW5/STzWEgMzfHk+HluyYSD1Wqlc+fOWK3Wkx8sqiUxNE9iaI7Ez7yKGFqCIpwb137gXE7fCrt/UctZKbD8X2o5cw/sc3bSbhMVzIyb+3FBwC61ISAcnx6XAeCj6fT2OQjAqn1ZXPrf5Ww9cmZ8+1rjNbjsn5CaBFu/gUOrmqRsDaq0AA6uAnvDd3CV93ElxTlAeXPEsFYu22tOLCSG5nh6/CSx8AKGYZCfn49xkrbEomYSQ/MkhuZI/MxzxDAgouaDlv6fagK1+CXnMLIAO+a6H3c0yTmaTbvh+LUd5Nj1j6F2mjdTNRiHTxRx8X+Wc827K/lq7UGvnsm72mvQMGDvAud6xu7GL1hDm3U1fDgWfnmswZ9a3seVuPaviGjjXK6lxkJiaI6nx08SCy+g6zqHDx/22BEAvIHE0DyJoTkSP/MqYmgEhLnvaNEX4nqp5dRN8Mc/YMts92N2zXP/Bnufy2hQHUZBi36O1dZFO/npvmH0buV8nTX7s5j27RaGvrqI5Xsyai1nic0zO39Xew2mb4O8VOd61r7GL1hDKs6FA3+q5cojfjUAeR9X4jrUbLhLYlFLjYXE0BxPj58kFkIIIbxLxXCzoCbYmzgDRkxzblv8onPZvzw5KMpyb+bjOn9Fh5EQ2x0sarZujmwgLiyAr+4awuPju9ChuXN28NxiG7d+vJbFO49VW7QPlu2j7/Pzufa9lZzwhv4Ze+e7r2cmN005GkrmHudyzhHpM3K6udZYNIsDq59als7bZy1JLIQQQngVI2EwaOX/vi56HaI6QOJFENvD/cDwNjDuFed6RXOoknw4tEYtR7RTo1L5+ENc+eMz90BxLgG+Vu4a0YEFj4zgh6lDOT+xOQClNp07P13H79vS3F7uvaXJvPjzDgpL7axOyeLmD9eQU6SaTu09lsd1/1vJ4JcXcu+s9Xyycj97j+U1ZFhOzd6F7utZKdUf5y0y9jqX9TIoOF7zscI81xGhAiOhYvLKWmbeFmc2SSy8gKZp+Pn5odV1KEZRhcTQPImhORI/8xwxbJ4Id/8Jdy6BvjeqnRYLDH/U/QGjnoKuFztrInbOVX0K/njN2f+iwyjn8S7NoUhNcnvd3gnhvH/zACb0jAegzG5w76wNPPJ1Eot3HePdpcm88stOt5ffciSHKR+t4d2lyVz01nJW7csiLbeYeVvSePqHbYx54w/enN94fRqqXIPFuXBwpftBWfu851t+WwnYKtUKudZYAOQcbtCXlPdxJa41FoEREFCeWNTSFEpiaI6nx08SCy9gsVho3769Rw8v5ukkhuZJDM2R+JnnFsPYbqpvhauul0F8H7XccgD0mAgBYdBuuNqWc0iNIrXiP+VP6AsD73A+3vX5qpmB29dq4d/X9eHKvi0BsOkGczYc4ZaP1vKqS1Jxy9C2RAWrJiE7D6bx5i+bKbWpm3VLpXuBd5cmczyvpH6BOEVVrsGUpWouEFe2IshPq/pgT5OVAv/oDG92gzyX8mZUTiwONejL1vt9bBiqdszbm5jVxK3GItylxiKvxskr5bPQHE+Pn2eWqgavvvoqmqbx0EMPObYVFxczdepUoqKiCAkJYeLEiaSnp7s97uDBg0yYMIGgoCBiYmJ47LHHsNkafhi608UwDLKzsz12BABvIDE0T2JojsTPvJPG0GKBm76Dqz5Svyv+8XaZ4Dxm3qNglH8jP/JxiOnq3NfSpcbiqEtioetwYAX89nd8lr3GPyZ2Z+rIDjTz96lShMfGJvLMJd357PZBDAo8zGr/qSz1f5gWWia3DWvHlmfHMvf+YUzopWo+Smw6HyxvnA7TVeLnOhpUVCfnsjfcBG/+WnUcLjgO275zbs/c635c7pEGfdl6v493/AQzLoB3hjZ47YlHqKnGwrCrYX+rIZ+F5nh6/LwmsVi7di3vvfcevXr1ctv+8MMP89NPPzF79myWLl3K0aNHufLKKx377XY7EyZMoLS0lBUrVvDxxx8zc+ZMnn766cY+hVOm6zppaWkeOwKAN5AYmicxNEfiZ16dYhgUCT2udN7gQHliUamqoGV/OPdB923RiaozOMD2H+GtfvDFDfBmd/hoPKz8Lyx5Bcvqd3hsbBfWPjmG/93Un0t7t6B9dDDPXNKNqSM7AtA1PpT/tV1MqFZEnHaCb/pt4amLuxHs70OPlmE8fXE3/KzqX/BnKw+QXVh9R++tR3JYvS+zQW4i3OJnGLCnPLGw+kO/m50HesPIUKmbnMtHy2dQ1/WqSVED38zX+328q3xeFVvRaRmlqslVTiz8Xd53NQw5K5+F5nh6/LwiscjPz2fSpEm8//77REQ4xy/PyclhxowZvPHGG4waNYr+/fvz0UcfsWLFClatUqN//P7772zfvp3PPvuMPn36MH78eF544QWmT59OaakXjNghhBDCnGZx0Ooc57rVHy5/F6yVahysPtB6SPmKAVnJsOtnyDvqftz6j8AwCPC1cmH3ON66vi+LHj2fW4a2cx6Tf4ywA84Rl1oc+MFtuNvY0ACuHqAmFCsotTNzxX63lzAMgzfn7+be/37L39//htd+23WqZ1+947sgt/ymu+1QNSpWhSwvqLFw6QPD0fLl3MPqBt5VU9cSpG1xLlfTvM7ruQ43GxgBAeEu+xq5A3dZMRRmNe5riiq8IrGYOnUqEyZMYMyYMW7b169fT1lZmdv2Ll260Lp1a1auVB3SVq5cSc+ePYmNjXUcM3bsWHJzc9m2bVvjnIAQQoim1WOic3n0U9C8c/XHXfwmDLhNdeT2CVDbLL7QeZxz1KmsfbB/We2vlzTLvf9Cfrp70yPg7hEdsJZ3uvjoz/3kl6jj7brB37/fytrF3zHf7zF+85vG3j++YvriSs18zHAdZrbjGDWyVgVPr7HIP+7exCljt2rTX7l/BTRtYmErheMuHforalbOJK41FgHh7jWFtXTgbvhyZMO/e8PrHVWzRdFkqjYQ9TBffvklGzZsYO3atVX2paWl4efnR3h4uNv22NhY0tLSHMe4JhUV+yv2VaekpISSEmdnutxc9eaw2+3Y7WriI03TsFgs6LruVkVd03aLxYKmaTVur3he1+2gqrx0XScwMBBd1922u7JarRiG4ba9oiw1ba9r2U/HOdVle0Oek2EYjhieKefU2H8ngKCgoDPqnBrz71TxPq445kw4p5NtPx3n5Po+rtc5DbgVS2k+un8zjP63Qk2f5aGtYPzraruho5/YjxEYBQGhaFu/xfKd6uxtrJ+J3npo9edk6FjWf1y58RXGhk/RO17gOL5VRCCX9o7nu41HySsq4fFvN5MY14x1+0+wbfdu5vn/F39NJRvP+n7MmN964G/VuHpAKwzDwMdqISTAr85/D8MwCA4OxijJx3Apn9FxDFpoKwyLL5pehpGZjG63e+61d3QjVvfIoh9NguO7q3xbauQcRncpv9lzqrgGNU07+Tml78DqMvu7kb4NvaRQDW1c13P18M8Io+gEGmD4BqNrVix+zRzXlb3oRLXvs8r3NA1yTsmL0coHHdA3zsJoNeiUz8kTP/dcaZpW5X/x6T6n+jTF9OjE4tChQzz44IPMnz+fgICARnvdV155heeee67K9uTkZEJCQgAICwsjPj6e9PR0cnKc1X3R0dFER0dz5MgRCgqcHZfi4uIIDw9n//79bk2wWrVqRUhICMnJyW4XQ7t27fDx8WHPHuc3MMnJyXTq1AmbzUZKinOscYvFQufOnSkoKODwYee3M35+frRv356cnBy3JCo4OJiEhASysrLIyHDOINsU5wQ0yjkdP36coqIikpOTz5hzaoq/U2xsrCOGZ8o5NfbfKTs7+4w7p8b+OyUnJ5/aOQ1/lKyMDDL2Oq/hk55TkT8FGelAOppPFzoFRGApPgHbfyS5013o5RPwuZ5TQOoaWp9QZdVbD0XLSlY3Pbt/Yd+W1dgDIh3ndFEbKy02f8/9Pt+xdkciz2yZwn4jjs98p9Ncc37j21LL5G6fn3hxXgAvzlPfgmvAyC4x3HtuHCF6edwNnfijvxEWFUt6zAhycvPczikhIYGCWZMJLh+WtSiyKyU+MYRbfSgLaYlf7n6MzGT27N5Nq4QEz7j2DIOw8HDH38m6dRExuMvZ+Qdk7aOisbRh9UOzl6IVHGPvzm0Y5RO3NdT7yWKxkJ+fX+s5haYsoIXLc2l6GYfW/UpxVDfAc95PFed0Kn8noyATDbD5hpC8Zw8tyjQq6izS9u8mz2hb4zklJyc32Dl1Pr7TkdCU7l/D/j17zrjPPde/U2RkpNv/4tN9TkFBQdSVZnhqt3Lg+++/54orrsBqdX43YbfbHRnVb7/9xpgxYzhx4oRbrUWbNm146KGHePjhh3n66af58ccfSUpKcuxPSUmhffv2bNiwgb59Kw1XSPU1FhV/mNBQ9ZZp7BqLEydOEBERgY+Pj2O7qzMxK2/Ic7LZbGRlZREREeEon7efU1PUWGRlZREeHu44xtvPqbFrLE6cOEFkZCQ+Pj5nxDmdbHtDn5PNZnN8FloslqY5pwVPo638ryrnBS9iDL63yjlp396GZbsaqci4aiakJqH9+S+3x1Sck7HiP1jmP+V4/hLDhzV6F86zblX7g2Og6ASaXkaJ4cuY0tc4ZLjXwvtYNCaf24bx3eOI3DmL9qvV8xm9b0C/+F9gUf83DMOgaNWHNFvwmFr3DUa/fRGWmET1Dfysq9H2/A6A/cGtWMJbkV9i4+iJQjrGhNT579SQ15628r9oS/8PhtyHNuoJdF1Hmz0ZbcePbq9h9LgKCo6jpSxV623PQytvrmafuh4i21X5O9VUdm3bHLRl/8QYfA9aead21xqLEydOEB0d7bi2azon7fe/Y1n9jtvr6ONfxxhwW7XnWlMMXMvoUZ8RmobxYiyavQQjtgf6nX+gJc3C8tP96vkvegOj/5Qq52S3293uaRrknObcjrZtDgCGxQd92kHwCTgjPveqq7HIzMx0+198us8pPz+f8PBwcnJyHPfBNfHoGovRo0ezZcsWt2233HILXbp0Ydq0aSQkJODr68vChQuZOFG1n921axcHDx5kyBDVAW/IkCG89NJLHDt2jJgY9R3H/PnzCQ0NpVu3btW+rr+/P/7+/lW2W61WtyQHnH/4yuq7vfLzVt6elZVFVFQUmqbVeLymafXa3lBlP9Vzqsv2hjonTdMcMXR9nDefU2P/nex2O5mZmURGRlbZ563nVNv203FOFddgXY8/WRnru93b/04Wi6XK+7jRz6nfZDU6FGDZ+Cmce58aYSlfDXNuLS1QHb4BgqLRukxQM3qXJxaWpFnqMZoGG2ehuSQVAP6azZFUoFnQrvlYjSy04i38tTLeDPuaN6OfxaJp7E7PIz23BJtuMGP5fmYsT+F3v3epaA+kbfocrbQAy8QPwMcP+9HNBC92vp52yb+wxnZxrkd1hPLEwppzgBz/OC6bvpz9mYU8ckFnHhjtMiQtjXDt6TosfwPKCtTvwXdjCYp0jgjlG6T6sdhL0VKTVOddgIBwtPjejn4w1vxUaN6xbmXPOwo/3ge2YrRf/go9rwK/YLfjK67BiuS2xnNK31r1vFI3QRPdR9Rle73+TqWFaHb1JawWGKH2B4Y7y1maW+25GoZR5Z7G9DllOCea1HQb1uM7oVX/+p9TLWXxlL/TqfwvNlv2ir9TXXh0YtGsWTN69Ojhti04OJioqCjH9ttuu41HHnmEyMhIQkNDuf/++xkyZAiDBw8G4MILL6Rbt27cdNNNvPbaa6SlpfHkk08yderUapMHIYQQokbNO0OboXDgT8jYBe+epzo7l1UzZn+fG8DHD6I7QcIgOLQaju+AL28AvxDY+q3z2OGPgb1MTd5nlH+jOepJaHOu6jS++SvIT2dA8UpmnZ8PHcdQWGrj3SXJvPfHPkpsOoO0nXS2uM/bYNnxA/nTd2MvyiOs2NkcZH/riUR2vgK37x4j2zuXM5N5cW0z9mcWAvDWwj1c2D2WLnG1f1vZoDL3OEcd0svUzOldL4HsA2pbXE8Vs6Mb3OeviO4EYQnO9Zo6cBuGSkysvs5tC58DW3mCYiuGvQuh26X1L7thOBOLoCg1QpJuc58fxdu5DTUbrn43Redt3V61437qRkdiIRqXV4wKVZs333yTiy++mIkTJzJ8+HDi4uKYM2eOY7/VamXu3LlYrVaGDBnCjTfeyM0338zzzz/fhKUWQgjhtfpNdi6nb6k+qUBzP67vjc7lXfNgy9fOBGLQ3TDy73DBc3DnEugzSSUVQx9W+wNC4QKX/1m/Pw26TpCfD49cmMiCR0bwwKiOPBXnHA3nc/toigzVryDkxA63pGKnnsC43RfT/4X53PXpOpbsOoauG26JxcHkrcxe73yMTTd4fM4WdVy543kl2OyncSz9g6vc17d8A6mbnevxfarOvg5qsr+wVs713EqJha5D0udqfpJ/dIad5TVMh9fBltnux+6ce2plzz3ivPFu0c85EePxnTVOHOd1Kg81C3Wax6LBndgP9kqz15+JI3B5CY+usajOkiVL3NYDAgKYPn0606dPr/Exbdq0Yd68eae5ZKePpmmEhYXVqypKuJMYmicxNEfiZ57HxLDbpappzvGdgAYRbdW35FY/9e0pBnS7HKJdmt/0uArWfwxH1rk/V+8bYOwrqmkUQHwvuPztqq/Z61pY/Z76xvvYNtj6DfS6BoCEyCAeGRIOq1T/AoKi6Xr12/z1q294qeglQrVCSgxfNhnt2UhX3i69iGL8wW7w27Z0ftuWTsvwQO7qaeHm8pdL3rkZOB+AEH8f8ktsbDyYzedrDjK+RxzPz93OD0lHaRkeyD+v6c3g9lENEVl3h9a4r+9fpmopKsT3diZnrqI7QlhL57prjcWR9TDvr+5/h69uhPGvqdm8K9v9q6oVKa/VqPM16Dp/RVxPKGyhthm6So7aDKn5sd6i8lCzAAFhzm011Fg0+Pv4eDVzvBzdVHXbGcJjPgdr4HWJxdnIYrEQHx/f1MXwahJD8ySG5kj8zPOYGPoGwh2LIfsghCeAX/DJH+MXBLcvUN/ylhZASb5KJqI7O5OK2mgajHkGPrlMrS9+SSUvPqpWgo2fOOfN6HczfdvF8erDd/P+r/3JPXaAtl36cX63VtweEUi/gyeYtyWVnzencixPfdN7JLuI55bZuc7fip9mJ86mJgUc2jGKqSM7csP7qwH4v1928sb83WQVlDoed/37q7hnRAceGtMZP58GbAhxaLX7uqHD2g+c6/G9gWrGn4nqWH1TqAMrYObFVZMRQ4d5jzrXoxMhthts+041Ydq/DDqMAupxDaa59K+I66Fusjd8rNaPbjzzEot61Fg0+PvYda6QCse2Q1mReq+eYTzmc7AGXt8U6myg6zqpqanVjtIj6kZiaJ7E0ByJn3keFUO/IIjpUrekooKmqRuwsFbqsc0T65ZUVGh/PrQboZZP7FfJBKhaknUzK14EykfiCfb34aHLhvD0Hddx83mdaRURwLH0NPq3DueZS7rz599G8d5N/Tk/sTmaBnasHDLUICdttHQCfS28emUvzu0QzVX9VdOivBKbI6momNzPMODtJclc+c6frD/gvNlMzy3m2a/+5K//9yaz1+yr+3kCFGSqPhYAIS6jYFX0f7D6q/g176KWXUV1Uv0aKiY4zCnvd7LqbWdSEZ0IN86BoQ9Vfe2x5UlbhR0/ORbrfA2muTTZiusFLfs518+UfhbVJRZufSyqn3m7wd/HLh23ieulfht2SD8zJ0H2qM/Bakhi4QUMwyAnJ6deE5QIdxJD8ySG5kj8zJMYAqOfcS4vfU01A1n8krMfQeexENGm2odWjp+v1cLY7nHMvGUgy/46kgdGdSTVqmZeCNJKeGFUFAmRavz6Jy7qSkSQs5PzhJ7xrPzbKP42vgs+5QnG1iO5THxnBVNnbVCdvf+xgOu23cVrRc8S/NNdfLpyv+Pxv25NY8wbS7nxg9UcyKymz8Fhl0lxe14NMZVGcYzroZonWX3dm0ehqb4imgah5c2hcg6DrQSSF6v1oCi4ezl0HK36tVz0D/U4ULOQd7pA/a5IWHbOU/0yqolhjSqaQvkGqfLEdHM+35nS/r8o27lckVj4+DsTuhqaQjX4+9hRY6Gpa6XCmRLnSjz9c1CaQgkhhBDeolV/NTLSjp/UELfTB7rvL58jod5PGxHEIxcmotvOgTXrAbgq63/w1Vug24kc8yyf3zGYz1cfZETn5owJ2Q+fjeTuZvGMm3A9d6+OYuexIgB+3pLKz1tSmWz9nS6+hwC4yLqGm3/6nBLbdexOz+PrdSoR2nssnwlvLefViT25uJfLdHKHXDpuJwxUow4t2u7cFt/budyir7PPRHhr8C2/sQ1rCVnJUJqnOmiX5qvtncY6m5ABDLxDjbx14E8453a1zT9ENX/a/Qvkp6nnT6gU65qU5EH5BInEdAOLFbCqBOjIOjWCVVG229Cs9WIY9avpOl2qGxUKVHMoW3HjdN42DDheXmMR0RZauzQxO5p0+l9fVCE1FkIIIYQ3GfUUaNX8++54gfoW3gRLVAfnypbZKoHZNQ++upGuzf154fIejOkQDN/cqtqxJy+k7fzb+cXyILP7biY6SH1fGUwR9/t85/bcT/p8xis/b3UkFRXyS2zc9/lGHvk6iR+SjrD9aC76QZf+FQmDoPuV7gWN741dNygstUGLPs7t0S5zbbj2s1g7w7nceWzVE28zBIY/6n6D3PVi57JLc6iTcm2C41qb4jqCVWpS3Z+vgq0UPr0SXu8I23+o/+MbWnVNocDZHKoxhpvNOewcla15oqrJ0srncThDayw8nSQWXkDTNMcsn+LUSAzNkxiaI/EzT2JYrnkijHwCfALVzeqoJ+He1TBpdvm349WrU/zanVd90pKxG5b9Uy0veaXKEK5a9kHO2fEqK3rN5eHRHXmz9XKiNfcby86WI1xvXQRAsJ+Vl6/oyWV9nLUUczYc4cEvk7j0rcWUHlBNoTJ94/l0WwkHiVfDtpb7ZH8Y3Z7+lR7P/MYDfwZglDdlOhzUlaW7j/PH7uOUBLt0cD2wXP22+Do6YgO1NyfpPN55k7pzLhhG3WJYeUSoCq79LHb/XvPja7L9e0heCIUZMPuW+iU7p0NNiUVFB+6SXEcTMlcN+j7OcBkRqnmi6qztNrRvofnX8DCe/jkoTaG8gMViITo6uqmL4dUkhuZJDM2R+JknMXQx/DH1Uw91il9MV7j1dzWkbXhrtW3W1WrEqWVvqBGXVr2jtvsEwIQ3YNsc2LsAAL+kT3iwVwlkl88NYfGBy6bDd3cB8Befb0hNuJhnrj6X1lFBXD8wgXM7RPHMj9soLlM3od20AwRoZQD8Udyep75XIyzdGnMJj1u2scFI5Jm1Phio4388HIhuuY9EyyHeX9OL3DVqmNpJPrm8VPkup+0wcvRAvv5jH7NWHyC/xM4Ng1pz85A2RIdU6gQeHKUmKNy/TE2CmLwQS8cxJ4+hW8dtl8Siw2jVz8JeAutmwJCp7sPinsya953Lhl0lF9d+Conj6/4cDcVucw4HrFkgyCUmjg7chmp+5tqhmwZ+H7sONRudqH7H91GTExp29buuTdia2qE1sOET1TTPtalfJZ7+OSg1Fl5A13UOHTrksSMAeAOJoXkSQ3MkfuZJDM2pc/wSzlEjS3UYpX4qRk7Sy2DOHc6RlYY/Cn0nwY3fwsQZzpqOzV85+zP0mwy9r3N0qo3Q8pihP0XrH6+GDy5A++Qyrj3wHEkDFzFv6F7+fkEbbm2d7ijKer2zY/nDY4l0LXyfa4umYWDBz2qhXbQalWuuPoR/2q4hF+coXQf1yCqnNjOjC4NfWchL83awP7OQjPwS3lq4h3NfXcTjc7aw/Wil5jvlI2wB8PvT6LYyZwwPr4dNX6qb7AqFWbCtvJmSxce903mzWBh0p1q2FcPS/6vxT1DF0SQ4vMb5vKD+Hl/frGYHb2y7foY8NSQxncepUdIq+Nc+MlSDvo9dE4vmXdRv16Zxm75QCdmyf1adnduT6DrMngIbP1XN3UryaznUsz8HpcbCCxiGQUFBgceOAOANJIbmSQzNkfiZJzE055TjN/wx1Qwnc69zW3RnOPcB53rPq9TvOXeoeSFAjYg0YppaHvMs7JgLtiLVN6OSAKAb0C34P27NaiZddRXx2XHM25LKtqO52MpvWy7oFsvfL+pK2+hg9mcUsHDnMQ5mFuDvayXA18qJglJ2bT0ONvfX+eB4IkUu81hYLRp23aDUpvPFmoN8seYgvVuFce05rbm8bwuCul8JK/+r2usf2wabPqcgeBDGjrnwzWR1rinL4PLySXqX/RNKym+me12nOoG7GvaImiixJBc2fgbn3u/eL6Qma11qK8a9qub42DIb7KXww33wYJIakamxuNaeDLzDfZ/rJHnVdOBu0PexW2JRnoS69mVZ96Fzef1MeCCp1uaCTSZ1o5qtHVRTtzXvwXl/qfZQT/8clMRCCCGEEDXzDYBL3oKZFzm3Xfxm1RvZnlep0Yq+La/VGPaw+pYe1NwdFzwPv/6t+tmyKxQcVz8AfiF07T2ErhYrU0d2JCWjgKW7jtE1PpRBLjN9t40O5rZh7ao8lT6uDbz6oGN9LwkcNmII8rMysV8rJp/bliA/Kx8uT+GLNQcpKFXl2nQ4h02Ht/DWwj08dXE3LrrgBbSPVUfugl+fZ3XsgySmvuhMoJI+U3OMtB4Ea/6ntvkEqH4wlQVFwtAHYNGLKg6LXlSd8Td8DAdXQt8b3WtJQNWCbPlGLfuHQu/rof8tkH8MUpaqmoOkWTDg1prj2pDSt6vmYaDmDGl3vvv+Osy+3SAMwznUbGhL8G+mlmN7qJnAi7Pdj88+qEb+ajf89JXpVFXuc/Pnv9UIb6c6clgTksRCCCGEELVrOxRGPgnL/qFqKtoOq/64HhNVW/fsA5B4kfu+QXdCv5tUfw2rn+pIXZqvEonco6rfwTaXkaRaDXD7drlddDDtoqsmEDWxBDRzu8HsMPQq1gweTWiALwG+zud98uJuPDCmEz9sPMKXaw+xrbw5VFpuMVM/38CQ9lE84j+Yc0pW0awsg8mHn6ryWsbch8hr3o9Qe2n5ud5dc/+JQffA6v9BwTFVE7T9e+e+w2vVhIfnuAwbnDTLOTFgnxuctSBjnoH3yzuiL3sD+tzoPoxubew22PoN7PpFjSTWZ1L13+QbhppY8MgGlSjG9XCvPRl4B1gqtaqvw+zbDaLguDN5aJ7o3O4bANd/Adu+V7VfRSdUDQCobaeSWBzfDaHxzuTlZHRdDXgQ2a5uNUl7fnNfL85RNWWjnqx/WZuY9LHwAhaLhbi4OCyV37yiziSG5kkMzZH4mScxNMd0/EY8Bk+mw6i/135cXA/oMqH6uRZ8A9XNmY+/uiENCIWoDmo0qqtnwj0roPsVqm/CiL+dWjlduQw5qyWOI6ZZgFtSUSE0wJebhrTl5wfO46f7hnF+YnPHvpX7Mvlb7kRshnvcVlv7k9n+MvXcpfmEHvkDgDK/MBj2EAAFJTYW7zrGH7uPO2Ysxz+k9o73P//FWUNhK4W1Hzj3VcyzAdCyv5rIDyDnEGz+srZIKHYbbJwF089RHeq3fw8/3g/vjVBNuirb/Sv89oRKQt4fpb5J3/SV2ucXompPKnObfbtqYtFg72PHxHg4O25XaHMuXPQajHwcRj/tnLRvx48qcauPxS+reH0wBkorTeaYm6pGAXNtlpS1Dz4cC28Pgrf6qaGBa2u2lJfuHBo3rLVKuEENklCQUeVwT/8clBoLL6BpGuHh4U1dDK8mMTRPYmiOxM88iaE5XhG/2O4qwWgo7UdA+hbVsbfVOXV6SM9WYXw05Rzmb0/nuZ+2cyS7iGSjJfP8xnFp2TwANugdmVI8FW07zPVbTXtLmuPxrxVMYO+XqqPwn8mZlNqcnWxbhgfSMSaEMP/ePBrYjdZF20n1SeAnnwsILTvOdfafAEPd9G/9FvYvd37r335k1f4YI6Y5RuRi2T+h9w1g9VHf0vsEOicLBNUf4Ztb1UhJlaVvgY8vhl7XqlG8rL5QVqyarlWwl8D8p53rva+rMuITUKnzdrb7Pl1HS9tMeHTnuk/yt/xfKrlKGKgGA2h7nhp2d8FzzmOaJ9b4cPxD1GzqO35StRz1aQ51dCP88bpaPr4TVvwHzi+PSfp2lUCU5KrR0gbcpjqx//Z35+AFuYdVB/sOo1TfmOrKWfH3A+h1tZo8cd0M9RzL34SxL7kd7unvY83w1N4fHiQ3N5ewsDBycnIIDa3mTXSa6brO/v37adu2rcdmqJ5OYmiexNAciZ95EkNzzsr42W3qRjK2hxo+tp6KSu38vj2NluGB9I/V4KeHycjJ5/bsm9mUqWo+umspfOf3DH6ajSNGFKNK/kkJJ2+S5EcZEeSRTgSgAQYv+8zgBp9F1T9g0jfqBrmyTy6DfUvUcvcrIDNZDXnrG6RqFAbfozp7z3sMylzmdWg3XO1f9Y77ELl9JqnkYtk/YdELaltInJqB3NW9qyGmS9Xy7JgLX01Sy/1uVv1zNE31Ffnieji0CltgNJYLnsPS54aqTalc7V0An01031bRvMlBg3tXOuevqM6Wb+Db8uZlA26Di9+o+dgKdht8MApSNzm3+QTC/eshJEbV4LjGrTL/0KpNwdqNUH1hukxQyRuoxKNiwsNbf1fDPL/VRzV/8wmAh7ZCiLMGrSnex/W5D5YaCy9gGAalpaUeOwKAN5AYmicxNEfiZ57E0JyzMn5WH1VrcYoC/axc1sfZV8I+cQaZe/Ywo2Ub/jZnK7vT8xnd5wIK4zvhu3cOuyKuJXyFTnpuCQDxYQGM7hqDn9XK1iM5bDua4+gkXoov6aghcf2s6gbxSdutNNMKucS6CoATRgiL9T78ZB/Ckbl+jEzcwYjOzeneMoywwPIb0xHTnImFax+VskL1zfc6l1nHAZp3VZ3v2wxR672uVSNUzXtM1UokzVJN1TaVN63SLHDTHMg+BD/cC4WZavLA6pIKKL/BV4kSGz5RzYCGPgifXwtZyQD4FGXAj1Nh3Qcw9mXVdKmyomz44f5qtrskFXE91aAAtSUVoIbE9QlQN+s7foSLXj/56FCr33UmFZpVdba3FcHC5yGirTOp8GsGpXnuj+17o6qh2LcEfn1cNVUD1dk+Zalqonf9l6oGI3mx2hcY4exXNOBW1bfFVqxGtjp/muOpPf19LImFEEIIIUQ9RAT58cFk16ZVidBzLKOARUNUv4o2kcH0aBnqNkOyrhvkFJWRX2KjoNRGmc0gLiyAqGA/jmQX8ficLTy49z6+tZ9HnhHERqMTekV32PR8dqfn894f+wBnsyqbbuGvvr3pXebyzXpsT9XWv6xSn4B+k9UNr+u8ExYr9J+sRnOaPQUw3IdpPed21UQttjvct05N5FZT531QfWbGPAMLnlXrGz9VyUr5KFqGbzBaRbmOboSPxqumQuc/oeZQqfDLNOdcGe1HqtqP9TPVjXl0ouo/0fWy2ms8KtS3OdSJA7C4ogmSppKAOXeopl2bv3TOyG7xgSk/qZqM9R9B+jYYeCd0u1Tt73qJOre1M9T+LPW3I+eQqmk6/2/OWo2OY5zJzqC7VWJj6KoZ2LCHGnc4YRMksRBCCCGEaCDB/j5c3KtFtfssFo2IYD8igqs2lUqIDOLT2wYye/1hPlgWSolNZ2BYAHGhARzIKiTpULZbH+Aj2UUcyS4CYAr3MMXnd44bYSw2BjCseS9uujCMTke+x3/jh6rT8fj/U6N21aT75ZD3Kvzq/HacwEg4/3HnelAkJI47eRCGPay+lf/+XlULUjE0b3Qi+vVfc2TrchK2TUermNMkeZH6aX0utOynahcqOqP7h8Fl/1VDFve4Up2Lb1Dd+2hU6Ha5SixAdUDXrCqxCQh1HxXLVgI/THU2Gzvnduh8oUoCKvqcOCaJfMw5b8b4GiY89AtWQwwPuU8lRQufU69bmAHzHnUe12msczmijUpKtv+gRg/b+q0aEcwLSB+LOmjqPhYVk6EEBwe7ffMh6k5iaJ7E0ByJn3kSQ3MkfuY1ZQyzCkpZuvsYGw5ksz01l52puY5mVZoGFk1N9ldZ82b+nNMmnKcu6U58WKBje3ZhKb9vS6dDTAh9EsKxWsrP5/enYMVbavmSf1edV6M+Dq6CL29QzafaDIPrPsMICFcxDPRH2/yVmoE8+2DNz3H5u9CnmtGn6qskH17v4By611XncWr2eB9/+HqymlkcoFk8TF2jkg97Gbw92DlRZHwfuH2Bs69EXRXnwMeXQmqSc5tmgceSVeJW4eBq+PBCtRzbE+5eBprWJNdgfe6DJbGog6ZOLIQQQgghXOm6QVZhKQG+VoJ8reQWl/Hhn/v56M8U8optVY5vHx3M13cPITrEn0NZhUz6YDUHs9S38pHBfpzfuTm9WoURF+pPl8z5lNh0lvuPYFd6Hr5WCzcNaUOXuFO4ByrOgWM71Khc1fVrsJepplLL34QT+933dbkYrv2s/rUTNfnqRmetRWVxPSGyvbMjtW8Q3PQdtB7sPGbfUph1tWpaNWVezf1MTqYwC2ZerGZzB0gYBLdVmiTPMOCD0XBkvVqf/FOTTe4niUUDa+rEwm63k5ycTIcOHbBaPXAqei8gMTRPYmiOxM88iaE5Ej/zvCGGOUVlzNlwmO1Hc9mfWcDO1DzySlSi0TU+lJeu6MG9n20gLbeab+5r4WvVuG9kJ+4d2QFfa+39GnKKyrBo0Cyg6rf5NcbQMCA/HY5tV0O5GnbVDMkvuF7lrFXGHvj2dtU0q2V/NYHdH/+Ekhz346z+MOlrNaN6ZQUZqpbCdYbxU5F/HD6/Rs2Dcc3HaqSoylxHs+o8Hm74skmuQRkV6gyk6/rJDxK1khiaJzE0R+JnnsTQHImfeZ4ew7BAX24Z6pyh/PCJQq5+dyWpOcXsSM3lyrdXOPZ1aB5Mp5hmLNtz3NGsqiZldoM3F+zm121pXD8wga7xoXRsHsLB8v4fmw5lk3w8nwNZhWQXluHvY+H1q3tzae+q/U0qYlhQYiPA16qaYWkaNItTPx1GNVA0KonuBHctdd/WeZyqhcg+oNYtPnDtp9UnFQDB0Q1TlpDmcMci1afDdb4RV90uU3OH5B5RkxVmJkN4W4++BiWxEEIIIYQ4Q7WKCOKz2wdxzbsryayY/Rvo3iKUT24dSFSIP6U2nY0HT3DoRBHpucWk5RTja7WQGBdC59hmLNiRzrtL92HXDXak5vL0D9tO+rolNp2HvtyIBlziklxkFZTy864c1ixdw5r9WbQMD+S5S7szumvs6Tj9k2ueqG7wf7wf0rbCuFeg89iTP64haFrNSQWompGBd5SPsGXAmv/BhS83TtlOkSQWQgghhBBnsA7NQ/j0tkFc97+V5Bbb6N8mgg+nnOOYC8PPx8Kg9lEMquHxfVtHMK57PI99s4mdaXk1HKXuk+NDAwgN9GVnWh66AQ99lURJ+ezjP206yvK9GW6dzA+fKOK2j9cxtnssz17q3sG80QRHw/VfNP7r1kX/KWqekT6TzHWkbyTSx6IOmrqPRcVkKH5+fjKSxymSGJonMTRH4meexNAciZ953h7DzPwSNh/JYWiHaPx86j9rs103SDqkRqXakZrLvuP5xIcF0ichnD4J4STGNSPA14quGzzx3Ra+XHuo1ueLDPYjy6UWJcDXwrUDErj9vPYkRAah6wb7MvJJzSmmV6tw56SAZxvDcHRgb4prUDpvNzBPSCx0XcdisXjlB5knkBiaJzE0R+JnnsTQHImfeRLDutN1g8fnbOGrde7JRYvwAC7uGc+lfVrQvUUYP246ygtzt5OR70wwLBr0ahVO8vF8xwhXAb4WLunVghsGtaZPQvhZG/+muAbrcx9c/3RVNDpd19mzZ49Hd9bxdBJD8ySG5kj8zJMYmiPxM09iWHcWi8YrV/bknvM7kBjbjCnntuXbe87lj0dHcGUHC13jmqFpGpf1acnCv5zPbcPaEeirRjnSDUg6lO02bG5xmc7s9Ye54u0VTHhrObNWHyC/pOqwuoZhkJpTxK60vGrn9ahQatOZu/koPyQdwWb3nr+np1+D0sdCCCGEEEI0OItFY9q4Lkwb55zvwW6vOvpUWKAvT13cjftGduSzVQeYuWI/mQWlxDTzp09COJHBfvy8JdWRaGxPzeXv323l5Z930K9NBD4WDatF40RhGbvTnMPrJkQGctPgNlwzIIHwIDXbeXGZndnrD/PukmTHzOXTF+/l6Yu7M6yTGvEpp6iMtJxiOsWEYLGcnTUjp0oSCyGEEEII0eQigv24f3Qn7h3ZkbziMsICfR3NfZ65pDs/bT7KrNUH2XQoG4CCUjvL9mTU+HyHsop4ed5O/vH7biKD/NANg4ISW5WhdXen53PjjNX0TggnI6/EkXCc2yGK927qX+18HKJ60hRKCCGEEEJ4DKtFIzzIvXNyoJ+VawYk8MPUocy9fxg3DGpNsF/VCeJahgcyMrE5QztGObaV2nTScos5llfillScn9ic3gnhjvVNh7IdSQXAiuRMrn1vFcfy6jeZ4NlMOm/XgXTe9n4SQ/MkhuZI/MyTGJoj8TNPYmheQ8bQZtcpKLWj6wY23SDQz0qIv7Mxzr7j+Xy66gALdxyjzK5j0TQsFujZMox7RnSkZ6swdN3g+6QjvPrLTo7llRDi70OXuGbsPZ5PdmEZAK0jg7hvVEeyC0vJzC/Fphv4+Vjws1qICvFjYLtIEmNVnxFdN9h9LI9daXlEBPnRLjqYFuGBahLABuDpnbclsagDT0gsvHl4O08gMTRPYmiOxM88iaE5Ej/zJIbmeWoMdd0go6CE6GB/LBaNvcfyuXnGao7m1K22IjrEjw7NQ9iemuvW6RzAz2phdNcYXrqiJ5HBfo7tR7OLOJBZyMB2kXVOPDx9uFlpCuUFdF0nJSXFY0cA8AYSQ/MkhuZI/MyTGJoj8TNPYmiep8bQYtGIaRbg6KzdMSaEb+89l04xIXV6fEZ+KatTsqokFQCldp1ftqZx6X+XszMtl1Kbzr8X7OH815dw/furuHXmWvKKy+r0Op4avwrSeVsIIYQQQohK4sMC+eaec/l2/WEsGkSF+BMV4oe/j4USm06JTWff8QJW7M1gdUoW+SU2okP8GdAmgp6twsgtKiMlo4C1+7M4UVjG4RNFXPn2CuLDAkg+XuB4naW7j3P1uyuZMeUcWoY7Zx7PKSpj3f4s1qRksWZ/Fh/fOpBgX8+uE5DEQgghhBBCiGqEBfpy67B2Ne4fmQi3DWuHza6TXVRGVHDVJkqpOUXc9el6Nh/OobDU7kgqrBaNIF8reSU2dqblcfn0PzmnbQTZhWUczyth7/F8XDssrD9wguEundI9kWenPcLBYpE/lVkSQ/MkhuZI/MyTGJoj8TNPYmjemRhDH6uF6BD/avs9xIcF8vVdQ7i8TwvHtp4tw/jxvqH8cN9Q2kYFAXA8r4R5W9JYkZzJnmPuSQXAnvQ8wLPjJ52366CpO28LIYQQQgjvZhgGC3Yco8RmZ1z3OHysKkHIKijlvs83sCI503Gsj0Wjc2wzBrWPZFC7SM5pG0lUiH+TlFtGhWpgTZ1YGIZBQUEBwcHBHjWCgjeRGJonMTRH4meexNAciZ95EkPzJIY1O3yiEE3TCA/0JcjPWm18miJ+MirUGUbXdQ4fPuyxIwB4A4mheRJDcyR+5kkMzZH4mScxNE9iWLNWEUG0DA8k2N+nxqTB0+MniYUQQgghhBDCNEkshBBCCCGEEKZJYuEFNE3zuBkqvY3E0DyJoTkSP/MkhuZI/MyTGJonMTTH0+MnnbfroKk7bwshhBBCCNEUpPP2GcYwDLKzs5Ec8NRJDM2TGJoj8TNPYmiOxM88iaF5EkNzPD1+klh4AV3XSUtL89gRALyBxNA8iaE5Ej/zJIbmSPzMkxiaJzE0x9PjJ4mFEEIIIYQQwjRJLIQQQgghhBCmSWLhBTRNkxkqTZIYmicxNEfiZ57E0ByJn3kSQ/MkhuZ4evxkVKg6kFGhhBBCCCHE2UhGhTrD6LpORkaGx3bU8QYSQ/MkhuZI/MyTGJoj8TNPYmiexNAcT4+fJBZewDAMMjIyPHZoMW8gMTRPYmiOxM88iaE5Ej/zJIbmSQzN8fT4SWIhhBBCCCGEME0SCyGEEEIIIYRpklh4AU3TCAsL89gRALyBxNA8iaE5Ej/zJIbmSPzMkxiaJzE0x9PjJ6NC1YGMCiWEEEIIIc5GMirUGUbXdVJTUz12BABvIDE0T2JojsTPPImhORI/8ySG5kkMzfH0+Eli4QUMwyAnJ8djRwDwBhJD8ySG5kj8zJMYmiPxM09iaJ7E0BxPj58kFkIIIYQQQgjTfJq6AN6gIivMzc1tkte32+3k5+eTm5uL1WptkjJ4O4mheRJDcyR+5kkMzZH4mScxNE9iaE5TxK/i/rcutSSSWNRBXl4eAAkJCU1cEiGEEEIIIRpfXl4eYWFhtR4jo0LVga7rHD16lGbNmjXJ8F65ubkkJCRw6NAhGZXqFEkMzZMYmiPxM09iaI7EzzyJoXkSQ3OaIn6GYZCXl0eLFi2wWGrvRSE1FnVgsVho1apVUxeD0NBQeROaJDE0T2JojsTPPImhORI/8ySG5kkMzWns+J2spqKCdN4WQgghhBBCmCaJhRBCCCGEEMI0SSy8gL+/P8888wz+/v5NXRSvJTE0T2JojsTPPImhORI/8ySG5kkMzfH0+EnnbSGEEEIIIYRpUmMhhBBCCCGEME0SCyGEEEIIIYRpklgIIYQQQgghTJPEwgtMnz6dtm3bEhAQwKBBg1izZk1TF8kjvfLKK5xzzjk0a9aMmJgYLr/8cnbt2uV2zPnnn4+maW4/d999dxOV2PM8++yzVeLTpUsXx/7i4mKmTp1KVFQUISEhTJw4kfT09CYssedp27ZtlRhqmsbUqVMBuQYr++OPP7jkkkto0aIFmqbx/fffu+03DIOnn36a+Ph4AgMDGTNmDHv27HE7Jisri0mTJhEaGkp4eDi33XYb+fn5jXgWTau2GJaVlTFt2jR69uxJcHAwLVq04Oabb+bo0aNuz1Hddfvqq6828pk0jZNdg1OmTKkSm3HjxrkdI9dg7TGs7jNR0zRef/11xzFn8zVYl/uXuvz/PXjwIBMmTCAoKIiYmBgee+wxbDZbY56KJBae7quvvuKRRx7hmWeeYcOGDfTu3ZuxY8dy7Nixpi6ax1m6dClTp05l1apVzJ8/n7KyMi688EIKCgrcjrvjjjtITU11/Lz22mtNVGLP1L17d7f4LF++3LHv4Ycf5qeffmL27NksXbqUo0ePcuWVVzZhaT3P2rVr3eI3f/58AK6++mrHMXINOhUUFNC7d2+mT59e7f7XXnuNt956i3fffZfVq1cTHBzM2LFjKS4udhwzadIktm3bxvz585k7dy5//PEHd955Z2OdQpOrLYaFhYVs2LCBp556ig0bNjBnzhx27drFpZdeWuXY559/3u26vP/++xuj+E3uZNcgwLhx49xi88UXX7jtl2uw9hi6xi41NZUPP/wQTdOYOHGi23Fn6zVYl/uXk/3/tdvtTJgwgdLSUlasWMHHH3/MzJkzefrppxv3ZAzh0QYOHGhMnTrVsW63240WLVoYr7zyShOWyjscO3bMAIylS5c6to0YMcJ48MEHm65QHu6ZZ54xevfuXe2+7Oxsw9fX15g9e7Zj244dOwzAWLlyZSOV0Ps8+OCDRocOHQxd1w3DkGuwNoDx3XffOdZ1XTfi4uKM119/3bEtOzvb8Pf3N7744gvDMAxj+/btBmCsXbvWccwvv/xiaJpmHDlypNHK7ikqx7A6a9asMQDjwIEDjm1t2rQx3nzzzdNbOC9QXfwmT55sXHbZZTU+Rq5Bd3W5Bi+77DJj1KhRbtvkGnSqfP9Sl/+/8+bNMywWi5GWluY45p133jFCQ0ONkpKSRiu71Fh4sNLSUtavX8+YMWMc2ywWC2PGjGHlypVNWDLvkJOTA0BkZKTb9lmzZhEdHU2PHj14/PHHKSwsbIrieaw9e/bQokUL2rdvz6RJkzh48CAA69evp6yszO167NKlC61bt5brsQalpaV89tln3HrrrWia5tgu12DdpKSkkJaW5nbNhYWFMWjQIMc1t3LlSsLDwxkwYIDjmDFjxmCxWFi9enWjl9kb5OTkoGka4eHhbttfffVVoqKi6Nu3L6+//nqjN6HwZEuWLCEmJobExETuueceMjMzHfvkGqyf9PR0fv75Z2677bYq++QaVCrfv9Tl/+/KlSvp2bMnsbGxjmPGjh1Lbm4u27Zta7Sy+zTaK4l6y8jIwG63u10kALGxsezcubOJSuUddF3noYceYujQofTo0cOx/YYbbqBNmza0aNGCzZs3M23aNHbt2sWcOXOasLSeY9CgQcycOZPExERSU1N57rnnOO+889i6dStpaWn4+flVuRmJjY0lLS2taQrs4b7//nuys7OZMmWKY5tcg3VXcV1V9xlYsS8tLY2YmBi3/T4+PkRGRsp1WY3i4mKmTZvG9ddfT2hoqGP7Aw88QL9+/YiMjGTFihU8/vjjpKam8sYbbzRhaT3DuHHjuPLKK2nXrh3Jyck88cQTjB8/npUrV2K1WuUarKePP/6YZs2aVWlGK9egUt39S13+/6alpVX7WVmxr7FIYiHOSFOnTmXr1q1u/QMAtzavPXv2JD4+ntGjR5OcnEyHDh0au5geZ/z48Y7lXr16MWjQINq0acPXX39NYGBgE5bMO82YMYPx48fTokULxza5BkVTKSsr45prrsEwDN555x23fY888ohjuVevXvj5+XHXXXfxyiuveOwMv43luuuucyz37NmTXr160aFDB5YsWcLo0aObsGTe6cMPP2TSpEkEBAS4bZdrUKnp/sVbSFMoDxYdHY3Vaq3S6z89PZ24uLgmKpXnu++++5g7dy6LFy+mVatWtR47aNAgAPbu3dsYRfM64eHhdO7cmb179xIXF0dpaSnZ2dlux8j1WL0DBw6wYMECbr/99lqPk2uwZhXXVW2fgXFxcVUGs7DZbGRlZcl16aIiqThw4ADz5893q62ozqBBg7DZbOzfv79xCuhF2rdvT3R0tOM9K9dg3S1btoxdu3ad9HMRzs5rsKb7l7r8/42Li6v2s7JiX2ORxMKD+fn50b9/fxYuXOjYpus6CxcuZMiQIU1YMs9kGAb33Xcf3333HYsWLaJdu3YnfUxSUhIA8fHxp7l03ik/P5/k5GTi4+Pp378/vr6+btfjrl27OHjwoFyP1fjoo4+IiYlhwoQJtR4n12DN2rVrR1xcnNs1l5uby+rVqx3X3JAhQ8jOzmb9+vWOYxYtWoSu646k7WxXkVTs2bOHBQsWEBUVddLHJCUlYbFYqjTxEXD48GEyMzMd71m5ButuxowZ9O/fn969e5/02LPpGjzZ/Utd/v8OGTKELVu2uCW5FV8idOvWrXFOBGRUKE/35ZdfGv7+/sbMmTON7du3G3feeacRHh7u1utfKPfcc48RFhZmLFmyxEhNTXX8FBYWGoZhGHv37jWef/55Y926dUZKSorxww8/GO3btzeGDx/exCX3HH/5y1+MJUuWGCkpKcaff/5pjBkzxoiOjjaOHTtmGIZh3H333Ubr1q2NRYsWGevWrTOGDBliDBkypIlL7XnsdrvRunVrY9q0aW7b5RqsKi8vz9i4caOxceNGAzDeeOMNY+PGjY4Ri1599VUjPDzc+OGHH4zNmzcbl112mdGuXTujqKjI8Rzjxo0z+vbta6xevdpYvny50alTJ+P6669vqlNqdLXFsLS01Lj00kuNVq1aGUlJSW6fjRUjxaxYscJ48803jaSkJCM5Odn47LPPjObNmxs333xzE59Z46gtfnl5ecajjz5qrFy50khJSTEWLFhg9OvXz+jUqZNRXFzseA65Bmt/HxuGYeTk5BhBQUHGO++8U+XxZ/s1eLL7F8M4+f9fm81m9OjRw7jwwguNpKQk49dffzWaN29uPP744416LpJYeIH//Oc/RuvWrQ0/Pz9j4MCBxqpVq5q6SB4JqPbno48+MgzDMA4ePGgMHz7ciIyMNPz9/Y2OHTsajz32mJGTk9O0Bfcg1157rREfH2/4+fkZLVu2NK699lpj7969jv1FRUXGvffea0RERBhBQUHGFVdcYaSmpjZhiT3Tb7/9ZgDGrl273LbLNVjV4sWLq33fTp482TAMNeTsU089ZcTGxhr+/v7G6NGjq8Q1MzPTuP76642QkBAjNDTUuOWWW4y8vLwmOJumUVsMU1JSavxsXLx4sWEYhrF+/Xpj0KBBRlhYmBEQEGB07drVePnll91unM9ktcWvsLDQuPDCC43mzZsbvr6+Rps2bYw77rijypd7cg3W/j42DMN47733jMDAQCM7O7vK48/2a/Bk9y+GUbf/v/v37zfGjx9vBAYGGtHR0cZf/vIXo6ysrFHPRSs/ISGEEEIIIYQ4ZdLHQgghhBBCCGGaJBZCCCGEEEII0ySxEEIIIYQQQpgmiYUQQgghhBDCNEkshBBCCCGEEKZJYiGEEEIIIYQwTRILIYQQQgghhGmSWAghhBBCCCFMk8RCCCHEGUnTNL7//vumLoYQQpw1JLEQQgjR4KZMmYKmaVV+xo0b19RFE0IIcZr4NHUBhBBCnJnGjRvHRx995LbN39+/iUojhBDidJMaCyGEEKeFv78/cXFxbj8RERGAaqb0zjvvMH78eAIDA2nfvj3ffPON2+O3bNnCqFGjCAwMJCoqijvvvJP8/Hy3Yz788EO6d++Ov78/8fHx3HfffW77MzIyuOKKKwgKCqJTp078+OOPp/ekhRDiLCaJhRBCiCbx1FNPMXHiRDZt2sSkSZO47rrr2LFjBwAFBQWMHTuWiIgI1q5dy+zZs1mwYIFb4vDOO+8wdepU7rzzTrZs2cKPP/5Ix44d3V7jueee45prrmHz5s1cdNFFTJo0iaysrEY9TyGEOFtohmEYTV0IIYQQZ5YpU6bw2WefERAQ4Lb9iSee4IknnkDTNO6++27eeecdx77BgwfTr18/3n77bd5//32mTZvGoUOHCA4OBmDevHlccsklHD16lNjYWFq2bMktt9zCiy++WG0ZNE3jySef5IUXXgBUshISEsIvv/wifT2EEOI0kD4WQgghTouRI0e6JQ4AkZGRjuUhQ4a47RsyZAhJSUkA7Nixg969ezuSCoChQ4ei6zq7du1C0zSOHj3K6NGjay1Dr169HMvBwcGEhoZy7NixUz0lIYQQtZDEQgghxGkRHBxcpWlSQwkMDKzTcb6+vm7rmqah6/rpKJIQQpz1pI+FEEKIJrFq1aoq6127dgWga9eubNq0iYKCAsf+P//8E4vFQmJiIs2aNaNt27YsXLiwUcsshBCiZlJjIYQQ4rQoKSkhLS3NbZuPjw/R0dEAzJ49mwEDBjBs2DBmzZrFmjVrmDFjBgCTJk3imWeeYfLkyTz77LMcP36c+++/n5tuuonY2FgAnn32We6++25iYmIYP348eXl5/Pnnn9x///2Ne6JCCCEASSyEEEKcJr/++ivx8fFu2xITE9m5cyegRmz68ssvuffee4mPj+eLL76gW7duAAQFBfHbb7/x4IMPcs455xAUFMTEiRN54403HM81efJkiouLefPNN3n00UeJjo7mqquuarwTFEII4UZGhRJCCNHoNE3ju+++4/LLL2/qogghhGgg0sdCCCGEEEIIYZokFkIIIYQQQgjTpI+FEEKIRietcIUQ4swjNRZCCCGEEEII0ySxEEIIIYQQQpgmiYUQQgghhBDCNEkshBBCCCGEEKZJYiGEEEIIIYQwTRILIYQQQgghhGmSWAghhBBCCCFMk8RCCCGEEEIIYZokFkIIIYQQQgjT/h9tXWX0tYp7cwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
