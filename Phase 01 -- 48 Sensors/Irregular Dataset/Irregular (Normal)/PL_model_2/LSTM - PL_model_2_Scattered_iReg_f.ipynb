{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_2_Scattered_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.406007</td>\n",
       "      <td>85.465645</td>\n",
       "      <td>46.676435</td>\n",
       "      <td>57.403574</td>\n",
       "      <td>66.385077</td>\n",
       "      <td>83.755009</td>\n",
       "      <td>60.222991</td>\n",
       "      <td>81.731340</td>\n",
       "      <td>54.146807</td>\n",
       "      <td>72.026821</td>\n",
       "      <td>...</td>\n",
       "      <td>58.654447</td>\n",
       "      <td>55.586006</td>\n",
       "      <td>59.621294</td>\n",
       "      <td>61.886111</td>\n",
       "      <td>90.600231</td>\n",
       "      <td>71.045191</td>\n",
       "      <td>58.392011</td>\n",
       "      <td>72.109779</td>\n",
       "      <td>54.770557</td>\n",
       "      <td>61.238352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.351704</td>\n",
       "      <td>73.971619</td>\n",
       "      <td>49.717074</td>\n",
       "      <td>71.733702</td>\n",
       "      <td>72.604477</td>\n",
       "      <td>74.323361</td>\n",
       "      <td>71.642854</td>\n",
       "      <td>81.550451</td>\n",
       "      <td>54.828538</td>\n",
       "      <td>74.455141</td>\n",
       "      <td>...</td>\n",
       "      <td>56.141836</td>\n",
       "      <td>66.074063</td>\n",
       "      <td>59.301755</td>\n",
       "      <td>74.178376</td>\n",
       "      <td>73.527994</td>\n",
       "      <td>77.744891</td>\n",
       "      <td>69.881647</td>\n",
       "      <td>76.405338</td>\n",
       "      <td>47.770099</td>\n",
       "      <td>68.878286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.878892</td>\n",
       "      <td>64.809892</td>\n",
       "      <td>69.192530</td>\n",
       "      <td>70.355513</td>\n",
       "      <td>68.884789</td>\n",
       "      <td>59.777149</td>\n",
       "      <td>65.629420</td>\n",
       "      <td>94.242576</td>\n",
       "      <td>57.244828</td>\n",
       "      <td>65.010419</td>\n",
       "      <td>...</td>\n",
       "      <td>63.968113</td>\n",
       "      <td>66.679467</td>\n",
       "      <td>52.122820</td>\n",
       "      <td>61.039546</td>\n",
       "      <td>62.873698</td>\n",
       "      <td>86.699905</td>\n",
       "      <td>63.250734</td>\n",
       "      <td>78.284037</td>\n",
       "      <td>55.390484</td>\n",
       "      <td>66.183183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.316636</td>\n",
       "      <td>80.498511</td>\n",
       "      <td>64.441418</td>\n",
       "      <td>56.912369</td>\n",
       "      <td>66.358069</td>\n",
       "      <td>86.564540</td>\n",
       "      <td>76.867275</td>\n",
       "      <td>76.334062</td>\n",
       "      <td>67.969230</td>\n",
       "      <td>76.411697</td>\n",
       "      <td>...</td>\n",
       "      <td>57.043472</td>\n",
       "      <td>63.030395</td>\n",
       "      <td>59.615085</td>\n",
       "      <td>56.388748</td>\n",
       "      <td>64.602431</td>\n",
       "      <td>64.466087</td>\n",
       "      <td>72.581645</td>\n",
       "      <td>66.845638</td>\n",
       "      <td>58.829371</td>\n",
       "      <td>75.603256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.911923</td>\n",
       "      <td>68.179991</td>\n",
       "      <td>67.936123</td>\n",
       "      <td>68.450759</td>\n",
       "      <td>70.633028</td>\n",
       "      <td>70.152683</td>\n",
       "      <td>68.569243</td>\n",
       "      <td>70.124111</td>\n",
       "      <td>51.508900</td>\n",
       "      <td>63.318079</td>\n",
       "      <td>...</td>\n",
       "      <td>59.409446</td>\n",
       "      <td>62.687461</td>\n",
       "      <td>51.773093</td>\n",
       "      <td>60.071736</td>\n",
       "      <td>72.803066</td>\n",
       "      <td>88.221204</td>\n",
       "      <td>64.157324</td>\n",
       "      <td>72.880851</td>\n",
       "      <td>49.007566</td>\n",
       "      <td>70.516981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>75.420924</td>\n",
       "      <td>72.983297</td>\n",
       "      <td>72.293340</td>\n",
       "      <td>70.574890</td>\n",
       "      <td>89.053725</td>\n",
       "      <td>84.569350</td>\n",
       "      <td>66.739765</td>\n",
       "      <td>72.234099</td>\n",
       "      <td>81.076902</td>\n",
       "      <td>80.482844</td>\n",
       "      <td>...</td>\n",
       "      <td>83.150568</td>\n",
       "      <td>65.953377</td>\n",
       "      <td>48.117080</td>\n",
       "      <td>49.682031</td>\n",
       "      <td>81.110885</td>\n",
       "      <td>58.450963</td>\n",
       "      <td>79.666812</td>\n",
       "      <td>77.889462</td>\n",
       "      <td>64.789617</td>\n",
       "      <td>52.903472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>72.586272</td>\n",
       "      <td>59.022907</td>\n",
       "      <td>72.990713</td>\n",
       "      <td>58.263311</td>\n",
       "      <td>80.833146</td>\n",
       "      <td>77.615216</td>\n",
       "      <td>67.822218</td>\n",
       "      <td>78.501928</td>\n",
       "      <td>68.473403</td>\n",
       "      <td>66.975001</td>\n",
       "      <td>...</td>\n",
       "      <td>67.039936</td>\n",
       "      <td>62.654153</td>\n",
       "      <td>53.132274</td>\n",
       "      <td>52.359962</td>\n",
       "      <td>60.410200</td>\n",
       "      <td>66.332568</td>\n",
       "      <td>61.709596</td>\n",
       "      <td>65.257602</td>\n",
       "      <td>75.843347</td>\n",
       "      <td>61.268631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>56.283441</td>\n",
       "      <td>73.072358</td>\n",
       "      <td>66.997185</td>\n",
       "      <td>62.548293</td>\n",
       "      <td>65.700286</td>\n",
       "      <td>61.067226</td>\n",
       "      <td>61.145387</td>\n",
       "      <td>75.482207</td>\n",
       "      <td>65.980870</td>\n",
       "      <td>59.776324</td>\n",
       "      <td>...</td>\n",
       "      <td>66.367211</td>\n",
       "      <td>71.064424</td>\n",
       "      <td>64.243497</td>\n",
       "      <td>46.093524</td>\n",
       "      <td>64.877998</td>\n",
       "      <td>79.549095</td>\n",
       "      <td>72.639319</td>\n",
       "      <td>74.272992</td>\n",
       "      <td>66.682511</td>\n",
       "      <td>64.059545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>77.908145</td>\n",
       "      <td>72.319050</td>\n",
       "      <td>76.136647</td>\n",
       "      <td>48.914493</td>\n",
       "      <td>67.858274</td>\n",
       "      <td>81.550251</td>\n",
       "      <td>74.442318</td>\n",
       "      <td>55.323266</td>\n",
       "      <td>60.177985</td>\n",
       "      <td>59.097731</td>\n",
       "      <td>...</td>\n",
       "      <td>71.733504</td>\n",
       "      <td>71.091485</td>\n",
       "      <td>67.318279</td>\n",
       "      <td>60.271055</td>\n",
       "      <td>80.732961</td>\n",
       "      <td>65.210486</td>\n",
       "      <td>67.417776</td>\n",
       "      <td>68.806994</td>\n",
       "      <td>66.393003</td>\n",
       "      <td>56.498697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>72.498225</td>\n",
       "      <td>64.546306</td>\n",
       "      <td>67.043324</td>\n",
       "      <td>53.831131</td>\n",
       "      <td>80.916082</td>\n",
       "      <td>69.252684</td>\n",
       "      <td>74.697408</td>\n",
       "      <td>71.993410</td>\n",
       "      <td>88.466893</td>\n",
       "      <td>74.215926</td>\n",
       "      <td>...</td>\n",
       "      <td>55.230278</td>\n",
       "      <td>68.590599</td>\n",
       "      <td>67.672809</td>\n",
       "      <td>57.354662</td>\n",
       "      <td>58.927945</td>\n",
       "      <td>71.631605</td>\n",
       "      <td>69.682465</td>\n",
       "      <td>78.281842</td>\n",
       "      <td>51.802674</td>\n",
       "      <td>62.521953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5   \\\n",
       "0     77.406007  85.465645  46.676435  57.403574  66.385077  83.755009   \n",
       "1     64.351704  73.971619  49.717074  71.733702  72.604477  74.323361   \n",
       "2     64.878892  64.809892  69.192530  70.355513  68.884789  59.777149   \n",
       "3     63.316636  80.498511  64.441418  56.912369  66.358069  86.564540   \n",
       "4     69.911923  68.179991  67.936123  68.450759  70.633028  70.152683   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  75.420924  72.983297  72.293340  70.574890  89.053725  84.569350   \n",
       "2439  72.586272  59.022907  72.990713  58.263311  80.833146  77.615216   \n",
       "2440  56.283441  73.072358  66.997185  62.548293  65.700286  61.067226   \n",
       "2441  77.908145  72.319050  76.136647  48.914493  67.858274  81.550251   \n",
       "2442  72.498225  64.546306  67.043324  53.831131  80.916082  69.252684   \n",
       "\n",
       "             6          7          8          9   ...         38         39  \\\n",
       "0     60.222991  81.731340  54.146807  72.026821  ...  58.654447  55.586006   \n",
       "1     71.642854  81.550451  54.828538  74.455141  ...  56.141836  66.074063   \n",
       "2     65.629420  94.242576  57.244828  65.010419  ...  63.968113  66.679467   \n",
       "3     76.867275  76.334062  67.969230  76.411697  ...  57.043472  63.030395   \n",
       "4     68.569243  70.124111  51.508900  63.318079  ...  59.409446  62.687461   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  66.739765  72.234099  81.076902  80.482844  ...  83.150568  65.953377   \n",
       "2439  67.822218  78.501928  68.473403  66.975001  ...  67.039936  62.654153   \n",
       "2440  61.145387  75.482207  65.980870  59.776324  ...  66.367211  71.064424   \n",
       "2441  74.442318  55.323266  60.177985  59.097731  ...  71.733504  71.091485   \n",
       "2442  74.697408  71.993410  88.466893  74.215926  ...  55.230278  68.590599   \n",
       "\n",
       "             40         41         42         43         44         45  \\\n",
       "0     59.621294  61.886111  90.600231  71.045191  58.392011  72.109779   \n",
       "1     59.301755  74.178376  73.527994  77.744891  69.881647  76.405338   \n",
       "2     52.122820  61.039546  62.873698  86.699905  63.250734  78.284037   \n",
       "3     59.615085  56.388748  64.602431  64.466087  72.581645  66.845638   \n",
       "4     51.773093  60.071736  72.803066  88.221204  64.157324  72.880851   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  48.117080  49.682031  81.110885  58.450963  79.666812  77.889462   \n",
       "2439  53.132274  52.359962  60.410200  66.332568  61.709596  65.257602   \n",
       "2440  64.243497  46.093524  64.877998  79.549095  72.639319  74.272992   \n",
       "2441  67.318279  60.271055  80.732961  65.210486  67.417776  68.806994   \n",
       "2442  67.672809  57.354662  58.927945  71.631605  69.682465  78.281842   \n",
       "\n",
       "             46         47  \n",
       "0     54.770557  61.238352  \n",
       "1     47.770099  68.878286  \n",
       "2     55.390484  66.183183  \n",
       "3     58.829371  75.603256  \n",
       "4     49.007566  70.516981  \n",
       "...         ...        ...  \n",
       "2438  64.789617  52.903472  \n",
       "2439  75.843347  61.268631  \n",
       "2440  66.682511  64.059545  \n",
       "2441  66.393003  56.498697  \n",
       "2442  51.802674  62.521953  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.406007</td>\n",
       "      <td>85.465645</td>\n",
       "      <td>46.676435</td>\n",
       "      <td>57.403574</td>\n",
       "      <td>66.385077</td>\n",
       "      <td>83.755009</td>\n",
       "      <td>60.222991</td>\n",
       "      <td>81.731340</td>\n",
       "      <td>54.146807</td>\n",
       "      <td>72.026821</td>\n",
       "      <td>...</td>\n",
       "      <td>58.654447</td>\n",
       "      <td>55.586006</td>\n",
       "      <td>59.621294</td>\n",
       "      <td>61.886111</td>\n",
       "      <td>90.600231</td>\n",
       "      <td>71.045191</td>\n",
       "      <td>58.392011</td>\n",
       "      <td>72.109779</td>\n",
       "      <td>54.770557</td>\n",
       "      <td>61.238352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.351704</td>\n",
       "      <td>73.971619</td>\n",
       "      <td>49.717074</td>\n",
       "      <td>71.733702</td>\n",
       "      <td>72.604477</td>\n",
       "      <td>74.323361</td>\n",
       "      <td>71.642854</td>\n",
       "      <td>81.550451</td>\n",
       "      <td>54.828538</td>\n",
       "      <td>74.455141</td>\n",
       "      <td>...</td>\n",
       "      <td>56.141836</td>\n",
       "      <td>66.074063</td>\n",
       "      <td>59.301755</td>\n",
       "      <td>74.178376</td>\n",
       "      <td>73.527994</td>\n",
       "      <td>77.744891</td>\n",
       "      <td>69.881647</td>\n",
       "      <td>76.405338</td>\n",
       "      <td>47.770099</td>\n",
       "      <td>68.878286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.878892</td>\n",
       "      <td>64.809892</td>\n",
       "      <td>69.192530</td>\n",
       "      <td>70.355513</td>\n",
       "      <td>68.884789</td>\n",
       "      <td>59.777149</td>\n",
       "      <td>65.629420</td>\n",
       "      <td>94.242576</td>\n",
       "      <td>57.244828</td>\n",
       "      <td>65.010419</td>\n",
       "      <td>...</td>\n",
       "      <td>63.968113</td>\n",
       "      <td>66.679467</td>\n",
       "      <td>52.122820</td>\n",
       "      <td>61.039546</td>\n",
       "      <td>62.873698</td>\n",
       "      <td>86.699905</td>\n",
       "      <td>63.250734</td>\n",
       "      <td>78.284037</td>\n",
       "      <td>55.390484</td>\n",
       "      <td>66.183183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.316636</td>\n",
       "      <td>80.498511</td>\n",
       "      <td>64.441418</td>\n",
       "      <td>56.912369</td>\n",
       "      <td>66.358069</td>\n",
       "      <td>86.564540</td>\n",
       "      <td>76.867275</td>\n",
       "      <td>76.334062</td>\n",
       "      <td>67.969230</td>\n",
       "      <td>76.411697</td>\n",
       "      <td>...</td>\n",
       "      <td>57.043472</td>\n",
       "      <td>63.030395</td>\n",
       "      <td>59.615085</td>\n",
       "      <td>56.388748</td>\n",
       "      <td>64.602431</td>\n",
       "      <td>64.466087</td>\n",
       "      <td>72.581645</td>\n",
       "      <td>66.845638</td>\n",
       "      <td>58.829371</td>\n",
       "      <td>75.603256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.911923</td>\n",
       "      <td>68.179991</td>\n",
       "      <td>67.936123</td>\n",
       "      <td>68.450759</td>\n",
       "      <td>70.633028</td>\n",
       "      <td>70.152683</td>\n",
       "      <td>68.569243</td>\n",
       "      <td>70.124111</td>\n",
       "      <td>51.508900</td>\n",
       "      <td>63.318079</td>\n",
       "      <td>...</td>\n",
       "      <td>59.409446</td>\n",
       "      <td>62.687461</td>\n",
       "      <td>51.773093</td>\n",
       "      <td>60.071736</td>\n",
       "      <td>72.803066</td>\n",
       "      <td>88.221204</td>\n",
       "      <td>64.157324</td>\n",
       "      <td>72.880851</td>\n",
       "      <td>49.007566</td>\n",
       "      <td>70.516981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>75.420924</td>\n",
       "      <td>72.983297</td>\n",
       "      <td>72.293340</td>\n",
       "      <td>70.574890</td>\n",
       "      <td>89.053725</td>\n",
       "      <td>84.569350</td>\n",
       "      <td>66.739765</td>\n",
       "      <td>72.234099</td>\n",
       "      <td>81.076902</td>\n",
       "      <td>80.482844</td>\n",
       "      <td>...</td>\n",
       "      <td>83.150568</td>\n",
       "      <td>65.953377</td>\n",
       "      <td>48.117080</td>\n",
       "      <td>49.682031</td>\n",
       "      <td>81.110885</td>\n",
       "      <td>58.450963</td>\n",
       "      <td>79.666812</td>\n",
       "      <td>77.889462</td>\n",
       "      <td>64.789617</td>\n",
       "      <td>52.903472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>72.586272</td>\n",
       "      <td>59.022907</td>\n",
       "      <td>72.990713</td>\n",
       "      <td>58.263311</td>\n",
       "      <td>80.833146</td>\n",
       "      <td>77.615216</td>\n",
       "      <td>67.822218</td>\n",
       "      <td>78.501928</td>\n",
       "      <td>68.473403</td>\n",
       "      <td>66.975001</td>\n",
       "      <td>...</td>\n",
       "      <td>67.039936</td>\n",
       "      <td>62.654153</td>\n",
       "      <td>53.132274</td>\n",
       "      <td>52.359962</td>\n",
       "      <td>60.410200</td>\n",
       "      <td>66.332568</td>\n",
       "      <td>61.709596</td>\n",
       "      <td>65.257602</td>\n",
       "      <td>75.843347</td>\n",
       "      <td>61.268631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>56.283441</td>\n",
       "      <td>73.072358</td>\n",
       "      <td>66.997185</td>\n",
       "      <td>62.548293</td>\n",
       "      <td>65.700286</td>\n",
       "      <td>61.067226</td>\n",
       "      <td>61.145387</td>\n",
       "      <td>75.482207</td>\n",
       "      <td>65.980870</td>\n",
       "      <td>59.776324</td>\n",
       "      <td>...</td>\n",
       "      <td>66.367211</td>\n",
       "      <td>71.064424</td>\n",
       "      <td>64.243497</td>\n",
       "      <td>46.093524</td>\n",
       "      <td>64.877998</td>\n",
       "      <td>79.549095</td>\n",
       "      <td>72.639319</td>\n",
       "      <td>74.272992</td>\n",
       "      <td>66.682511</td>\n",
       "      <td>64.059545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>77.908145</td>\n",
       "      <td>72.319050</td>\n",
       "      <td>76.136647</td>\n",
       "      <td>48.914493</td>\n",
       "      <td>67.858274</td>\n",
       "      <td>81.550251</td>\n",
       "      <td>74.442318</td>\n",
       "      <td>55.323266</td>\n",
       "      <td>60.177985</td>\n",
       "      <td>59.097731</td>\n",
       "      <td>...</td>\n",
       "      <td>71.733504</td>\n",
       "      <td>71.091485</td>\n",
       "      <td>67.318279</td>\n",
       "      <td>60.271055</td>\n",
       "      <td>80.732961</td>\n",
       "      <td>65.210486</td>\n",
       "      <td>67.417776</td>\n",
       "      <td>68.806994</td>\n",
       "      <td>66.393003</td>\n",
       "      <td>56.498697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>72.498225</td>\n",
       "      <td>64.546306</td>\n",
       "      <td>67.043324</td>\n",
       "      <td>53.831131</td>\n",
       "      <td>80.916082</td>\n",
       "      <td>69.252684</td>\n",
       "      <td>74.697408</td>\n",
       "      <td>71.993410</td>\n",
       "      <td>88.466893</td>\n",
       "      <td>74.215926</td>\n",
       "      <td>...</td>\n",
       "      <td>55.230278</td>\n",
       "      <td>68.590599</td>\n",
       "      <td>67.672809</td>\n",
       "      <td>57.354662</td>\n",
       "      <td>58.927945</td>\n",
       "      <td>71.631605</td>\n",
       "      <td>69.682465</td>\n",
       "      <td>78.281842</td>\n",
       "      <td>51.802674</td>\n",
       "      <td>62.521953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor1    sensor2    sensor3    sensor4    sensor5    sensor6  \\\n",
       "0     77.406007  85.465645  46.676435  57.403574  66.385077  83.755009   \n",
       "1     64.351704  73.971619  49.717074  71.733702  72.604477  74.323361   \n",
       "2     64.878892  64.809892  69.192530  70.355513  68.884789  59.777149   \n",
       "3     63.316636  80.498511  64.441418  56.912369  66.358069  86.564540   \n",
       "4     69.911923  68.179991  67.936123  68.450759  70.633028  70.152683   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  75.420924  72.983297  72.293340  70.574890  89.053725  84.569350   \n",
       "2439  72.586272  59.022907  72.990713  58.263311  80.833146  77.615216   \n",
       "2440  56.283441  73.072358  66.997185  62.548293  65.700286  61.067226   \n",
       "2441  77.908145  72.319050  76.136647  48.914493  67.858274  81.550251   \n",
       "2442  72.498225  64.546306  67.043324  53.831131  80.916082  69.252684   \n",
       "\n",
       "        sensor7    sensor8    sensor9   sensor10  ...   sensor39   sensor40  \\\n",
       "0     60.222991  81.731340  54.146807  72.026821  ...  58.654447  55.586006   \n",
       "1     71.642854  81.550451  54.828538  74.455141  ...  56.141836  66.074063   \n",
       "2     65.629420  94.242576  57.244828  65.010419  ...  63.968113  66.679467   \n",
       "3     76.867275  76.334062  67.969230  76.411697  ...  57.043472  63.030395   \n",
       "4     68.569243  70.124111  51.508900  63.318079  ...  59.409446  62.687461   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  66.739765  72.234099  81.076902  80.482844  ...  83.150568  65.953377   \n",
       "2439  67.822218  78.501928  68.473403  66.975001  ...  67.039936  62.654153   \n",
       "2440  61.145387  75.482207  65.980870  59.776324  ...  66.367211  71.064424   \n",
       "2441  74.442318  55.323266  60.177985  59.097731  ...  71.733504  71.091485   \n",
       "2442  74.697408  71.993410  88.466893  74.215926  ...  55.230278  68.590599   \n",
       "\n",
       "       sensor41   sensor42   sensor43   sensor44   sensor45   sensor46  \\\n",
       "0     59.621294  61.886111  90.600231  71.045191  58.392011  72.109779   \n",
       "1     59.301755  74.178376  73.527994  77.744891  69.881647  76.405338   \n",
       "2     52.122820  61.039546  62.873698  86.699905  63.250734  78.284037   \n",
       "3     59.615085  56.388748  64.602431  64.466087  72.581645  66.845638   \n",
       "4     51.773093  60.071736  72.803066  88.221204  64.157324  72.880851   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  48.117080  49.682031  81.110885  58.450963  79.666812  77.889462   \n",
       "2439  53.132274  52.359962  60.410200  66.332568  61.709596  65.257602   \n",
       "2440  64.243497  46.093524  64.877998  79.549095  72.639319  74.272992   \n",
       "2441  67.318279  60.271055  80.732961  65.210486  67.417776  68.806994   \n",
       "2442  67.672809  57.354662  58.927945  71.631605  69.682465  78.281842   \n",
       "\n",
       "       sensor47   sensor48  \n",
       "0     54.770557  61.238352  \n",
       "1     47.770099  68.878286  \n",
       "2     55.390484  66.183183  \n",
       "3     58.829371  75.603256  \n",
       "4     49.007566  70.516981  \n",
       "...         ...        ...  \n",
       "2438  64.789617  52.903472  \n",
       "2439  75.843347  61.268631  \n",
       "2440  66.682511  64.059545  \n",
       "2441  66.393003  56.498697  \n",
       "2442  51.802674  62.521953  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 22ms/step - loss: 1384.0125 - val_loss: 1248.8662\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 1226.7094 - val_loss: 1146.5593\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1139.7610 - val_loss: 1070.6265\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1072.7578 - val_loss: 1013.9573\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1024.2443 - val_loss: 973.0506\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 989.0765 - val_loss: 943.7697\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 964.2231 - val_loss: 923.8991\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 947.5684 - val_loss: 911.1003\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 937.0452 - val_loss: 903.5304\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 930.9215 - val_loss: 899.4282\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 927.6201 - val_loss: 897.4264\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 926.0411 - val_loss: 896.6041\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 925.4402 - val_loss: 896.3221\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.1753 - val_loss: 896.2643\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 925.1071 - val_loss: 896.2541\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 925.0720 - val_loss: 896.2601\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.0540 - val_loss: 896.2836\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0525 - val_loss: 896.2538\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 925.0529 - val_loss: 896.2750\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0491 - val_loss: 896.2720\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0508 - val_loss: 896.2339\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0555 - val_loss: 896.2968\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 925.0787 - val_loss: 896.2250\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0537 - val_loss: 896.2158\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0840 - val_loss: 896.2359\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0408 - val_loss: 896.2256\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0557 - val_loss: 896.2078\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.0413 - val_loss: 896.2383\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.0401 - val_loss: 896.2470\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0500 - val_loss: 896.2725\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0267 - val_loss: 896.2848\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0605 - val_loss: 896.2773\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0699 - val_loss: 896.2520\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.0258 - val_loss: 896.2256\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.0463 - val_loss: 896.2231\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0553 - val_loss: 896.2490\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0660 - val_loss: 896.2664\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.0675 - val_loss: 896.2606\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.1898 - val_loss: 896.5787\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.1442 - val_loss: 896.3282\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.0860 - val_loss: 896.2930\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 925.0585 - val_loss: 896.2790\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0723 - val_loss: 896.2790\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0861 - val_loss: 896.3159\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 925.0921 - val_loss: 896.2552\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.0653 - val_loss: 896.3032\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.0406 - val_loss: 896.1672\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 918.7586 - val_loss: 880.8967\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 904.5018 - val_loss: 873.7218\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 899.2445 - val_loss: 869.1683\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 894.4564 - val_loss: 864.5180\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 887.7443 - val_loss: 856.6845\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 876.2551 - val_loss: 842.6970\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 863.6182 - val_loss: 829.8047\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 850.7794 - val_loss: 818.1926\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 833.3521 - val_loss: 797.9205\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 816.3380 - val_loss: 781.2293\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 799.9562 - val_loss: 760.4413\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 782.2213 - val_loss: 742.2037\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 759.9620 - val_loss: 721.9503\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 735.7798 - val_loss: 694.7137\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 711.5660 - val_loss: 681.5012\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 687.5715 - val_loss: 649.5624\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 665.4752 - val_loss: 637.4931\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 643.9759 - val_loss: 612.9938\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 619.2718 - val_loss: 586.9503\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 603.0477 - val_loss: 571.8611\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 576.1105 - val_loss: 549.0854\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 555.9514 - val_loss: 537.4786\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 537.8370 - val_loss: 516.5310\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 515.2822 - val_loss: 509.0190\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 497.2971 - val_loss: 482.8703\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 484.4547 - val_loss: 466.6170\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 463.9632 - val_loss: 454.1191\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 445.4023 - val_loss: 437.9695\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 432.4374 - val_loss: 441.1263\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 421.7441 - val_loss: 410.7796\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 402.9137 - val_loss: 414.5605\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 386.7128 - val_loss: 385.2624\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 375.5036 - val_loss: 367.5456\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 363.3491 - val_loss: 354.3606\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 353.2102 - val_loss: 338.7241\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 339.5968 - val_loss: 333.5216\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 325.9735 - val_loss: 338.3107\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 317.2651 - val_loss: 317.6360\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 306.4622 - val_loss: 311.4574\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 297.9181 - val_loss: 295.6211\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 292.2771 - val_loss: 287.6688\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 279.4815 - val_loss: 289.4585\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 272.4459 - val_loss: 288.4458\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 264.0290 - val_loss: 266.4036\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 254.9004 - val_loss: 263.8912\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 249.3771 - val_loss: 245.3219\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 244.3212 - val_loss: 243.6264\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 233.7007 - val_loss: 248.8044\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 225.6174 - val_loss: 227.4138\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 222.5114 - val_loss: 223.7101\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 216.2944 - val_loss: 229.3823\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 210.2475 - val_loss: 219.3648\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 203.0907 - val_loss: 215.3342\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 199.0827 - val_loss: 207.4444\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 196.1328 - val_loss: 205.4902\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 192.1677 - val_loss: 204.7823\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 188.0601 - val_loss: 199.0581\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 183.3602 - val_loss: 196.7241\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 180.8254 - val_loss: 187.7406\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 174.1487 - val_loss: 204.3816\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 170.4595 - val_loss: 184.1298\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 165.5803 - val_loss: 173.6301\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 164.0715 - val_loss: 178.0356\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 160.3647 - val_loss: 171.2656\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 157.9928 - val_loss: 174.2964\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 153.7749 - val_loss: 167.3851\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 149.6175 - val_loss: 163.2551\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 147.7866 - val_loss: 161.8734\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 146.7550 - val_loss: 158.8078\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 139.5059 - val_loss: 158.4365\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 138.2385 - val_loss: 159.0412\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 136.8051 - val_loss: 157.0465\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 136.5945 - val_loss: 155.5183\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 131.3356 - val_loss: 151.0851\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 127.6062 - val_loss: 153.9544\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 126.9372 - val_loss: 142.4600\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 126.0018 - val_loss: 145.2468\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 122.2968 - val_loss: 145.5225\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 123.9492 - val_loss: 143.9628\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 122.1070 - val_loss: 156.9933\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 119.2404 - val_loss: 145.8231\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 116.5829 - val_loss: 153.5411\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 115.6416 - val_loss: 138.4002\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 113.6813 - val_loss: 136.1091\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 112.8734 - val_loss: 148.3783\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 113.6671 - val_loss: 144.8255\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 109.2541 - val_loss: 139.2119\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 112.1673 - val_loss: 140.6039\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 110.2099 - val_loss: 147.2131\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 108.3703 - val_loss: 131.3539\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 105.6075 - val_loss: 133.3719\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 106.0704 - val_loss: 139.7710\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 104.1161 - val_loss: 139.8280\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.5270 - val_loss: 131.6819\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 102.2458 - val_loss: 139.6925\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 100.8414 - val_loss: 128.9532\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 100.1127 - val_loss: 141.2895\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 99.8834 - val_loss: 136.9659\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.4097 - val_loss: 133.8666\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 96.7619 - val_loss: 134.4378\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 95.4420 - val_loss: 133.6600\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 97.3181 - val_loss: 135.1504\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 94.2131 - val_loss: 142.3829\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.8041 - val_loss: 138.5631\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 92.4440 - val_loss: 132.2106\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 92.1490 - val_loss: 143.3880\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 92.4778 - val_loss: 135.9784\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.1827 - val_loss: 133.7633\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 89.4301 - val_loss: 139.5492\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 87.4848 - val_loss: 126.6569\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 86.2447 - val_loss: 133.8718\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 85.8402 - val_loss: 135.9783\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 87.3568 - val_loss: 129.9059\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 84.1214 - val_loss: 125.2188\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 83.6556 - val_loss: 132.5073\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 83.7387 - val_loss: 137.0937\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 81.2767 - val_loss: 127.8301\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 79.5348 - val_loss: 131.1255\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 81.5586 - val_loss: 127.6747\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 79.2818 - val_loss: 125.9135\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 78.2535 - val_loss: 139.9724\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 78.6810 - val_loss: 134.3968\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 76.9247 - val_loss: 126.4948\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 75.4927 - val_loss: 125.6072\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 73.9642 - val_loss: 134.9557\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 74.8692 - val_loss: 136.4668\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 74.8876 - val_loss: 133.3894\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 72.0983 - val_loss: 132.4668\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 72.1502 - val_loss: 128.4820\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 70.7634 - val_loss: 133.0536\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 71.4857 - val_loss: 129.2654\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 72.8440 - val_loss: 127.8138\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 67.0524 - val_loss: 134.8864\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 69.2307 - val_loss: 132.4846\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 67.3853 - val_loss: 127.0290\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 66.7556 - val_loss: 132.2766\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 66.9712 - val_loss: 130.5816\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 64.3679 - val_loss: 130.0049\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 64.8008 - val_loss: 129.7743\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.7504 - val_loss: 143.7885\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.3846 - val_loss: 138.0581\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 62.4889 - val_loss: 133.0892\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 59.8799 - val_loss: 129.5546\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 59.7963 - val_loss: 130.5344\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 61.7259 - val_loss: 143.2971\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 61.4918 - val_loss: 134.7483\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 60.5803 - val_loss: 131.5881\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 57.8173 - val_loss: 135.6796\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 57.0650 - val_loss: 129.6870\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.9343 - val_loss: 138.1121\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 56.7237 - val_loss: 136.8775\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 54.6425 - val_loss: 134.7043\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 54.4794 - val_loss: 134.0013\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 134.00127893033257\n",
      "Mean Absolute Error (MAE): 8.565628518077524\n",
      "Root Mean Squared Error (RMSE): 11.575892144035057\n",
      "Time taken: 1241.4095129966736\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 19ms/step - loss: 1393.4287 - val_loss: 1278.1863\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1231.9011 - val_loss: 1172.9845\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1142.4570 - val_loss: 1095.7468\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1075.8326 - val_loss: 1038.1534\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1026.0303 - val_loss: 995.7449\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 989.3555 - val_loss: 965.1411\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 963.1802 - val_loss: 944.1105\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 945.4274 - val_loss: 930.3366\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 934.1099 - val_loss: 922.0732\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 927.2922 - val_loss: 917.5297\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6527 - val_loss: 915.3299\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.8397 - val_loss: 914.4275\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 921.0959 - val_loss: 914.0853\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.8355 - val_loss: 914.1192\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.7031 - val_loss: 914.0914\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6854 - val_loss: 914.0908\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6710 - val_loss: 914.0297\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6313 - val_loss: 914.1008\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6246 - val_loss: 914.0800\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6677 - val_loss: 914.0551\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6746 - val_loss: 914.0314\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.7010 - val_loss: 914.0922\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6567 - val_loss: 914.1049\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6542 - val_loss: 914.0431\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6328 - val_loss: 914.0797\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6414 - val_loss: 914.0651\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6650 - val_loss: 914.0386\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6718 - val_loss: 914.0221\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6222 - val_loss: 914.0817\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6676 - val_loss: 914.0632\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6483 - val_loss: 914.0234\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6446 - val_loss: 914.0716\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6305 - val_loss: 914.0927\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6794 - val_loss: 914.0663\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6749 - val_loss: 914.1180\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6390 - val_loss: 914.0823\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 920.6655 - val_loss: 914.0434\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 920.6478 - val_loss: 914.0427\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6388 - val_loss: 913.9903\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.7042 - val_loss: 913.9913\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6415 - val_loss: 914.0333\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.9978 - val_loss: 913.8579\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.8416 - val_loss: 913.7837\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.7187 - val_loss: 913.9170\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6686 - val_loss: 913.8763\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6557 - val_loss: 914.0164\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6587 - val_loss: 914.0435\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6588 - val_loss: 914.0606\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 920.6544 - val_loss: 914.0462\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6466 - val_loss: 914.0429\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 920.6472 - val_loss: 914.1492\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 919.3727 - val_loss: 903.5435\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 909.4498 - val_loss: 894.1182\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 904.6470 - val_loss: 891.9955\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 898.9232 - val_loss: 882.6376\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 894.6937 - val_loss: 877.5948\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 890.3857 - val_loss: 882.3024\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 885.1799 - val_loss: 873.6241\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 878.3149 - val_loss: 868.9713\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 872.5495 - val_loss: 867.5291\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 867.4782 - val_loss: 857.2483\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 863.3885 - val_loss: 856.4655\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 858.6542 - val_loss: 853.7919\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 855.0987 - val_loss: 845.6721\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 850.4905 - val_loss: 845.2231\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 846.3702 - val_loss: 836.0858\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 840.9962 - val_loss: 832.2855\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 835.7712 - val_loss: 827.5594\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 834.3621 - val_loss: 845.4092\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 824.6618 - val_loss: 814.7499\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 811.8848 - val_loss: 812.6974\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 792.0240 - val_loss: 785.7908\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 778.8546 - val_loss: 768.7783\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 766.8102 - val_loss: 756.7955\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 756.6865 - val_loss: 750.8018\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 744.2505 - val_loss: 734.5622\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 732.2617 - val_loss: 727.3226\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 720.2765 - val_loss: 711.0298\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 705.9454 - val_loss: 696.7393\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 695.9745 - val_loss: 685.3669\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 681.6205 - val_loss: 684.2328\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 669.3644 - val_loss: 661.2342\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 650.6006 - val_loss: 647.0873\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 633.4043 - val_loss: 627.5580\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 615.9042 - val_loss: 601.5165\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 591.3680 - val_loss: 610.6433\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 569.0999 - val_loss: 558.7681\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 538.2870 - val_loss: 525.5704\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 514.4392 - val_loss: 520.6875\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 492.4205 - val_loss: 484.9192\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 467.5735 - val_loss: 468.4429\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 452.1031 - val_loss: 473.7090\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 433.3134 - val_loss: 423.9424\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 411.0101 - val_loss: 410.8668\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 398.3396 - val_loss: 403.5870\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 384.0705 - val_loss: 384.6929\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 371.7162 - val_loss: 459.4336\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 357.1544 - val_loss: 359.4059\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 343.4736 - val_loss: 343.3073\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 333.0678 - val_loss: 334.1282\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 319.8778 - val_loss: 332.3232\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 311.0511 - val_loss: 308.0165\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 300.3218 - val_loss: 315.5054\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 289.0888 - val_loss: 310.2402\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 279.9496 - val_loss: 293.8268\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 275.5385 - val_loss: 279.7892\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 263.1913 - val_loss: 276.9248\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 259.8143 - val_loss: 268.2317\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 252.7523 - val_loss: 262.3716\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 243.3736 - val_loss: 259.3952\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 242.3394 - val_loss: 248.1981\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 236.1298 - val_loss: 255.6793\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 228.4253 - val_loss: 236.2985\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 229.1229 - val_loss: 232.2066\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 221.1803 - val_loss: 248.3392\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 214.5770 - val_loss: 218.8186\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 209.0356 - val_loss: 228.0809\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 206.9866 - val_loss: 227.1258\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 209.0520 - val_loss: 213.3457\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 196.9891 - val_loss: 207.5966\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 195.2153 - val_loss: 212.8053\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 190.4120 - val_loss: 205.6592\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 190.6780 - val_loss: 199.0139\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 185.2459 - val_loss: 191.2198\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 180.4854 - val_loss: 207.8029\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 177.5382 - val_loss: 190.2516\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 172.3396 - val_loss: 186.0059\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 166.4169 - val_loss: 187.6770\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 166.0401 - val_loss: 177.5381\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 160.3362 - val_loss: 192.8786\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 157.4976 - val_loss: 163.5832\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 157.0388 - val_loss: 174.7096\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 147.6831 - val_loss: 168.5916\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 149.3214 - val_loss: 162.4990\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 144.8731 - val_loss: 162.5003\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 143.5061 - val_loss: 156.0069\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 144.9200 - val_loss: 180.0203\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 141.7719 - val_loss: 156.4324\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 140.1316 - val_loss: 150.3862\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 137.2464 - val_loss: 151.8247\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 134.2330 - val_loss: 146.1097\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 133.8310 - val_loss: 147.8238\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 131.4877 - val_loss: 147.3011\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 131.2957 - val_loss: 166.9354\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.0498 - val_loss: 145.0738\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.9480 - val_loss: 142.5191\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 127.0569 - val_loss: 142.6083\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.2544 - val_loss: 144.8924\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 124.9463 - val_loss: 143.3606\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 121.3529 - val_loss: 142.5056\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 120.3833 - val_loss: 134.9848\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 119.5053 - val_loss: 154.6122\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 117.3603 - val_loss: 146.6576\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 114.3177 - val_loss: 132.3445\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 116.9478 - val_loss: 133.0346\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 113.7216 - val_loss: 159.7525\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 112.8257 - val_loss: 133.2780\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 111.0627 - val_loss: 136.6040\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 110.6422 - val_loss: 138.3781\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 110.8504 - val_loss: 136.0514\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 111.6069 - val_loss: 140.7938\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 112.0567 - val_loss: 147.6585\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 107.5691 - val_loss: 130.9402\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 106.3051 - val_loss: 129.6275\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 103.9919 - val_loss: 138.5520\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.5075 - val_loss: 125.6856\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 105.1735 - val_loss: 138.4992\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.8159 - val_loss: 130.8001\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.7414 - val_loss: 128.2511\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 103.6870 - val_loss: 128.1108\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 103.0829 - val_loss: 132.6386\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.4231 - val_loss: 126.1054\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 99.6204 - val_loss: 135.4409\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 98.2868 - val_loss: 129.3680\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 99.3530 - val_loss: 132.4429\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 96.3408 - val_loss: 125.1131\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 96.3349 - val_loss: 124.8139\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 95.6157 - val_loss: 127.6873\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 95.7962 - val_loss: 131.3625\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.1198 - val_loss: 122.4987\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.9483 - val_loss: 132.8918\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 92.7220 - val_loss: 125.1116\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 94.0730 - val_loss: 129.7331\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 90.9524 - val_loss: 135.6341\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 89.4389 - val_loss: 136.8177\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 90.8794 - val_loss: 126.8190\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 87.6552 - val_loss: 125.6996\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 88.2339 - val_loss: 126.7014\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 87.8522 - val_loss: 129.8407\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 86.5123 - val_loss: 143.8002\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 86.0865 - val_loss: 127.1404\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 84.3834 - val_loss: 126.9437\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 85.2563 - val_loss: 147.6260\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 84.5408 - val_loss: 133.5772\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 84.1709 - val_loss: 126.7949\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 82.7475 - val_loss: 132.4363\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 83.1169 - val_loss: 130.2475\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 81.2084 - val_loss: 124.4961\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 81.2579 - val_loss: 125.8232\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 80.3591 - val_loss: 130.1690\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 130.1690061139329\n",
      "Mean Absolute Error (MAE): 8.686806155658672\n",
      "Root Mean Squared Error (RMSE): 11.409163252137859\n",
      "Time taken: 1226.2510154247284\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 19ms/step - loss: 1380.9332 - val_loss: 1298.3040\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1217.9802 - val_loss: 1195.1217\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1131.2432 - val_loss: 1118.8198\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1066.6429 - val_loss: 1061.1665\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1018.5168 - val_loss: 1018.3378\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 983.1542 - val_loss: 986.8893\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 957.9700 - val_loss: 964.4525\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 940.7914 - val_loss: 949.4730\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 929.8915 - val_loss: 939.8536\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.3755 - val_loss: 934.3622\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 919.9051 - val_loss: 931.1647\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 918.2010 - val_loss: 929.6388\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.4826 - val_loss: 928.8094\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.1859 - val_loss: 928.4664\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.1114 - val_loss: 928.3338\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.1055 - val_loss: 928.2062\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0961 - val_loss: 928.1882\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0827 - val_loss: 928.2097\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0851 - val_loss: 928.1737\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0931 - val_loss: 928.1520\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0573 - val_loss: 928.1642\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0400 - val_loss: 928.1698\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0842 - val_loss: 928.1426\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0848 - val_loss: 928.1541\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0941 - val_loss: 928.1224\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.1236 - val_loss: 928.1503\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0814 - val_loss: 928.1644\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0684 - val_loss: 928.1777\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0557 - val_loss: 928.1945\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0851 - val_loss: 928.2448\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0948 - val_loss: 928.1819\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0999 - val_loss: 928.1629\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0863 - val_loss: 928.1430\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.0759 - val_loss: 928.1146\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0729 - val_loss: 928.0778\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.0757 - val_loss: 928.1713\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 917.1180 - val_loss: 928.1357\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 917.4584 - val_loss: 928.1542\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 909.5526 - val_loss: 913.1628\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 896.4842 - val_loss: 908.5545\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 890.3331 - val_loss: 900.7484\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 884.3798 - val_loss: 896.1803\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 880.1537 - val_loss: 893.6799\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 875.4802 - val_loss: 888.4553\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 871.3010 - val_loss: 883.2460\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 863.1587 - val_loss: 875.9316\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 849.6259 - val_loss: 860.2640\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 834.3367 - val_loss: 846.6357\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 819.8617 - val_loss: 830.6331\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 805.2344 - val_loss: 814.6056\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 786.6332 - val_loss: 797.1022\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 769.5876 - val_loss: 780.9377\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 751.8920 - val_loss: 763.4357\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 735.5418 - val_loss: 746.9493\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 719.5365 - val_loss: 739.4364\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 701.5859 - val_loss: 711.9328\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 684.3830 - val_loss: 694.0330\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 666.1944 - val_loss: 682.6326\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 642.6736 - val_loss: 651.9244\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 619.7914 - val_loss: 645.0200\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 604.0717 - val_loss: 641.0981\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 578.9529 - val_loss: 586.8185\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 557.2229 - val_loss: 556.5319\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 536.8652 - val_loss: 531.3282\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 508.1398 - val_loss: 508.2380\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 488.4174 - val_loss: 491.1718\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 478.3230 - val_loss: 479.4549\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 456.9163 - val_loss: 459.9226\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 438.6288 - val_loss: 439.6174\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 422.5509 - val_loss: 415.6791\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 405.7942 - val_loss: 425.9050\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 393.8284 - val_loss: 392.3593\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 376.9273 - val_loss: 370.2448\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 358.6361 - val_loss: 356.0527\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 349.7637 - val_loss: 345.1682\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 336.3358 - val_loss: 336.2686\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 317.0347 - val_loss: 321.6997\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 315.1806 - val_loss: 305.7328\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 297.9297 - val_loss: 300.2263\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 289.9621 - val_loss: 308.6862\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 275.8595 - val_loss: 282.1492\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 267.1184 - val_loss: 274.1976\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 256.2285 - val_loss: 257.3415\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 250.1330 - val_loss: 248.2558\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 239.7554 - val_loss: 245.8176\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 230.5079 - val_loss: 236.5125\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 225.8930 - val_loss: 241.6213\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 214.3320 - val_loss: 234.7932\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 210.4893 - val_loss: 211.9807\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 200.6638 - val_loss: 200.1654\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 192.2165 - val_loss: 198.4105\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 186.1030 - val_loss: 198.0062\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 180.1036 - val_loss: 186.5626\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 177.1755 - val_loss: 201.8591\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 168.7882 - val_loss: 191.6247\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 163.9561 - val_loss: 163.7936\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 158.2764 - val_loss: 175.6694\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 156.4567 - val_loss: 171.1753\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 150.0389 - val_loss: 164.7805\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 143.2718 - val_loss: 161.3092\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 142.7094 - val_loss: 149.5513\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 136.9157 - val_loss: 153.5511\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 136.7361 - val_loss: 151.1357\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 132.6739 - val_loss: 141.4478\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 129.4497 - val_loss: 147.3620\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 126.9314 - val_loss: 141.8057\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.7135 - val_loss: 139.2659\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 123.6751 - val_loss: 136.9332\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 121.9537 - val_loss: 141.5361\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 120.0847 - val_loss: 147.4590\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 117.1072 - val_loss: 160.7635\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 116.8296 - val_loss: 135.2045\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 114.2278 - val_loss: 127.4023\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 114.4164 - val_loss: 136.5968\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 110.1327 - val_loss: 132.7422\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 110.5743 - val_loss: 133.1038\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 110.5045 - val_loss: 121.7825\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 108.6968 - val_loss: 127.6878\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 106.5562 - val_loss: 126.3924\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 106.6367 - val_loss: 140.8744\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 105.4756 - val_loss: 124.7550\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.5512 - val_loss: 126.0753\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.6790 - val_loss: 125.1370\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 103.5691 - val_loss: 133.7126\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 99.8784 - val_loss: 124.9935\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 99.4637 - val_loss: 121.7137\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 95.6787 - val_loss: 126.3756\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 97.8658 - val_loss: 123.0542\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 95.5092 - val_loss: 121.4913\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 95.8943 - val_loss: 124.0070\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 92.3524 - val_loss: 129.6626\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 93.8287 - val_loss: 123.6562\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 91.0253 - val_loss: 129.7311\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 93.1424 - val_loss: 121.0834\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 89.5797 - val_loss: 129.5487\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 89.5559 - val_loss: 126.4029\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 87.6139 - val_loss: 125.2179\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 86.8531 - val_loss: 128.6678\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 85.4960 - val_loss: 123.1850\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 84.2459 - val_loss: 119.4162\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 85.3940 - val_loss: 119.9870\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 88.7449 - val_loss: 140.5383\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 82.9977 - val_loss: 123.3029\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 81.0145 - val_loss: 122.4384\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 80.3275 - val_loss: 133.9747\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 80.9776 - val_loss: 122.6687\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 78.7705 - val_loss: 122.6240\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 79.4135 - val_loss: 124.6968\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 79.8415 - val_loss: 127.2989\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 75.8390 - val_loss: 119.2512\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 76.9351 - val_loss: 129.3814\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 74.4903 - val_loss: 123.3818\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 76.6608 - val_loss: 125.4893\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.4582 - val_loss: 132.2655\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 73.1264 - val_loss: 142.6199\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 74.9800 - val_loss: 129.7860\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.9229 - val_loss: 127.2352\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 70.4063 - val_loss: 129.3977\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 70.0126 - val_loss: 122.1339\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 69.0286 - val_loss: 119.1158\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 68.8630 - val_loss: 133.2348\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 68.6699 - val_loss: 125.4184\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 67.0730 - val_loss: 126.3383\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 66.2415 - val_loss: 133.8736\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 66.3211 - val_loss: 124.1495\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.7191 - val_loss: 126.6476\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.3483 - val_loss: 123.2449\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.4191 - val_loss: 128.5074\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 64.7631 - val_loss: 125.3167\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 64.5743 - val_loss: 127.3269\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.6078 - val_loss: 127.1299\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 60.4302 - val_loss: 131.8454\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 57.5650 - val_loss: 132.6973\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 56.9401 - val_loss: 124.7559\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 59.8269 - val_loss: 138.2171\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 57.2359 - val_loss: 125.2530\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 55.6542 - val_loss: 122.7896\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 55.2787 - val_loss: 127.1422\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 53.7534 - val_loss: 125.7896\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 55.2990 - val_loss: 128.8173\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 52.5379 - val_loss: 128.1166\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 52.8276 - val_loss: 127.4142\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 52.5561 - val_loss: 126.6480\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 51.4448 - val_loss: 131.7812\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 51.1816 - val_loss: 127.6098\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 50.4338 - val_loss: 129.6456\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 48.3183 - val_loss: 132.3780\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 51.2425 - val_loss: 137.7957\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 49.8570 - val_loss: 124.0034\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 46.9107 - val_loss: 131.1802\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 45.1994 - val_loss: 135.8564\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 46.6373 - val_loss: 128.1505\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 44.6351 - val_loss: 135.5019\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 44.6226 - val_loss: 130.1507\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 45.7853 - val_loss: 131.0032\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 44.4858 - val_loss: 135.1194\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 42.4857 - val_loss: 131.2157\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 43.2265 - val_loss: 134.3781\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 40.7759 - val_loss: 136.6835\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 42.4777 - val_loss: 136.4301\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 136.43013566799397\n",
      "Mean Absolute Error (MAE): 8.74061154190158\n",
      "Root Mean Squared Error (RMSE): 11.680331145476739\n",
      "Time taken: 1206.8442673683167\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 17ms/step - loss: 1386.3864 - val_loss: 1227.4454\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 1220.6724 - val_loss: 1128.5648\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1133.9092 - val_loss: 1057.3369\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1069.9457 - val_loss: 1004.5327\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1022.6167 - val_loss: 965.9310\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 988.2229 - val_loss: 938.3987\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 963.3356 - val_loss: 918.2429\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 946.2943 - val_loss: 906.3002\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 936.3436 - val_loss: 899.5666\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 930.7236 - val_loss: 896.1303\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 927.7693 - val_loss: 894.6156\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.4779 - val_loss: 894.0460\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.8793 - val_loss: 893.9094\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6882 - val_loss: 893.9210\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6396 - val_loss: 893.9820\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6169 - val_loss: 893.9777\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6502 - val_loss: 893.9288\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6647 - val_loss: 893.9922\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.5939 - val_loss: 894.1105\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 925.6365 - val_loss: 894.1616\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.5988 - val_loss: 894.1561\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6132 - val_loss: 894.1075\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 925.5892 - val_loss: 894.1440\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 925.6163 - val_loss: 894.1354\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6486 - val_loss: 894.1207\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.5926 - val_loss: 894.0608\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6420 - val_loss: 894.1232\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6044 - val_loss: 894.0969\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 925.6152 - val_loss: 894.0932\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 925.5977 - val_loss: 894.1342\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 925.6207 - val_loss: 894.1064\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.5831 - val_loss: 894.0100\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6241 - val_loss: 894.0310\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.4105 - val_loss: 880.4408\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 909.7194 - val_loss: 869.6058\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 902.0676 - val_loss: 865.9144\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 896.5526 - val_loss: 857.6091\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 889.0261 - val_loss: 849.8881\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 881.2365 - val_loss: 844.3742\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 874.8663 - val_loss: 837.9982\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 869.0303 - val_loss: 835.4268\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 863.7006 - val_loss: 827.9937\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 856.9575 - val_loss: 831.8660\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 850.5613 - val_loss: 812.6160\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 835.4506 - val_loss: 799.3160\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 814.8375 - val_loss: 777.7578\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 795.9033 - val_loss: 769.0914\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 777.5950 - val_loss: 737.6644\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 752.5693 - val_loss: 714.2480\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 729.6405 - val_loss: 696.4091\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 705.8304 - val_loss: 670.6113\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 682.2818 - val_loss: 641.7742\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 658.7869 - val_loss: 628.6266\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 635.3748 - val_loss: 610.1895\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 613.2112 - val_loss: 588.0876\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 594.7629 - val_loss: 559.9662\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 567.2880 - val_loss: 538.7126\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 549.7156 - val_loss: 523.7269\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 521.4223 - val_loss: 510.8980\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 500.2087 - val_loss: 493.3814\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 481.3447 - val_loss: 461.9182\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 466.7716 - val_loss: 440.3927\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 444.9249 - val_loss: 427.2562\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 429.1974 - val_loss: 409.2553\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 416.9532 - val_loss: 397.2745\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 397.0737 - val_loss: 385.1995\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 378.3954 - val_loss: 397.5099\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 368.2377 - val_loss: 355.2951\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 354.8761 - val_loss: 342.3480\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 339.0520 - val_loss: 328.2300\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 330.8733 - val_loss: 322.0977\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 315.0271 - val_loss: 318.8544\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 309.0846 - val_loss: 298.3774\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 290.6242 - val_loss: 304.5663\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 282.0210 - val_loss: 274.4719\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 268.7959 - val_loss: 279.7477\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 259.7652 - val_loss: 255.7886\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 255.2555 - val_loss: 272.3698\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 244.0267 - val_loss: 246.1930\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 239.0638 - val_loss: 241.5395\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 232.2204 - val_loss: 235.8587\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 219.8640 - val_loss: 259.5383\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 218.1427 - val_loss: 224.3760\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 208.7168 - val_loss: 208.5299\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 204.1607 - val_loss: 207.0279\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 200.1030 - val_loss: 206.2194\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 194.3167 - val_loss: 220.9101\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 193.6308 - val_loss: 204.1939\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 186.6503 - val_loss: 190.6589\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 181.3748 - val_loss: 192.7612\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 176.8708 - val_loss: 182.9919\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 172.6387 - val_loss: 180.3988\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 167.2709 - val_loss: 170.8280\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 167.8678 - val_loss: 169.5559\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 163.1623 - val_loss: 176.4581\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 159.0293 - val_loss: 167.2881\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 156.8367 - val_loss: 164.7465\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 153.0466 - val_loss: 168.5512\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 154.5801 - val_loss: 162.0040\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 149.4994 - val_loss: 168.1917\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 147.1548 - val_loss: 159.5259\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 143.7910 - val_loss: 174.7313\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 144.5278 - val_loss: 146.6473\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 140.8558 - val_loss: 152.0706\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 137.0858 - val_loss: 167.2594\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 135.2504 - val_loss: 152.7691\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 134.3411 - val_loss: 146.1990\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 134.1598 - val_loss: 144.7343\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 131.8681 - val_loss: 149.5406\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 128.4425 - val_loss: 150.1619\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 126.7936 - val_loss: 148.2229\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 126.6187 - val_loss: 144.2325\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 125.7853 - val_loss: 139.0830\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 123.7711 - val_loss: 177.1823\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 123.5570 - val_loss: 135.4760\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 121.9180 - val_loss: 151.8542\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 119.7257 - val_loss: 142.3772\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 118.5131 - val_loss: 140.7009\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 120.6407 - val_loss: 136.8369\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 115.5304 - val_loss: 134.7369\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 115.7173 - val_loss: 141.1291\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 113.5039 - val_loss: 135.4467\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 113.9308 - val_loss: 140.6546\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 112.5671 - val_loss: 137.2985\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 112.1756 - val_loss: 129.2420\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 111.4011 - val_loss: 136.3781\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 106.8666 - val_loss: 131.8239\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 108.4722 - val_loss: 140.6575\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 106.0785 - val_loss: 148.4824\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 105.7869 - val_loss: 136.4455\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.0091 - val_loss: 133.0415\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 104.7722 - val_loss: 130.4874\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 102.4635 - val_loss: 136.0236\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.0090 - val_loss: 130.2223\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 99.1554 - val_loss: 142.2119\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 99.2302 - val_loss: 127.3977\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.4110 - val_loss: 130.1850\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 97.2088 - val_loss: 134.3642\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 95.9156 - val_loss: 132.9575\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 96.4666 - val_loss: 131.9781\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 94.2610 - val_loss: 129.0053\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 94.1263 - val_loss: 142.2933\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 94.1768 - val_loss: 130.7127\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 92.0842 - val_loss: 133.0026\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.3045 - val_loss: 129.9756\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 90.8839 - val_loss: 129.8734\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 89.3705 - val_loss: 133.8266\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.1289 - val_loss: 131.8451\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 89.0140 - val_loss: 134.4935\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 87.2824 - val_loss: 126.8206\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 87.0096 - val_loss: 128.3460\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 84.9291 - val_loss: 134.0769\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 14ms/step - loss: 86.7799 - val_loss: 133.5348\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 85.9326 - val_loss: 133.0357\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 83.2524 - val_loss: 131.6236\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 85.9485 - val_loss: 131.0389\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 83.7614 - val_loss: 125.9682\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 82.0020 - val_loss: 132.0650\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 82.5436 - val_loss: 129.8175\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 81.5925 - val_loss: 131.3031\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 78.4455 - val_loss: 134.5110\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 78.9115 - val_loss: 135.6138\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 78.2809 - val_loss: 132.6606\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 75.6059 - val_loss: 130.0805\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 75.8867 - val_loss: 137.0033\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 75.0671 - val_loss: 129.2427\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 76.5695 - val_loss: 142.8368\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 76.3990 - val_loss: 131.9294\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 74.2785 - val_loss: 132.7264\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.1529 - val_loss: 129.4256\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 72.2176 - val_loss: 129.4662\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.1510 - val_loss: 138.5762\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 71.2434 - val_loss: 130.4609\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 69.9718 - val_loss: 132.3785\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 69.7762 - val_loss: 135.2614\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 70.2956 - val_loss: 137.5440\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 68.6721 - val_loss: 136.7063\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 67.5078 - val_loss: 134.3311\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 67.4100 - val_loss: 132.5367\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 69.3040 - val_loss: 143.5658\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 65.5750 - val_loss: 134.1470\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.7139 - val_loss: 139.5027\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 65.1827 - val_loss: 136.7746\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.6562 - val_loss: 134.6682\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 64.8030 - val_loss: 135.4631\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 61.2788 - val_loss: 134.9827\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 62.4071 - val_loss: 140.5561\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 61.9943 - val_loss: 134.4529\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 60.2965 - val_loss: 140.5598\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 61.3031 - val_loss: 146.7001\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 59.3015 - val_loss: 136.7484\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 58.9815 - val_loss: 137.7560\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.4631 - val_loss: 138.7980\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 55.5896 - val_loss: 137.6063\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.0669 - val_loss: 140.7962\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 55.4049 - val_loss: 141.2432\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 54.2719 - val_loss: 141.7480\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 55.8772 - val_loss: 144.4546\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 54.8015 - val_loss: 143.0404\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 52.2019 - val_loss: 140.8940\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 140.8960699023212\n",
      "Mean Absolute Error (MAE): 8.78422825553146\n",
      "Root Mean Squared Error (RMSE): 11.869965033744673\n",
      "Time taken: 1159.5726025104523\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 17ms/step - loss: 1366.5480 - val_loss: 1312.1432\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1199.4963 - val_loss: 1211.7407\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1113.3191 - val_loss: 1138.8010\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1049.7139 - val_loss: 1084.1011\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1002.6362 - val_loss: 1043.8092\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 968.6083 - val_loss: 1014.8740\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 944.7887 - val_loss: 994.8923\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 928.9081 - val_loss: 981.7078\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 918.9184 - val_loss: 973.7783\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.1890 - val_loss: 969.1823\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 910.1945 - val_loss: 966.8345\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 908.8083 - val_loss: 965.7824\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 908.2275 - val_loss: 965.3462\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9987 - val_loss: 965.1425\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9288 - val_loss: 965.0136\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9070 - val_loss: 964.9534\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9143 - val_loss: 965.0087\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.8793 - val_loss: 965.0565\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 907.8936 - val_loss: 965.0086\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 907.8961 - val_loss: 964.9972\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 907.9405 - val_loss: 965.0143\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9037 - val_loss: 964.9866\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9280 - val_loss: 964.9864\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9220 - val_loss: 965.0419\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.8933 - val_loss: 965.0186\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9153 - val_loss: 965.0316\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9349 - val_loss: 965.0507\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9128 - val_loss: 965.0089\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.8884 - val_loss: 964.9479\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9140 - val_loss: 964.9933\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.8791 - val_loss: 965.0247\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9221 - val_loss: 965.0633\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.8957 - val_loss: 964.9812\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9025 - val_loss: 965.0474\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9025 - val_loss: 965.0125\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.8991 - val_loss: 965.0392\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9350 - val_loss: 965.0849\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 907.9609 - val_loss: 965.0011\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 907.9356 - val_loss: 965.0172\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 907.6943 - val_loss: 962.6243\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 896.7120 - val_loss: 947.8240\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 887.1428 - val_loss: 941.6880\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 881.6506 - val_loss: 936.6137\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 877.1037 - val_loss: 934.6998\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 872.5709 - val_loss: 927.5336\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 867.0595 - val_loss: 923.4152\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 861.4000 - val_loss: 917.0668\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 855.9865 - val_loss: 909.7684\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 850.6481 - val_loss: 905.0220\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 844.4474 - val_loss: 896.3175\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 837.3918 - val_loss: 886.9873\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 831.7632 - val_loss: 879.9277\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 820.1458 - val_loss: 870.3849\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 802.9656 - val_loss: 836.1310\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 784.1248 - val_loss: 809.4763\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 757.9286 - val_loss: 792.5109\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 733.7903 - val_loss: 769.7106\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 708.0237 - val_loss: 736.9630\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 676.9159 - val_loss: 704.0677\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 653.0148 - val_loss: 685.5933\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 628.4888 - val_loss: 649.7540\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 605.0322 - val_loss: 625.6847\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 582.8973 - val_loss: 600.5049\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 557.0266 - val_loss: 588.3824\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 534.6058 - val_loss: 558.9376\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 515.7952 - val_loss: 536.2939\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 492.3825 - val_loss: 543.2704\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 472.8297 - val_loss: 499.8898\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 454.0190 - val_loss: 480.5291\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 440.6218 - val_loss: 464.0291\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 417.1908 - val_loss: 450.0594\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 406.1345 - val_loss: 426.5549\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 386.8075 - val_loss: 417.8631\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 376.9637 - val_loss: 398.6376\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 359.4743 - val_loss: 385.0242\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 343.5067 - val_loss: 373.7267\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 14ms/step - loss: 334.4144 - val_loss: 354.0526\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 314.2783 - val_loss: 346.3263\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 303.4513 - val_loss: 337.7034\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 291.1071 - val_loss: 330.3131\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 287.5529 - val_loss: 332.2299\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 268.4365 - val_loss: 304.9701\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 261.4885 - val_loss: 295.9230\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 248.6535 - val_loss: 286.9088\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 248.3078 - val_loss: 271.6581\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 233.5424 - val_loss: 264.1150\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 229.3793 - val_loss: 285.6431\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 222.1474 - val_loss: 254.4200\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 211.9070 - val_loss: 238.0987\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 205.2362 - val_loss: 236.3625\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 200.9977 - val_loss: 233.0521\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 195.3767 - val_loss: 240.2629\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 186.0599 - val_loss: 217.0523\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 181.9341 - val_loss: 226.6164\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 177.5115 - val_loss: 216.0648\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 173.2778 - val_loss: 202.5191\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 164.4771 - val_loss: 196.3557\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 161.8677 - val_loss: 191.3671\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 159.8920 - val_loss: 183.5582\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 152.0061 - val_loss: 207.6836\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 151.5027 - val_loss: 183.9036\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 146.6451 - val_loss: 167.9725\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 142.3896 - val_loss: 167.4894\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 138.8007 - val_loss: 173.1942\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 136.7792 - val_loss: 158.2687\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 132.3994 - val_loss: 170.1593\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 130.2066 - val_loss: 157.1552\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 128.7134 - val_loss: 151.5628\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.7641 - val_loss: 153.4465\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 121.5246 - val_loss: 142.3550\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 121.3103 - val_loss: 151.6018\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 118.7948 - val_loss: 152.9790\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 120.5333 - val_loss: 154.2159\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 116.7182 - val_loss: 139.1885\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 115.3038 - val_loss: 147.3358\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 112.6817 - val_loss: 145.4601\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 112.4137 - val_loss: 139.8165\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 110.5379 - val_loss: 147.1501\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 110.5503 - val_loss: 146.9477\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 108.5385 - val_loss: 148.8750\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 106.0638 - val_loss: 136.0403\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.7378 - val_loss: 145.4456\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.6189 - val_loss: 141.6929\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 101.6057 - val_loss: 163.0087\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.7686 - val_loss: 139.0633\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 100.0435 - val_loss: 142.2408\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 99.4401 - val_loss: 142.9344\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.8711 - val_loss: 135.1457\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 96.8822 - val_loss: 150.2946\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 97.5576 - val_loss: 133.7737\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 93.9297 - val_loss: 134.0482\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 94.1450 - val_loss: 134.9728\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 93.5674 - val_loss: 138.8444\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 93.3246 - val_loss: 136.0967\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 90.1226 - val_loss: 138.0670\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.6156 - val_loss: 149.0176\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 89.0180 - val_loss: 149.0896\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 88.3497 - val_loss: 138.5811\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 90.2787 - val_loss: 144.6560\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 86.9599 - val_loss: 130.7561\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 86.4118 - val_loss: 144.2073\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 85.4285 - val_loss: 140.4236\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 84.0205 - val_loss: 147.8049\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 83.2247 - val_loss: 145.0484\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 82.9941 - val_loss: 147.1187\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 81.2708 - val_loss: 153.1432\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 80.4120 - val_loss: 139.2163\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 80.0914 - val_loss: 146.4585\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 79.4161 - val_loss: 145.0385\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 77.2570 - val_loss: 142.7817\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 76.5948 - val_loss: 167.2594\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 77.8429 - val_loss: 146.0809\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 76.2993 - val_loss: 154.1830\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 76.1912 - val_loss: 146.8546\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 73.6855 - val_loss: 144.5321\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 73.3807 - val_loss: 145.2813\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 79.5129 - val_loss: 158.9706\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 70.0733 - val_loss: 147.2574\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 71.3894 - val_loss: 147.5179\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 71.5089 - val_loss: 148.9775\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 69.3215 - val_loss: 144.3435\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 68.5611 - val_loss: 141.0563\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 68.3226 - val_loss: 147.4589\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 65.5726 - val_loss: 147.1159\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 89.8013 - val_loss: 157.3370\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.7703 - val_loss: 147.2128\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 64.6616 - val_loss: 142.5053\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 61.7277 - val_loss: 140.7431\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 63.2363 - val_loss: 150.4391\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 62.6053 - val_loss: 144.0058\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 62.4960 - val_loss: 147.3754\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 61.1290 - val_loss: 153.7336\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 61.8118 - val_loss: 142.1345\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 58.9534 - val_loss: 146.6911\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 61.9347 - val_loss: 143.5765\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 59.2452 - val_loss: 150.2396\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 59.1763 - val_loss: 154.0481\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 56.5726 - val_loss: 150.5308\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 57.6708 - val_loss: 152.5878\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 56.6913 - val_loss: 144.3536\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 54.3493 - val_loss: 142.4249\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 54.0059 - val_loss: 151.1302\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.0690 - val_loss: 150.3601\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 53.5188 - val_loss: 149.2589\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 52.4593 - val_loss: 143.7448\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 50.9319 - val_loss: 144.1195\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 50.6919 - val_loss: 149.6650\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 49.5233 - val_loss: 146.3978\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 51.0193 - val_loss: 145.6786\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 49.2671 - val_loss: 153.4821\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 53.4273 - val_loss: 142.7580\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 49.6962 - val_loss: 147.6677\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 45.6505 - val_loss: 150.7603\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 44.1228 - val_loss: 151.8399\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 46.5329 - val_loss: 153.1837\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 46.8815 - val_loss: 150.3461\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 43.0675 - val_loss: 158.5651\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 43.6351 - val_loss: 154.7968\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 41.7598 - val_loss: 151.4407\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 43.4635 - val_loss: 151.6794\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 151.6795292070224\n",
      "Mean Absolute Error (MAE): 8.778804700937584\n",
      "Root Mean Squared Error (RMSE): 12.31582434135135\n",
      "Time taken: 1168.44904088974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 48, 512)           1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 48, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_3092\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold         MSE       MAE       RMSE   Time taken\n",
      "0        1  134.001279  8.565629  11.575892  1241.409513\n",
      "1        2  130.169006  8.686806  11.409163  1226.251015\n",
      "2        3  136.430136  8.740612  11.680331  1206.844267\n",
      "3        4  140.896070  8.784228  11.869965  1159.572603\n",
      "4        5  151.679529  8.778805  12.315824  1168.449041\n",
      "5  Average  138.635204  8.711216  11.770235  1200.505288\n",
      "Results saved to 'DL_Result_PL_model_2_Scattered_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_2_Scattered_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'DL_Result_PL_model_2_Scattered_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
