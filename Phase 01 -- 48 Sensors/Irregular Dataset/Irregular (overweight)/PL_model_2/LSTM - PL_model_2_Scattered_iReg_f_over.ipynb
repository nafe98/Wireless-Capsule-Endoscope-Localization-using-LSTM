{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_2_Scattered_iReg_f_over.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.015811</td>\n",
       "      <td>87.079352</td>\n",
       "      <td>66.557988</td>\n",
       "      <td>83.477127</td>\n",
       "      <td>82.924537</td>\n",
       "      <td>98.016051</td>\n",
       "      <td>81.155271</td>\n",
       "      <td>80.318841</td>\n",
       "      <td>86.289190</td>\n",
       "      <td>80.803460</td>\n",
       "      <td>...</td>\n",
       "      <td>64.382199</td>\n",
       "      <td>78.044421</td>\n",
       "      <td>76.333780</td>\n",
       "      <td>80.585743</td>\n",
       "      <td>79.712478</td>\n",
       "      <td>85.675612</td>\n",
       "      <td>73.352786</td>\n",
       "      <td>92.344344</td>\n",
       "      <td>56.075480</td>\n",
       "      <td>84.186219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.411546</td>\n",
       "      <td>78.935969</td>\n",
       "      <td>64.281244</td>\n",
       "      <td>75.929107</td>\n",
       "      <td>88.542239</td>\n",
       "      <td>65.777430</td>\n",
       "      <td>77.351480</td>\n",
       "      <td>84.200773</td>\n",
       "      <td>85.745554</td>\n",
       "      <td>76.266443</td>\n",
       "      <td>...</td>\n",
       "      <td>78.666453</td>\n",
       "      <td>81.409869</td>\n",
       "      <td>72.071530</td>\n",
       "      <td>73.681691</td>\n",
       "      <td>87.605202</td>\n",
       "      <td>76.050438</td>\n",
       "      <td>79.461153</td>\n",
       "      <td>73.653767</td>\n",
       "      <td>55.563222</td>\n",
       "      <td>83.862769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.411995</td>\n",
       "      <td>87.317315</td>\n",
       "      <td>72.546540</td>\n",
       "      <td>77.271697</td>\n",
       "      <td>93.110096</td>\n",
       "      <td>85.770885</td>\n",
       "      <td>81.424461</td>\n",
       "      <td>94.755188</td>\n",
       "      <td>91.975696</td>\n",
       "      <td>74.468728</td>\n",
       "      <td>...</td>\n",
       "      <td>74.664997</td>\n",
       "      <td>81.896947</td>\n",
       "      <td>67.347589</td>\n",
       "      <td>61.710086</td>\n",
       "      <td>83.936005</td>\n",
       "      <td>86.728580</td>\n",
       "      <td>87.433082</td>\n",
       "      <td>83.676800</td>\n",
       "      <td>54.095236</td>\n",
       "      <td>70.735974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.860662</td>\n",
       "      <td>75.171591</td>\n",
       "      <td>66.511190</td>\n",
       "      <td>75.335435</td>\n",
       "      <td>86.749672</td>\n",
       "      <td>92.725955</td>\n",
       "      <td>74.477870</td>\n",
       "      <td>94.291663</td>\n",
       "      <td>80.538937</td>\n",
       "      <td>91.161372</td>\n",
       "      <td>...</td>\n",
       "      <td>60.005406</td>\n",
       "      <td>80.244252</td>\n",
       "      <td>82.853566</td>\n",
       "      <td>76.956383</td>\n",
       "      <td>75.972086</td>\n",
       "      <td>81.969438</td>\n",
       "      <td>82.472468</td>\n",
       "      <td>78.391222</td>\n",
       "      <td>69.501299</td>\n",
       "      <td>64.732297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.364328</td>\n",
       "      <td>93.813363</td>\n",
       "      <td>63.816744</td>\n",
       "      <td>74.894551</td>\n",
       "      <td>78.468572</td>\n",
       "      <td>86.792705</td>\n",
       "      <td>76.932616</td>\n",
       "      <td>94.095866</td>\n",
       "      <td>90.212163</td>\n",
       "      <td>80.678981</td>\n",
       "      <td>...</td>\n",
       "      <td>74.417818</td>\n",
       "      <td>74.472188</td>\n",
       "      <td>97.144534</td>\n",
       "      <td>76.033392</td>\n",
       "      <td>99.380429</td>\n",
       "      <td>82.118814</td>\n",
       "      <td>81.876570</td>\n",
       "      <td>84.613716</td>\n",
       "      <td>54.336007</td>\n",
       "      <td>63.388750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>82.925078</td>\n",
       "      <td>85.056123</td>\n",
       "      <td>75.638201</td>\n",
       "      <td>60.898821</td>\n",
       "      <td>86.691446</td>\n",
       "      <td>96.835173</td>\n",
       "      <td>78.978049</td>\n",
       "      <td>84.194262</td>\n",
       "      <td>92.321167</td>\n",
       "      <td>72.536704</td>\n",
       "      <td>...</td>\n",
       "      <td>87.756942</td>\n",
       "      <td>77.359634</td>\n",
       "      <td>66.711044</td>\n",
       "      <td>54.290729</td>\n",
       "      <td>84.742187</td>\n",
       "      <td>77.249460</td>\n",
       "      <td>77.721910</td>\n",
       "      <td>78.859700</td>\n",
       "      <td>75.614738</td>\n",
       "      <td>70.947172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>94.422995</td>\n",
       "      <td>89.226249</td>\n",
       "      <td>73.931346</td>\n",
       "      <td>63.087668</td>\n",
       "      <td>94.450733</td>\n",
       "      <td>81.898077</td>\n",
       "      <td>62.718210</td>\n",
       "      <td>88.219794</td>\n",
       "      <td>74.275413</td>\n",
       "      <td>68.953841</td>\n",
       "      <td>...</td>\n",
       "      <td>82.477134</td>\n",
       "      <td>74.933372</td>\n",
       "      <td>72.775093</td>\n",
       "      <td>67.348402</td>\n",
       "      <td>87.181066</td>\n",
       "      <td>84.173965</td>\n",
       "      <td>89.559115</td>\n",
       "      <td>77.098196</td>\n",
       "      <td>70.797202</td>\n",
       "      <td>53.884827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>83.952863</td>\n",
       "      <td>66.065812</td>\n",
       "      <td>84.551264</td>\n",
       "      <td>56.552603</td>\n",
       "      <td>89.824039</td>\n",
       "      <td>89.198244</td>\n",
       "      <td>89.166751</td>\n",
       "      <td>88.622224</td>\n",
       "      <td>77.223711</td>\n",
       "      <td>79.464550</td>\n",
       "      <td>...</td>\n",
       "      <td>73.747033</td>\n",
       "      <td>84.761981</td>\n",
       "      <td>66.271831</td>\n",
       "      <td>69.599351</td>\n",
       "      <td>82.467908</td>\n",
       "      <td>76.711520</td>\n",
       "      <td>95.792929</td>\n",
       "      <td>72.814163</td>\n",
       "      <td>67.916404</td>\n",
       "      <td>66.695185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>83.310233</td>\n",
       "      <td>84.973098</td>\n",
       "      <td>72.042251</td>\n",
       "      <td>57.899950</td>\n",
       "      <td>89.732326</td>\n",
       "      <td>74.722796</td>\n",
       "      <td>83.250694</td>\n",
       "      <td>89.482927</td>\n",
       "      <td>89.880388</td>\n",
       "      <td>79.130474</td>\n",
       "      <td>...</td>\n",
       "      <td>72.287636</td>\n",
       "      <td>82.705989</td>\n",
       "      <td>77.745400</td>\n",
       "      <td>72.320879</td>\n",
       "      <td>95.100104</td>\n",
       "      <td>76.552170</td>\n",
       "      <td>84.367495</td>\n",
       "      <td>86.212913</td>\n",
       "      <td>66.282294</td>\n",
       "      <td>70.109882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>72.910645</td>\n",
       "      <td>90.936111</td>\n",
       "      <td>69.508792</td>\n",
       "      <td>64.992568</td>\n",
       "      <td>82.610572</td>\n",
       "      <td>90.872479</td>\n",
       "      <td>88.106736</td>\n",
       "      <td>77.286704</td>\n",
       "      <td>76.902771</td>\n",
       "      <td>75.120663</td>\n",
       "      <td>...</td>\n",
       "      <td>75.382492</td>\n",
       "      <td>73.565450</td>\n",
       "      <td>76.732590</td>\n",
       "      <td>68.218872</td>\n",
       "      <td>82.177815</td>\n",
       "      <td>88.754353</td>\n",
       "      <td>87.109144</td>\n",
       "      <td>91.486898</td>\n",
       "      <td>74.986697</td>\n",
       "      <td>66.529407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5   \\\n",
       "0     92.015811  87.079352  66.557988  83.477127  82.924537  98.016051   \n",
       "1     70.411546  78.935969  64.281244  75.929107  88.542239  65.777430   \n",
       "2     73.411995  87.317315  72.546540  77.271697  93.110096  85.770885   \n",
       "3     77.860662  75.171591  66.511190  75.335435  86.749672  92.725955   \n",
       "4     63.364328  93.813363  63.816744  74.894551  78.468572  86.792705   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  82.925078  85.056123  75.638201  60.898821  86.691446  96.835173   \n",
       "2439  94.422995  89.226249  73.931346  63.087668  94.450733  81.898077   \n",
       "2440  83.952863  66.065812  84.551264  56.552603  89.824039  89.198244   \n",
       "2441  83.310233  84.973098  72.042251  57.899950  89.732326  74.722796   \n",
       "2442  72.910645  90.936111  69.508792  64.992568  82.610572  90.872479   \n",
       "\n",
       "             6          7          8          9   ...         38         39  \\\n",
       "0     81.155271  80.318841  86.289190  80.803460  ...  64.382199  78.044421   \n",
       "1     77.351480  84.200773  85.745554  76.266443  ...  78.666453  81.409869   \n",
       "2     81.424461  94.755188  91.975696  74.468728  ...  74.664997  81.896947   \n",
       "3     74.477870  94.291663  80.538937  91.161372  ...  60.005406  80.244252   \n",
       "4     76.932616  94.095866  90.212163  80.678981  ...  74.417818  74.472188   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  78.978049  84.194262  92.321167  72.536704  ...  87.756942  77.359634   \n",
       "2439  62.718210  88.219794  74.275413  68.953841  ...  82.477134  74.933372   \n",
       "2440  89.166751  88.622224  77.223711  79.464550  ...  73.747033  84.761981   \n",
       "2441  83.250694  89.482927  89.880388  79.130474  ...  72.287636  82.705989   \n",
       "2442  88.106736  77.286704  76.902771  75.120663  ...  75.382492  73.565450   \n",
       "\n",
       "             40         41         42         43         44         45  \\\n",
       "0     76.333780  80.585743  79.712478  85.675612  73.352786  92.344344   \n",
       "1     72.071530  73.681691  87.605202  76.050438  79.461153  73.653767   \n",
       "2     67.347589  61.710086  83.936005  86.728580  87.433082  83.676800   \n",
       "3     82.853566  76.956383  75.972086  81.969438  82.472468  78.391222   \n",
       "4     97.144534  76.033392  99.380429  82.118814  81.876570  84.613716   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  66.711044  54.290729  84.742187  77.249460  77.721910  78.859700   \n",
       "2439  72.775093  67.348402  87.181066  84.173965  89.559115  77.098196   \n",
       "2440  66.271831  69.599351  82.467908  76.711520  95.792929  72.814163   \n",
       "2441  77.745400  72.320879  95.100104  76.552170  84.367495  86.212913   \n",
       "2442  76.732590  68.218872  82.177815  88.754353  87.109144  91.486898   \n",
       "\n",
       "             46         47  \n",
       "0     56.075480  84.186219  \n",
       "1     55.563222  83.862769  \n",
       "2     54.095236  70.735974  \n",
       "3     69.501299  64.732297  \n",
       "4     54.336007  63.388750  \n",
       "...         ...        ...  \n",
       "2438  75.614738  70.947172  \n",
       "2439  70.797202  53.884827  \n",
       "2440  67.916404  66.695185  \n",
       "2441  66.282294  70.109882  \n",
       "2442  74.986697  66.529407  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.015811</td>\n",
       "      <td>87.079352</td>\n",
       "      <td>66.557988</td>\n",
       "      <td>83.477127</td>\n",
       "      <td>82.924537</td>\n",
       "      <td>98.016051</td>\n",
       "      <td>81.155271</td>\n",
       "      <td>80.318841</td>\n",
       "      <td>86.289190</td>\n",
       "      <td>80.803460</td>\n",
       "      <td>...</td>\n",
       "      <td>64.382199</td>\n",
       "      <td>78.044421</td>\n",
       "      <td>76.333780</td>\n",
       "      <td>80.585743</td>\n",
       "      <td>79.712478</td>\n",
       "      <td>85.675612</td>\n",
       "      <td>73.352786</td>\n",
       "      <td>92.344344</td>\n",
       "      <td>56.075480</td>\n",
       "      <td>84.186219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.411546</td>\n",
       "      <td>78.935969</td>\n",
       "      <td>64.281244</td>\n",
       "      <td>75.929107</td>\n",
       "      <td>88.542239</td>\n",
       "      <td>65.777430</td>\n",
       "      <td>77.351480</td>\n",
       "      <td>84.200773</td>\n",
       "      <td>85.745554</td>\n",
       "      <td>76.266443</td>\n",
       "      <td>...</td>\n",
       "      <td>78.666453</td>\n",
       "      <td>81.409869</td>\n",
       "      <td>72.071530</td>\n",
       "      <td>73.681691</td>\n",
       "      <td>87.605202</td>\n",
       "      <td>76.050438</td>\n",
       "      <td>79.461153</td>\n",
       "      <td>73.653767</td>\n",
       "      <td>55.563222</td>\n",
       "      <td>83.862769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.411995</td>\n",
       "      <td>87.317315</td>\n",
       "      <td>72.546540</td>\n",
       "      <td>77.271697</td>\n",
       "      <td>93.110096</td>\n",
       "      <td>85.770885</td>\n",
       "      <td>81.424461</td>\n",
       "      <td>94.755188</td>\n",
       "      <td>91.975696</td>\n",
       "      <td>74.468728</td>\n",
       "      <td>...</td>\n",
       "      <td>74.664997</td>\n",
       "      <td>81.896947</td>\n",
       "      <td>67.347589</td>\n",
       "      <td>61.710086</td>\n",
       "      <td>83.936005</td>\n",
       "      <td>86.728580</td>\n",
       "      <td>87.433082</td>\n",
       "      <td>83.676800</td>\n",
       "      <td>54.095236</td>\n",
       "      <td>70.735974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.860662</td>\n",
       "      <td>75.171591</td>\n",
       "      <td>66.511190</td>\n",
       "      <td>75.335435</td>\n",
       "      <td>86.749672</td>\n",
       "      <td>92.725955</td>\n",
       "      <td>74.477870</td>\n",
       "      <td>94.291663</td>\n",
       "      <td>80.538937</td>\n",
       "      <td>91.161372</td>\n",
       "      <td>...</td>\n",
       "      <td>60.005406</td>\n",
       "      <td>80.244252</td>\n",
       "      <td>82.853566</td>\n",
       "      <td>76.956383</td>\n",
       "      <td>75.972086</td>\n",
       "      <td>81.969438</td>\n",
       "      <td>82.472468</td>\n",
       "      <td>78.391222</td>\n",
       "      <td>69.501299</td>\n",
       "      <td>64.732297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.364328</td>\n",
       "      <td>93.813363</td>\n",
       "      <td>63.816744</td>\n",
       "      <td>74.894551</td>\n",
       "      <td>78.468572</td>\n",
       "      <td>86.792705</td>\n",
       "      <td>76.932616</td>\n",
       "      <td>94.095866</td>\n",
       "      <td>90.212163</td>\n",
       "      <td>80.678981</td>\n",
       "      <td>...</td>\n",
       "      <td>74.417818</td>\n",
       "      <td>74.472188</td>\n",
       "      <td>97.144534</td>\n",
       "      <td>76.033392</td>\n",
       "      <td>99.380429</td>\n",
       "      <td>82.118814</td>\n",
       "      <td>81.876570</td>\n",
       "      <td>84.613716</td>\n",
       "      <td>54.336007</td>\n",
       "      <td>63.388750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>82.925078</td>\n",
       "      <td>85.056123</td>\n",
       "      <td>75.638201</td>\n",
       "      <td>60.898821</td>\n",
       "      <td>86.691446</td>\n",
       "      <td>96.835173</td>\n",
       "      <td>78.978049</td>\n",
       "      <td>84.194262</td>\n",
       "      <td>92.321167</td>\n",
       "      <td>72.536704</td>\n",
       "      <td>...</td>\n",
       "      <td>87.756942</td>\n",
       "      <td>77.359634</td>\n",
       "      <td>66.711044</td>\n",
       "      <td>54.290729</td>\n",
       "      <td>84.742187</td>\n",
       "      <td>77.249460</td>\n",
       "      <td>77.721910</td>\n",
       "      <td>78.859700</td>\n",
       "      <td>75.614738</td>\n",
       "      <td>70.947172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>94.422995</td>\n",
       "      <td>89.226249</td>\n",
       "      <td>73.931346</td>\n",
       "      <td>63.087668</td>\n",
       "      <td>94.450733</td>\n",
       "      <td>81.898077</td>\n",
       "      <td>62.718210</td>\n",
       "      <td>88.219794</td>\n",
       "      <td>74.275413</td>\n",
       "      <td>68.953841</td>\n",
       "      <td>...</td>\n",
       "      <td>82.477134</td>\n",
       "      <td>74.933372</td>\n",
       "      <td>72.775093</td>\n",
       "      <td>67.348402</td>\n",
       "      <td>87.181066</td>\n",
       "      <td>84.173965</td>\n",
       "      <td>89.559115</td>\n",
       "      <td>77.098196</td>\n",
       "      <td>70.797202</td>\n",
       "      <td>53.884827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>83.952863</td>\n",
       "      <td>66.065812</td>\n",
       "      <td>84.551264</td>\n",
       "      <td>56.552603</td>\n",
       "      <td>89.824039</td>\n",
       "      <td>89.198244</td>\n",
       "      <td>89.166751</td>\n",
       "      <td>88.622224</td>\n",
       "      <td>77.223711</td>\n",
       "      <td>79.464550</td>\n",
       "      <td>...</td>\n",
       "      <td>73.747033</td>\n",
       "      <td>84.761981</td>\n",
       "      <td>66.271831</td>\n",
       "      <td>69.599351</td>\n",
       "      <td>82.467908</td>\n",
       "      <td>76.711520</td>\n",
       "      <td>95.792929</td>\n",
       "      <td>72.814163</td>\n",
       "      <td>67.916404</td>\n",
       "      <td>66.695185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>83.310233</td>\n",
       "      <td>84.973098</td>\n",
       "      <td>72.042251</td>\n",
       "      <td>57.899950</td>\n",
       "      <td>89.732326</td>\n",
       "      <td>74.722796</td>\n",
       "      <td>83.250694</td>\n",
       "      <td>89.482927</td>\n",
       "      <td>89.880388</td>\n",
       "      <td>79.130474</td>\n",
       "      <td>...</td>\n",
       "      <td>72.287636</td>\n",
       "      <td>82.705989</td>\n",
       "      <td>77.745400</td>\n",
       "      <td>72.320879</td>\n",
       "      <td>95.100104</td>\n",
       "      <td>76.552170</td>\n",
       "      <td>84.367495</td>\n",
       "      <td>86.212913</td>\n",
       "      <td>66.282294</td>\n",
       "      <td>70.109882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>72.910645</td>\n",
       "      <td>90.936111</td>\n",
       "      <td>69.508792</td>\n",
       "      <td>64.992568</td>\n",
       "      <td>82.610572</td>\n",
       "      <td>90.872479</td>\n",
       "      <td>88.106736</td>\n",
       "      <td>77.286704</td>\n",
       "      <td>76.902771</td>\n",
       "      <td>75.120663</td>\n",
       "      <td>...</td>\n",
       "      <td>75.382492</td>\n",
       "      <td>73.565450</td>\n",
       "      <td>76.732590</td>\n",
       "      <td>68.218872</td>\n",
       "      <td>82.177815</td>\n",
       "      <td>88.754353</td>\n",
       "      <td>87.109144</td>\n",
       "      <td>91.486898</td>\n",
       "      <td>74.986697</td>\n",
       "      <td>66.529407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor1    sensor2    sensor3    sensor4    sensor5    sensor6  \\\n",
       "0     92.015811  87.079352  66.557988  83.477127  82.924537  98.016051   \n",
       "1     70.411546  78.935969  64.281244  75.929107  88.542239  65.777430   \n",
       "2     73.411995  87.317315  72.546540  77.271697  93.110096  85.770885   \n",
       "3     77.860662  75.171591  66.511190  75.335435  86.749672  92.725955   \n",
       "4     63.364328  93.813363  63.816744  74.894551  78.468572  86.792705   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  82.925078  85.056123  75.638201  60.898821  86.691446  96.835173   \n",
       "2439  94.422995  89.226249  73.931346  63.087668  94.450733  81.898077   \n",
       "2440  83.952863  66.065812  84.551264  56.552603  89.824039  89.198244   \n",
       "2441  83.310233  84.973098  72.042251  57.899950  89.732326  74.722796   \n",
       "2442  72.910645  90.936111  69.508792  64.992568  82.610572  90.872479   \n",
       "\n",
       "        sensor7    sensor8    sensor9   sensor10  ...   sensor39   sensor40  \\\n",
       "0     81.155271  80.318841  86.289190  80.803460  ...  64.382199  78.044421   \n",
       "1     77.351480  84.200773  85.745554  76.266443  ...  78.666453  81.409869   \n",
       "2     81.424461  94.755188  91.975696  74.468728  ...  74.664997  81.896947   \n",
       "3     74.477870  94.291663  80.538937  91.161372  ...  60.005406  80.244252   \n",
       "4     76.932616  94.095866  90.212163  80.678981  ...  74.417818  74.472188   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  78.978049  84.194262  92.321167  72.536704  ...  87.756942  77.359634   \n",
       "2439  62.718210  88.219794  74.275413  68.953841  ...  82.477134  74.933372   \n",
       "2440  89.166751  88.622224  77.223711  79.464550  ...  73.747033  84.761981   \n",
       "2441  83.250694  89.482927  89.880388  79.130474  ...  72.287636  82.705989   \n",
       "2442  88.106736  77.286704  76.902771  75.120663  ...  75.382492  73.565450   \n",
       "\n",
       "       sensor41   sensor42   sensor43   sensor44   sensor45   sensor46  \\\n",
       "0     76.333780  80.585743  79.712478  85.675612  73.352786  92.344344   \n",
       "1     72.071530  73.681691  87.605202  76.050438  79.461153  73.653767   \n",
       "2     67.347589  61.710086  83.936005  86.728580  87.433082  83.676800   \n",
       "3     82.853566  76.956383  75.972086  81.969438  82.472468  78.391222   \n",
       "4     97.144534  76.033392  99.380429  82.118814  81.876570  84.613716   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  66.711044  54.290729  84.742187  77.249460  77.721910  78.859700   \n",
       "2439  72.775093  67.348402  87.181066  84.173965  89.559115  77.098196   \n",
       "2440  66.271831  69.599351  82.467908  76.711520  95.792929  72.814163   \n",
       "2441  77.745400  72.320879  95.100104  76.552170  84.367495  86.212913   \n",
       "2442  76.732590  68.218872  82.177815  88.754353  87.109144  91.486898   \n",
       "\n",
       "       sensor47   sensor48  \n",
       "0     56.075480  84.186219  \n",
       "1     55.563222  83.862769  \n",
       "2     54.095236  70.735974  \n",
       "3     69.501299  64.732297  \n",
       "4     54.336007  63.388750  \n",
       "...         ...        ...  \n",
       "2438  75.614738  70.947172  \n",
       "2439  70.797202  53.884827  \n",
       "2440  67.916404  66.695185  \n",
       "2441  66.282294  70.109882  \n",
       "2442  74.986697  66.529407  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 16s 14ms/step - loss: 1402.8784 - val_loss: 1257.1736\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1238.1685 - val_loss: 1154.9091\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1147.8253 - val_loss: 1079.3716\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1080.5466 - val_loss: 1023.0323\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1030.4435 - val_loss: 981.3315\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 993.7336 - val_loss: 951.1124\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 967.5712 - val_loss: 930.1287\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 949.6703 - val_loss: 915.7268\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 937.7900 - val_loss: 907.2637\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 930.9312 - val_loss: 902.4896\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 927.2882 - val_loss: 900.2927\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.4938 - val_loss: 899.2758\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.7590 - val_loss: 899.0191\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.5171 - val_loss: 898.9188\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4308 - val_loss: 898.8530\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4059 - val_loss: 898.9418\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4426 - val_loss: 898.9304\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4176 - val_loss: 898.9706\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4069 - val_loss: 898.9573\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4119 - val_loss: 898.9872\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4012 - val_loss: 898.9196\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4308 - val_loss: 898.9907\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.4136 - val_loss: 898.9968\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4040 - val_loss: 898.9825\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 924.4072 - val_loss: 898.9877\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4328 - val_loss: 898.9583\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 924.3793 - val_loss: 898.9821\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 924.4255 - val_loss: 898.9335\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 924.3941 - val_loss: 898.9190\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.4121 - val_loss: 898.9788\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 924.3460 - val_loss: 897.6193\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 911.9286 - val_loss: 875.7017\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 894.4023 - val_loss: 866.1979\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 886.3008 - val_loss: 860.0187\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 878.6660 - val_loss: 853.8146\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 871.7444 - val_loss: 847.7430\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 863.8145 - val_loss: 841.3122\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 856.2915 - val_loss: 835.4701\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 849.3664 - val_loss: 831.0797\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 843.0300 - val_loss: 825.1340\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 837.5764 - val_loss: 820.5042\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 833.0295 - val_loss: 817.2482\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 828.1680 - val_loss: 813.4391\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 823.6688 - val_loss: 813.4639\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 820.1554 - val_loss: 807.7365\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 815.9071 - val_loss: 803.9212\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 813.6947 - val_loss: 801.8850\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 809.5585 - val_loss: 799.9615\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 807.6287 - val_loss: 800.7991\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 805.6720 - val_loss: 795.1915\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 802.2119 - val_loss: 795.5578\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 800.8149 - val_loss: 792.0629\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 797.4562 - val_loss: 789.1209\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 794.7990 - val_loss: 786.1185\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 791.4179 - val_loss: 781.3491\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 784.8142 - val_loss: 773.4861\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 770.4280 - val_loss: 758.3061\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 744.0856 - val_loss: 731.5779\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 723.8091 - val_loss: 719.5759\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 710.1737 - val_loss: 693.3994\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 687.5628 - val_loss: 671.5452\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 668.7650 - val_loss: 674.0110\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 654.7817 - val_loss: 647.1365\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 636.4738 - val_loss: 623.2791\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 635.1609 - val_loss: 618.0677\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 599.1406 - val_loss: 595.0516\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 581.5798 - val_loss: 583.7173\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 567.8215 - val_loss: 558.9283\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 538.3143 - val_loss: 551.5776\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 531.3544 - val_loss: 523.8799\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 507.6894 - val_loss: 529.0774\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 490.0013 - val_loss: 511.8141\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 484.3206 - val_loss: 475.4818\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 454.7085 - val_loss: 655.1222\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 482.3685 - val_loss: 487.9481\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 438.3479 - val_loss: 461.7270\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 416.1867 - val_loss: 426.8684\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 418.4730 - val_loss: 424.2915\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 402.7976 - val_loss: 424.8044\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 396.9209 - val_loss: 440.3331\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 391.5494 - val_loss: 406.7678\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 377.3594 - val_loss: 429.0385\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 362.0903 - val_loss: 385.6768\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 351.6558 - val_loss: 377.2313\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 361.0218 - val_loss: 367.9096\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 338.7629 - val_loss: 366.2978\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 337.4785 - val_loss: 365.4595\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 322.2947 - val_loss: 348.8813\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 319.8987 - val_loss: 349.3594\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 313.4146 - val_loss: 423.8148\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 305.3714 - val_loss: 362.5239\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 303.8346 - val_loss: 342.4380\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 296.9034 - val_loss: 324.3902\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 288.8992 - val_loss: 317.9460\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 283.8140 - val_loss: 313.1311\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 282.6522 - val_loss: 322.8927\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 273.8499 - val_loss: 311.2863\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 269.6324 - val_loss: 295.0322\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 267.8266 - val_loss: 291.4556\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 257.7817 - val_loss: 319.8573\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 256.0903 - val_loss: 288.2755\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 252.5396 - val_loss: 281.0814\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 250.3011 - val_loss: 271.7943\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 245.4059 - val_loss: 266.5905\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 240.6488 - val_loss: 262.4028\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 241.3980 - val_loss: 262.9619\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 233.7539 - val_loss: 259.4666\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 235.5748 - val_loss: 286.6178\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 229.3467 - val_loss: 276.6706\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 228.9177 - val_loss: 247.2435\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 225.3021 - val_loss: 242.7183\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 218.1670 - val_loss: 245.5696\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 215.5380 - val_loss: 236.0502\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 213.5808 - val_loss: 233.3729\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 209.4273 - val_loss: 230.9371\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 210.4371 - val_loss: 236.7230\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 204.0096 - val_loss: 234.9596\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 199.0947 - val_loss: 232.2024\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 200.6750 - val_loss: 233.6237\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 194.5591 - val_loss: 218.7303\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 188.8156 - val_loss: 217.2082\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 189.9718 - val_loss: 219.7986\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 186.2569 - val_loss: 212.9990\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 184.2133 - val_loss: 221.9859\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 183.9727 - val_loss: 216.3720\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 177.3094 - val_loss: 201.9980\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 175.5191 - val_loss: 197.6749\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 174.6001 - val_loss: 197.9268\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 174.7458 - val_loss: 199.7844\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 173.3015 - val_loss: 196.0230\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 168.4976 - val_loss: 194.3125\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 166.6370 - val_loss: 197.1118\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 164.9387 - val_loss: 193.0653\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 165.5173 - val_loss: 199.4973\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 162.2524 - val_loss: 181.5071\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 161.3579 - val_loss: 187.0214\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 158.4090 - val_loss: 186.3404\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 158.1060 - val_loss: 185.5856\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 158.6393 - val_loss: 181.6899\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 153.9509 - val_loss: 177.9744\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 153.9503 - val_loss: 197.1691\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 153.1229 - val_loss: 171.6475\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 150.7671 - val_loss: 179.0388\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 149.6770 - val_loss: 172.2474\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 148.2679 - val_loss: 181.7521\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 146.1220 - val_loss: 170.6449\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 148.8629 - val_loss: 173.3382\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 144.2829 - val_loss: 167.2452\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 146.4300 - val_loss: 165.8910\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 144.6405 - val_loss: 166.8461\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 139.4079 - val_loss: 169.2914\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 139.9462 - val_loss: 163.5492\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 138.9625 - val_loss: 164.4609\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 137.0406 - val_loss: 168.5863\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 136.2908 - val_loss: 166.9585\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 136.8907 - val_loss: 157.2870\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 132.4198 - val_loss: 156.1333\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 133.5520 - val_loss: 164.3332\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 131.9647 - val_loss: 155.1935\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 129.9516 - val_loss: 160.7280\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 130.2171 - val_loss: 173.1140\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.2327 - val_loss: 159.6179\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 126.2183 - val_loss: 156.3751\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 128.1105 - val_loss: 178.4321\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 124.4637 - val_loss: 151.0473\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 123.8737 - val_loss: 157.5099\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.5135 - val_loss: 180.5455\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 124.1407 - val_loss: 147.0464\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 122.1666 - val_loss: 146.9205\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 119.3303 - val_loss: 146.8304\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 122.1554 - val_loss: 157.0389\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 119.1546 - val_loss: 145.7805\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 117.9907 - val_loss: 171.5766\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 118.6145 - val_loss: 150.1836\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 117.0417 - val_loss: 177.6409\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 115.4832 - val_loss: 145.6099\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 113.9641 - val_loss: 149.5237\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 112.6351 - val_loss: 154.0221\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 113.2396 - val_loss: 151.0626\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 113.0040 - val_loss: 144.5379\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 112.1782 - val_loss: 151.5920\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 110.8141 - val_loss: 148.5669\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 108.9694 - val_loss: 144.4228\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 108.7018 - val_loss: 145.8146\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 108.7894 - val_loss: 148.0973\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 109.6019 - val_loss: 143.5148\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 107.7136 - val_loss: 149.5804\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 106.4756 - val_loss: 142.1196\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 105.6053 - val_loss: 151.1785\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 106.4989 - val_loss: 148.0177\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 104.1840 - val_loss: 153.3186\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 104.0130 - val_loss: 150.7270\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.1790 - val_loss: 143.3579\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.1335 - val_loss: 146.6869\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 100.9578 - val_loss: 140.8169\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.3614 - val_loss: 146.9314\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 100.0462 - val_loss: 154.7070\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 99.1770 - val_loss: 144.6140\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 98.8415 - val_loss: 143.1433\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 97.0688 - val_loss: 143.0239\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 143.02387940274284\n",
      "Mean Absolute Error (MAE): 9.499881934136447\n",
      "Root Mean Squared Error (RMSE): 11.959259149409835\n",
      "Time taken: 1253.0041348934174\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 19ms/step - loss: 1376.4465 - val_loss: 1260.2936\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1217.5079 - val_loss: 1157.9626\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1131.9512 - val_loss: 1083.6044\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1068.3435 - val_loss: 1026.6176\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1020.4107 - val_loss: 984.7764\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 985.8462 - val_loss: 954.8764\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 961.6516 - val_loss: 933.8621\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 945.4280 - val_loss: 920.1320\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 935.2000 - val_loss: 911.5601\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 929.2707 - val_loss: 906.6525\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.1469 - val_loss: 904.0548\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 924.6241 - val_loss: 902.7675\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.9705 - val_loss: 902.1430\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.7589 - val_loss: 901.9095\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.7053 - val_loss: 901.8152\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6822 - val_loss: 901.7672\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6733 - val_loss: 901.7368\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6686 - val_loss: 901.7272\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6586 - val_loss: 901.7124\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6290 - val_loss: 901.7659\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.6462 - val_loss: 901.7264\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 923.6694 - val_loss: 901.7020\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6826 - val_loss: 901.7269\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6746 - val_loss: 901.6961\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6595 - val_loss: 901.7169\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.6547 - val_loss: 901.7155\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6693 - val_loss: 901.7333\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.7037 - val_loss: 901.7234\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.6929 - val_loss: 901.7048\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6493 - val_loss: 901.7448\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 923.6650 - val_loss: 901.7434\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6781 - val_loss: 901.7194\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.6592 - val_loss: 901.7433\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 923.7062 - val_loss: 901.7032\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 915.5522 - val_loss: 882.1866\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 899.1041 - val_loss: 874.2570\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 891.4064 - val_loss: 865.3063\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 884.7975 - val_loss: 859.0956\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 878.8403 - val_loss: 856.2150\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 872.8868 - val_loss: 848.6339\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 868.1860 - val_loss: 841.9926\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 859.2648 - val_loss: 832.7325\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 852.4348 - val_loss: 826.1787\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 846.5999 - val_loss: 819.9538\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 838.5923 - val_loss: 812.7126\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 826.9601 - val_loss: 795.1740\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 811.8011 - val_loss: 782.7819\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 795.0797 - val_loss: 767.7959\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 776.3704 - val_loss: 752.0567\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 751.9230 - val_loss: 728.5613\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 728.3419 - val_loss: 745.6987\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 715.9828 - val_loss: 686.9611\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 685.5984 - val_loss: 657.0767\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 672.0755 - val_loss: 646.8042\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 638.1104 - val_loss: 614.2512\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 618.8896 - val_loss: 593.8752\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 651.7208 - val_loss: 635.1200\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 624.4694 - val_loss: 596.5660\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 598.7744 - val_loss: 588.6628\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 568.5280 - val_loss: 554.9724\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 560.0561 - val_loss: 550.0449\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 534.2417 - val_loss: 551.3773\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 517.9825 - val_loss: 497.9271\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 498.1009 - val_loss: 496.3769\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 476.0909 - val_loss: 467.2401\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 453.7844 - val_loss: 488.4429\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 469.0299 - val_loss: 459.2012\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 448.5822 - val_loss: 464.3648\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 422.2028 - val_loss: 417.4903\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 406.9589 - val_loss: 395.7185\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 411.6444 - val_loss: 393.1723\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 386.4199 - val_loss: 376.1573\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 381.4525 - val_loss: 373.0753\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 373.1357 - val_loss: 374.4447\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 367.0250 - val_loss: 384.8223\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 436.6161 - val_loss: 380.4014\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 17ms/step - loss: 357.0712 - val_loss: 346.9743\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 346.5164 - val_loss: 391.8722\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 353.1800 - val_loss: 352.7576\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 333.2724 - val_loss: 358.4166\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 326.7411 - val_loss: 464.0150\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 317.7450 - val_loss: 349.2908\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 312.3016 - val_loss: 346.9776\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 301.8653 - val_loss: 305.1325\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 293.8187 - val_loss: 288.5338\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 283.7488 - val_loss: 283.7613\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 275.9518 - val_loss: 279.2350\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 268.2131 - val_loss: 276.2126\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 262.6846 - val_loss: 255.1346\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 257.6431 - val_loss: 261.9761\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 259.8931 - val_loss: 259.1433\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 242.0918 - val_loss: 237.2770\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 238.3570 - val_loss: 238.6953\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 232.4802 - val_loss: 230.5716\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 227.6264 - val_loss: 236.1953\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 221.9957 - val_loss: 240.3159\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 218.4169 - val_loss: 221.3754\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 218.0267 - val_loss: 213.3525\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 215.6281 - val_loss: 213.8156\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 209.4918 - val_loss: 207.1230\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 220.4430 - val_loss: 219.1788\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 206.5362 - val_loss: 211.2939\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 204.4270 - val_loss: 209.9034\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 192.9230 - val_loss: 207.7232\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 196.7853 - val_loss: 194.3993\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 192.0988 - val_loss: 220.5682\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 195.4284 - val_loss: 190.7973\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 190.2447 - val_loss: 194.2675\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 187.2774 - val_loss: 198.2795\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 188.0146 - val_loss: 211.7286\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 186.9400 - val_loss: 209.7029\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 185.8511 - val_loss: 186.1970\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 178.1932 - val_loss: 183.7445\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 180.0006 - val_loss: 191.2691\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 182.9929 - val_loss: 197.4018\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 176.1051 - val_loss: 184.8352\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 175.7932 - val_loss: 185.9449\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 173.8519 - val_loss: 185.1740\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 173.0709 - val_loss: 193.4893\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 169.3318 - val_loss: 179.5855\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 170.7310 - val_loss: 187.4090\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 167.7860 - val_loss: 180.7334\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 168.1233 - val_loss: 179.5030\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 164.0634 - val_loss: 174.4212\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 173.6853 - val_loss: 177.8784\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 162.1829 - val_loss: 179.4777\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 162.8991 - val_loss: 182.6133\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 159.0455 - val_loss: 172.5082\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 157.0170 - val_loss: 183.8180\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 155.7205 - val_loss: 186.1486\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 157.0407 - val_loss: 180.8763\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 156.5647 - val_loss: 177.6918\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 153.2393 - val_loss: 165.1708\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 153.2405 - val_loss: 169.1177\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 148.8961 - val_loss: 173.0461\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 155.1960 - val_loss: 180.1232\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 147.4336 - val_loss: 168.1926\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 145.1121 - val_loss: 170.8527\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 145.9724 - val_loss: 173.8675\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 143.3955 - val_loss: 162.4140\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 143.6557 - val_loss: 172.9683\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 148.8667 - val_loss: 163.0865\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 143.4767 - val_loss: 161.8277\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 143.2709 - val_loss: 166.1178\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 143.0693 - val_loss: 163.9912\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 139.4547 - val_loss: 156.4085\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 140.1531 - val_loss: 173.3174\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 135.4147 - val_loss: 156.0976\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 138.1454 - val_loss: 155.8036\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 135.3970 - val_loss: 158.7134\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 134.8555 - val_loss: 161.7340\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 134.4951 - val_loss: 159.6526\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 131.8445 - val_loss: 161.8014\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 128.9803 - val_loss: 151.8523\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 128.2607 - val_loss: 158.8904\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 126.4357 - val_loss: 154.9490\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.8497 - val_loss: 163.4009\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.0730 - val_loss: 155.2798\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.7781 - val_loss: 151.8060\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.5979 - val_loss: 150.8639\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 124.9076 - val_loss: 152.5874\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 121.6217 - val_loss: 157.7719\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 122.6195 - val_loss: 164.2435\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 124.2920 - val_loss: 154.3007\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 119.2592 - val_loss: 153.8650\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 120.9300 - val_loss: 146.5051\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 117.0624 - val_loss: 168.6415\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 116.2048 - val_loss: 147.8031\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 119.5285 - val_loss: 150.6272\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 115.5027 - val_loss: 150.3575\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 116.2502 - val_loss: 158.2557\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 115.0847 - val_loss: 154.9452\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 114.0951 - val_loss: 147.6026\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 111.8922 - val_loss: 159.2801\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 113.3035 - val_loss: 150.0144\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 110.3121 - val_loss: 150.8710\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 109.3841 - val_loss: 150.1113\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 113.1266 - val_loss: 150.8290\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 110.0375 - val_loss: 147.4357\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 114.6020 - val_loss: 160.9612\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 108.9834 - val_loss: 146.1047\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 107.1015 - val_loss: 145.9839\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 105.2490 - val_loss: 149.8713\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.7146 - val_loss: 148.1832\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.3880 - val_loss: 143.8951\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.7196 - val_loss: 152.9722\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.1548 - val_loss: 150.6174\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 104.3041 - val_loss: 164.0119\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 101.0639 - val_loss: 150.4967\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 100.0563 - val_loss: 157.0794\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 98.6552 - val_loss: 149.3135\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 98.7351 - val_loss: 148.0638\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 99.6544 - val_loss: 149.4045\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 98.4628 - val_loss: 147.0775\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 99.4525 - val_loss: 149.8095\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 94.6807 - val_loss: 149.7610\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 95.0566 - val_loss: 161.9492\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 96.9019 - val_loss: 151.7157\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 94.8036 - val_loss: 146.8933\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 93.6766 - val_loss: 144.0803\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 144.08037134726962\n",
      "Mean Absolute Error (MAE): 9.362988359550679\n",
      "Root Mean Squared Error (RMSE): 12.00334833899565\n",
      "Time taken: 1256.664202451706\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 1377.9554 - val_loss: 1302.9460\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1214.2372 - val_loss: 1201.7963\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1124.8407 - val_loss: 1127.7168\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1058.9523 - val_loss: 1073.5111\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1009.8826 - val_loss: 1033.5065\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 974.0413 - val_loss: 1005.2478\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 948.8779 - val_loss: 986.1319\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 931.9993 - val_loss: 973.9008\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 921.2216 - val_loss: 966.5975\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 914.8520 - val_loss: 963.0481\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 911.5612 - val_loss: 961.4421\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 910.0042 - val_loss: 960.8915\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 909.3244 - val_loss: 960.8351\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 909.0864 - val_loss: 960.8389\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 909.0133 - val_loss: 960.8971\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9761 - val_loss: 960.9339\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 909.0184 - val_loss: 961.0619\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9730 - val_loss: 961.0532\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9409 - val_loss: 961.0723\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9631 - val_loss: 961.0624\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9414 - val_loss: 961.0055\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9719 - val_loss: 961.0107\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9587 - val_loss: 961.0665\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9583 - val_loss: 961.1588\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9634 - val_loss: 961.0721\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 908.9560 - val_loss: 961.0446\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9765 - val_loss: 961.2005\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9419 - val_loss: 961.2236\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 909.0141 - val_loss: 960.9702\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9622 - val_loss: 961.0615\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 908.9677 - val_loss: 961.0690\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 907.3994 - val_loss: 948.6671\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 889.2378 - val_loss: 930.6915\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 879.7436 - val_loss: 923.4768\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 873.4613 - val_loss: 919.4397\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 867.7913 - val_loss: 916.4867\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 862.4334 - val_loss: 907.8957\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 855.8044 - val_loss: 903.0093\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 849.3501 - val_loss: 894.1303\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 842.0428 - val_loss: 888.7077\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 836.2682 - val_loss: 882.5844\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 830.4248 - val_loss: 878.8070\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 825.2011 - val_loss: 872.3468\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 821.0450 - val_loss: 866.8619\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 815.2740 - val_loss: 862.1998\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 811.1454 - val_loss: 858.2051\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 807.3619 - val_loss: 854.3202\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 802.8569 - val_loss: 848.7840\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 798.7208 - val_loss: 841.8884\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 793.4685 - val_loss: 834.5454\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 787.3934 - val_loss: 820.4360\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 775.1257 - val_loss: 803.9035\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 755.0178 - val_loss: 775.7127\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 729.7384 - val_loss: 750.0997\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 709.0660 - val_loss: 736.3630\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 692.5901 - val_loss: 705.3184\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 670.2688 - val_loss: 687.9818\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 651.0011 - val_loss: 676.6676\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 637.9079 - val_loss: 673.9505\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 621.5447 - val_loss: 627.1738\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 596.5703 - val_loss: 602.8388\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 579.5586 - val_loss: 616.2296\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 557.3932 - val_loss: 570.5866\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 536.6605 - val_loss: 563.4907\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 515.8404 - val_loss: 531.2555\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 496.1316 - val_loss: 529.0619\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 485.1496 - val_loss: 494.0072\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 466.0765 - val_loss: 463.1960\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 455.9728 - val_loss: 449.6866\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 439.6085 - val_loss: 463.7775\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 423.1839 - val_loss: 430.8188\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 409.0439 - val_loss: 410.3604\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 396.7902 - val_loss: 417.5116\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 381.7066 - val_loss: 378.4129\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 370.1587 - val_loss: 380.9737\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 364.3311 - val_loss: 361.1509\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 354.0219 - val_loss: 348.9911\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 339.2708 - val_loss: 432.9474\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 330.3210 - val_loss: 368.6216\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 317.6049 - val_loss: 338.9278\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 312.1539 - val_loss: 312.8699\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 304.8370 - val_loss: 306.8424\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 297.6528 - val_loss: 307.3651\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 286.5524 - val_loss: 289.0662\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 281.2560 - val_loss: 292.8605\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 271.4251 - val_loss: 285.2348\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 266.8701 - val_loss: 277.5813\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 263.7263 - val_loss: 281.3966\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 251.6798 - val_loss: 268.4826\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 250.4791 - val_loss: 259.4659\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 250.2094 - val_loss: 255.2601\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 241.2160 - val_loss: 245.8477\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 238.8901 - val_loss: 247.2301\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 235.0992 - val_loss: 257.4485\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 232.3633 - val_loss: 233.4076\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 223.0312 - val_loss: 229.8815\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 222.0684 - val_loss: 226.9244\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 213.8992 - val_loss: 224.0443\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 208.1944 - val_loss: 225.8784\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 213.5788 - val_loss: 218.9349\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 207.0498 - val_loss: 212.4589\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 208.1878 - val_loss: 215.0893\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 205.3459 - val_loss: 222.1782\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 197.3063 - val_loss: 207.1605\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 198.2445 - val_loss: 239.8383\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 193.9987 - val_loss: 197.7926\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 188.6839 - val_loss: 210.1141\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 189.4609 - val_loss: 188.8306\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 181.8174 - val_loss: 190.0534\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 183.5727 - val_loss: 195.6163\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 181.7232 - val_loss: 187.3410\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 180.0366 - val_loss: 253.3195\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 175.4956 - val_loss: 179.8665\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 172.6133 - val_loss: 186.2454\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 172.5888 - val_loss: 184.1584\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 173.8076 - val_loss: 177.4563\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 168.5796 - val_loss: 196.8734\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 168.2020 - val_loss: 171.6635\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 166.3204 - val_loss: 170.6230\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 163.2513 - val_loss: 171.2834\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 164.3883 - val_loss: 166.2499\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 159.3917 - val_loss: 165.8492\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 160.7914 - val_loss: 177.4037\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 155.8608 - val_loss: 161.8295\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 155.6922 - val_loss: 166.2036\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 154.9825 - val_loss: 164.6066\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 150.9313 - val_loss: 159.8785\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 150.6250 - val_loss: 162.3933\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 151.2721 - val_loss: 169.0726\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 152.3583 - val_loss: 161.9768\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 149.3174 - val_loss: 171.0397\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 151.2578 - val_loss: 163.5977\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 147.2716 - val_loss: 162.5553\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 145.6229 - val_loss: 160.0968\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 142.7122 - val_loss: 159.2403\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 143.1052 - val_loss: 157.6912\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 142.3145 - val_loss: 157.7618\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 140.3435 - val_loss: 161.1573\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 139.9278 - val_loss: 165.8898\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 138.5688 - val_loss: 157.5405\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 138.8811 - val_loss: 155.2791\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 136.3157 - val_loss: 167.3513\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 138.3987 - val_loss: 159.9723\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 136.9458 - val_loss: 162.4571\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 136.6764 - val_loss: 154.7251\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 134.1591 - val_loss: 160.0313\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 132.0248 - val_loss: 159.6597\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 132.7526 - val_loss: 151.2662\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 132.2589 - val_loss: 173.8853\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 133.3594 - val_loss: 147.6723\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 130.6023 - val_loss: 158.8739\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 128.0603 - val_loss: 150.3033\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 16ms/step - loss: 132.0274 - val_loss: 157.8588\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 127.7136 - val_loss: 149.8526\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 127.0348 - val_loss: 152.3689\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 127.6163 - val_loss: 147.8397\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 125.6189 - val_loss: 157.0910\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 124.7656 - val_loss: 152.3700\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 124.5996 - val_loss: 148.3212\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 124.9720 - val_loss: 153.2038\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 123.1639 - val_loss: 148.8790\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 120.6671 - val_loss: 145.4685\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 122.1030 - val_loss: 152.0465\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 119.8847 - val_loss: 148.4453\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 119.9184 - val_loss: 147.9155\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 117.2164 - val_loss: 152.3218\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 119.0515 - val_loss: 158.6700\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 118.2802 - val_loss: 144.5855\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 118.1079 - val_loss: 151.8120\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 118.7372 - val_loss: 157.3730\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 117.6779 - val_loss: 148.1162\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 115.2504 - val_loss: 148.1525\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 114.6247 - val_loss: 149.2140\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 112.4863 - val_loss: 144.1996\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 113.6550 - val_loss: 163.4836\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 112.5162 - val_loss: 150.9815\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 112.0509 - val_loss: 148.7742\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 111.2920 - val_loss: 151.0537\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 109.6845 - val_loss: 167.0439\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 109.6539 - val_loss: 160.8973\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 108.5567 - val_loss: 145.0934\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 106.9422 - val_loss: 142.5406\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 110.9245 - val_loss: 145.4628\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 108.0715 - val_loss: 144.1404\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 17ms/step - loss: 107.8327 - val_loss: 150.4199\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.1649 - val_loss: 151.1168\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.7287 - val_loss: 145.0693\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 104.7415 - val_loss: 144.0497\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 103.5284 - val_loss: 144.7697\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 102.9842 - val_loss: 143.4129\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.5746 - val_loss: 147.5931\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.4189 - val_loss: 149.8091\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 102.7869 - val_loss: 148.5977\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 100.2822 - val_loss: 151.7879\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 100.4292 - val_loss: 146.8686\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.3614 - val_loss: 144.4706\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 98.9374 - val_loss: 154.5008\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 97.7656 - val_loss: 151.0047\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 97.5497 - val_loss: 152.9222\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 97.7440 - val_loss: 152.8848\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 152.88478308176923\n",
      "Mean Absolute Error (MAE): 9.71762109463989\n",
      "Root Mean Squared Error (RMSE): 12.36465863183328\n",
      "Time taken: 1247.4653596878052\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 17ms/step - loss: 1390.3264 - val_loss: 1257.3535\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1227.1869 - val_loss: 1153.6099\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1138.7770 - val_loss: 1076.3385\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1073.6429 - val_loss: 1019.9501\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1025.5603 - val_loss: 977.7178\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 989.4450 - val_loss: 946.6809\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 964.3295 - val_loss: 926.0341\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 947.7808 - val_loss: 912.0363\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 937.4147 - val_loss: 903.8854\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 931.3799 - val_loss: 899.3643\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 928.1606 - val_loss: 896.8819\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 926.5630 - val_loss: 895.8358\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.9157 - val_loss: 895.4788\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.7582 - val_loss: 895.2811\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6595 - val_loss: 895.1739\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6646 - val_loss: 895.0506\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6233 - val_loss: 895.1343\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.5872 - val_loss: 895.0911\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6248 - val_loss: 895.0967\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6390 - val_loss: 894.9488\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6414 - val_loss: 895.0596\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6365 - val_loss: 894.9216\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 925.6104 - val_loss: 894.8228\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6079 - val_loss: 895.0191\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6508 - val_loss: 895.0359\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6636 - val_loss: 895.2206\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6121 - val_loss: 895.0157\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6293 - val_loss: 894.9003\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6533 - val_loss: 895.0876\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6091 - val_loss: 895.0691\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6174 - val_loss: 895.0768\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6706 - val_loss: 895.2385\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6360 - val_loss: 895.1958\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6276 - val_loss: 895.1063\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.9445 - val_loss: 895.4437\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.9326 - val_loss: 894.8233\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6634 - val_loss: 894.7895\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.6273 - val_loss: 895.0790\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 925.5419 - val_loss: 894.7859\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 916.3675 - val_loss: 876.6747\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 897.6790 - val_loss: 865.8279\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 885.2144 - val_loss: 854.9805\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 875.7443 - val_loss: 842.8180\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 864.3093 - val_loss: 829.8077\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 853.8737 - val_loss: 823.8089\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 839.9730 - val_loss: 810.7682\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 829.7810 - val_loss: 797.9409\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 815.6535 - val_loss: 788.4415\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 799.9030 - val_loss: 772.5312\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 785.1531 - val_loss: 757.3888\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 770.4395 - val_loss: 740.7917\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 744.4818 - val_loss: 712.3409\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 723.2313 - val_loss: 708.4353\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 705.7017 - val_loss: 675.6329\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 687.9203 - val_loss: 646.9830\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 669.6058 - val_loss: 629.1456\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 645.6091 - val_loss: 604.7089\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 619.4609 - val_loss: 586.7286\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 608.4255 - val_loss: 568.7086\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 595.8958 - val_loss: 556.5010\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 606.4511 - val_loss: 549.1008\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 558.1359 - val_loss: 539.6173\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 547.0720 - val_loss: 508.8918\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 514.7791 - val_loss: 492.9582\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 498.8670 - val_loss: 498.1267\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 483.0802 - val_loss: 639.6008\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 499.1927 - val_loss: 525.0021\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 459.4334 - val_loss: 436.5812\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 451.0389 - val_loss: 426.8651\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 429.6102 - val_loss: 424.4812\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 455.2563 - val_loss: 431.8762\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 405.0896 - val_loss: 389.1135\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 389.7017 - val_loss: 379.5706\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 386.0947 - val_loss: 364.9522\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 364.8895 - val_loss: 361.3341\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 367.4020 - val_loss: 349.7960\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 349.7686 - val_loss: 342.3809\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 342.0639 - val_loss: 325.0077\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 332.1030 - val_loss: 323.9991\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 324.2477 - val_loss: 323.6254\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 314.4267 - val_loss: 303.3010\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 305.2654 - val_loss: 297.4227\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 298.4848 - val_loss: 301.9210\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 295.1565 - val_loss: 295.5406\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 293.0952 - val_loss: 282.6817\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 277.9037 - val_loss: 266.5587\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 270.1592 - val_loss: 259.7863\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 265.4809 - val_loss: 260.2422\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 260.6003 - val_loss: 260.0841\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 254.7429 - val_loss: 260.9853\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 250.1716 - val_loss: 236.4711\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 246.1640 - val_loss: 252.2779\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 240.3060 - val_loss: 231.0547\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 232.6533 - val_loss: 224.7549\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 227.9282 - val_loss: 229.3552\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 229.0627 - val_loss: 212.6441\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 217.6993 - val_loss: 211.0267\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 215.0282 - val_loss: 204.4193\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 207.6502 - val_loss: 243.3316\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 202.8400 - val_loss: 211.1884\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 201.0634 - val_loss: 201.5037\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 197.8875 - val_loss: 196.6061\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 195.3035 - val_loss: 184.3313\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 202.2840 - val_loss: 190.1484\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 192.9763 - val_loss: 193.9764\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 188.5464 - val_loss: 178.0323\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 187.7054 - val_loss: 190.4140\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 185.1729 - val_loss: 183.9140\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 180.6613 - val_loss: 177.9824\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 178.1311 - val_loss: 176.2871\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 179.0532 - val_loss: 171.4712\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 175.9384 - val_loss: 175.1949\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 174.4132 - val_loss: 174.3420\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 175.0587 - val_loss: 169.9450\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 171.5142 - val_loss: 174.8689\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 172.0721 - val_loss: 175.7000\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 170.2709 - val_loss: 178.0675\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 168.9142 - val_loss: 171.2383\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 167.9708 - val_loss: 162.4417\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 164.9659 - val_loss: 173.6722\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 168.9868 - val_loss: 187.6518\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 166.2999 - val_loss: 173.7434\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 160.4630 - val_loss: 173.4887\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 161.9107 - val_loss: 165.5718\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 159.5074 - val_loss: 160.7326\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 161.0283 - val_loss: 163.7153\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 158.1470 - val_loss: 158.9646\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 156.6660 - val_loss: 165.7935\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 158.2954 - val_loss: 158.1176\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 156.5444 - val_loss: 160.2961\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 155.4452 - val_loss: 158.9247\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 156.2800 - val_loss: 157.5865\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 155.4654 - val_loss: 169.9300\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 153.3341 - val_loss: 155.5697\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 151.6611 - val_loss: 166.7434\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 155.8925 - val_loss: 155.0254\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 150.2657 - val_loss: 156.5576\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 147.8639 - val_loss: 153.9650\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 150.2096 - val_loss: 165.7636\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 149.7740 - val_loss: 168.9307\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 149.8613 - val_loss: 153.1725\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 147.8022 - val_loss: 151.8680\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 152.0452 - val_loss: 152.6380\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 146.9503 - val_loss: 153.2819\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 144.2182 - val_loss: 151.2600\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 146.0405 - val_loss: 151.9508\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 147.2321 - val_loss: 165.5181\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 145.6082 - val_loss: 150.1533\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 142.6381 - val_loss: 148.7104\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 140.8580 - val_loss: 154.9770\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 141.3340 - val_loss: 150.9906\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 141.4903 - val_loss: 149.6780\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 141.6292 - val_loss: 146.6102\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 138.5443 - val_loss: 149.9352\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 138.7389 - val_loss: 152.5571\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 137.8587 - val_loss: 154.9732\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 139.6343 - val_loss: 156.1709\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 135.9809 - val_loss: 151.3986\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 138.7490 - val_loss: 159.8634\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 135.8497 - val_loss: 151.3925\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 134.5119 - val_loss: 150.7952\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 135.8175 - val_loss: 150.1067\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 137.5631 - val_loss: 147.5181\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 135.2454 - val_loss: 149.9706\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 133.8482 - val_loss: 146.1663\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 132.1686 - val_loss: 143.3711\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 131.1352 - val_loss: 143.5748\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 132.0748 - val_loss: 154.6084\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 131.6595 - val_loss: 147.8727\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 128.6196 - val_loss: 154.9848\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 127.8378 - val_loss: 153.7915\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 128.6085 - val_loss: 142.2306\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 128.6194 - val_loss: 151.7480\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 126.4738 - val_loss: 146.7462\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 128.3594 - val_loss: 148.8106\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 125.5649 - val_loss: 149.2583\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 126.7715 - val_loss: 143.8299\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 124.5547 - val_loss: 149.7050\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 125.2734 - val_loss: 151.0507\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 123.7954 - val_loss: 140.0835\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 124.5771 - val_loss: 144.1173\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 123.1313 - val_loss: 140.4022\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 122.7018 - val_loss: 148.2057\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 120.7907 - val_loss: 150.6699\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 121.0720 - val_loss: 143.5864\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 119.2811 - val_loss: 145.3598\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 120.1446 - val_loss: 141.7689\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 120.1286 - val_loss: 139.3334\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 119.9816 - val_loss: 144.6576\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 120.4646 - val_loss: 141.9753\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 118.1876 - val_loss: 144.8071\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 115.8525 - val_loss: 138.6340\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 116.5103 - val_loss: 147.5134\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 116.8473 - val_loss: 146.1344\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 116.7198 - val_loss: 142.4283\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 113.8582 - val_loss: 146.1418\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 114.3632 - val_loss: 140.1249\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 115.1104 - val_loss: 149.5707\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 113.1238 - val_loss: 140.1046\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 112.2648 - val_loss: 145.3809\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 145.38126490694833\n",
      "Mean Absolute Error (MAE): 9.518707841525417\n",
      "Root Mean Squared Error (RMSE): 12.057415349358598\n",
      "Time taken: 1177.725349664688\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 18ms/step - loss: 1364.5344 - val_loss: 1299.5242\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1206.6844 - val_loss: 1195.6117\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1120.1283 - val_loss: 1120.2009\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1056.3013 - val_loss: 1064.1295\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1009.0821 - val_loss: 1022.9969\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 974.8221 - val_loss: 993.5367\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 950.7345 - val_loss: 973.1279\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 934.6078 - val_loss: 959.8856\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 924.5134 - val_loss: 951.7501\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 918.6530 - val_loss: 947.1735\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 915.6060 - val_loss: 944.9197\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 914.2020 - val_loss: 943.8441\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.6438 - val_loss: 943.4742\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.4152 - val_loss: 943.3237\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3873 - val_loss: 943.2563\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3666 - val_loss: 943.2588\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3411 - val_loss: 943.1492\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3831 - val_loss: 943.1422\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3863 - val_loss: 943.2526\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3374 - val_loss: 943.1708\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3879 - val_loss: 943.1277\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3554 - val_loss: 943.1055\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3812 - val_loss: 943.2162\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3687 - val_loss: 943.2546\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 913.3624 - val_loss: 943.1983\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 913.3867 - val_loss: 943.2875\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3589 - val_loss: 943.3008\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3839 - val_loss: 943.3547\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3994 - val_loss: 943.2677\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3554 - val_loss: 943.2552\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 913.3959 - val_loss: 943.2421\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 913.3752 - val_loss: 943.2440\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 913.3647 - val_loss: 943.2169\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 909.2133 - val_loss: 935.7208\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 892.6778 - val_loss: 918.9994\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 884.5857 - val_loss: 911.4989\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 878.8534 - val_loss: 906.5555\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 872.7788 - val_loss: 899.6838\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 867.0184 - val_loss: 894.8818\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 861.2409 - val_loss: 889.8175\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 856.7025 - val_loss: 886.4902\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 851.2025 - val_loss: 880.1362\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 846.5547 - val_loss: 875.1207\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 840.4885 - val_loss: 870.1619\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 836.2354 - val_loss: 865.3489\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 830.7186 - val_loss: 859.8293\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 825.8361 - val_loss: 856.7675\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 820.4873 - val_loss: 850.4685\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 815.6873 - val_loss: 843.7642\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 810.4355 - val_loss: 838.9919\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 803.8105 - val_loss: 833.2654\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 797.3470 - val_loss: 824.3488\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 789.8229 - val_loss: 815.1997\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 780.6569 - val_loss: 809.9145\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 774.5084 - val_loss: 808.6956\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 756.6945 - val_loss: 782.5696\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 748.0296 - val_loss: 777.7280\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 740.4391 - val_loss: 769.9332\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 732.7713 - val_loss: 769.1382\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 724.8371 - val_loss: 753.7028\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 721.9414 - val_loss: 749.6780\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 707.0522 - val_loss: 731.5230\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 692.9132 - val_loss: 721.5838\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 666.3766 - val_loss: 678.1755\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 642.1089 - val_loss: 660.1227\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 632.5939 - val_loss: 622.4573\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 585.6481 - val_loss: 589.3992\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 562.8043 - val_loss: 567.6445\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 542.1246 - val_loss: 569.3010\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 522.9236 - val_loss: 520.4567\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 492.8915 - val_loss: 498.1139\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 482.7160 - val_loss: 468.9952\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 450.6011 - val_loss: 448.1470\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 433.8520 - val_loss: 436.4299\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 412.2175 - val_loss: 427.4828\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 393.0662 - val_loss: 390.8990\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 376.6498 - val_loss: 396.1360\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 361.0446 - val_loss: 372.9167\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 346.9567 - val_loss: 370.8062\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 331.0242 - val_loss: 334.0891\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 318.3462 - val_loss: 316.8112\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 310.0048 - val_loss: 319.1368\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 294.0590 - val_loss: 294.6186\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 282.9231 - val_loss: 284.8271\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 274.3562 - val_loss: 271.2304\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 263.8105 - val_loss: 261.8979\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 254.6432 - val_loss: 256.3840\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 249.0039 - val_loss: 244.1362\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 237.5143 - val_loss: 254.9745\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 229.7507 - val_loss: 236.1834\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 225.4375 - val_loss: 227.1743\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 215.8439 - val_loss: 221.4993\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 213.2784 - val_loss: 215.2728\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 206.5493 - val_loss: 219.0500\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 199.1987 - val_loss: 205.9126\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 195.4812 - val_loss: 196.8314\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 191.3592 - val_loss: 191.5289\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 187.4356 - val_loss: 197.5500\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 183.0944 - val_loss: 185.0450\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 182.0500 - val_loss: 188.5426\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 177.5388 - val_loss: 178.4384\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 175.8564 - val_loss: 181.1529\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 171.5088 - val_loss: 180.4203\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 169.9202 - val_loss: 174.1426\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 167.9750 - val_loss: 177.0262\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 162.6980 - val_loss: 167.1037\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 158.2799 - val_loss: 170.7145\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 156.7578 - val_loss: 165.1731\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 155.8930 - val_loss: 166.4200\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 153.4719 - val_loss: 164.7111\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 150.4235 - val_loss: 159.8139\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 148.6923 - val_loss: 164.0663\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 149.7103 - val_loss: 174.6135\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 147.9409 - val_loss: 154.3285\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 147.5393 - val_loss: 158.1719\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 143.8233 - val_loss: 155.5250\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 142.1938 - val_loss: 154.2105\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 140.8119 - val_loss: 159.2795\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 140.1323 - val_loss: 161.8224\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 140.7018 - val_loss: 175.0839\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 140.3031 - val_loss: 149.7375\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 135.6688 - val_loss: 148.3818\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 132.3792 - val_loss: 156.6078\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 134.4322 - val_loss: 150.0266\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 132.7986 - val_loss: 155.9279\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 129.9703 - val_loss: 144.6614\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 130.2951 - val_loss: 152.4172\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 131.1342 - val_loss: 141.9530\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 129.6298 - val_loss: 161.2015\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 127.1101 - val_loss: 152.1776\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 123.0919 - val_loss: 143.7045\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 123.2662 - val_loss: 159.5345\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 122.1062 - val_loss: 150.6817\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 120.8968 - val_loss: 145.8165\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 119.8623 - val_loss: 139.7720\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 115.2578 - val_loss: 138.8554\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 117.3343 - val_loss: 150.6445\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 120.4628 - val_loss: 137.5357\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 115.8557 - val_loss: 139.1398\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 112.8323 - val_loss: 153.8640\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 112.9667 - val_loss: 142.2802\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 110.2723 - val_loss: 137.9914\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 108.3378 - val_loss: 144.5848\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 108.3410 - val_loss: 141.2441\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 105.7334 - val_loss: 136.0210\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 107.7217 - val_loss: 133.8810\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 103.3844 - val_loss: 140.5703\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 102.1596 - val_loss: 139.5972\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 103.2153 - val_loss: 134.7722\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 102.1047 - val_loss: 142.6646\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 100.0137 - val_loss: 132.7541\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 97.4695 - val_loss: 133.8176\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 15ms/step - loss: 99.8108 - val_loss: 151.9802\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 97.5237 - val_loss: 146.0749\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 96.2818 - val_loss: 138.0099\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 96.7166 - val_loss: 136.0689\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 93.5062 - val_loss: 130.7865\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.5282 - val_loss: 143.1212\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.4076 - val_loss: 135.3548\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 91.1824 - val_loss: 133.2412\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 88.2822 - val_loss: 132.2736\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 87.9090 - val_loss: 132.7319\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 88.1247 - val_loss: 132.2563\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 87.3118 - val_loss: 140.4316\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 84.8818 - val_loss: 139.2846\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 85.3276 - val_loss: 134.8265\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 82.4184 - val_loss: 136.1702\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 83.2375 - val_loss: 138.4906\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 81.9891 - val_loss: 142.7121\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 80.3144 - val_loss: 135.8908\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 78.8165 - val_loss: 134.6456\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 77.1872 - val_loss: 135.7366\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 78.5559 - val_loss: 136.6451\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 75.2800 - val_loss: 133.4849\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 74.7075 - val_loss: 135.9963\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 74.8550 - val_loss: 142.3129\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.5701 - val_loss: 142.8255\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 73.5316 - val_loss: 138.4479\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 71.7005 - val_loss: 140.0450\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 72.4366 - val_loss: 137.3596\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 69.7119 - val_loss: 136.7520\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 67.9493 - val_loss: 141.6491\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 67.4696 - val_loss: 143.2892\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 68.0349 - val_loss: 143.7122\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 66.9922 - val_loss: 146.1433\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 64.9285 - val_loss: 138.2680\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 63.0488 - val_loss: 137.3438\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 63.4893 - val_loss: 143.6830\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 63.1663 - val_loss: 138.0174\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 62.1500 - val_loss: 151.6445\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 61.4184 - val_loss: 134.5180\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 59.2960 - val_loss: 144.1718\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.9937 - val_loss: 150.3860\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 57.9391 - val_loss: 141.7457\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 58.9153 - val_loss: 142.2799\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 56.8973 - val_loss: 138.5249\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 54.6126 - val_loss: 145.6309\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 53.1281 - val_loss: 144.3000\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 54.0411 - val_loss: 149.7746\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 53.6029 - val_loss: 151.7142\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 151.7146047943127\n",
      "Mean Absolute Error (MAE): 9.369280557594688\n",
      "Root Mean Squared Error (RMSE): 12.317248263890466\n",
      "Time taken: 1198.1229526996613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 48, 512)           1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 48, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_20428\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold         MSE       MAE       RMSE   Time taken\n",
      "0        1  143.023879  9.499882  11.959259  1253.004135\n",
      "1        2  144.080371  9.362988  12.003348  1256.664202\n",
      "2        3  152.884783  9.717621  12.364659  1247.465360\n",
      "3        4  145.381265  9.518708  12.057415  1177.725350\n",
      "4        5  151.714605  9.369281  12.317248  1198.122953\n",
      "5  Average  147.416981  9.493696  12.140386  1226.596400\n",
      "Results saved to 'DL_Result_PL_model_2_Scattered_iReg_f_over.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_2_Scattered_iReg_f_over.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'DL_Result_PL_model_2_Scattered_iReg_f_over.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
