{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered1_Reg1.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.343526</td>\n",
       "      <td>132.086973</td>\n",
       "      <td>81.738024</td>\n",
       "      <td>120.226650</td>\n",
       "      <td>127.621983</td>\n",
       "      <td>141.734180</td>\n",
       "      <td>104.808368</td>\n",
       "      <td>135.708107</td>\n",
       "      <td>100.574201</td>\n",
       "      <td>121.172680</td>\n",
       "      <td>...</td>\n",
       "      <td>100.001333</td>\n",
       "      <td>93.030358</td>\n",
       "      <td>108.610318</td>\n",
       "      <td>80.971633</td>\n",
       "      <td>127.068253</td>\n",
       "      <td>113.273672</td>\n",
       "      <td>102.118525</td>\n",
       "      <td>120.868728</td>\n",
       "      <td>81.395424</td>\n",
       "      <td>119.242231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.733610</td>\n",
       "      <td>136.739848</td>\n",
       "      <td>85.595980</td>\n",
       "      <td>121.531174</td>\n",
       "      <td>128.150768</td>\n",
       "      <td>146.754292</td>\n",
       "      <td>112.456378</td>\n",
       "      <td>142.308630</td>\n",
       "      <td>99.220561</td>\n",
       "      <td>113.623552</td>\n",
       "      <td>...</td>\n",
       "      <td>94.944468</td>\n",
       "      <td>92.532748</td>\n",
       "      <td>102.178885</td>\n",
       "      <td>85.745827</td>\n",
       "      <td>127.498364</td>\n",
       "      <td>101.891695</td>\n",
       "      <td>100.754638</td>\n",
       "      <td>132.995837</td>\n",
       "      <td>81.702073</td>\n",
       "      <td>109.877760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.503893</td>\n",
       "      <td>122.812742</td>\n",
       "      <td>79.306588</td>\n",
       "      <td>116.294374</td>\n",
       "      <td>121.246788</td>\n",
       "      <td>147.866563</td>\n",
       "      <td>114.673974</td>\n",
       "      <td>145.754454</td>\n",
       "      <td>98.140959</td>\n",
       "      <td>113.898725</td>\n",
       "      <td>...</td>\n",
       "      <td>106.442714</td>\n",
       "      <td>104.297185</td>\n",
       "      <td>109.932826</td>\n",
       "      <td>83.496819</td>\n",
       "      <td>130.000814</td>\n",
       "      <td>106.665402</td>\n",
       "      <td>100.613200</td>\n",
       "      <td>124.160411</td>\n",
       "      <td>71.817836</td>\n",
       "      <td>119.550575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.439048</td>\n",
       "      <td>128.212611</td>\n",
       "      <td>91.820230</td>\n",
       "      <td>108.778849</td>\n",
       "      <td>126.667009</td>\n",
       "      <td>154.660799</td>\n",
       "      <td>114.044773</td>\n",
       "      <td>138.616554</td>\n",
       "      <td>103.117246</td>\n",
       "      <td>119.596471</td>\n",
       "      <td>...</td>\n",
       "      <td>102.668226</td>\n",
       "      <td>97.500489</td>\n",
       "      <td>103.068480</td>\n",
       "      <td>85.886335</td>\n",
       "      <td>135.283285</td>\n",
       "      <td>109.376512</td>\n",
       "      <td>105.742410</td>\n",
       "      <td>129.627503</td>\n",
       "      <td>75.726365</td>\n",
       "      <td>114.868672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.124270</td>\n",
       "      <td>136.003305</td>\n",
       "      <td>84.028696</td>\n",
       "      <td>124.663682</td>\n",
       "      <td>135.153193</td>\n",
       "      <td>143.579315</td>\n",
       "      <td>110.567758</td>\n",
       "      <td>136.614045</td>\n",
       "      <td>99.838684</td>\n",
       "      <td>120.974244</td>\n",
       "      <td>...</td>\n",
       "      <td>105.042089</td>\n",
       "      <td>105.829707</td>\n",
       "      <td>104.026800</td>\n",
       "      <td>91.996143</td>\n",
       "      <td>128.574882</td>\n",
       "      <td>114.729913</td>\n",
       "      <td>107.554774</td>\n",
       "      <td>130.510348</td>\n",
       "      <td>72.869732</td>\n",
       "      <td>117.584639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>123.531786</td>\n",
       "      <td>111.827755</td>\n",
       "      <td>107.779643</td>\n",
       "      <td>82.168949</td>\n",
       "      <td>160.639754</td>\n",
       "      <td>141.197845</td>\n",
       "      <td>140.466814</td>\n",
       "      <td>118.054020</td>\n",
       "      <td>115.311765</td>\n",
       "      <td>108.883964</td>\n",
       "      <td>...</td>\n",
       "      <td>105.092582</td>\n",
       "      <td>116.499181</td>\n",
       "      <td>108.017102</td>\n",
       "      <td>63.983262</td>\n",
       "      <td>136.902008</td>\n",
       "      <td>119.899001</td>\n",
       "      <td>129.392320</td>\n",
       "      <td>115.266232</td>\n",
       "      <td>108.386809</td>\n",
       "      <td>75.319480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>123.851078</td>\n",
       "      <td>116.655550</td>\n",
       "      <td>108.100194</td>\n",
       "      <td>74.078485</td>\n",
       "      <td>145.023257</td>\n",
       "      <td>137.365691</td>\n",
       "      <td>132.357551</td>\n",
       "      <td>125.922760</td>\n",
       "      <td>113.876599</td>\n",
       "      <td>105.546221</td>\n",
       "      <td>...</td>\n",
       "      <td>115.201369</td>\n",
       "      <td>120.309415</td>\n",
       "      <td>107.178216</td>\n",
       "      <td>66.857463</td>\n",
       "      <td>129.040700</td>\n",
       "      <td>112.293239</td>\n",
       "      <td>126.342438</td>\n",
       "      <td>119.304489</td>\n",
       "      <td>102.924841</td>\n",
       "      <td>80.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>124.844037</td>\n",
       "      <td>107.987896</td>\n",
       "      <td>112.489683</td>\n",
       "      <td>79.497709</td>\n",
       "      <td>144.453616</td>\n",
       "      <td>139.741209</td>\n",
       "      <td>131.974434</td>\n",
       "      <td>112.734939</td>\n",
       "      <td>115.106630</td>\n",
       "      <td>101.798861</td>\n",
       "      <td>...</td>\n",
       "      <td>107.010916</td>\n",
       "      <td>123.180474</td>\n",
       "      <td>115.516488</td>\n",
       "      <td>68.961718</td>\n",
       "      <td>138.727408</td>\n",
       "      <td>117.477414</td>\n",
       "      <td>132.911279</td>\n",
       "      <td>115.787103</td>\n",
       "      <td>112.693310</td>\n",
       "      <td>92.181445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>121.997334</td>\n",
       "      <td>111.025481</td>\n",
       "      <td>110.218214</td>\n",
       "      <td>80.971138</td>\n",
       "      <td>153.382936</td>\n",
       "      <td>137.157752</td>\n",
       "      <td>145.942473</td>\n",
       "      <td>103.728702</td>\n",
       "      <td>115.493008</td>\n",
       "      <td>109.567823</td>\n",
       "      <td>...</td>\n",
       "      <td>105.686902</td>\n",
       "      <td>111.360597</td>\n",
       "      <td>108.686738</td>\n",
       "      <td>72.850986</td>\n",
       "      <td>137.977188</td>\n",
       "      <td>115.350605</td>\n",
       "      <td>134.436456</td>\n",
       "      <td>117.627324</td>\n",
       "      <td>112.260333</td>\n",
       "      <td>82.313619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>135.537949</td>\n",
       "      <td>113.579156</td>\n",
       "      <td>101.360531</td>\n",
       "      <td>74.057339</td>\n",
       "      <td>147.118505</td>\n",
       "      <td>139.976279</td>\n",
       "      <td>136.489963</td>\n",
       "      <td>116.466831</td>\n",
       "      <td>118.252801</td>\n",
       "      <td>103.166842</td>\n",
       "      <td>...</td>\n",
       "      <td>105.027692</td>\n",
       "      <td>119.419711</td>\n",
       "      <td>106.443638</td>\n",
       "      <td>69.086185</td>\n",
       "      <td>140.365965</td>\n",
       "      <td>119.729570</td>\n",
       "      <td>139.456786</td>\n",
       "      <td>116.487862</td>\n",
       "      <td>108.080218</td>\n",
       "      <td>84.064615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0      99.343526  132.086973   81.738024  120.226650  127.621983  141.734180   \n",
       "1     104.733610  136.739848   85.595980  121.531174  128.150768  146.754292   \n",
       "2     102.503893  122.812742   79.306588  116.294374  121.246788  147.866563   \n",
       "3     105.439048  128.212611   91.820230  108.778849  126.667009  154.660799   \n",
       "4     104.124270  136.003305   84.028696  124.663682  135.153193  143.579315   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  123.531786  111.827755  107.779643   82.168949  160.639754  141.197845   \n",
       "2439  123.851078  116.655550  108.100194   74.078485  145.023257  137.365691   \n",
       "2440  124.844037  107.987896  112.489683   79.497709  144.453616  139.741209   \n",
       "2441  121.997334  111.025481  110.218214   80.971138  153.382936  137.157752   \n",
       "2442  135.537949  113.579156  101.360531   74.057339  147.118505  139.976279   \n",
       "\n",
       "              6           7           8           9   ...          38  \\\n",
       "0     104.808368  135.708107  100.574201  121.172680  ...  100.001333   \n",
       "1     112.456378  142.308630   99.220561  113.623552  ...   94.944468   \n",
       "2     114.673974  145.754454   98.140959  113.898725  ...  106.442714   \n",
       "3     114.044773  138.616554  103.117246  119.596471  ...  102.668226   \n",
       "4     110.567758  136.614045   99.838684  120.974244  ...  105.042089   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  140.466814  118.054020  115.311765  108.883964  ...  105.092582   \n",
       "2439  132.357551  125.922760  113.876599  105.546221  ...  115.201369   \n",
       "2440  131.974434  112.734939  115.106630  101.798861  ...  107.010916   \n",
       "2441  145.942473  103.728702  115.493008  109.567823  ...  105.686902   \n",
       "2442  136.489963  116.466831  118.252801  103.166842  ...  105.027692   \n",
       "\n",
       "              39          40         41          42          43          44  \\\n",
       "0      93.030358  108.610318  80.971633  127.068253  113.273672  102.118525   \n",
       "1      92.532748  102.178885  85.745827  127.498364  101.891695  100.754638   \n",
       "2     104.297185  109.932826  83.496819  130.000814  106.665402  100.613200   \n",
       "3      97.500489  103.068480  85.886335  135.283285  109.376512  105.742410   \n",
       "4     105.829707  104.026800  91.996143  128.574882  114.729913  107.554774   \n",
       "...          ...         ...        ...         ...         ...         ...   \n",
       "2438  116.499181  108.017102  63.983262  136.902008  119.899001  129.392320   \n",
       "2439  120.309415  107.178216  66.857463  129.040700  112.293239  126.342438   \n",
       "2440  123.180474  115.516488  68.961718  138.727408  117.477414  132.911279   \n",
       "2441  111.360597  108.686738  72.850986  137.977188  115.350605  134.436456   \n",
       "2442  119.419711  106.443638  69.086185  140.365965  119.729570  139.456786   \n",
       "\n",
       "              45          46          47  \n",
       "0     120.868728   81.395424  119.242231  \n",
       "1     132.995837   81.702073  109.877760  \n",
       "2     124.160411   71.817836  119.550575  \n",
       "3     129.627503   75.726365  114.868672  \n",
       "4     130.510348   72.869732  117.584639  \n",
       "...          ...         ...         ...  \n",
       "2438  115.266232  108.386809   75.319480  \n",
       "2439  119.304489  102.924841   80.198171  \n",
       "2440  115.787103  112.693310   92.181445  \n",
       "2441  117.627324  112.260333   82.313619  \n",
       "2442  116.487862  108.080218   84.064615  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_Reg1.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.343526</td>\n",
       "      <td>132.086973</td>\n",
       "      <td>81.738024</td>\n",
       "      <td>120.226650</td>\n",
       "      <td>127.621983</td>\n",
       "      <td>141.734180</td>\n",
       "      <td>104.808368</td>\n",
       "      <td>135.708107</td>\n",
       "      <td>100.574201</td>\n",
       "      <td>121.172680</td>\n",
       "      <td>...</td>\n",
       "      <td>100.001333</td>\n",
       "      <td>93.030358</td>\n",
       "      <td>108.610318</td>\n",
       "      <td>80.971633</td>\n",
       "      <td>127.068253</td>\n",
       "      <td>113.273672</td>\n",
       "      <td>102.118525</td>\n",
       "      <td>120.868728</td>\n",
       "      <td>81.395424</td>\n",
       "      <td>119.242231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.733610</td>\n",
       "      <td>136.739848</td>\n",
       "      <td>85.595980</td>\n",
       "      <td>121.531174</td>\n",
       "      <td>128.150768</td>\n",
       "      <td>146.754292</td>\n",
       "      <td>112.456378</td>\n",
       "      <td>142.308630</td>\n",
       "      <td>99.220561</td>\n",
       "      <td>113.623552</td>\n",
       "      <td>...</td>\n",
       "      <td>94.944468</td>\n",
       "      <td>92.532748</td>\n",
       "      <td>102.178885</td>\n",
       "      <td>85.745827</td>\n",
       "      <td>127.498364</td>\n",
       "      <td>101.891695</td>\n",
       "      <td>100.754638</td>\n",
       "      <td>132.995837</td>\n",
       "      <td>81.702073</td>\n",
       "      <td>109.877760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.503893</td>\n",
       "      <td>122.812742</td>\n",
       "      <td>79.306588</td>\n",
       "      <td>116.294374</td>\n",
       "      <td>121.246788</td>\n",
       "      <td>147.866563</td>\n",
       "      <td>114.673974</td>\n",
       "      <td>145.754454</td>\n",
       "      <td>98.140959</td>\n",
       "      <td>113.898725</td>\n",
       "      <td>...</td>\n",
       "      <td>106.442714</td>\n",
       "      <td>104.297185</td>\n",
       "      <td>109.932826</td>\n",
       "      <td>83.496819</td>\n",
       "      <td>130.000814</td>\n",
       "      <td>106.665402</td>\n",
       "      <td>100.613200</td>\n",
       "      <td>124.160411</td>\n",
       "      <td>71.817836</td>\n",
       "      <td>119.550575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.439048</td>\n",
       "      <td>128.212611</td>\n",
       "      <td>91.820230</td>\n",
       "      <td>108.778849</td>\n",
       "      <td>126.667009</td>\n",
       "      <td>154.660799</td>\n",
       "      <td>114.044773</td>\n",
       "      <td>138.616554</td>\n",
       "      <td>103.117246</td>\n",
       "      <td>119.596471</td>\n",
       "      <td>...</td>\n",
       "      <td>102.668226</td>\n",
       "      <td>97.500489</td>\n",
       "      <td>103.068480</td>\n",
       "      <td>85.886335</td>\n",
       "      <td>135.283285</td>\n",
       "      <td>109.376512</td>\n",
       "      <td>105.742410</td>\n",
       "      <td>129.627503</td>\n",
       "      <td>75.726365</td>\n",
       "      <td>114.868672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.124270</td>\n",
       "      <td>136.003305</td>\n",
       "      <td>84.028696</td>\n",
       "      <td>124.663682</td>\n",
       "      <td>135.153193</td>\n",
       "      <td>143.579315</td>\n",
       "      <td>110.567758</td>\n",
       "      <td>136.614045</td>\n",
       "      <td>99.838684</td>\n",
       "      <td>120.974244</td>\n",
       "      <td>...</td>\n",
       "      <td>105.042089</td>\n",
       "      <td>105.829707</td>\n",
       "      <td>104.026800</td>\n",
       "      <td>91.996143</td>\n",
       "      <td>128.574882</td>\n",
       "      <td>114.729913</td>\n",
       "      <td>107.554774</td>\n",
       "      <td>130.510348</td>\n",
       "      <td>72.869732</td>\n",
       "      <td>117.584639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>123.531786</td>\n",
       "      <td>111.827755</td>\n",
       "      <td>107.779643</td>\n",
       "      <td>82.168949</td>\n",
       "      <td>160.639754</td>\n",
       "      <td>141.197845</td>\n",
       "      <td>140.466814</td>\n",
       "      <td>118.054020</td>\n",
       "      <td>115.311765</td>\n",
       "      <td>108.883964</td>\n",
       "      <td>...</td>\n",
       "      <td>105.092582</td>\n",
       "      <td>116.499181</td>\n",
       "      <td>108.017102</td>\n",
       "      <td>63.983262</td>\n",
       "      <td>136.902008</td>\n",
       "      <td>119.899001</td>\n",
       "      <td>129.392320</td>\n",
       "      <td>115.266232</td>\n",
       "      <td>108.386809</td>\n",
       "      <td>75.319480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>123.851078</td>\n",
       "      <td>116.655550</td>\n",
       "      <td>108.100194</td>\n",
       "      <td>74.078485</td>\n",
       "      <td>145.023257</td>\n",
       "      <td>137.365691</td>\n",
       "      <td>132.357551</td>\n",
       "      <td>125.922760</td>\n",
       "      <td>113.876599</td>\n",
       "      <td>105.546221</td>\n",
       "      <td>...</td>\n",
       "      <td>115.201369</td>\n",
       "      <td>120.309415</td>\n",
       "      <td>107.178216</td>\n",
       "      <td>66.857463</td>\n",
       "      <td>129.040700</td>\n",
       "      <td>112.293239</td>\n",
       "      <td>126.342438</td>\n",
       "      <td>119.304489</td>\n",
       "      <td>102.924841</td>\n",
       "      <td>80.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>124.844037</td>\n",
       "      <td>107.987896</td>\n",
       "      <td>112.489683</td>\n",
       "      <td>79.497709</td>\n",
       "      <td>144.453616</td>\n",
       "      <td>139.741209</td>\n",
       "      <td>131.974434</td>\n",
       "      <td>112.734939</td>\n",
       "      <td>115.106630</td>\n",
       "      <td>101.798861</td>\n",
       "      <td>...</td>\n",
       "      <td>107.010916</td>\n",
       "      <td>123.180474</td>\n",
       "      <td>115.516488</td>\n",
       "      <td>68.961718</td>\n",
       "      <td>138.727408</td>\n",
       "      <td>117.477414</td>\n",
       "      <td>132.911279</td>\n",
       "      <td>115.787103</td>\n",
       "      <td>112.693310</td>\n",
       "      <td>92.181445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>121.997334</td>\n",
       "      <td>111.025481</td>\n",
       "      <td>110.218214</td>\n",
       "      <td>80.971138</td>\n",
       "      <td>153.382936</td>\n",
       "      <td>137.157752</td>\n",
       "      <td>145.942473</td>\n",
       "      <td>103.728702</td>\n",
       "      <td>115.493008</td>\n",
       "      <td>109.567823</td>\n",
       "      <td>...</td>\n",
       "      <td>105.686902</td>\n",
       "      <td>111.360597</td>\n",
       "      <td>108.686738</td>\n",
       "      <td>72.850986</td>\n",
       "      <td>137.977188</td>\n",
       "      <td>115.350605</td>\n",
       "      <td>134.436456</td>\n",
       "      <td>117.627324</td>\n",
       "      <td>112.260333</td>\n",
       "      <td>82.313619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>135.537949</td>\n",
       "      <td>113.579156</td>\n",
       "      <td>101.360531</td>\n",
       "      <td>74.057339</td>\n",
       "      <td>147.118505</td>\n",
       "      <td>139.976279</td>\n",
       "      <td>136.489963</td>\n",
       "      <td>116.466831</td>\n",
       "      <td>118.252801</td>\n",
       "      <td>103.166842</td>\n",
       "      <td>...</td>\n",
       "      <td>105.027692</td>\n",
       "      <td>119.419711</td>\n",
       "      <td>106.443638</td>\n",
       "      <td>69.086185</td>\n",
       "      <td>140.365965</td>\n",
       "      <td>119.729570</td>\n",
       "      <td>139.456786</td>\n",
       "      <td>116.487862</td>\n",
       "      <td>108.080218</td>\n",
       "      <td>84.064615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0      99.343526  132.086973   81.738024  120.226650  127.621983  141.734180   \n",
       "1     104.733610  136.739848   85.595980  121.531174  128.150768  146.754292   \n",
       "2     102.503893  122.812742   79.306588  116.294374  121.246788  147.866563   \n",
       "3     105.439048  128.212611   91.820230  108.778849  126.667009  154.660799   \n",
       "4     104.124270  136.003305   84.028696  124.663682  135.153193  143.579315   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  123.531786  111.827755  107.779643   82.168949  160.639754  141.197845   \n",
       "2439  123.851078  116.655550  108.100194   74.078485  145.023257  137.365691   \n",
       "2440  124.844037  107.987896  112.489683   79.497709  144.453616  139.741209   \n",
       "2441  121.997334  111.025481  110.218214   80.971138  153.382936  137.157752   \n",
       "2442  135.537949  113.579156  101.360531   74.057339  147.118505  139.976279   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor39  \\\n",
       "0     104.808368  135.708107  100.574201  121.172680  ...  100.001333   \n",
       "1     112.456378  142.308630   99.220561  113.623552  ...   94.944468   \n",
       "2     114.673974  145.754454   98.140959  113.898725  ...  106.442714   \n",
       "3     114.044773  138.616554  103.117246  119.596471  ...  102.668226   \n",
       "4     110.567758  136.614045   99.838684  120.974244  ...  105.042089   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  140.466814  118.054020  115.311765  108.883964  ...  105.092582   \n",
       "2439  132.357551  125.922760  113.876599  105.546221  ...  115.201369   \n",
       "2440  131.974434  112.734939  115.106630  101.798861  ...  107.010916   \n",
       "2441  145.942473  103.728702  115.493008  109.567823  ...  105.686902   \n",
       "2442  136.489963  116.466831  118.252801  103.166842  ...  105.027692   \n",
       "\n",
       "        sensor40    sensor41   sensor42    sensor43    sensor44    sensor45  \\\n",
       "0      93.030358  108.610318  80.971633  127.068253  113.273672  102.118525   \n",
       "1      92.532748  102.178885  85.745827  127.498364  101.891695  100.754638   \n",
       "2     104.297185  109.932826  83.496819  130.000814  106.665402  100.613200   \n",
       "3      97.500489  103.068480  85.886335  135.283285  109.376512  105.742410   \n",
       "4     105.829707  104.026800  91.996143  128.574882  114.729913  107.554774   \n",
       "...          ...         ...        ...         ...         ...         ...   \n",
       "2438  116.499181  108.017102  63.983262  136.902008  119.899001  129.392320   \n",
       "2439  120.309415  107.178216  66.857463  129.040700  112.293239  126.342438   \n",
       "2440  123.180474  115.516488  68.961718  138.727408  117.477414  132.911279   \n",
       "2441  111.360597  108.686738  72.850986  137.977188  115.350605  134.436456   \n",
       "2442  119.419711  106.443638  69.086185  140.365965  119.729570  139.456786   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     120.868728   81.395424  119.242231  \n",
       "1     132.995837   81.702073  109.877760  \n",
       "2     124.160411   71.817836  119.550575  \n",
       "3     129.627503   75.726365  114.868672  \n",
       "4     130.510348   72.869732  117.584639  \n",
       "...          ...         ...         ...  \n",
       "2438  115.266232  108.386809   75.319480  \n",
       "2439  119.304489  102.924841   80.198171  \n",
       "2440  115.787103  112.693310   92.181445  \n",
       "2441  117.627324  112.260333   82.313619  \n",
       "2442  116.487862  108.080218   84.064615  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf63fe",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090b68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.343526</td>\n",
       "      <td>132.086973</td>\n",
       "      <td>81.738024</td>\n",
       "      <td>120.226650</td>\n",
       "      <td>127.621983</td>\n",
       "      <td>141.734180</td>\n",
       "      <td>104.808368</td>\n",
       "      <td>135.708107</td>\n",
       "      <td>100.574201</td>\n",
       "      <td>121.172680</td>\n",
       "      <td>82.333930</td>\n",
       "      <td>93.789366</td>\n",
       "      <td>119.324209</td>\n",
       "      <td>136.794290</td>\n",
       "      <td>107.793093</td>\n",
       "      <td>120.263026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.733610</td>\n",
       "      <td>136.739848</td>\n",
       "      <td>85.595980</td>\n",
       "      <td>121.531174</td>\n",
       "      <td>128.150768</td>\n",
       "      <td>146.754292</td>\n",
       "      <td>112.456378</td>\n",
       "      <td>142.308630</td>\n",
       "      <td>99.220561</td>\n",
       "      <td>113.623552</td>\n",
       "      <td>80.217410</td>\n",
       "      <td>97.310246</td>\n",
       "      <td>129.664434</td>\n",
       "      <td>135.466249</td>\n",
       "      <td>106.384720</td>\n",
       "      <td>116.778120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.503893</td>\n",
       "      <td>122.812742</td>\n",
       "      <td>79.306588</td>\n",
       "      <td>116.294374</td>\n",
       "      <td>121.246788</td>\n",
       "      <td>147.866563</td>\n",
       "      <td>114.673974</td>\n",
       "      <td>145.754454</td>\n",
       "      <td>98.140959</td>\n",
       "      <td>113.898725</td>\n",
       "      <td>85.614511</td>\n",
       "      <td>91.602001</td>\n",
       "      <td>127.045587</td>\n",
       "      <td>139.271721</td>\n",
       "      <td>102.341191</td>\n",
       "      <td>129.622060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.439048</td>\n",
       "      <td>128.212611</td>\n",
       "      <td>91.820230</td>\n",
       "      <td>108.778849</td>\n",
       "      <td>126.667009</td>\n",
       "      <td>154.660799</td>\n",
       "      <td>114.044773</td>\n",
       "      <td>138.616554</td>\n",
       "      <td>103.117246</td>\n",
       "      <td>119.596471</td>\n",
       "      <td>84.496056</td>\n",
       "      <td>103.637516</td>\n",
       "      <td>130.509635</td>\n",
       "      <td>136.819671</td>\n",
       "      <td>112.633822</td>\n",
       "      <td>121.699406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.124270</td>\n",
       "      <td>136.003305</td>\n",
       "      <td>84.028696</td>\n",
       "      <td>124.663682</td>\n",
       "      <td>135.153193</td>\n",
       "      <td>143.579315</td>\n",
       "      <td>110.567758</td>\n",
       "      <td>136.614045</td>\n",
       "      <td>99.838684</td>\n",
       "      <td>120.974244</td>\n",
       "      <td>85.565759</td>\n",
       "      <td>102.289988</td>\n",
       "      <td>134.487569</td>\n",
       "      <td>140.539859</td>\n",
       "      <td>104.250181</td>\n",
       "      <td>116.536543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>123.531786</td>\n",
       "      <td>111.827755</td>\n",
       "      <td>107.779643</td>\n",
       "      <td>82.168949</td>\n",
       "      <td>160.639754</td>\n",
       "      <td>141.197845</td>\n",
       "      <td>140.466814</td>\n",
       "      <td>118.054020</td>\n",
       "      <td>115.311765</td>\n",
       "      <td>108.883964</td>\n",
       "      <td>85.931597</td>\n",
       "      <td>66.560026</td>\n",
       "      <td>138.436863</td>\n",
       "      <td>139.892914</td>\n",
       "      <td>124.894868</td>\n",
       "      <td>113.918293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>123.851078</td>\n",
       "      <td>116.655550</td>\n",
       "      <td>108.100194</td>\n",
       "      <td>74.078485</td>\n",
       "      <td>145.023257</td>\n",
       "      <td>137.365691</td>\n",
       "      <td>132.357551</td>\n",
       "      <td>125.922760</td>\n",
       "      <td>113.876599</td>\n",
       "      <td>105.546221</td>\n",
       "      <td>88.843120</td>\n",
       "      <td>60.169525</td>\n",
       "      <td>137.671632</td>\n",
       "      <td>136.365141</td>\n",
       "      <td>120.412344</td>\n",
       "      <td>100.108167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>124.844037</td>\n",
       "      <td>107.987896</td>\n",
       "      <td>112.489683</td>\n",
       "      <td>79.497709</td>\n",
       "      <td>144.453616</td>\n",
       "      <td>139.741209</td>\n",
       "      <td>131.974434</td>\n",
       "      <td>112.734939</td>\n",
       "      <td>115.106630</td>\n",
       "      <td>101.798861</td>\n",
       "      <td>82.781896</td>\n",
       "      <td>76.996147</td>\n",
       "      <td>135.726816</td>\n",
       "      <td>129.584853</td>\n",
       "      <td>115.277284</td>\n",
       "      <td>117.353452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>121.997334</td>\n",
       "      <td>111.025481</td>\n",
       "      <td>110.218214</td>\n",
       "      <td>80.971138</td>\n",
       "      <td>153.382936</td>\n",
       "      <td>137.157752</td>\n",
       "      <td>145.942473</td>\n",
       "      <td>103.728702</td>\n",
       "      <td>115.493008</td>\n",
       "      <td>109.567823</td>\n",
       "      <td>77.123826</td>\n",
       "      <td>69.949946</td>\n",
       "      <td>145.575395</td>\n",
       "      <td>139.555621</td>\n",
       "      <td>120.950724</td>\n",
       "      <td>116.983920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>135.537949</td>\n",
       "      <td>113.579156</td>\n",
       "      <td>101.360531</td>\n",
       "      <td>74.057339</td>\n",
       "      <td>147.118505</td>\n",
       "      <td>139.976279</td>\n",
       "      <td>136.489963</td>\n",
       "      <td>116.466831</td>\n",
       "      <td>118.252801</td>\n",
       "      <td>103.166842</td>\n",
       "      <td>81.796673</td>\n",
       "      <td>64.602991</td>\n",
       "      <td>143.957850</td>\n",
       "      <td>129.315674</td>\n",
       "      <td>123.626082</td>\n",
       "      <td>104.996047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0      99.343526  132.086973   81.738024  120.226650  127.621983  141.734180   \n",
       "1     104.733610  136.739848   85.595980  121.531174  128.150768  146.754292   \n",
       "2     102.503893  122.812742   79.306588  116.294374  121.246788  147.866563   \n",
       "3     105.439048  128.212611   91.820230  108.778849  126.667009  154.660799   \n",
       "4     104.124270  136.003305   84.028696  124.663682  135.153193  143.579315   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  123.531786  111.827755  107.779643   82.168949  160.639754  141.197845   \n",
       "2439  123.851078  116.655550  108.100194   74.078485  145.023257  137.365691   \n",
       "2440  124.844037  107.987896  112.489683   79.497709  144.453616  139.741209   \n",
       "2441  121.997334  111.025481  110.218214   80.971138  153.382936  137.157752   \n",
       "2442  135.537949  113.579156  101.360531   74.057339  147.118505  139.976279   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10   sensor11    sensor12  \\\n",
       "0     104.808368  135.708107  100.574201  121.172680  82.333930   93.789366   \n",
       "1     112.456378  142.308630   99.220561  113.623552  80.217410   97.310246   \n",
       "2     114.673974  145.754454   98.140959  113.898725  85.614511   91.602001   \n",
       "3     114.044773  138.616554  103.117246  119.596471  84.496056  103.637516   \n",
       "4     110.567758  136.614045   99.838684  120.974244  85.565759  102.289988   \n",
       "...          ...         ...         ...         ...        ...         ...   \n",
       "2438  140.466814  118.054020  115.311765  108.883964  85.931597   66.560026   \n",
       "2439  132.357551  125.922760  113.876599  105.546221  88.843120   60.169525   \n",
       "2440  131.974434  112.734939  115.106630  101.798861  82.781896   76.996147   \n",
       "2441  145.942473  103.728702  115.493008  109.567823  77.123826   69.949946   \n",
       "2442  136.489963  116.466831  118.252801  103.166842  81.796673   64.602991   \n",
       "\n",
       "        sensor13    sensor14    sensor15    sensor16  \n",
       "0     119.324209  136.794290  107.793093  120.263026  \n",
       "1     129.664434  135.466249  106.384720  116.778120  \n",
       "2     127.045587  139.271721  102.341191  129.622060  \n",
       "3     130.509635  136.819671  112.633822  121.699406  \n",
       "4     134.487569  140.539859  104.250181  116.536543  \n",
       "...          ...         ...         ...         ...  \n",
       "2438  138.436863  139.892914  124.894868  113.918293  \n",
       "2439  137.671632  136.365141  120.412344  100.108167  \n",
       "2440  135.726816  129.584853  115.277284  117.353452  \n",
       "2441  145.575395  139.555621  120.950724  116.983920  \n",
       "2442  143.957850  129.315674  123.626082  104.996047  \n",
       "\n",
       "[2443 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:16]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 13s 16ms/step - loss: 1080.5157 - val_loss: 799.0793\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 645.1841 - val_loss: 509.3637\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 417.2897 - val_loss: 345.5310\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 282.5465 - val_loss: 232.3516\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 168.7759 - val_loss: 123.4610\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 96.5607 - val_loss: 77.0830\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 61.7292 - val_loss: 62.2617\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 41.8555 - val_loss: 41.0590\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 34.9906 - val_loss: 58.1001\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 28.4220 - val_loss: 32.5485\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 26.4514 - val_loss: 40.9776\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 25.2454 - val_loss: 33.0667\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 22.5972 - val_loss: 33.4696\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 22.8279 - val_loss: 36.6730\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 20.9600 - val_loss: 18.2115\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.2365 - val_loss: 22.9362\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.4796 - val_loss: 17.9284\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 19.9131 - val_loss: 21.7160\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.4313 - val_loss: 20.3783\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.5174 - val_loss: 17.6810\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.4028 - val_loss: 28.9398\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.6705 - val_loss: 15.6761\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.1024 - val_loss: 17.8105\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.5783 - val_loss: 23.3713\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.9415 - val_loss: 23.7121\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.0999 - val_loss: 26.2896\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.5210 - val_loss: 19.5140\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.1046 - val_loss: 20.1645\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.4495 - val_loss: 33.8657\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.0425 - val_loss: 24.6658\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.7295 - val_loss: 17.5312\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.8249 - val_loss: 20.7572\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.7825 - val_loss: 20.9495\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.5550 - val_loss: 20.7581\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.4794 - val_loss: 13.9330\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.7609 - val_loss: 22.0406\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.8509 - val_loss: 16.3205\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.4625 - val_loss: 16.9466\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.1027 - val_loss: 18.7076\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.1856 - val_loss: 19.3744\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9184 - val_loss: 19.2919\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9737 - val_loss: 14.1035\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.3328 - val_loss: 16.9023\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.1059 - val_loss: 24.2406\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.4422 - val_loss: 16.3524\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 12.5389 - val_loss: 19.2791\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.7654 - val_loss: 23.7697\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.3550 - val_loss: 17.3128\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.6416 - val_loss: 17.9396\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.5077 - val_loss: 21.9956\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5772 - val_loss: 14.4983\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.9049 - val_loss: 19.2921\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.7776 - val_loss: 15.4313\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5872 - val_loss: 20.5531\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.7263 - val_loss: 14.1162\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.2524 - val_loss: 28.6100\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.0623 - val_loss: 17.6789\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 10.0919 - val_loss: 17.5361\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 10.0475 - val_loss: 14.8426\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.8916 - val_loss: 15.7604\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.5896 - val_loss: 14.6435\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 10.0210 - val_loss: 19.7891\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 10.9215 - val_loss: 16.0561\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.4654 - val_loss: 27.3237\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.5568 - val_loss: 17.2916\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 13.934402183131965\n",
      "Mean Absolute Error (MAE): 2.5831601862467157\n",
      "Root Mean Squared Error (RMSE): 3.7328812173885155\n",
      "Time taken: 190.7799515724182\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 11ms/step - loss: 1051.2069 - val_loss: 824.1246\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 667.1877 - val_loss: 605.7073\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 463.9296 - val_loss: 367.5738\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 311.9649 - val_loss: 267.9460\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 208.7175 - val_loss: 153.2294\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 117.8548 - val_loss: 87.4283\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 71.9416 - val_loss: 53.2960\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 50.0290 - val_loss: 65.4029\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 38.2486 - val_loss: 56.5581\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 33.7181 - val_loss: 32.6980\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 28.4252 - val_loss: 30.2896\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.9556 - val_loss: 27.7120\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 24.2894 - val_loss: 28.0726\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 23.2445 - val_loss: 25.6248\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 22.0028 - val_loss: 27.0319\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.1181 - val_loss: 27.7938\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 20.1644 - val_loss: 19.7472\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.4160 - val_loss: 26.3328\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.0274 - val_loss: 25.9159\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.5936 - val_loss: 22.1143\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.1254 - val_loss: 28.3281\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.6988 - val_loss: 34.2480\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.6228 - val_loss: 16.6423\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.3688 - val_loss: 20.2357\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.0094 - val_loss: 17.7313\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.1778 - val_loss: 28.6488\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 16.5056 - val_loss: 18.6160\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.9480 - val_loss: 16.3202\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.0991 - val_loss: 39.4608\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 15.0865 - val_loss: 17.9022\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.6539 - val_loss: 23.3269\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.0234 - val_loss: 18.3448\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.4163 - val_loss: 15.5187\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.9275 - val_loss: 24.1074\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.0565 - val_loss: 20.5953\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.0340 - val_loss: 22.0062\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.9858 - val_loss: 22.0787\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.2356 - val_loss: 26.9564\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.0833 - val_loss: 26.4722\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.7491 - val_loss: 16.8193\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.5912 - val_loss: 17.8739\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.7004 - val_loss: 25.2701\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.1934 - val_loss: 18.3608\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.2970 - val_loss: 28.7821\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.5959 - val_loss: 16.4998\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1999 - val_loss: 18.5375\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.3391 - val_loss: 21.7885\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.4310 - val_loss: 25.9323\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.5150 - val_loss: 17.9466\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.1364 - val_loss: 28.2025\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1223 - val_loss: 15.5510\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.6652 - val_loss: 18.8649\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.2632 - val_loss: 18.5188\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.5558 - val_loss: 18.7413\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8262 - val_loss: 16.6362\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.6130 - val_loss: 17.7055\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5740 - val_loss: 18.9681\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.9100 - val_loss: 18.6931\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.3773 - val_loss: 21.2246\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.3331 - val_loss: 22.1433\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.2737 - val_loss: 16.4021\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.3263 - val_loss: 22.3129\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.5913 - val_loss: 17.3925\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 15.519096843643885\n",
      "Mean Absolute Error (MAE): 2.7647245133394946\n",
      "Root Mean Squared Error (RMSE): 3.9394284920079317\n",
      "Time taken: 174.2723319530487\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 13ms/step - loss: 1055.1942 - val_loss: 753.8470\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 579.6916 - val_loss: 467.2801\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 388.3999 - val_loss: 349.3420\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 268.2990 - val_loss: 266.2761\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 170.8172 - val_loss: 141.3199\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 100.6083 - val_loss: 82.5520\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 63.0897 - val_loss: 54.7256\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 43.1497 - val_loss: 59.6533\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 35.0290 - val_loss: 36.4441\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 29.3519 - val_loss: 68.5441\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 27.2917 - val_loss: 25.3203\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 23.9240 - val_loss: 27.0496\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 23.2314 - val_loss: 25.5871\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 22.6633 - val_loss: 28.7896\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 20.5708 - val_loss: 24.2659\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.9824 - val_loss: 24.5681\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 18.5324 - val_loss: 22.2809\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 18.6506 - val_loss: 22.8800\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.4086 - val_loss: 25.0981\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.1362 - val_loss: 25.3974\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.8793 - val_loss: 20.7675\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.9388 - val_loss: 18.0179\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.9361 - val_loss: 23.1690\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.0641 - val_loss: 18.0502\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.4028 - val_loss: 28.2952\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.3088 - val_loss: 25.4952\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.7903 - val_loss: 18.9772\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.1154 - val_loss: 27.5153\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.1580 - val_loss: 26.1470\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.6076 - val_loss: 25.0895\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.3015 - val_loss: 22.5242\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.7790 - val_loss: 17.2975\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.9358 - val_loss: 19.1516\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.1836 - val_loss: 18.5419\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.9243 - val_loss: 23.0085\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.0401 - val_loss: 18.8400\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.2198 - val_loss: 19.1783\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.2467 - val_loss: 18.4918\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9377 - val_loss: 15.8389\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.1867 - val_loss: 15.7854\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.6895 - val_loss: 21.3262\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.2324 - val_loss: 35.9683\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1947 - val_loss: 17.8269\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.3407 - val_loss: 18.4916\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.5290 - val_loss: 18.5243\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1412 - val_loss: 22.6332\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.4680 - val_loss: 17.2132\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.3501 - val_loss: 26.3647\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.9646 - val_loss: 18.2693\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.7477 - val_loss: 19.2402\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6826 - val_loss: 15.1617\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.3643 - val_loss: 15.3672\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 10.6128 - val_loss: 17.3329\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.2991 - val_loss: 15.9313\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.7460 - val_loss: 17.5185\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 10.5304 - val_loss: 14.5560\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.9512 - val_loss: 15.5989\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 10.6349 - val_loss: 45.6882\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.6436 - val_loss: 16.1027\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.2659 - val_loss: 16.2439\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.4096 - val_loss: 16.1885\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.3278 - val_loss: 17.0421\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.0015 - val_loss: 15.3883\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.9424 - val_loss: 15.5014\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.7233 - val_loss: 23.5659\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.0315 - val_loss: 17.3643\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.5255 - val_loss: 25.3503\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.8218 - val_loss: 15.9813\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.6407 - val_loss: 18.5227\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7024 - val_loss: 30.9434\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.5261 - val_loss: 18.9182\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.4517 - val_loss: 19.2026\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.8252 - val_loss: 14.3017\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 8.7476 - val_loss: 32.9175\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.1218 - val_loss: 16.8902\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.0446 - val_loss: 15.3353\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.3664 - val_loss: 17.1153\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.2613 - val_loss: 17.0308\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.6774 - val_loss: 17.9291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.3528 - val_loss: 15.1730\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.1352 - val_loss: 16.1767\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.3477 - val_loss: 16.8340\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.9866 - val_loss: 24.3055\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0395 - val_loss: 19.5764\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.0843 - val_loss: 15.7731\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.6191 - val_loss: 18.8037\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.8673 - val_loss: 15.8404\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0760 - val_loss: 16.4198\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.9980 - val_loss: 16.8711\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.7901 - val_loss: 18.0414\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 6.1607 - val_loss: 18.0042\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.1922 - val_loss: 15.5700\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 6.5720 - val_loss: 19.5595\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.2402 - val_loss: 17.0923\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.2243 - val_loss: 22.5852\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.1998 - val_loss: 19.4482\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 5.7590 - val_loss: 17.4137\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.0180 - val_loss: 33.1034\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.0013 - val_loss: 32.2107\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.7782 - val_loss: 17.8747\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 5.7465 - val_loss: 16.5740\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 5.9730 - val_loss: 18.2028\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.8417 - val_loss: 30.5546\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 14.305049672241593\n",
      "Mean Absolute Error (MAE): 2.464851719719976\n",
      "Root Mean Squared Error (RMSE): 3.7822016963987513\n",
      "Time taken: 290.69036650657654\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 8s 12ms/step - loss: 1057.6351 - val_loss: 764.1725\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 563.9265 - val_loss: 462.2066\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 378.2075 - val_loss: 321.3906\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 276.8955 - val_loss: 261.2855\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 178.3707 - val_loss: 125.9141\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 99.5954 - val_loss: 81.9038\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 59.2928 - val_loss: 58.1716\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 41.7483 - val_loss: 34.8016\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 33.5473 - val_loss: 32.4237\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 29.3902 - val_loss: 39.3204\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 25.2123 - val_loss: 32.9757\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.6869 - val_loss: 24.3880\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.0900 - val_loss: 26.1619\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.8586 - val_loss: 33.1007\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.4020 - val_loss: 29.4402\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.0492 - val_loss: 27.3557\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.8883 - val_loss: 49.6307\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.0979 - val_loss: 19.3074\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.1826 - val_loss: 25.5812\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.1441 - val_loss: 17.9112\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.3530 - val_loss: 31.4169\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.6072 - val_loss: 36.8675\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.9641 - val_loss: 25.0504\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 16.5796 - val_loss: 27.1621\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.1690 - val_loss: 20.0901\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.9093 - val_loss: 18.5055\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.8727 - val_loss: 21.3357\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.1857 - val_loss: 17.3009\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.8659 - val_loss: 25.3525\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.2810 - val_loss: 23.4492\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.6827 - val_loss: 20.8844\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.1327 - val_loss: 24.2244\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.8762 - val_loss: 17.4582\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.9954 - val_loss: 21.5474\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.8841 - val_loss: 22.4415\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 13.7945 - val_loss: 17.3391\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 13.4259 - val_loss: 16.0766\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.7598 - val_loss: 24.9471\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.8874 - val_loss: 28.7422\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.3003 - val_loss: 17.0630\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 13.1209 - val_loss: 28.9630\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 14.3837 - val_loss: 17.1157\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.7688 - val_loss: 19.9989\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.7265 - val_loss: 17.3890\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.1102 - val_loss: 18.8079\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.3464 - val_loss: 17.7935\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1381 - val_loss: 20.0034\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.4408 - val_loss: 17.8691\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.8046 - val_loss: 24.0850\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.1931 - val_loss: 16.3935\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.5616 - val_loss: 25.7297\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.5638 - val_loss: 17.7308\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8457 - val_loss: 20.0275\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.1049 - val_loss: 17.1352\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8284 - val_loss: 19.6414\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.6904 - val_loss: 15.5976\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.4666 - val_loss: 17.9109\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.6894 - val_loss: 21.4101\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.9443 - val_loss: 15.7257\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.9944 - val_loss: 17.1978\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.6177 - val_loss: 20.0290\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.3248 - val_loss: 18.2888\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7150 - val_loss: 20.3918\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.1092 - val_loss: 17.2445\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.3358 - val_loss: 18.5450\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.7763 - val_loss: 19.9432\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.4209 - val_loss: 17.6114\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.7519 - val_loss: 15.2670\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.4759 - val_loss: 20.8594\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.5539 - val_loss: 17.7821\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.6706 - val_loss: 15.3566\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.6565 - val_loss: 27.9147\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.3117 - val_loss: 17.5210\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.8485 - val_loss: 16.5395\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.3141 - val_loss: 28.1670\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.9307 - val_loss: 26.3653\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.9316 - val_loss: 24.0221\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 8.2422 - val_loss: 19.1002\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 8.3407 - val_loss: 20.5899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.3542 - val_loss: 16.3057\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.7037 - val_loss: 17.9436\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.1560 - val_loss: 16.1583\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 7.7778 - val_loss: 15.8060\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.8391 - val_loss: 19.9451\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.3637 - val_loss: 26.9436\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0600 - val_loss: 22.7924\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.7225 - val_loss: 17.1299\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.8975 - val_loss: 27.1598\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.7670 - val_loss: 16.9702\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.5456 - val_loss: 20.6287\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.5514 - val_loss: 16.1800\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.4435 - val_loss: 20.7586\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.8940 - val_loss: 17.5103\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.9621 - val_loss: 19.2190\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.6378 - val_loss: 20.9283\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.6709 - val_loss: 19.6643\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.4516 - val_loss: 16.9129\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.3679 - val_loss: 21.0916\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 15.267098375777243\n",
      "Mean Absolute Error (MAE): 2.621837664461373\n",
      "Root Mean Squared Error (RMSE): 3.9073134473416955\n",
      "Time taken: 284.77562737464905\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 11ms/step - loss: 1111.7059 - val_loss: 873.3576\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 618.8284 - val_loss: 545.3712\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 396.7390 - val_loss: 353.2919\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 244.2195 - val_loss: 194.7115\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 135.0278 - val_loss: 126.6742\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 74.5848 - val_loss: 96.8218\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 52.7852 - val_loss: 48.7957\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 36.8711 - val_loss: 43.5290\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.8594 - val_loss: 34.3774\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 26.7132 - val_loss: 43.0592\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 25.4730 - val_loss: 34.2395\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 24.5981 - val_loss: 28.7632\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 22.1142 - val_loss: 26.6446\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 21.4365 - val_loss: 22.3581\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.9467 - val_loss: 20.3515\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.2245 - val_loss: 25.9154\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.6338 - val_loss: 32.8918\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.1888 - val_loss: 30.0294\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.0697 - val_loss: 26.6014\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.4485 - val_loss: 28.9552\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.2545 - val_loss: 26.4194\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.6899 - val_loss: 21.6622\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.4111 - val_loss: 19.5443\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.1082 - val_loss: 28.3328\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 15.3465 - val_loss: 24.7751\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.0686 - val_loss: 19.1273\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.1253 - val_loss: 21.4577\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 14.4421 - val_loss: 30.2919\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.4364 - val_loss: 24.1248\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.4832 - val_loss: 24.3518\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.0632 - val_loss: 24.0410\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.6295 - val_loss: 17.0830\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.1259 - val_loss: 20.6492\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.3966 - val_loss: 19.4337\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.9560 - val_loss: 22.9381\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.1278 - val_loss: 19.1374\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.7682 - val_loss: 22.1697\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.0289 - val_loss: 20.3219\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.5389 - val_loss: 25.6533\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.7169 - val_loss: 16.1614\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.0339 - val_loss: 18.7825\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.5277 - val_loss: 20.6777\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.9065 - val_loss: 19.8065\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.8820 - val_loss: 17.0267\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.0944 - val_loss: 18.1895\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.5843 - val_loss: 18.8568\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.3051 - val_loss: 15.7648\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1248 - val_loss: 24.7271\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.3507 - val_loss: 18.5672\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8779 - val_loss: 18.8985\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.9380 - val_loss: 18.6216\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.8589 - val_loss: 16.6757\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.2290 - val_loss: 17.9415\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.1448 - val_loss: 29.3679\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6058 - val_loss: 16.2467\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.0248 - val_loss: 28.2477\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.2892 - val_loss: 23.7514\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.9421 - val_loss: 18.2026\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.4161 - val_loss: 29.0071\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.6687 - val_loss: 18.6342\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.3599 - val_loss: 18.8586\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.1900 - val_loss: 18.5104\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.7227 - val_loss: 17.1210\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.8692 - val_loss: 20.7906\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.3307 - val_loss: 18.9479\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.0132 - val_loss: 16.7409\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.5387 - val_loss: 23.5188\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.6269 - val_loss: 26.4099\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 9.4112 - val_loss: 31.1662\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.1044 - val_loss: 16.9357\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.2096 - val_loss: 23.2730\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.4157 - val_loss: 18.9516\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.5663 - val_loss: 19.8768\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.5868 - val_loss: 16.0662\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.6960 - val_loss: 20.1709\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.0549 - val_loss: 25.5385\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.8140 - val_loss: 21.2076\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 15.764920867976278\n",
      "Mean Absolute Error (MAE): 2.7324862639151397\n",
      "Root Mean Squared Error (RMSE): 3.9705063742520648\n",
      "Time taken: 215.46553230285645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=6,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 16, 512)           1052672   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16, 512)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 16, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,047,747\n",
      "Trainable params: 2,046,723\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_14972\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold        MSE       MAE      RMSE  Time taken\n",
      "0        1  13.934402  2.583160  3.732881  190.779952\n",
      "1        2  15.519097  2.764725  3.939428  174.272332\n",
      "2        3  14.305050  2.464852  3.782202  290.690367\n",
      "3        4  15.267098  2.621838  3.907313  284.775627\n",
      "4        5  15.764921  2.732486  3.970506  215.465532\n",
      "5  Average  14.958114  2.633412  3.866466  231.196762\n",
      "Results saved to 'LSTM Results PL_model_1_Scattered1_Reg1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('LSTM Results PL_model_1_Scattered1_Reg1.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'LSTM Results PL_model_1_Scattered1_Reg1.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
