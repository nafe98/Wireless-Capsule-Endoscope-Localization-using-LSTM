{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered_iReg_f_over.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159.151730</td>\n",
       "      <td>199.542510</td>\n",
       "      <td>93.204352</td>\n",
       "      <td>141.610133</td>\n",
       "      <td>208.230033</td>\n",
       "      <td>220.674816</td>\n",
       "      <td>158.863186</td>\n",
       "      <td>189.306563</td>\n",
       "      <td>144.184843</td>\n",
       "      <td>160.406591</td>\n",
       "      <td>...</td>\n",
       "      <td>125.388714</td>\n",
       "      <td>134.794757</td>\n",
       "      <td>137.019077</td>\n",
       "      <td>133.083826</td>\n",
       "      <td>188.991982</td>\n",
       "      <td>178.155730</td>\n",
       "      <td>161.186367</td>\n",
       "      <td>192.737363</td>\n",
       "      <td>73.724932</td>\n",
       "      <td>138.491142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166.398547</td>\n",
       "      <td>184.865378</td>\n",
       "      <td>100.886692</td>\n",
       "      <td>142.019092</td>\n",
       "      <td>200.934261</td>\n",
       "      <td>231.777862</td>\n",
       "      <td>156.058008</td>\n",
       "      <td>203.353192</td>\n",
       "      <td>140.903362</td>\n",
       "      <td>165.565921</td>\n",
       "      <td>...</td>\n",
       "      <td>131.875666</td>\n",
       "      <td>144.307763</td>\n",
       "      <td>144.125796</td>\n",
       "      <td>127.552055</td>\n",
       "      <td>183.965512</td>\n",
       "      <td>179.206473</td>\n",
       "      <td>153.405338</td>\n",
       "      <td>192.374917</td>\n",
       "      <td>83.476169</td>\n",
       "      <td>127.547566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168.699960</td>\n",
       "      <td>195.483494</td>\n",
       "      <td>102.242983</td>\n",
       "      <td>151.909099</td>\n",
       "      <td>206.502507</td>\n",
       "      <td>224.945880</td>\n",
       "      <td>161.279681</td>\n",
       "      <td>183.895077</td>\n",
       "      <td>145.834056</td>\n",
       "      <td>158.360219</td>\n",
       "      <td>...</td>\n",
       "      <td>126.723309</td>\n",
       "      <td>138.780776</td>\n",
       "      <td>128.601055</td>\n",
       "      <td>130.194494</td>\n",
       "      <td>181.584965</td>\n",
       "      <td>176.214339</td>\n",
       "      <td>163.883558</td>\n",
       "      <td>187.026603</td>\n",
       "      <td>74.422808</td>\n",
       "      <td>145.994348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165.108359</td>\n",
       "      <td>195.489980</td>\n",
       "      <td>95.088657</td>\n",
       "      <td>146.039074</td>\n",
       "      <td>194.145214</td>\n",
       "      <td>233.067175</td>\n",
       "      <td>159.540317</td>\n",
       "      <td>187.301984</td>\n",
       "      <td>135.145034</td>\n",
       "      <td>168.508921</td>\n",
       "      <td>...</td>\n",
       "      <td>120.952913</td>\n",
       "      <td>134.810703</td>\n",
       "      <td>133.864237</td>\n",
       "      <td>144.482189</td>\n",
       "      <td>181.923756</td>\n",
       "      <td>181.988992</td>\n",
       "      <td>158.399493</td>\n",
       "      <td>187.715639</td>\n",
       "      <td>83.992892</td>\n",
       "      <td>138.966512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168.168172</td>\n",
       "      <td>185.840023</td>\n",
       "      <td>99.153895</td>\n",
       "      <td>139.952871</td>\n",
       "      <td>194.029188</td>\n",
       "      <td>225.089917</td>\n",
       "      <td>155.754544</td>\n",
       "      <td>188.479389</td>\n",
       "      <td>141.177966</td>\n",
       "      <td>170.835688</td>\n",
       "      <td>...</td>\n",
       "      <td>117.921545</td>\n",
       "      <td>139.772629</td>\n",
       "      <td>138.342093</td>\n",
       "      <td>130.464550</td>\n",
       "      <td>192.744036</td>\n",
       "      <td>183.586504</td>\n",
       "      <td>153.567238</td>\n",
       "      <td>188.398368</td>\n",
       "      <td>79.339979</td>\n",
       "      <td>133.595655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>191.446233</td>\n",
       "      <td>163.863018</td>\n",
       "      <td>120.196717</td>\n",
       "      <td>81.691845</td>\n",
       "      <td>232.944152</td>\n",
       "      <td>213.767370</td>\n",
       "      <td>188.466104</td>\n",
       "      <td>177.347899</td>\n",
       "      <td>156.237599</td>\n",
       "      <td>139.888740</td>\n",
       "      <td>...</td>\n",
       "      <td>121.416400</td>\n",
       "      <td>158.272110</td>\n",
       "      <td>135.787415</td>\n",
       "      <td>110.038074</td>\n",
       "      <td>204.484919</td>\n",
       "      <td>181.772215</td>\n",
       "      <td>183.221858</td>\n",
       "      <td>165.974294</td>\n",
       "      <td>129.016781</td>\n",
       "      <td>91.163284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>192.210071</td>\n",
       "      <td>169.472938</td>\n",
       "      <td>126.408295</td>\n",
       "      <td>80.555287</td>\n",
       "      <td>226.421779</td>\n",
       "      <td>212.131048</td>\n",
       "      <td>189.024391</td>\n",
       "      <td>161.463544</td>\n",
       "      <td>146.955323</td>\n",
       "      <td>136.197913</td>\n",
       "      <td>...</td>\n",
       "      <td>124.351245</td>\n",
       "      <td>155.065263</td>\n",
       "      <td>138.527748</td>\n",
       "      <td>112.555788</td>\n",
       "      <td>199.509706</td>\n",
       "      <td>186.175599</td>\n",
       "      <td>183.299073</td>\n",
       "      <td>175.290848</td>\n",
       "      <td>130.406301</td>\n",
       "      <td>90.511453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>182.613814</td>\n",
       "      <td>174.438416</td>\n",
       "      <td>116.411536</td>\n",
       "      <td>91.348961</td>\n",
       "      <td>233.275747</td>\n",
       "      <td>210.510062</td>\n",
       "      <td>189.619989</td>\n",
       "      <td>163.533342</td>\n",
       "      <td>152.167692</td>\n",
       "      <td>144.491181</td>\n",
       "      <td>...</td>\n",
       "      <td>124.840993</td>\n",
       "      <td>154.881355</td>\n",
       "      <td>129.234448</td>\n",
       "      <td>110.663062</td>\n",
       "      <td>193.894392</td>\n",
       "      <td>184.388362</td>\n",
       "      <td>181.968458</td>\n",
       "      <td>177.496974</td>\n",
       "      <td>121.539625</td>\n",
       "      <td>87.932897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>179.865005</td>\n",
       "      <td>159.415279</td>\n",
       "      <td>123.315088</td>\n",
       "      <td>80.356934</td>\n",
       "      <td>226.317654</td>\n",
       "      <td>215.812200</td>\n",
       "      <td>185.093114</td>\n",
       "      <td>175.015502</td>\n",
       "      <td>161.770560</td>\n",
       "      <td>143.224881</td>\n",
       "      <td>...</td>\n",
       "      <td>119.455255</td>\n",
       "      <td>156.300451</td>\n",
       "      <td>131.414059</td>\n",
       "      <td>116.108234</td>\n",
       "      <td>193.147585</td>\n",
       "      <td>181.736531</td>\n",
       "      <td>183.386660</td>\n",
       "      <td>165.651099</td>\n",
       "      <td>129.228967</td>\n",
       "      <td>81.105373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>176.406070</td>\n",
       "      <td>160.883552</td>\n",
       "      <td>123.303897</td>\n",
       "      <td>90.376887</td>\n",
       "      <td>229.966006</td>\n",
       "      <td>218.518262</td>\n",
       "      <td>186.131661</td>\n",
       "      <td>172.264626</td>\n",
       "      <td>158.317146</td>\n",
       "      <td>144.987837</td>\n",
       "      <td>...</td>\n",
       "      <td>125.298911</td>\n",
       "      <td>162.548268</td>\n",
       "      <td>134.958068</td>\n",
       "      <td>112.415088</td>\n",
       "      <td>196.695747</td>\n",
       "      <td>186.109119</td>\n",
       "      <td>191.853005</td>\n",
       "      <td>173.257644</td>\n",
       "      <td>123.993322</td>\n",
       "      <td>90.839897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     159.151730  199.542510   93.204352  141.610133  208.230033  220.674816   \n",
       "1     166.398547  184.865378  100.886692  142.019092  200.934261  231.777862   \n",
       "2     168.699960  195.483494  102.242983  151.909099  206.502507  224.945880   \n",
       "3     165.108359  195.489980   95.088657  146.039074  194.145214  233.067175   \n",
       "4     168.168172  185.840023   99.153895  139.952871  194.029188  225.089917   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  191.446233  163.863018  120.196717   81.691845  232.944152  213.767370   \n",
       "2439  192.210071  169.472938  126.408295   80.555287  226.421779  212.131048   \n",
       "2440  182.613814  174.438416  116.411536   91.348961  233.275747  210.510062   \n",
       "2441  179.865005  159.415279  123.315088   80.356934  226.317654  215.812200   \n",
       "2442  176.406070  160.883552  123.303897   90.376887  229.966006  218.518262   \n",
       "\n",
       "              6           7           8           9   ...          38  \\\n",
       "0     158.863186  189.306563  144.184843  160.406591  ...  125.388714   \n",
       "1     156.058008  203.353192  140.903362  165.565921  ...  131.875666   \n",
       "2     161.279681  183.895077  145.834056  158.360219  ...  126.723309   \n",
       "3     159.540317  187.301984  135.145034  168.508921  ...  120.952913   \n",
       "4     155.754544  188.479389  141.177966  170.835688  ...  117.921545   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  188.466104  177.347899  156.237599  139.888740  ...  121.416400   \n",
       "2439  189.024391  161.463544  146.955323  136.197913  ...  124.351245   \n",
       "2440  189.619989  163.533342  152.167692  144.491181  ...  124.840993   \n",
       "2441  185.093114  175.015502  161.770560  143.224881  ...  119.455255   \n",
       "2442  186.131661  172.264626  158.317146  144.987837  ...  125.298911   \n",
       "\n",
       "              39          40          41          42          43          44  \\\n",
       "0     134.794757  137.019077  133.083826  188.991982  178.155730  161.186367   \n",
       "1     144.307763  144.125796  127.552055  183.965512  179.206473  153.405338   \n",
       "2     138.780776  128.601055  130.194494  181.584965  176.214339  163.883558   \n",
       "3     134.810703  133.864237  144.482189  181.923756  181.988992  158.399493   \n",
       "4     139.772629  138.342093  130.464550  192.744036  183.586504  153.567238   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  158.272110  135.787415  110.038074  204.484919  181.772215  183.221858   \n",
       "2439  155.065263  138.527748  112.555788  199.509706  186.175599  183.299073   \n",
       "2440  154.881355  129.234448  110.663062  193.894392  184.388362  181.968458   \n",
       "2441  156.300451  131.414059  116.108234  193.147585  181.736531  183.386660   \n",
       "2442  162.548268  134.958068  112.415088  196.695747  186.109119  191.853005   \n",
       "\n",
       "              45          46          47  \n",
       "0     192.737363   73.724932  138.491142  \n",
       "1     192.374917   83.476169  127.547566  \n",
       "2     187.026603   74.422808  145.994348  \n",
       "3     187.715639   83.992892  138.966512  \n",
       "4     188.398368   79.339979  133.595655  \n",
       "...          ...         ...         ...  \n",
       "2438  165.974294  129.016781   91.163284  \n",
       "2439  175.290848  130.406301   90.511453  \n",
       "2440  177.496974  121.539625   87.932897  \n",
       "2441  165.651099  129.228967   81.105373  \n",
       "2442  173.257644  123.993322   90.839897  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159.151730</td>\n",
       "      <td>199.542510</td>\n",
       "      <td>93.204352</td>\n",
       "      <td>141.610133</td>\n",
       "      <td>208.230033</td>\n",
       "      <td>220.674816</td>\n",
       "      <td>158.863186</td>\n",
       "      <td>189.306563</td>\n",
       "      <td>144.184843</td>\n",
       "      <td>160.406591</td>\n",
       "      <td>...</td>\n",
       "      <td>125.388714</td>\n",
       "      <td>134.794757</td>\n",
       "      <td>137.019077</td>\n",
       "      <td>133.083826</td>\n",
       "      <td>188.991982</td>\n",
       "      <td>178.155730</td>\n",
       "      <td>161.186367</td>\n",
       "      <td>192.737363</td>\n",
       "      <td>73.724932</td>\n",
       "      <td>138.491142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166.398547</td>\n",
       "      <td>184.865378</td>\n",
       "      <td>100.886692</td>\n",
       "      <td>142.019092</td>\n",
       "      <td>200.934261</td>\n",
       "      <td>231.777862</td>\n",
       "      <td>156.058008</td>\n",
       "      <td>203.353192</td>\n",
       "      <td>140.903362</td>\n",
       "      <td>165.565921</td>\n",
       "      <td>...</td>\n",
       "      <td>131.875666</td>\n",
       "      <td>144.307763</td>\n",
       "      <td>144.125796</td>\n",
       "      <td>127.552055</td>\n",
       "      <td>183.965512</td>\n",
       "      <td>179.206473</td>\n",
       "      <td>153.405338</td>\n",
       "      <td>192.374917</td>\n",
       "      <td>83.476169</td>\n",
       "      <td>127.547566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168.699960</td>\n",
       "      <td>195.483494</td>\n",
       "      <td>102.242983</td>\n",
       "      <td>151.909099</td>\n",
       "      <td>206.502507</td>\n",
       "      <td>224.945880</td>\n",
       "      <td>161.279681</td>\n",
       "      <td>183.895077</td>\n",
       "      <td>145.834056</td>\n",
       "      <td>158.360219</td>\n",
       "      <td>...</td>\n",
       "      <td>126.723309</td>\n",
       "      <td>138.780776</td>\n",
       "      <td>128.601055</td>\n",
       "      <td>130.194494</td>\n",
       "      <td>181.584965</td>\n",
       "      <td>176.214339</td>\n",
       "      <td>163.883558</td>\n",
       "      <td>187.026603</td>\n",
       "      <td>74.422808</td>\n",
       "      <td>145.994348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165.108359</td>\n",
       "      <td>195.489980</td>\n",
       "      <td>95.088657</td>\n",
       "      <td>146.039074</td>\n",
       "      <td>194.145214</td>\n",
       "      <td>233.067175</td>\n",
       "      <td>159.540317</td>\n",
       "      <td>187.301984</td>\n",
       "      <td>135.145034</td>\n",
       "      <td>168.508921</td>\n",
       "      <td>...</td>\n",
       "      <td>120.952913</td>\n",
       "      <td>134.810703</td>\n",
       "      <td>133.864237</td>\n",
       "      <td>144.482189</td>\n",
       "      <td>181.923756</td>\n",
       "      <td>181.988992</td>\n",
       "      <td>158.399493</td>\n",
       "      <td>187.715639</td>\n",
       "      <td>83.992892</td>\n",
       "      <td>138.966512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168.168172</td>\n",
       "      <td>185.840023</td>\n",
       "      <td>99.153895</td>\n",
       "      <td>139.952871</td>\n",
       "      <td>194.029188</td>\n",
       "      <td>225.089917</td>\n",
       "      <td>155.754544</td>\n",
       "      <td>188.479389</td>\n",
       "      <td>141.177966</td>\n",
       "      <td>170.835688</td>\n",
       "      <td>...</td>\n",
       "      <td>117.921545</td>\n",
       "      <td>139.772629</td>\n",
       "      <td>138.342093</td>\n",
       "      <td>130.464550</td>\n",
       "      <td>192.744036</td>\n",
       "      <td>183.586504</td>\n",
       "      <td>153.567238</td>\n",
       "      <td>188.398368</td>\n",
       "      <td>79.339979</td>\n",
       "      <td>133.595655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>191.446233</td>\n",
       "      <td>163.863018</td>\n",
       "      <td>120.196717</td>\n",
       "      <td>81.691845</td>\n",
       "      <td>232.944152</td>\n",
       "      <td>213.767370</td>\n",
       "      <td>188.466104</td>\n",
       "      <td>177.347899</td>\n",
       "      <td>156.237599</td>\n",
       "      <td>139.888740</td>\n",
       "      <td>...</td>\n",
       "      <td>121.416400</td>\n",
       "      <td>158.272110</td>\n",
       "      <td>135.787415</td>\n",
       "      <td>110.038074</td>\n",
       "      <td>204.484919</td>\n",
       "      <td>181.772215</td>\n",
       "      <td>183.221858</td>\n",
       "      <td>165.974294</td>\n",
       "      <td>129.016781</td>\n",
       "      <td>91.163284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>192.210071</td>\n",
       "      <td>169.472938</td>\n",
       "      <td>126.408295</td>\n",
       "      <td>80.555287</td>\n",
       "      <td>226.421779</td>\n",
       "      <td>212.131048</td>\n",
       "      <td>189.024391</td>\n",
       "      <td>161.463544</td>\n",
       "      <td>146.955323</td>\n",
       "      <td>136.197913</td>\n",
       "      <td>...</td>\n",
       "      <td>124.351245</td>\n",
       "      <td>155.065263</td>\n",
       "      <td>138.527748</td>\n",
       "      <td>112.555788</td>\n",
       "      <td>199.509706</td>\n",
       "      <td>186.175599</td>\n",
       "      <td>183.299073</td>\n",
       "      <td>175.290848</td>\n",
       "      <td>130.406301</td>\n",
       "      <td>90.511453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>182.613814</td>\n",
       "      <td>174.438416</td>\n",
       "      <td>116.411536</td>\n",
       "      <td>91.348961</td>\n",
       "      <td>233.275747</td>\n",
       "      <td>210.510062</td>\n",
       "      <td>189.619989</td>\n",
       "      <td>163.533342</td>\n",
       "      <td>152.167692</td>\n",
       "      <td>144.491181</td>\n",
       "      <td>...</td>\n",
       "      <td>124.840993</td>\n",
       "      <td>154.881355</td>\n",
       "      <td>129.234448</td>\n",
       "      <td>110.663062</td>\n",
       "      <td>193.894392</td>\n",
       "      <td>184.388362</td>\n",
       "      <td>181.968458</td>\n",
       "      <td>177.496974</td>\n",
       "      <td>121.539625</td>\n",
       "      <td>87.932897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>179.865005</td>\n",
       "      <td>159.415279</td>\n",
       "      <td>123.315088</td>\n",
       "      <td>80.356934</td>\n",
       "      <td>226.317654</td>\n",
       "      <td>215.812200</td>\n",
       "      <td>185.093114</td>\n",
       "      <td>175.015502</td>\n",
       "      <td>161.770560</td>\n",
       "      <td>143.224881</td>\n",
       "      <td>...</td>\n",
       "      <td>119.455255</td>\n",
       "      <td>156.300451</td>\n",
       "      <td>131.414059</td>\n",
       "      <td>116.108234</td>\n",
       "      <td>193.147585</td>\n",
       "      <td>181.736531</td>\n",
       "      <td>183.386660</td>\n",
       "      <td>165.651099</td>\n",
       "      <td>129.228967</td>\n",
       "      <td>81.105373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>176.406070</td>\n",
       "      <td>160.883552</td>\n",
       "      <td>123.303897</td>\n",
       "      <td>90.376887</td>\n",
       "      <td>229.966006</td>\n",
       "      <td>218.518262</td>\n",
       "      <td>186.131661</td>\n",
       "      <td>172.264626</td>\n",
       "      <td>158.317146</td>\n",
       "      <td>144.987837</td>\n",
       "      <td>...</td>\n",
       "      <td>125.298911</td>\n",
       "      <td>162.548268</td>\n",
       "      <td>134.958068</td>\n",
       "      <td>112.415088</td>\n",
       "      <td>196.695747</td>\n",
       "      <td>186.109119</td>\n",
       "      <td>191.853005</td>\n",
       "      <td>173.257644</td>\n",
       "      <td>123.993322</td>\n",
       "      <td>90.839897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     159.151730  199.542510   93.204352  141.610133  208.230033  220.674816   \n",
       "1     166.398547  184.865378  100.886692  142.019092  200.934261  231.777862   \n",
       "2     168.699960  195.483494  102.242983  151.909099  206.502507  224.945880   \n",
       "3     165.108359  195.489980   95.088657  146.039074  194.145214  233.067175   \n",
       "4     168.168172  185.840023   99.153895  139.952871  194.029188  225.089917   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  191.446233  163.863018  120.196717   81.691845  232.944152  213.767370   \n",
       "2439  192.210071  169.472938  126.408295   80.555287  226.421779  212.131048   \n",
       "2440  182.613814  174.438416  116.411536   91.348961  233.275747  210.510062   \n",
       "2441  179.865005  159.415279  123.315088   80.356934  226.317654  215.812200   \n",
       "2442  176.406070  160.883552  123.303897   90.376887  229.966006  218.518262   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor39  \\\n",
       "0     158.863186  189.306563  144.184843  160.406591  ...  125.388714   \n",
       "1     156.058008  203.353192  140.903362  165.565921  ...  131.875666   \n",
       "2     161.279681  183.895077  145.834056  158.360219  ...  126.723309   \n",
       "3     159.540317  187.301984  135.145034  168.508921  ...  120.952913   \n",
       "4     155.754544  188.479389  141.177966  170.835688  ...  117.921545   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  188.466104  177.347899  156.237599  139.888740  ...  121.416400   \n",
       "2439  189.024391  161.463544  146.955323  136.197913  ...  124.351245   \n",
       "2440  189.619989  163.533342  152.167692  144.491181  ...  124.840993   \n",
       "2441  185.093114  175.015502  161.770560  143.224881  ...  119.455255   \n",
       "2442  186.131661  172.264626  158.317146  144.987837  ...  125.298911   \n",
       "\n",
       "        sensor40    sensor41    sensor42    sensor43    sensor44    sensor45  \\\n",
       "0     134.794757  137.019077  133.083826  188.991982  178.155730  161.186367   \n",
       "1     144.307763  144.125796  127.552055  183.965512  179.206473  153.405338   \n",
       "2     138.780776  128.601055  130.194494  181.584965  176.214339  163.883558   \n",
       "3     134.810703  133.864237  144.482189  181.923756  181.988992  158.399493   \n",
       "4     139.772629  138.342093  130.464550  192.744036  183.586504  153.567238   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  158.272110  135.787415  110.038074  204.484919  181.772215  183.221858   \n",
       "2439  155.065263  138.527748  112.555788  199.509706  186.175599  183.299073   \n",
       "2440  154.881355  129.234448  110.663062  193.894392  184.388362  181.968458   \n",
       "2441  156.300451  131.414059  116.108234  193.147585  181.736531  183.386660   \n",
       "2442  162.548268  134.958068  112.415088  196.695747  186.109119  191.853005   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     192.737363   73.724932  138.491142  \n",
       "1     192.374917   83.476169  127.547566  \n",
       "2     187.026603   74.422808  145.994348  \n",
       "3     187.715639   83.992892  138.966512  \n",
       "4     188.398368   79.339979  133.595655  \n",
       "...          ...         ...         ...  \n",
       "2438  165.974294  129.016781   91.163284  \n",
       "2439  175.290848  130.406301   90.511453  \n",
       "2440  177.496974  121.539625   87.932897  \n",
       "2441  165.651099  129.228967   81.105373  \n",
       "2442  173.257644  123.993322   90.839897  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf63fe",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090b68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159.151730</td>\n",
       "      <td>199.542510</td>\n",
       "      <td>93.204352</td>\n",
       "      <td>141.610133</td>\n",
       "      <td>208.230033</td>\n",
       "      <td>220.674816</td>\n",
       "      <td>158.863186</td>\n",
       "      <td>189.306563</td>\n",
       "      <td>144.184843</td>\n",
       "      <td>160.406591</td>\n",
       "      <td>102.069873</td>\n",
       "      <td>131.840360</td>\n",
       "      <td>188.606982</td>\n",
       "      <td>198.112558</td>\n",
       "      <td>165.173355</td>\n",
       "      <td>184.936532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166.398547</td>\n",
       "      <td>184.865378</td>\n",
       "      <td>100.886692</td>\n",
       "      <td>142.019092</td>\n",
       "      <td>200.934261</td>\n",
       "      <td>231.777862</td>\n",
       "      <td>156.058008</td>\n",
       "      <td>203.353192</td>\n",
       "      <td>140.903362</td>\n",
       "      <td>165.565921</td>\n",
       "      <td>106.858379</td>\n",
       "      <td>133.644672</td>\n",
       "      <td>187.484463</td>\n",
       "      <td>200.595836</td>\n",
       "      <td>171.508982</td>\n",
       "      <td>175.626034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168.699960</td>\n",
       "      <td>195.483494</td>\n",
       "      <td>102.242983</td>\n",
       "      <td>151.909099</td>\n",
       "      <td>206.502507</td>\n",
       "      <td>224.945880</td>\n",
       "      <td>161.279681</td>\n",
       "      <td>183.895077</td>\n",
       "      <td>145.834056</td>\n",
       "      <td>158.360219</td>\n",
       "      <td>102.637528</td>\n",
       "      <td>136.457962</td>\n",
       "      <td>185.327626</td>\n",
       "      <td>206.206472</td>\n",
       "      <td>171.106003</td>\n",
       "      <td>176.065766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165.108359</td>\n",
       "      <td>195.489980</td>\n",
       "      <td>95.088657</td>\n",
       "      <td>146.039074</td>\n",
       "      <td>194.145214</td>\n",
       "      <td>233.067175</td>\n",
       "      <td>159.540317</td>\n",
       "      <td>187.301984</td>\n",
       "      <td>135.145034</td>\n",
       "      <td>168.508921</td>\n",
       "      <td>112.321149</td>\n",
       "      <td>146.706777</td>\n",
       "      <td>186.878590</td>\n",
       "      <td>190.757863</td>\n",
       "      <td>169.726624</td>\n",
       "      <td>186.217886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168.168172</td>\n",
       "      <td>185.840023</td>\n",
       "      <td>99.153895</td>\n",
       "      <td>139.952871</td>\n",
       "      <td>194.029188</td>\n",
       "      <td>225.089917</td>\n",
       "      <td>155.754544</td>\n",
       "      <td>188.479389</td>\n",
       "      <td>141.177966</td>\n",
       "      <td>170.835688</td>\n",
       "      <td>111.019304</td>\n",
       "      <td>134.733819</td>\n",
       "      <td>185.305455</td>\n",
       "      <td>200.696685</td>\n",
       "      <td>169.215126</td>\n",
       "      <td>171.769006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>191.446233</td>\n",
       "      <td>163.863018</td>\n",
       "      <td>120.196717</td>\n",
       "      <td>81.691845</td>\n",
       "      <td>232.944152</td>\n",
       "      <td>213.767370</td>\n",
       "      <td>188.466104</td>\n",
       "      <td>177.347899</td>\n",
       "      <td>156.237599</td>\n",
       "      <td>139.888740</td>\n",
       "      <td>114.609675</td>\n",
       "      <td>89.819850</td>\n",
       "      <td>207.554104</td>\n",
       "      <td>200.207521</td>\n",
       "      <td>182.785568</td>\n",
       "      <td>173.870295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>192.210071</td>\n",
       "      <td>169.472938</td>\n",
       "      <td>126.408295</td>\n",
       "      <td>80.555287</td>\n",
       "      <td>226.421779</td>\n",
       "      <td>212.131048</td>\n",
       "      <td>189.024391</td>\n",
       "      <td>161.463544</td>\n",
       "      <td>146.955323</td>\n",
       "      <td>136.197913</td>\n",
       "      <td>105.575552</td>\n",
       "      <td>94.301317</td>\n",
       "      <td>204.741741</td>\n",
       "      <td>199.289652</td>\n",
       "      <td>183.024518</td>\n",
       "      <td>174.970145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>182.613814</td>\n",
       "      <td>174.438416</td>\n",
       "      <td>116.411536</td>\n",
       "      <td>91.348961</td>\n",
       "      <td>233.275747</td>\n",
       "      <td>210.510062</td>\n",
       "      <td>189.619989</td>\n",
       "      <td>163.533342</td>\n",
       "      <td>152.167692</td>\n",
       "      <td>144.491181</td>\n",
       "      <td>109.729203</td>\n",
       "      <td>88.256424</td>\n",
       "      <td>208.000737</td>\n",
       "      <td>208.592806</td>\n",
       "      <td>185.616372</td>\n",
       "      <td>170.316898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>179.865005</td>\n",
       "      <td>159.415279</td>\n",
       "      <td>123.315088</td>\n",
       "      <td>80.356934</td>\n",
       "      <td>226.317654</td>\n",
       "      <td>215.812200</td>\n",
       "      <td>185.093114</td>\n",
       "      <td>175.015502</td>\n",
       "      <td>161.770560</td>\n",
       "      <td>143.224881</td>\n",
       "      <td>110.190730</td>\n",
       "      <td>92.811610</td>\n",
       "      <td>209.785158</td>\n",
       "      <td>202.830059</td>\n",
       "      <td>182.697032</td>\n",
       "      <td>170.152463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>176.406070</td>\n",
       "      <td>160.883552</td>\n",
       "      <td>123.303897</td>\n",
       "      <td>90.376887</td>\n",
       "      <td>229.966006</td>\n",
       "      <td>218.518262</td>\n",
       "      <td>186.131661</td>\n",
       "      <td>172.264626</td>\n",
       "      <td>158.317146</td>\n",
       "      <td>144.987837</td>\n",
       "      <td>101.898543</td>\n",
       "      <td>84.504215</td>\n",
       "      <td>212.534241</td>\n",
       "      <td>202.657706</td>\n",
       "      <td>175.989827</td>\n",
       "      <td>169.045684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     159.151730  199.542510   93.204352  141.610133  208.230033  220.674816   \n",
       "1     166.398547  184.865378  100.886692  142.019092  200.934261  231.777862   \n",
       "2     168.699960  195.483494  102.242983  151.909099  206.502507  224.945880   \n",
       "3     165.108359  195.489980   95.088657  146.039074  194.145214  233.067175   \n",
       "4     168.168172  185.840023   99.153895  139.952871  194.029188  225.089917   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  191.446233  163.863018  120.196717   81.691845  232.944152  213.767370   \n",
       "2439  192.210071  169.472938  126.408295   80.555287  226.421779  212.131048   \n",
       "2440  182.613814  174.438416  116.411536   91.348961  233.275747  210.510062   \n",
       "2441  179.865005  159.415279  123.315088   80.356934  226.317654  215.812200   \n",
       "2442  176.406070  160.883552  123.303897   90.376887  229.966006  218.518262   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10    sensor11    sensor12  \\\n",
       "0     158.863186  189.306563  144.184843  160.406591  102.069873  131.840360   \n",
       "1     156.058008  203.353192  140.903362  165.565921  106.858379  133.644672   \n",
       "2     161.279681  183.895077  145.834056  158.360219  102.637528  136.457962   \n",
       "3     159.540317  187.301984  135.145034  168.508921  112.321149  146.706777   \n",
       "4     155.754544  188.479389  141.177966  170.835688  111.019304  134.733819   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  188.466104  177.347899  156.237599  139.888740  114.609675   89.819850   \n",
       "2439  189.024391  161.463544  146.955323  136.197913  105.575552   94.301317   \n",
       "2440  189.619989  163.533342  152.167692  144.491181  109.729203   88.256424   \n",
       "2441  185.093114  175.015502  161.770560  143.224881  110.190730   92.811610   \n",
       "2442  186.131661  172.264626  158.317146  144.987837  101.898543   84.504215   \n",
       "\n",
       "        sensor13    sensor14    sensor15    sensor16  \n",
       "0     188.606982  198.112558  165.173355  184.936532  \n",
       "1     187.484463  200.595836  171.508982  175.626034  \n",
       "2     185.327626  206.206472  171.106003  176.065766  \n",
       "3     186.878590  190.757863  169.726624  186.217886  \n",
       "4     185.305455  200.696685  169.215126  171.769006  \n",
       "...          ...         ...         ...         ...  \n",
       "2438  207.554104  200.207521  182.785568  173.870295  \n",
       "2439  204.741741  199.289652  183.024518  174.970145  \n",
       "2440  208.000737  208.592806  185.616372  170.316898  \n",
       "2441  209.785158  202.830059  182.697032  170.152463  \n",
       "2442  212.534241  202.657706  175.989827  169.045684  \n",
       "\n",
       "[2443 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:16]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 12ms/step - loss: 1046.9319 - val_loss: 801.5094\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 645.1051 - val_loss: 525.2772\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 443.7293 - val_loss: 386.2286\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 316.9867 - val_loss: 273.2343\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 237.6164 - val_loss: 209.8942\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 156.5703 - val_loss: 115.7318\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 88.5697 - val_loss: 95.6293\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 52.3492 - val_loss: 39.0580\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 36.1596 - val_loss: 30.5364\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.4896 - val_loss: 49.7318\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 23.6160 - val_loss: 45.5613\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 23.0381 - val_loss: 47.6628\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.2920 - val_loss: 50.0040\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 17.3460 - val_loss: 15.1533\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.2809 - val_loss: 16.4372\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.2101 - val_loss: 17.0289\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.7523 - val_loss: 21.7431\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.7623 - val_loss: 47.2956\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.9488 - val_loss: 26.7812\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.6785 - val_loss: 31.6391\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.6404 - val_loss: 16.4172\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.9854 - val_loss: 14.5479\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.2870 - val_loss: 16.2016\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.7642 - val_loss: 18.0890\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9172 - val_loss: 14.5623\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.1513 - val_loss: 12.3023\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.2618 - val_loss: 30.3903\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.1267 - val_loss: 69.5201\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.4298 - val_loss: 16.5053\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.1946 - val_loss: 18.3007\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.2117 - val_loss: 39.0026\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.7954 - val_loss: 34.8218\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.4608 - val_loss: 18.6218\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5045 - val_loss: 21.3303\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.8606 - val_loss: 9.0837\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.1519 - val_loss: 29.6219\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.0679 - val_loss: 31.3159\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.8674 - val_loss: 17.1039\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.4329 - val_loss: 15.0548\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 9.8608 - val_loss: 24.2860\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.6924 - val_loss: 11.0451\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.9937 - val_loss: 15.4640\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 8.7500 - val_loss: 13.5950\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.4828 - val_loss: 8.5844\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 8.0027 - val_loss: 13.8992\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.5412 - val_loss: 28.7971\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.3061 - val_loss: 19.7289\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.3320 - val_loss: 13.0368\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.0042 - val_loss: 15.4867\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.5443 - val_loss: 56.6515\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.5086 - val_loss: 12.0440\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.0432 - val_loss: 7.3050\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.2357 - val_loss: 11.7640\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.5436 - val_loss: 18.1906\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.6296 - val_loss: 57.3969\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.3771 - val_loss: 13.0290\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.4204 - val_loss: 17.4712\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.3360 - val_loss: 8.7042\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.1691 - val_loss: 8.4927\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.0534 - val_loss: 17.1858\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.8976 - val_loss: 10.3697\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.9203 - val_loss: 18.1733\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.2996 - val_loss: 17.1791\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.0394 - val_loss: 12.8149\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.2628 - val_loss: 14.7459\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.3989 - val_loss: 7.9330\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.0744 - val_loss: 12.3908\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.7715 - val_loss: 10.2713\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.9588 - val_loss: 7.2633\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.0628 - val_loss: 10.8669\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.0043 - val_loss: 15.9653\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.6591 - val_loss: 8.7630\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0146 - val_loss: 6.8373\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 2s 6ms/step - loss: 6.4892 - val_loss: 14.4041\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.9400 - val_loss: 15.0279\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.5715 - val_loss: 15.8264\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.3376 - val_loss: 6.9185\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.4678 - val_loss: 13.6255\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.1501 - val_loss: 5.9800\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 2s 8ms/step - loss: 5.6938 - val_loss: 9.3432\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.0560 - val_loss: 8.7139\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.7312 - val_loss: 7.4311\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.5897 - val_loss: 11.3108\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.3820 - val_loss: 11.3880\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.2463 - val_loss: 16.5778\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.9054 - val_loss: 9.8466\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 6.2614 - val_loss: 7.0006\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.3696 - val_loss: 9.1486\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 5.3526 - val_loss: 12.4728\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.8979 - val_loss: 9.5553\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.1051 - val_loss: 9.6618\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.4496 - val_loss: 10.5273\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.4647 - val_loss: 8.5687\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.0952 - val_loss: 83.9000\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.6348 - val_loss: 8.5768\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.4322 - val_loss: 16.3900\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.2171 - val_loss: 22.7664\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.6500 - val_loss: 8.5477\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.4026 - val_loss: 8.9771\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 5.6492 - val_loss: 10.6767\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.6165 - val_loss: 8.4524\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8610 - val_loss: 36.7334\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0365 - val_loss: 6.9926\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.5463 - val_loss: 9.0022\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.1424 - val_loss: 9.0189\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.0837 - val_loss: 7.8231\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 4.9823 - val_loss: 11.7789\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8135 - val_loss: 8.7835\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.6560 - val_loss: 7.0257\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 5.979826959536422\n",
      "Mean Absolute Error (MAE): 1.5719201697081253\n",
      "Root Mean Squared Error (RMSE): 2.4453684711176806\n",
      "Time taken: 300.9975209236145\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 6s 11ms/step - loss: 1051.9336 - val_loss: 747.4548\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 602.3521 - val_loss: 480.2202\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 420.9354 - val_loss: 361.1302\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 318.8878 - val_loss: 278.9787\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 234.5052 - val_loss: 220.6745\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 148.6492 - val_loss: 131.3547\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 80.6309 - val_loss: 65.3552\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 50.3252 - val_loss: 52.2361\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 37.9676 - val_loss: 38.2482\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.5080 - val_loss: 36.8575\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.7541 - val_loss: 19.9012\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.9405 - val_loss: 21.6820\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.3894 - val_loss: 27.3393\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.3305 - val_loss: 16.8279\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.1200 - val_loss: 17.1439\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.6593 - val_loss: 26.8992\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.3138 - val_loss: 12.4169\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.3328 - val_loss: 20.4038\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 15.0105 - val_loss: 75.9678\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 14.2604 - val_loss: 16.8277\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.8478 - val_loss: 18.5977\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.7654 - val_loss: 22.1244\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.5861 - val_loss: 13.5663\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.1215 - val_loss: 21.7363\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.3916 - val_loss: 18.0423\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.6812 - val_loss: 17.2011\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.2416 - val_loss: 12.5786\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 12.1625 - val_loss: 47.3569\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5467 - val_loss: 9.8334\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 12.7331 - val_loss: 26.1889\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.7844 - val_loss: 31.4184\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5715 - val_loss: 19.5732\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.9160 - val_loss: 40.5934\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.1039 - val_loss: 9.1400\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.9157 - val_loss: 22.2790\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.5010 - val_loss: 19.4231\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.8443 - val_loss: 12.5515\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7408 - val_loss: 22.8964\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.6579 - val_loss: 16.2002\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.8090 - val_loss: 38.9823\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.2821 - val_loss: 22.2159\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7256 - val_loss: 10.1881\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.8287 - val_loss: 12.6375\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7789 - val_loss: 28.4242\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.0461 - val_loss: 10.2825\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.9224 - val_loss: 9.9797\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.2958 - val_loss: 11.0886\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.2115 - val_loss: 12.7066\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.3753 - val_loss: 16.3792\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.2004 - val_loss: 12.9330\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.1058 - val_loss: 15.0234\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.9267 - val_loss: 9.6688\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 7.6430 - val_loss: 10.6691\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.5007 - val_loss: 10.5953\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.4593 - val_loss: 13.3861\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.2240 - val_loss: 19.1003\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.4139 - val_loss: 11.4296\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.0401 - val_loss: 9.6931\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.4182 - val_loss: 14.6622\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.4511 - val_loss: 13.3515\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.6828 - val_loss: 12.0556\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 7.1645 - val_loss: 20.4824\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.2822 - val_loss: 26.6511\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 7.5682 - val_loss: 9.3195\n",
      "16/16 [==============================] - 1s 23ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 9.14020856259609\n",
      "Mean Absolute Error (MAE): 2.001547934773086\n",
      "Root Mean Squared Error (RMSE): 3.023277784557034\n",
      "Time taken: 180.50526642799377\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 12ms/step - loss: 1064.2922 - val_loss: 776.9365\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 646.5364 - val_loss: 519.4088\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 439.6448 - val_loss: 422.0361\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 312.4908 - val_loss: 264.5960\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 222.3123 - val_loss: 205.7974\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 143.5954 - val_loss: 136.7012\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 86.5927 - val_loss: 59.3061\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 51.7099 - val_loss: 71.9299\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 36.4302 - val_loss: 61.8923\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 28.8931 - val_loss: 41.9123\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.6312 - val_loss: 28.7992\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.0498 - val_loss: 37.1071\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 20.0338 - val_loss: 37.6260\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 20.9644 - val_loss: 17.7793\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.9696 - val_loss: 88.4629\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.7559 - val_loss: 51.3621\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.0569 - val_loss: 17.5236\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 16.0456 - val_loss: 13.8680\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.1842 - val_loss: 14.3520\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.4021 - val_loss: 26.1834\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.4605 - val_loss: 14.9874\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.7528 - val_loss: 31.7684\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.3124 - val_loss: 12.3322\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.7836 - val_loss: 13.6198\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.1363 - val_loss: 31.3384\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1933 - val_loss: 16.4360\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.0965 - val_loss: 18.3623\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.3156 - val_loss: 13.7830\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.5701 - val_loss: 15.1025\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.5187 - val_loss: 10.8184\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.5422 - val_loss: 21.5909\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.3246 - val_loss: 14.8191\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.3104 - val_loss: 10.7280\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5359 - val_loss: 11.0017\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.3822 - val_loss: 19.1080\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.8588 - val_loss: 9.7425\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.1437 - val_loss: 35.4833\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.8875 - val_loss: 31.2859\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.2136 - val_loss: 14.7201\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.1188 - val_loss: 30.7889\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6107 - val_loss: 13.4659\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.9201 - val_loss: 11.1037\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.6332 - val_loss: 13.3414\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.6790 - val_loss: 12.4607\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 8.7672 - val_loss: 13.0355\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.7292 - val_loss: 10.4780\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 9.3814 - val_loss: 11.5888\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.1288 - val_loss: 13.4603\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 9.6848 - val_loss: 10.4959\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 9.6591 - val_loss: 11.2372\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.9747 - val_loss: 9.3813\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.7926 - val_loss: 10.5125\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.6481 - val_loss: 12.7089\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.5646 - val_loss: 24.9179\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.7048 - val_loss: 17.5129\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 8.0998 - val_loss: 11.3384\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.1741 - val_loss: 20.4083\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.1290 - val_loss: 15.4445\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.5012 - val_loss: 18.2934\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.8475 - val_loss: 9.4771\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.4005 - val_loss: 22.3283\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.3528 - val_loss: 10.8937\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.5824 - val_loss: 12.3653\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.2580 - val_loss: 9.0826\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.5162 - val_loss: 13.2591\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.5602 - val_loss: 10.9508\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.3862 - val_loss: 8.1185\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 8.1726 - val_loss: 8.8725\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.3845 - val_loss: 9.9088\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.4230 - val_loss: 7.7750\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 7.9508 - val_loss: 27.5644\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 7.9096 - val_loss: 14.1602\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.3395 - val_loss: 8.5201\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.0560 - val_loss: 10.8862\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.8486 - val_loss: 10.8567\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 5.8362 - val_loss: 10.0107\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.2259 - val_loss: 9.4659\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.0895 - val_loss: 9.1014\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.2094 - val_loss: 9.8341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 5.3849 - val_loss: 9.0163\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 5.5896 - val_loss: 7.5937\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.9552 - val_loss: 14.7314\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.9548 - val_loss: 9.7450\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.6691 - val_loss: 16.2602\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.3105 - val_loss: 10.0506\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.5736 - val_loss: 15.9242\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.7181 - val_loss: 11.5945\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.6542 - val_loss: 10.3817\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8401 - val_loss: 9.6305\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.3746 - val_loss: 8.4955\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.4119 - val_loss: 9.3183\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.4107 - val_loss: 12.4473\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.8018 - val_loss: 38.9664\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.4353 - val_loss: 8.7236\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.8373 - val_loss: 15.0280\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.3579 - val_loss: 9.7891\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 4.5349 - val_loss: 10.6185\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8346 - val_loss: 9.6683\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.9882 - val_loss: 11.7848\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.2899 - val_loss: 50.7335\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8133 - val_loss: 9.8324\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.6545 - val_loss: 15.6789\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.0270 - val_loss: 10.4773\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.4929 - val_loss: 8.3637\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 4.0868 - val_loss: 9.9589\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8973 - val_loss: 15.8387\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.2330 - val_loss: 9.1747\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.7409 - val_loss: 8.8543\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 4.4712 - val_loss: 6.9680\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 6.3608 - val_loss: 13.7588\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 4.0847 - val_loss: 9.2824\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.1409 - val_loss: 25.5279\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 4.1585 - val_loss: 9.2055\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8084 - val_loss: 8.3488\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 3.8558 - val_loss: 8.4623\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 4.8958 - val_loss: 41.7083\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 4.6909 - val_loss: 21.9851\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 5.0290 - val_loss: 11.8769\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 5.6026 - val_loss: 8.4059\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.9457 - val_loss: 6.9752\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.1976 - val_loss: 8.3859\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8416 - val_loss: 19.5466\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.0725 - val_loss: 12.8415\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.6914 - val_loss: 10.7657\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 5.9520 - val_loss: 9.3951\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.0659 - val_loss: 8.6833\n",
      "Epoch 127/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.6139 - val_loss: 9.0785\n",
      "Epoch 128/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 5.1085 - val_loss: 30.2628\n",
      "Epoch 129/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 4.3075 - val_loss: 7.7249\n",
      "Epoch 130/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 4.3527 - val_loss: 8.4950\n",
      "Epoch 131/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.5983 - val_loss: 11.9046\n",
      "Epoch 132/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 3.5530 - val_loss: 9.4564\n",
      "Epoch 133/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.7889 - val_loss: 9.6218\n",
      "Epoch 134/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.8939 - val_loss: 8.7887\n",
      "Epoch 135/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 5.4731 - val_loss: 10.3510\n",
      "Epoch 136/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.7072 - val_loss: 7.5861\n",
      "Epoch 137/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 3.5951 - val_loss: 6.9795\n",
      "Epoch 138/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.7196 - val_loss: 8.1121\n",
      "Epoch 139/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.1322 - val_loss: 8.2279\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 6.967974140714587\n",
      "Mean Absolute Error (MAE): 1.641020516431863\n",
      "Root Mean Squared Error (RMSE): 2.6396920541446853\n",
      "Time taken: 402.51459646224976\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 12ms/step - loss: 1054.3859 - val_loss: 742.8222\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 592.1940 - val_loss: 490.4132\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 408.3909 - val_loss: 392.8116\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 269.0375 - val_loss: 311.8352\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 172.2689 - val_loss: 136.8715\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 99.7583 - val_loss: 89.5394\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 62.6370 - val_loss: 65.0183\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 40.7168 - val_loss: 31.4303\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.8043 - val_loss: 42.3040\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.3458 - val_loss: 20.3143\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.7273 - val_loss: 31.7767\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.8734 - val_loss: 58.1016\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.7476 - val_loss: 33.4102\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.1185 - val_loss: 34.6771\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.1675 - val_loss: 27.8597\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.4646 - val_loss: 18.1851\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.0436 - val_loss: 14.5620\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.1192 - val_loss: 17.2291\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.7366 - val_loss: 20.3496\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 13.9059 - val_loss: 25.0297\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9085 - val_loss: 18.9490\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.0400 - val_loss: 52.2971\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.6614 - val_loss: 18.4778\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.9388 - val_loss: 37.9015\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.2247 - val_loss: 20.0625\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.5494 - val_loss: 12.7780\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.6098 - val_loss: 53.2530\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.6518 - val_loss: 20.9769\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.5936 - val_loss: 15.6577\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.5601 - val_loss: 15.7312\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.9619 - val_loss: 12.3830\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.4825 - val_loss: 14.1250\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.6507 - val_loss: 29.5653\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.9984 - val_loss: 18.1039\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.1407 - val_loss: 11.6897\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.1025 - val_loss: 11.5262\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.8452 - val_loss: 40.2909\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.3855 - val_loss: 19.5827\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.4089 - val_loss: 13.1778\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.1496 - val_loss: 13.5850\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.1939 - val_loss: 13.6104\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.6760 - val_loss: 11.5790\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.2225 - val_loss: 19.3038\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.4299 - val_loss: 9.1306\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.5040 - val_loss: 45.9529\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 8.1795 - val_loss: 8.9118\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.7984 - val_loss: 9.2912\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.6961 - val_loss: 13.0364\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.4895 - val_loss: 10.6153\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.9460 - val_loss: 21.7389\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.9163 - val_loss: 11.0379\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.9079 - val_loss: 14.9399\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.2346 - val_loss: 11.8396\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.5435 - val_loss: 14.1273\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.6695 - val_loss: 8.5534\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.1770 - val_loss: 12.6737\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.9756 - val_loss: 13.1036\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0734 - val_loss: 11.7016\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.8362 - val_loss: 8.5997\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.9715 - val_loss: 12.2885\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.4291 - val_loss: 16.1645\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 6.3400 - val_loss: 18.8471\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.4278 - val_loss: 19.6536\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.5274 - val_loss: 9.9561\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.1987 - val_loss: 21.4055\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.3849 - val_loss: 12.7751\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.2038 - val_loss: 11.6064\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.0704 - val_loss: 9.9795\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.3453 - val_loss: 10.8316\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.4670 - val_loss: 44.4490\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.5588 - val_loss: 12.0001\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0128 - val_loss: 10.3466\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.8833 - val_loss: 8.3660\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 7.1343 - val_loss: 15.0652\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 6.0806 - val_loss: 9.9603\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.0100 - val_loss: 11.5258\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.4209 - val_loss: 27.3627\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.6924 - val_loss: 10.0668\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.0136 - val_loss: 10.5375\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 3s 8ms/step - loss: 5.1869 - val_loss: 12.9552\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.7895 - val_loss: 10.0758\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.2583 - val_loss: 11.5592\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.3772 - val_loss: 9.6343\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.1392 - val_loss: 13.8168\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.0098 - val_loss: 9.0058\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.8887 - val_loss: 8.7572\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.7863 - val_loss: 8.3383\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 4.9118 - val_loss: 9.3973\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.2054 - val_loss: 11.4030\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.2633 - val_loss: 36.3664\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 4.9149 - val_loss: 17.6586\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 4.5879 - val_loss: 12.5528\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.1859 - val_loss: 9.5776\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.2350 - val_loss: 8.2991\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.9000 - val_loss: 11.4219\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.2921 - val_loss: 16.1098\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.1275 - val_loss: 42.2336\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.8691 - val_loss: 15.2167\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.7587 - val_loss: 7.7990\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.3342 - val_loss: 12.0889\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.6687 - val_loss: 8.6169\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 4.5046 - val_loss: 8.6342\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.5391 - val_loss: 11.1544\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 5.0986 - val_loss: 9.8910\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.2096 - val_loss: 13.4260\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.5956 - val_loss: 14.7165\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 4.6357 - val_loss: 11.4975\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 3.7789 - val_loss: 12.0418\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 5.3672 - val_loss: 10.3652\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 3.9879 - val_loss: 8.1435\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 4.0148 - val_loss: 9.0386\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.5792 - val_loss: 8.8482\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 5.6978 - val_loss: 24.0484\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 3.8700 - val_loss: 8.5234\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 4.3142 - val_loss: 7.9064\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 3.7561 - val_loss: 9.4238\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.2876 - val_loss: 22.8297\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 3.9903 - val_loss: 24.5876\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.0987 - val_loss: 11.3927\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 4.0709 - val_loss: 9.4587\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.4326 - val_loss: 10.2190\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.4680 - val_loss: 12.6335\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.3487 - val_loss: 9.2398\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.5805 - val_loss: 8.6420\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 3.8009 - val_loss: 8.1924\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 3.3811 - val_loss: 10.4732\n",
      "Epoch 127/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.4689 - val_loss: 18.1888\n",
      "Epoch 128/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.2206 - val_loss: 19.9735\n",
      "Epoch 129/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 3.7890 - val_loss: 8.2759\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 7.798626452057469\n",
      "Mean Absolute Error (MAE): 1.7108687808686887\n",
      "Root Mean Squared Error (RMSE): 2.7926020933991778\n",
      "Time taken: 347.58583784103394\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 10ms/step - loss: 1008.6376 - val_loss: 729.8231\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 572.5219 - val_loss: 497.7239\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 412.8125 - val_loss: 361.3108\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 300.5234 - val_loss: 252.9372\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 204.1369 - val_loss: 158.1402\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 110.8184 - val_loss: 131.5731\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 61.9741 - val_loss: 45.3268\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 41.3985 - val_loss: 47.4557\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.8970 - val_loss: 43.5797\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.3488 - val_loss: 26.4469\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 25.0622 - val_loss: 21.3327\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.9060 - val_loss: 22.5315\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 20.4397 - val_loss: 36.3488\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 20.1607 - val_loss: 22.8660\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.3845 - val_loss: 13.8318\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.8768 - val_loss: 12.7862\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 16.3352 - val_loss: 24.7503\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 14.6514 - val_loss: 41.6974\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.3273 - val_loss: 10.0243\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.1488 - val_loss: 13.2073\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.9799 - val_loss: 14.8758\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.0694 - val_loss: 12.6753\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.3657 - val_loss: 52.1021\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 12.2347 - val_loss: 13.9240\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 13.2673 - val_loss: 16.1366\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6865 - val_loss: 11.0548\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.0298 - val_loss: 16.7280\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.0183 - val_loss: 21.1275\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.3215 - val_loss: 35.8502\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.4518 - val_loss: 19.9293\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.3720 - val_loss: 17.8815\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5208 - val_loss: 11.6817\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4437 - val_loss: 17.5596\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.5901 - val_loss: 11.1835\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.4681 - val_loss: 20.2628\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.9448 - val_loss: 15.5736\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.3262 - val_loss: 26.5186\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.0689 - val_loss: 29.5045\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.2704 - val_loss: 12.6784\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.3460 - val_loss: 10.6559\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.4308 - val_loss: 13.3137\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.6640 - val_loss: 13.6481\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.9542 - val_loss: 14.8016\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.8371 - val_loss: 17.7791\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.4253 - val_loss: 11.4759\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.1713 - val_loss: 8.4754\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.3505 - val_loss: 9.9587\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.1521 - val_loss: 7.1562\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.7665 - val_loss: 23.8725\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.1166 - val_loss: 45.0753\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 8.3912 - val_loss: 10.5473\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.2166 - val_loss: 22.1608\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.3294 - val_loss: 11.0766\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.8747 - val_loss: 9.7857\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.5922 - val_loss: 9.5834\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.5268 - val_loss: 10.2892\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.4341 - val_loss: 19.2810\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 6.8986 - val_loss: 10.8419\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.5526 - val_loss: 10.2843\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.0639 - val_loss: 12.7631\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.5681 - val_loss: 10.1772\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.6535 - val_loss: 17.2179\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.6082 - val_loss: 8.7911\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.0191 - val_loss: 23.9593\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.1186 - val_loss: 15.7072\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.0736 - val_loss: 10.4364\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.3082 - val_loss: 9.0011\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.5401 - val_loss: 10.9674\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.8302 - val_loss: 19.0214\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.1013 - val_loss: 14.4520\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.2770 - val_loss: 10.0891\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.7279 - val_loss: 8.6714\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.8208 - val_loss: 8.2484\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.9645 - val_loss: 7.9758\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.7613 - val_loss: 13.2009\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 5.8709 - val_loss: 38.4837\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.8444 - val_loss: 9.2820\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 5.9231 - val_loss: 10.6743\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 7.156740784785658\n",
      "Mean Absolute Error (MAE): 1.7807258813197127\n",
      "Root Mean Squared Error (RMSE): 2.675208549774327\n",
      "Time taken: 218.96304750442505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=6,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 16, 512)           1052672   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16, 512)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 16, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,047,747\n",
      "Trainable params: 2,046,723\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_2852\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold       MSE       MAE      RMSE  Time taken\n",
      "0        1  5.979827  1.571920  2.445368  300.997521\n",
      "1        2  9.140209  2.001548  3.023278  180.505266\n",
      "2        3  6.967974  1.641021  2.639692  402.514596\n",
      "3        4  7.798626  1.710869  2.792602  347.585838\n",
      "4        5  7.156741  1.780726  2.675209  218.963048\n",
      "5  Average  7.408675  1.741217  2.715230  290.113254\n",
      "Results saved to 'LSTM Results PL_model_1_Scattered_iReg_f_over.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('LSTM Results PL_model_1_Scattered_iReg_f_over.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'LSTM Results PL_model_1_Scattered_iReg_f_over.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
