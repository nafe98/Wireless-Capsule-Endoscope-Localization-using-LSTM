{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "              6           7           8           9   ...         38  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "              39         40         41          42          43          44  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "              45          46          47  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...   sensor39  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "        sensor40   sensor41   sensor42    sensor43    sensor44    sensor45  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf63fe",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090b68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>67.947886</td>\n",
       "      <td>99.572673</td>\n",
       "      <td>110.860036</td>\n",
       "      <td>127.054607</td>\n",
       "      <td>107.051532</td>\n",
       "      <td>124.324976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>67.812086</td>\n",
       "      <td>102.363262</td>\n",
       "      <td>119.562646</td>\n",
       "      <td>126.677060</td>\n",
       "      <td>113.850953</td>\n",
       "      <td>117.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>69.814048</td>\n",
       "      <td>92.404807</td>\n",
       "      <td>108.156692</td>\n",
       "      <td>128.072802</td>\n",
       "      <td>101.090832</td>\n",
       "      <td>113.383786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>68.907057</td>\n",
       "      <td>96.459290</td>\n",
       "      <td>110.743724</td>\n",
       "      <td>125.010229</td>\n",
       "      <td>109.590169</td>\n",
       "      <td>126.267858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>73.751383</td>\n",
       "      <td>94.954049</td>\n",
       "      <td>119.152370</td>\n",
       "      <td>129.047302</td>\n",
       "      <td>101.223119</td>\n",
       "      <td>118.873622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>82.457246</td>\n",
       "      <td>54.138747</td>\n",
       "      <td>129.982822</td>\n",
       "      <td>126.579534</td>\n",
       "      <td>119.940259</td>\n",
       "      <td>103.272859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>78.918123</td>\n",
       "      <td>57.107506</td>\n",
       "      <td>139.217056</td>\n",
       "      <td>127.217398</td>\n",
       "      <td>117.365194</td>\n",
       "      <td>114.416527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>83.447222</td>\n",
       "      <td>75.444186</td>\n",
       "      <td>139.410454</td>\n",
       "      <td>129.015596</td>\n",
       "      <td>123.582865</td>\n",
       "      <td>113.049668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>81.220414</td>\n",
       "      <td>70.247052</td>\n",
       "      <td>132.356387</td>\n",
       "      <td>137.478002</td>\n",
       "      <td>124.604990</td>\n",
       "      <td>113.155807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>85.647172</td>\n",
       "      <td>57.589165</td>\n",
       "      <td>129.954877</td>\n",
       "      <td>127.169556</td>\n",
       "      <td>116.554557</td>\n",
       "      <td>109.144032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10   sensor11    sensor12  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  67.947886   99.572673   \n",
       "1     106.645699  137.372609   92.314999  112.314087  67.812086  102.363262   \n",
       "2     103.789337  135.667714   99.182335  106.232463  69.814048   92.404807   \n",
       "3     102.460744  129.928887   86.763744  106.168512  68.907057   96.459290   \n",
       "4     116.786233  139.061346   83.559242  103.091764  73.751383   94.954049   \n",
       "...          ...         ...         ...         ...        ...         ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  82.457246   54.138747   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  78.918123   57.107506   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  83.447222   75.444186   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  81.220414   70.247052   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  85.647172   57.589165   \n",
       "\n",
       "        sensor13    sensor14    sensor15    sensor16  \n",
       "0     110.860036  127.054607  107.051532  124.324976  \n",
       "1     119.562646  126.677060  113.850953  117.801200  \n",
       "2     108.156692  128.072802  101.090832  113.383786  \n",
       "3     110.743724  125.010229  109.590169  126.267858  \n",
       "4     119.152370  129.047302  101.223119  118.873622  \n",
       "...          ...         ...         ...         ...  \n",
       "2438  129.982822  126.579534  119.940259  103.272859  \n",
       "2439  139.217056  127.217398  117.365194  114.416527  \n",
       "2440  139.410454  129.015596  123.582865  113.049668  \n",
       "2441  132.356387  137.478002  124.604990  113.155807  \n",
       "2442  129.954877  127.169556  116.554557  109.144032  \n",
       "\n",
       "[2443 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:16]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 15s 16ms/step - loss: 1048.7863 - val_loss: 877.1545\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 613.0696 - val_loss: 509.6810\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 408.3495 - val_loss: 354.5905\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 277.9441 - val_loss: 233.6697\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 157.2718 - val_loss: 127.4708\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 88.2767 - val_loss: 64.9585\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 55.4738 - val_loss: 64.9782\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 42.2159 - val_loss: 36.8266\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.5763 - val_loss: 35.0359\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 31.3452 - val_loss: 26.6081\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 27.1419 - val_loss: 24.8031\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 24.6680 - val_loss: 24.1765\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.9866 - val_loss: 23.1648\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.8064 - val_loss: 23.8040\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.4742 - val_loss: 25.3261\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.2436 - val_loss: 20.4660\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 20.8725 - val_loss: 25.7741\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 20.5774 - val_loss: 37.2258\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 19.7826 - val_loss: 18.2365\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 17.9156 - val_loss: 22.1750\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.2304 - val_loss: 19.4630\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.6840 - val_loss: 20.8318\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.6349 - val_loss: 18.6290\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.9174 - val_loss: 16.3905\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 15.4408 - val_loss: 17.8933\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.8124 - val_loss: 18.6151\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.2350 - val_loss: 21.2786\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.4974 - val_loss: 21.2750\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.8157 - val_loss: 28.4531\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.8958 - val_loss: 20.0266\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.6939 - val_loss: 16.9708\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.0399 - val_loss: 16.3200\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.2342 - val_loss: 16.9212\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.0974 - val_loss: 19.8743\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.8637 - val_loss: 21.6677\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.3692 - val_loss: 18.0532\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.2720 - val_loss: 24.8097\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9017 - val_loss: 16.6462\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.0398 - val_loss: 18.1015\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.6332 - val_loss: 18.9784\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 13.9545 - val_loss: 15.7622\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 12.4975 - val_loss: 17.5046\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.3050 - val_loss: 21.2809\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.1719 - val_loss: 15.9576\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.3176 - val_loss: 17.1841\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.6071 - val_loss: 16.0920\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.9709 - val_loss: 15.6341\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.4803 - val_loss: 16.4266\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.7513 - val_loss: 16.9624\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.9147 - val_loss: 18.9255\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.7286 - val_loss: 15.3163\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.5175 - val_loss: 15.9418\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.9129 - val_loss: 15.3351\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.9370 - val_loss: 19.4393\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.4052 - val_loss: 24.0276\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.5412 - val_loss: 18.7784\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.4746 - val_loss: 16.2918\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.2316 - val_loss: 15.7318\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.8742 - val_loss: 16.1693\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 11.1431 - val_loss: 18.0595\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.4208 - val_loss: 17.5749\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.5182 - val_loss: 16.5515\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 9.4812 - val_loss: 13.8870\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 9.1358 - val_loss: 16.9922\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.8852 - val_loss: 18.8089\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.9774 - val_loss: 16.9866\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.2173 - val_loss: 16.3643\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.5259 - val_loss: 16.0193\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.1716 - val_loss: 19.9529\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.0290 - val_loss: 19.4169\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.8264 - val_loss: 16.5892\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.0285 - val_loss: 15.8332\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.2816 - val_loss: 16.1617\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.9021 - val_loss: 14.6886\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.2205 - val_loss: 15.3295\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.7618 - val_loss: 15.1713\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.2843 - val_loss: 18.0778\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.5298 - val_loss: 16.0640\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 11ms/step - loss: 8.6335 - val_loss: 16.1389\n",
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.8961 - val_loss: 16.7631\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.3554 - val_loss: 16.3317\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.6827 - val_loss: 19.5099\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.8197 - val_loss: 17.4000\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.1042 - val_loss: 18.5876\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.0194 - val_loss: 17.0043\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.5920 - val_loss: 17.2897\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.2909 - val_loss: 20.2332\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.6641 - val_loss: 15.1501\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.7981 - val_loss: 14.3785\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.0762 - val_loss: 22.0613\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.0753 - val_loss: 17.1624\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.7366 - val_loss: 17.4495\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.8135 - val_loss: 18.7585\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 13.886813864231053\n",
      "Mean Absolute Error (MAE): 2.539444530066634\n",
      "Root Mean Squared Error (RMSE): 3.726501558329347\n",
      "Time taken: 294.2137453556061\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 12ms/step - loss: 1012.7383 - val_loss: 733.3377\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 591.2339 - val_loss: 481.8177\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 414.8466 - val_loss: 442.7529\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 314.1656 - val_loss: 267.1875\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 220.7565 - val_loss: 142.0331\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 121.3481 - val_loss: 79.6766\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 68.1983 - val_loss: 78.4750\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 47.2564 - val_loss: 39.6900\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 35.6979 - val_loss: 38.5328\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.6757 - val_loss: 29.0156\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 26.6969 - val_loss: 27.6548\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.2038 - val_loss: 23.9283\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 23.9489 - val_loss: 24.9767\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.1170 - val_loss: 27.1490\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.5127 - val_loss: 24.8632\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.9357 - val_loss: 19.4977\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.1384 - val_loss: 17.2358\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.7095 - val_loss: 17.8932\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 19.4922 - val_loss: 25.1764\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.1763 - val_loss: 19.5757\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.3026 - val_loss: 19.2884\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.4172 - val_loss: 19.1399\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 16.2299 - val_loss: 29.3196\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.2998 - val_loss: 16.7395\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.9166 - val_loss: 23.8947\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.8437 - val_loss: 35.2835\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.9702 - val_loss: 18.1210\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.5236 - val_loss: 17.3005\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.6011 - val_loss: 17.2941\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.0376 - val_loss: 20.3424\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.0434 - val_loss: 19.9790\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 15.3196 - val_loss: 15.8406\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.3882 - val_loss: 21.4710\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.8906 - val_loss: 15.4301\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.6063 - val_loss: 22.7931\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.0347 - val_loss: 16.9131\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.0665 - val_loss: 18.7642\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.2965 - val_loss: 16.4980\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.1506 - val_loss: 47.8996\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9796 - val_loss: 18.7393\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 12.6003 - val_loss: 24.0776\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.6760 - val_loss: 24.0153\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.0305 - val_loss: 16.1016\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.6160 - val_loss: 15.2471\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.1442 - val_loss: 24.6276\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.3379 - val_loss: 25.7019\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.0613 - val_loss: 20.2908\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.2968 - val_loss: 15.1196\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 11.1324 - val_loss: 31.8563\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 11.8251 - val_loss: 17.9064\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.2121 - val_loss: 15.8525\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.7537 - val_loss: 17.6920\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6990 - val_loss: 17.4470\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 10.8039 - val_loss: 16.8655\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6603 - val_loss: 15.0098\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.8756 - val_loss: 23.2278\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.9641 - val_loss: 18.1327\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.5339 - val_loss: 18.8284\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6513 - val_loss: 15.5691\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.4194 - val_loss: 15.8747\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.6112 - val_loss: 14.9436\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.9915 - val_loss: 15.2586\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.1486 - val_loss: 18.4053\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.3898 - val_loss: 14.4919\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.1211 - val_loss: 14.4784\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.1628 - val_loss: 15.8691\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.8875 - val_loss: 20.2948\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.2243 - val_loss: 16.3214\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.2282 - val_loss: 14.8659\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.1101 - val_loss: 16.8198\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.8437 - val_loss: 17.7942\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.2083 - val_loss: 14.8507\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.0713 - val_loss: 18.5283\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.8531 - val_loss: 16.5037\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.3286 - val_loss: 16.8043\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.7374 - val_loss: 17.8363\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 8.3707 - val_loss: 13.8763\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.4527 - val_loss: 22.1987\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.8348 - val_loss: 16.9582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.5839 - val_loss: 15.8294\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 7.3099 - val_loss: 13.7403\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.4886 - val_loss: 16.1893\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.3638 - val_loss: 15.9882\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.8010 - val_loss: 22.9245\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.9660 - val_loss: 14.7475\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 7.4469 - val_loss: 24.0684\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.1143 - val_loss: 14.7773\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.6129 - val_loss: 19.7933\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.6714 - val_loss: 16.1236\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.0431 - val_loss: 16.1370\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.5990 - val_loss: 16.8486\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 6.4443 - val_loss: 16.2714\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.8129 - val_loss: 17.6876\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.5024 - val_loss: 24.1146\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 5.9178 - val_loss: 14.8696\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.9118 - val_loss: 17.3640\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.3944 - val_loss: 16.2081\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.8270 - val_loss: 15.6441\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.4543 - val_loss: 15.1569\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.0934 - val_loss: 17.2604\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.8921 - val_loss: 16.1916\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 4.9838 - val_loss: 14.3651\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.0091 - val_loss: 14.6053\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 5.8656 - val_loss: 15.7315\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.6011 - val_loss: 16.3297\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.3964 - val_loss: 20.2028\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.2914 - val_loss: 16.7364\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.2859 - val_loss: 15.8510\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.1030 - val_loss: 15.6256\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.6297 - val_loss: 14.2310\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 4.9068 - val_loss: 15.6635\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 13.740392090324656\n",
      "Mean Absolute Error (MAE): 2.417821622434088\n",
      "Root Mean Squared Error (RMSE): 3.706803486877158\n",
      "Time taken: 308.0659177303314\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 11ms/step - loss: 1067.6987 - val_loss: 755.0402\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 587.9467 - val_loss: 507.8582\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 404.4003 - val_loss: 385.8859\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 260.4044 - val_loss: 215.0315\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 143.4492 - val_loss: 100.4627\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 82.9586 - val_loss: 58.6879\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 53.8198 - val_loss: 45.8259\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 40.1717 - val_loss: 45.2366\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 34.1090 - val_loss: 31.4654\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 28.7107 - val_loss: 27.0047\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 26.5062 - val_loss: 28.9220\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.4051 - val_loss: 32.7133\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.2165 - val_loss: 29.8346\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 22.2314 - val_loss: 24.2926\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 21.2264 - val_loss: 22.2929\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.9633 - val_loss: 20.2984\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.5847 - val_loss: 29.6087\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.2615 - val_loss: 26.4672\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.8329 - val_loss: 30.9072\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 18.9667 - val_loss: 27.3626\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.9367 - val_loss: 25.6650\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.6241 - val_loss: 18.6347\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.5707 - val_loss: 16.9093\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.3790 - val_loss: 21.0021\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.6126 - val_loss: 17.0054\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.8996 - val_loss: 21.1353\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.7682 - val_loss: 16.7143\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.9647 - val_loss: 19.1222\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.7205 - val_loss: 16.2292\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.5275 - val_loss: 17.7886\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.8393 - val_loss: 19.7115\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.9668 - val_loss: 19.1296\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.3754 - val_loss: 18.5511\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.8952 - val_loss: 18.8246\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.8574 - val_loss: 19.7847\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 2s 6ms/step - loss: 15.5091 - val_loss: 19.1931\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.4501 - val_loss: 14.7730\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.1338 - val_loss: 23.9726\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.4321 - val_loss: 21.3402\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.9848 - val_loss: 15.9769\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.0755 - val_loss: 21.4042\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.9767 - val_loss: 20.9752\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.8193 - val_loss: 17.7291\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.8257 - val_loss: 14.1828\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 12.1337 - val_loss: 14.3378\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.2979 - val_loss: 24.7378\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.1975 - val_loss: 14.8082\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.1545 - val_loss: 17.8812\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.0931 - val_loss: 18.8042\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.6572 - val_loss: 16.9071\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.3482 - val_loss: 16.7756\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.4381 - val_loss: 27.0338\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.0670 - val_loss: 14.0911\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.2775 - val_loss: 16.2821\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.3600 - val_loss: 29.1297\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.3047 - val_loss: 12.9122\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.5955 - val_loss: 22.8987\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.4091 - val_loss: 15.9582\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4692 - val_loss: 13.0492\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.9581 - val_loss: 15.1954\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.5816 - val_loss: 23.0961\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4921 - val_loss: 16.5843\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.0218 - val_loss: 20.6785\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.1263 - val_loss: 16.7378\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.6690 - val_loss: 14.9315\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.0183 - val_loss: 15.7456\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.7092 - val_loss: 14.5115\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.8586 - val_loss: 15.5208\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 9.6506 - val_loss: 20.0684\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.1245 - val_loss: 18.3185\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 8.7219 - val_loss: 22.1383\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.6586 - val_loss: 16.1945\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.1292 - val_loss: 21.6871\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 8.9265 - val_loss: 22.5792\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 8.5265 - val_loss: 14.1765\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.8819 - val_loss: 25.4348\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.1471 - val_loss: 18.6027\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.6884 - val_loss: 13.8525\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.5865 - val_loss: 15.5052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7915 - val_loss: 17.6049\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.8648 - val_loss: 16.2923\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.9764 - val_loss: 14.3514\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.1779 - val_loss: 19.3364\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.7895 - val_loss: 18.2218\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.3238 - val_loss: 19.3358\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.7741 - val_loss: 13.4353\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 12.912218105992887\n",
      "Mean Absolute Error (MAE): 2.437147495791615\n",
      "Root Mean Squared Error (RMSE): 3.593357497660494\n",
      "Time taken: 232.6593532562256\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 11ms/step - loss: 1048.6493 - val_loss: 840.7507\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 609.1140 - val_loss: 513.3378\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 413.6787 - val_loss: 393.7097\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 290.9569 - val_loss: 247.1042\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 179.8770 - val_loss: 162.5267\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 103.2984 - val_loss: 80.0426\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 62.3920 - val_loss: 52.5637\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 45.9134 - val_loss: 39.4064\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 35.3649 - val_loss: 35.0877\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.8142 - val_loss: 31.2571\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 27.5673 - val_loss: 28.9769\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.1831 - val_loss: 46.3488\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 2s 6ms/step - loss: 24.1057 - val_loss: 34.7931\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 23.0592 - val_loss: 43.9873\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 21.4356 - val_loss: 26.1827\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.1306 - val_loss: 20.8146\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.8374 - val_loss: 21.3619\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.7721 - val_loss: 21.0233\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.9142 - val_loss: 23.1014\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.5259 - val_loss: 23.1242\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.5167 - val_loss: 18.6233\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.9479 - val_loss: 21.1049\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 16.7414 - val_loss: 28.5112\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.4946 - val_loss: 42.9286\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.0709 - val_loss: 17.3664\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.6375 - val_loss: 18.3642\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 14.7685 - val_loss: 18.2518\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 15.0666 - val_loss: 27.5961\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.8389 - val_loss: 19.3634\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.5649 - val_loss: 20.9368\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.2097 - val_loss: 21.7127\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.9425 - val_loss: 21.0975\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.7690 - val_loss: 18.8230\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.0791 - val_loss: 21.1902\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.8775 - val_loss: 18.0658\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.7891 - val_loss: 17.8624\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.8533 - val_loss: 20.8963\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.3234 - val_loss: 22.6651\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.0996 - val_loss: 19.2033\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.2832 - val_loss: 18.9556\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.5993 - val_loss: 18.9806\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.0095 - val_loss: 21.1710\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.4195 - val_loss: 16.7158\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.4139 - val_loss: 16.2964\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.8819 - val_loss: 29.1715\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.8790 - val_loss: 20.8891\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.2869 - val_loss: 20.5160\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.1318 - val_loss: 17.0503\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.8321 - val_loss: 16.2763\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8339 - val_loss: 18.5547\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.8692 - val_loss: 21.2322\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4915 - val_loss: 30.9172\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.7298 - val_loss: 17.6698\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6400 - val_loss: 15.9593\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.3457 - val_loss: 17.2384\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.7223 - val_loss: 16.6653\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.7473 - val_loss: 31.2416\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.3225 - val_loss: 15.6226\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.9750 - val_loss: 16.5553\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.3572 - val_loss: 15.6129\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.4106 - val_loss: 16.2709\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.4126 - val_loss: 19.6556\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.8479 - val_loss: 20.6976\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.9628 - val_loss: 16.0759\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.5803 - val_loss: 17.4916\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.2867 - val_loss: 21.0146\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.6448 - val_loss: 19.0475\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.8285 - val_loss: 15.7130\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.3223 - val_loss: 23.5255\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.5943 - val_loss: 15.8035\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.6363 - val_loss: 17.7749\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.8657 - val_loss: 16.0226\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.4639 - val_loss: 18.1969\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.4303 - val_loss: 16.0173\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.2364 - val_loss: 22.3367\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.9107 - val_loss: 17.4323\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.6777 - val_loss: 18.9417\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 8.2987 - val_loss: 17.5398\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 8.1254 - val_loss: 17.6054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.6273 - val_loss: 16.0102\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.3089 - val_loss: 18.2708\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.4271 - val_loss: 19.4057\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.8104 - val_loss: 21.2739\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.6812 - val_loss: 18.6204\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 7.2323 - val_loss: 18.7234\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.2334 - val_loss: 16.1918\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.9433 - val_loss: 21.9534\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.3255 - val_loss: 28.9955\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.7996 - val_loss: 17.9875\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 5.9321 - val_loss: 20.2702\n",
      "16/16 [==============================] - 1s 18ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 15.612924272402807\n",
      "Mean Absolute Error (MAE): 2.592571177044357\n",
      "Root Mean Squared Error (RMSE): 3.95131930782654\n",
      "Time taken: 242.60241985321045\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 8s 12ms/step - loss: 1024.1252 - val_loss: 722.4102\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 555.6658 - val_loss: 464.2204\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 377.1831 - val_loss: 310.3041\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 276.6105 - val_loss: 220.8809\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 171.3122 - val_loss: 123.9255\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 100.1534 - val_loss: 80.5384\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 62.3271 - val_loss: 46.6076\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 43.2967 - val_loss: 36.9302\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 33.2553 - val_loss: 33.4446\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 27.9185 - val_loss: 28.0149\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 26.1141 - val_loss: 31.5624\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 24.0405 - val_loss: 32.8212\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 23.6240 - val_loss: 22.5790\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 20.9681 - val_loss: 23.7421\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 21.5136 - val_loss: 24.5026\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 20.0091 - val_loss: 26.4327\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 19.7796 - val_loss: 24.0345\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.7239 - val_loss: 25.2125\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.8287 - val_loss: 22.2266\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 18.0606 - val_loss: 23.4007\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.3865 - val_loss: 21.8985\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.9956 - val_loss: 21.5072\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.2007 - val_loss: 18.3063\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.9938 - val_loss: 27.2069\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.9791 - val_loss: 24.0969\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.6947 - val_loss: 24.9318\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.4292 - val_loss: 22.1900\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 14.6546 - val_loss: 20.6114\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.8725 - val_loss: 21.0548\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 14.3783 - val_loss: 23.4094\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 14.5101 - val_loss: 16.6517\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.8757 - val_loss: 19.4156\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.1198 - val_loss: 18.2460\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.3048 - val_loss: 17.0676\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 14.0164 - val_loss: 25.7657\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.4433 - val_loss: 20.7432\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.6826 - val_loss: 18.3159\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.8774 - val_loss: 20.7733\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.6337 - val_loss: 19.1614\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.5685 - val_loss: 19.6480\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.6867 - val_loss: 15.9720\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.5412 - val_loss: 21.9780\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.1265 - val_loss: 23.8257\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.1915 - val_loss: 17.0774\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.9803 - val_loss: 16.0011\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 11.4109 - val_loss: 15.9613\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.3142 - val_loss: 23.4495\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.2604 - val_loss: 17.8009\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 12.0006 - val_loss: 19.1709\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.5092 - val_loss: 17.3871\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.6562 - val_loss: 20.4920\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 10.7349 - val_loss: 18.0511\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 11.2511 - val_loss: 27.5158\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.1285 - val_loss: 17.5370\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.1073 - val_loss: 19.5720\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.0184 - val_loss: 18.9566\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.4394 - val_loss: 16.2669\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.3449 - val_loss: 18.1080\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.7990 - val_loss: 17.0197\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.3321 - val_loss: 18.8521\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.0972 - val_loss: 17.2563\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.1626 - val_loss: 17.6234\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.8423 - val_loss: 18.3099\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.9182 - val_loss: 23.7853\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.9764 - val_loss: 16.5114\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.7206 - val_loss: 25.5881\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.4564 - val_loss: 18.3757\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.7662 - val_loss: 25.1841\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.5515 - val_loss: 28.7926\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.0407 - val_loss: 18.1181\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.0354 - val_loss: 17.0922\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.7479 - val_loss: 24.9436\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.1288 - val_loss: 18.0439\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.9143 - val_loss: 21.1976\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.7910 - val_loss: 16.0278\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.9263 - val_loss: 16.1834\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 15.961298400697169\n",
      "Mean Absolute Error (MAE): 2.577111269656467\n",
      "Root Mean Squared Error (RMSE): 3.9951593711261593\n",
      "Time taken: 251.9535207748413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=6,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 16, 512)           1052672   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16, 512)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 16, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,047,747\n",
      "Trainable params: 2,046,723\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_4756\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold        MSE       MAE      RMSE  Time taken\n",
      "0        1  13.886814  2.539445  3.726502  294.213745\n",
      "1        2  13.740392  2.417822  3.706803  308.065918\n",
      "2        3  12.912218  2.437147  3.593357  232.659353\n",
      "3        4  15.612924  2.592571  3.951319  242.602420\n",
      "4        5  15.961298  2.577111  3.995159  251.953521\n",
      "5  Average  14.422729  2.512819  3.794628  265.898991\n",
      "Results saved to 'LSTM Results PL_model_1_Scattered_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('LSTM Results PL_model_1_Scattered_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'LSTM Results PL_model_1_Scattered_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAACoZUlEQVR4nOzdeXwU9f0/8NfMXtns5oKQAxIggUQOBW/EqyhUPGo9qKilHq3VakGr/dVavx5f0ar1qLVqq7UHaKut9vv9ep9ovUHEA0VACCFAgCQQcpFjr5n5/THZyW4ucnw+2Z3k9Xw88shkdrOZz2uWZd/7OUYxDMMAERERERHRIKiJPgAiIiIiIrI/FhZERERERDRoLCyIiIiIiGjQWFgQEREREdGgsbAgIiIiIqJBY2FBRERERESDxsKCiIiIiIgGjYUFERERERENGgsLIiIiIiIaNBYWREREREQ0aCwsiIhGoOXLl0NRFHz66aeJPpQ+Wbt2LX7wgx+gsLAQHo8Ho0aNwrx587Bs2TJompbowyMiIgDORB8AERFRb/7yl7/gyiuvRG5uLi666CKUlJRg//79ePvtt3HZZZehqqoK//Vf/5XowyQiGvFYWBARUdL6+OOPceWVV2L27Nl49dVXkZaWZt127bXX4tNPP8XXX38t5G+1tLTA5/MJeSwiopGIQ6GIiKhHX3zxBU477TSkp6fD7/dj7ty5+Pjjj+PuEw6HsXTpUpSUlCAlJQWjR4/G8ccfjxUrVlj3qa6uxg9/+EMUFBTA4/EgPz8fZ511FrZt29br31+6dCkURcFTTz0VV1REHXnkkbj00ksBAO+++y4URcG7774bd59t27ZBURQsX77c2nfppZfC7/ejvLwcp59+OtLS0rBo0SIsWbIEfr8fra2tXf7WhRdeiLy8vLihV6+99hpOOOEE+Hw+pKWl4YwzzsD69et7bRMR0XDFwoKIiLq1fv16nHDCCfjyyy/xy1/+ErfccgsqKiowZ84crF692rrfbbfdhqVLl+Kkk07CI488gptuugnjx4/H559/bt1nwYIFeO655/DDH/4Qf/zjH3HNNddg//792LFjR49/v7W1FW+//TZOPPFEjB8/Xnj7IpEI5s+fj5ycHNx///1YsGABzj//fLS0tOCVV17pciwvvfQSvve978HhcAAA/v73v+OMM86A3+/HPffcg1tuuQUbNmzA8ccff8CCiYhoOOJQKCIi6tbNN9+McDiMDz/8EMXFxQCAiy++GAcddBB++ctf4r333gMAvPLKKzj99NPx+OOPd/s4DQ0NWLlyJe677z784he/sPbfeOONvf79LVu2IBwO45BDDhHUonjBYBDnnXce7r77bmufYRgYN24cnnnmGZx33nnW/ldeeQUtLS04//zzAQDNzc245ppr8OMf/ziu3ZdccgkOOugg3HXXXT3mQUQ0XLHHgoiIutA0DW+++SbOPvtsq6gAgPz8fHz/+9/Hhx9+iKamJgBAZmYm1q9fj7Kysm4fy+v1wu12491330V9fX2fjyH6+N0NgRLlqquuivtZURScd955ePXVV9Hc3Gztf+aZZzBu3Dgcf/zxAIAVK1agoaEBF154IWpra60vh8OBWbNm4Z133pF2zEREyYqFBRERdbF37160trbioIMO6nLb1KlToes6KisrAQC33347GhoaUFpaikMOOQTXX389vvrqK+v+Ho8H99xzD1577TXk5ubixBNPxL333ovq6upejyE9PR0AsH//foEt6+B0OlFQUNBl//nnn4+2tja8+OKLAMzeiVdffRXnnXceFEUBAKuIOvnkkzFmzJi4rzfffBN79uyRcsxERMmMhQUREQ3KiSeeiPLycvztb3/DwQcfjL/85S84/PDD8Ze//MW6z7XXXovNmzfj7rvvRkpKCm655RZMnToVX3zxRY+PO3nyZDidTqxbt65PxxF9099ZT9e58Hg8UNWu/w0ec8wxmDhxIp599lkAwEsvvYS2tjZrGBQA6LoOwJxnsWLFii5fL7zwQp+OmYhoOGFhQUREXYwZMwapqanYtGlTl9u++eYbqKqKwsJCa9+oUaPwwx/+EP/85z9RWVmJGTNm4Lbbbov7vUmTJuH//b//hzfffBNff/01QqEQfvvb3/Z4DKmpqTj55JPx/vvvW70jvcnKygJgzumItX379gP+bmcLFy7E66+/jqamJjzzzDOYOHEijjnmmLi2AEBOTg7mzZvX5WvOnDn9/ptERHbHwoKIiLpwOBw45ZRT8MILL8StcFRTU4Onn34axx9/vDVUad++fXG/6/f7MXnyZASDQQDmikqBQCDuPpMmTUJaWpp1n57893//NwzDwEUXXRQ35yHqs88+wxNPPAEAmDBhAhwOB95///24+/zxj3/sW6NjnH/++QgGg3jiiSfw+uuvY+HChXG3z58/H+np6bjrrrsQDoe7/P7evXv7/TeJiOyOq0IREY1gf/vb3/D666932f+zn/0Mv/71r7FixQocf/zx+OlPfwqn04k//elPCAaDuPfee637Tps2DXPmzMERRxyBUaNG4dNPP8X//M//YMmSJQCAzZs3Y+7cuVi4cCGmTZsGp9OJ5557DjU1Nbjgggt6Pb5jjz0Wf/jDH/DTn/4UU6ZMibvy9rvvvosXX3wRv/71rwEAGRkZOO+88/Dwww9DURRMmjQJL7/88oDmOxx++OGYPHkybrrpJgSDwbhhUIA5/+PRRx/FRRddhMMPPxwXXHABxowZgx07duCVV17Bcccdh0ceeaTff5eIyNYMIiIacZYtW2YA6PGrsrLSMAzD+Pzzz4358+cbfr/fSE1NNU466SRj5cqVcY/161//2jj66KONzMxMw+v1GlOmTDHuvPNOIxQKGYZhGLW1tcbixYuNKVOmGD6fz8jIyDBmzZplPPvss30+3s8++8z4/ve/b4wdO9ZwuVxGVlaWMXfuXOOJJ54wNE2z7rd3715jwYIFRmpqqpGVlWX85Cc/Mb7++msDgLFs2TLrfpdcconh8/l6/Zs33XSTAcCYPHlyj/d55513jPnz5xsZGRlGSkqKMWnSJOPSSy81Pv300z63jYhouFAMwzASVtUQEREREdGwwDkWREREREQ0aCwsiIiIiIho0FhYEBERERHRoLGwICIiIiKiQWNhQUREREREg8bCgoiIiIiIBo0XyOsDXdexe/dupKWlQVGURB8OEREREdGQMAwD+/fvx9ixY6GqvfdJsLDog927d6OwsDDRh0FERERElBCVlZUoKCjo9T4sLPogLS0NgBloenr6kP99TdNQXl6OSZMmweFwDPnfH66YqxzMVTxmKgdzFY+ZysFcxWOmfdfU1ITCwkLr/XBvWFj0QXT4U3p6esIKC7/fj/T0dD75BWKucjBX8ZipHMxVPGYqB3MVj5n2X1+mA3DyNhERERERDRoLC5s40GQZGhjmKgdzFY+ZysFcxWOmcjBX8ZipeIphGEaiDyLZNTU1ISMjA42NjQkZCkVERERElAj9eR/MORY2YBgGWlpa4PP5uNytQMxVDuYqHjOVg7mKx0zliObq9XoRDocTfTjDgmEYaG1tRWpq6oh/rrpcLmHzTFhY2ICu69i5cydKSko4wUgg5ioHcxWPmcrBXMVjpnLouo4dO3ZAVVVwoIkYhmEgEonA6XSO+MICADIzM5GXlzfoLFhYEBERESUxwzAQDofh8/n6dJEyOjDDMBAMBuHxeEZ0YRHtudmzZw8AID8/f1CPx8KCiIiIKIlFIhEAwJgxY5Camprgoxkeoj0/KSkpI7qwAACv1wsA2LNnD3JycgbV28iS1wYURYHb7R7xT3zRmKsczFU8ZioHcxWPmcqh6zpUVYXL5Ur0oQwr7PnpEC1YBzuHhz0WNqCqKoqLixN9GMMOc5WDuYrHTOVgruIxUzlUVYXT6eQbYYEURYHH40n0YSQNUR8G8BlqA4ZhoKGhgRO2BGOucjBX8ZipHMxVPGYqh2EY0HWduQoUnbzNTMViYWEDuq6juroauq4n+lCGFeYqB3MVj5nKwVzFY6Zy6LoOTdMSfRhJYeLEiXjwwQf7fP93330XiqKgoaGhy21culc8FhZEREREJJSiKL1+3XbbbQN63DVr1uCKK67o8/2PPfZYVFVVISMjY0B/r696K2BGEs6xICIiIiKhqqqqrO1nnnkGt956KzZt2mTt8/v91rZhGNA0DU7ngd+Wjhkzpl/H4Xa7kZeX16/foYFjj4UNKIrCq5hKwFzlYK7iMVM5mKt4zFSO6Kf8dpKXl2d9ZWRkQFEU6+dvvvkGaWlpeO2113DEEUfA4/Hgww8/RHl5Oc466yzk5ubC7/fjqKOOwltvvRX3uJ2HQimKgr/85S8455xzkJqaipKSErz44ovW7Z17EpYvX47MzEy88cYbOOyww5CWloZTTz01rhCKRCK45pprkJmZidGjR+OGG27AJZdcgrPPPnvAedTX1+Piiy9GVlYWUlNTcdppp6GsrMy6ffv27TjzzDORlZUFn8+H6dOn49VXX7V+d9GiRRgzZgy8Xi9KSkqwbNmyAR+LTCwsbEBVVRQWFnI1CMGYqxzMVTxmKgdzFY+ZyhFdFcpuxcWB/OpXv8JvfvMbbNy4ETNmzEBzczNOP/10vP322/jiiy9w6qmn4swzz8SOHTt6fZylS5di4cKF+Oqrr3D66adj0aJFqKur6/H+ra2t+O1vf4t//OMfeP/997Fjxw784he/sG6/55578NRTT2HZsmX46KOP0NTUhOeff35Qbb300kvx6aef4sUXX8SqVatgGAZOP/10a57H4sWLEQwG8f7772PdunW45557rF6dW265BRs2bMBrr72GjRs34tFHH0V2dvagjkcWDoWyAV3XUVdXh1GjRvHFWiDmKgdzFY+ZysFcxWOmckQnb8euYHTmwx9i7/7gkB/LmDQPXrr6eCGPdfvtt+Pb3/629fOoUaMwc+ZM6+c77rgDzz33HF588UUsWbKkx8e59NJLceGFFwIA7rrrLjz00EP45JNPcOqpp3Z7/3A4jEcffRQTJkyA0+nEkiVLcPvtt1u3P/zww7jxxhtxzjnnAAAeeeQRq/dgIMrKyvDiiy/io48+wrHHHgsAeOqpp1BYWIjnn38e5513Hnbs2IEFCxbgkEMOAYC4ZZt37NiBww47DEceeSQAs9cmWbGwsAHDMFBbW4usrKxEH8qwwlzlYK7iMVM5mKt4zFSO6HKzsfbuD6K6KZCgIxIj+kY5qrm5GbfddhteeeUVVFVVIRKJoK2t7YA9FjNmzLC2fT4f0tPTsWfPnh7vn5qaikmTJiEQCMDpdCI/P9+6f2NjI2pqanD00Udb93c4HDjiiCMGvNrZxo0b4XQ6MWvWLGvf6NGjcdBBB2Hjxo0AgGuuuQZXXXUV3nzzTcybNw8LFiyw2nXVVVdhwYIF+Pzzz3HKKafg7LPPtgqUZMPCgoiIiMhmxqQl5uJuIv+uz+eL+/kXv/gFVqxYgfvvvx+TJ0+G1+vF9773PYRCoV4fp/MVyRVF6bUI6O7+ib6exY9//GPMnz8fr7zyCt58803cfffd+O1vf4urr74ap512GrZv345XX30VK1aswNy5c7F48WLcf//9CT3m7rCwsIHa5iCq9ofh3teK4py0RB8OERERJZio4UjJ5KOPPsKll15qDUFqbm7Gtm3bhvQYMjIykJubizVr1uDEE08EAGiahs8//xyHHnrogB5z6tSpiEQiWL16tdXTsG/fPmzatAnTpk2z7ldYWIgrr7wSV155JW688Ub8+c9/xtVXXw3AXA3rkksuwSWXXIITTjgB119/PQsLGpiTf/s+WkIaJo/Zh7f+35xEH86woSiKtVIFicNcxWOmcjBX8ZipHIqijIg5KyUlJfi///s/nHnmmVAUBbfccovUiy06HI5u91999dW4++67MXnyZEyZMgUPP/ww6uvr+/S8XrduHdLSOj4EVhQFM2fOxFlnnYXLL78cf/rTn5CWloZf/epXGDduHM466ywAwLXXXovTTjsNpaWlqK+vxzvvvIOpU6cCAG699VYcccQRmD59OoLBIF5++WXrtmTDwsIGvG4nWkIa2sK8kqlIqqoiPz8/0Ycx7DBX8ZipHMxVPGYqh6qqcDgcw75ge+CBB/CjH/0Ixx57LLKzs3HDDTegqalJyt9SFAVut7vb22644QZUV1fj4osvhsPhwBVXXIH58+f3WIjEivZyRDkcDkQiESxbtgw/+9nP8J3vfAehUAgnnngiXn31VWtYlqZpWLx4MXbu3In09HSceuqp+N3vfgfAvBbHjTfeiG3btsHr9eKEE07Av/71r0EmIIdiJHpQmQ00NTUhIyMDjY2NSE9PH/K/f8I9/0FlfRtGpbrw+a2nDPnfH650XUdNTQ1yc3NHxCdBQ4W5isdM5WCu4jFTOVpbW7F161ZMmjQJXq830YczLBiGgXA4DJfLdcCCTdd1TJ06FQsXLsQdd9wxREc4tAKBACoqKlBUVISUlJS42/rzPpj/6m0gxWVWyOyxEMswDDQ2NiZ8wtZww1zFY6ZyMFfxmKkc3a0KRYOnaVq3+7dv344///nP2Lx5M9atW4errroKFRUV+P73vz/ER2g/LCxsINUdLSw0vlgTERERSaSqKpYvX46jjjoKxx13HNatW4e33noraec1JBPOsbCBaI8FAATCOrzuA4/xIyIiIqL+KywsxEcffZTow7Al9ljYQGwh0RbuvtuO+k9RFGRnZw/7yXBDjbmKx0zlYK7iMVM5RsqqUEPN6eTn66IxURvwuTtOEwsLcVRVRXZ2dqIPY9hhruIxUzmYq3jMVI6RsirUUFIUpcuF8mjwElr+vv/++zjzzDMxduxYKIqC559/Pu52wzBw6623Ij8/H16vF/PmzUNZWVncferq6rBo0SKkp6cjMzMTl112GZqbm+Pu89VXX+GEE05ASkoKCgsLce+998pumlApro7T1BaKJPBIhhdd11FZWckJcYIxV/GYqRzMVTxmKoeu64hEIpxnKZBhGAiFQsxUsIQWFi0tLZg5cyb+8Ic/dHv7vffei4ceegiPPfYYVq9eDZ/Ph/nz5yMQCFj3WbRoEdavX48VK1bg5Zdfxvvvv48rrrjCur2pqQmnnHIKJkyYgM8++wz33XcfbrvtNjz++OPS2yeKN2aORVuIL9aiGIaBlpYWvqgIxlzFY6ZyMFfxmKkchmEwUwl6WhWKBi6hQ6FOO+00nHbaad3eZhgGHnzwQdx8883WVQmffPJJ5Obm4vnnn8cFF1yAjRs34vXXX8eaNWtw5JFHAgAefvhhnH766bj//vsxduxYPPXUUwiFQvjb3/4Gt9uN6dOnY+3atXjggQfiCpBkFtdjwaFQRERERJSEknaORUVFBaqrqzFv3jxrX0ZGBmbNmoVVq1bhggsuwKpVq5CZmWkVFQAwb948qKqK1atX45xzzsGqVatw4oknxl1dcf78+bjnnntQX1+PrKysLn87GAwiGAxaP0ev+qhpmlXdRidS6boe9ylCT/tVVYWiKD3u71w1Rydp6boOj7OjsGgNRrpdz9rhcHTZHz2Wnvb39dhltKkv+2W3CTAL2NjjtHubkuE8aVrHssjDpU2xx5KINkWPsfNz1c5tSobzFPtcHS5tGsh+kW2KHmPs79i9Td3tH+o2xR5vdz0XiqIMukejp8dItv390dtjR3XO3s5tGsz+2F6xzs/J/hxz0hYW1dXVAIDc3Ny4/bm5udZt1dXVyMnJibvd6XRi1KhRcfcpKirq8hjR27orLO6++24sXbq0y/7y8nL4/X4AZpGTn5+PmpoaNDY2WvfJzs5GdnY2du3ahZaWFmt/Xl4eMjMzsW3bNoRCIWt/QUEB/H4/ysvL416IioqK4HQ6UVZWhrb9Ddb+1lAYoVAIFRUV1j5VVVFaWoqWlhbs3LnT2u92u1FcXIzGxkYrDwDw+XwoLCxEXV0damtrrf1D2aZYJSUliEQiQ96m0aNHQ1VVlJeXWy8ydm9TMpyn6H+qqqoOmzYBiT1PPp8PkUgk7rlq9zYlw3kyDAMulwuqqqK6unpYtAlI/HkKhULWc3W4tCnR50nTNOvffigUijt2t9sNh8OBYDAY9wbQ4/FAUZS44eMAkJKSAsMw4j5AVRQFKSkp0HU9Li9VVeHxeKBpGsLhsLXf4XDA7XYjEokgEol02R8Oh+OKIafTCZfL1WW/y+WC0+nstU2nnHIKZsyYgfvuuw8ejwfFxcVYvHgxlixZ0mObUlNT8cwzz2DhwoW9tin2d7prU2pqKp599lmcd955QtuUjOcpGAxax9v531Nqair6SjGSZNCeoih47rnncPbZZwMAVq5cieOOOw67d+9Gfn6+db+FCxdCURQ888wzuOuuu/DEE09g06ZNcY+Vk5ODpUuX4qqrrsIpp5yCoqIi/OlPf7Ju37BhA6ZPn44NGzZ0e7GT7nosoi8K0UuZD+WnJ0+u2o6lL28EAPz2vJk49/BxCf/0ZLBt6st+toltYpvYJraJbWKbgEAggB07dqCoqAgejwedJeMn4d/97ncRDofx2muvdbn/Bx98gG9961tYu3YtZs6c2evjnHTSSZg5cyYefPBBAMDevXvh8/l6fbOrqir+7//+D+ecc06fjv22227DCy+8gLVr18btj34AHX2TLyqbWMuXL8d1112H+vr6Htsj+m92tz8QCKCiogLFxcVwu91xtzU3NyMzMxONjY3W++CeJG2PRV5eHgCgpqYmrrCoqanBoYceat1nz549cb8XiURQV1dn/X5eXh5qamri7hP9OXqfzjweT7f/cB0OBxyO+IvTRV90Ouvv/s6PG7s/9joWgYj5qUV39+/vflHHPpA29XW/zDbpuo5t27Zh4sSJXW63a5sGsl90mzrnOhza1Jf9Mtuk6zq2b9/e7XPVrm3q6Rj7u38wbertNeBAx56sbZKxvz/H3tNz1c5t6mn/ULZJURRrVajYYTyd/+5g9fexe9t/2WWXYcGCBdi1axcKCgri7r98+XIceeSRmDlzZp8eX1EUa7vzSJUDtaW3XEKhENxud9x9Yrdj33+KzKa/xyn6b3a3Pzbjzs/J/hxb0l5tpaioCHl5eXj77betfU1NTVi9ejVmz54NAJg9ezYaGhrw2WefWff5z3/+A13XMWvWLOs+77//flzX0IoVK3DQQQd1OwwqGcWvCsXJ26IYBpeak4G5isdM5WCu4jFTOWLHv9vFd77zHYwZMwbLly+P29/c3Ix///vfuOyyy7Bv3z5ceOGFGDduHFJTU3HIIYfgn//8Z6+PO3HiRKv3AgDKyspw4oknIiUlBdOmTcOKFSu6/M4NN9yA0tJSpKamori4GLfccgvC4TB0Xcfy5cuxdOlSfPnll9ab6+gxK0r8pRDWrVuHk08+GV6vF6NHj8YVV1wRd4mDSy+9FGeffTbuv/9+5OfnY/To0Vi8eHHce9D+2rFjB8466yz4/X6kp6dj4cKFcR+Yf/nllzjppJOQlpaG9PR0HHHEEfj0008BANu3b8eZZ56JrKws+Hw+TJ8+Ha+++uqAj6UvEtpj0dzcjC1btlg/V1RUYO3atRg1ahTGjx+Pa6+9Fr/+9a9RUlKCoqIi3HLLLRg7dqw1XGrq1Kk49dRTcfnll+Oxxx5DOBzGkiVLcMEFF2Ds2LEAgO9///tYunQpLrvsMtxwww34+uuv8fvf/x6/+93vEtHkAWFhQURERHbidDpx8cUXY/ny5bjpppusT73//e9/Q9M0XHjhhWhubsYRRxyBG264Aenp6XjllVdw0UUXYdKkSTj66KMP+Dd0Xce5556L3NxcrF69Go2Njbj22mu73C8tLQ3Lly/H2LFjsW7dOlx++eXw+/245pprcP7552P9+vV4/fXX8dZbbwEw57901tLSgvnz52P27NlYs2YN9uzZgx//+MdYsmRJXPH0zjvvID8/H++88w62bNmC888/H4ceeiguv/zyfmeo67pVVLz33nuIRCJYvHgxzj//fLz77rsAzMsuHHbYYXj00UfhcDiwdu1a68J/ixcvRigUwvvvvw+fz4cNGzZYc4VlSWhh8emnn+Kkk06yfv75z38OALjkkkuwfPly/PKXv0RLSwuuuOIKNDQ04Pjjj8frr7+OlJQU63eeeuopLFmyBHPnzoWqqliwYAEeeugh6/aMjAy8+eabWLx4MY444ghkZ2fj1ltvtc1SswCQEjMUisvNEhEREf70LaB5z4HvJ5o/B/jJe326649+9CPcd999eO+99zBnzhwAwLJly7BgwQJkZGQgIyMDv/jFL6z7X3311XjjjTfw7LPP9qmweOutt/DNN9/gjTfesD5Qvuuuu7pcyuDmm2+2tidOnIhf/OIX+Ne//oVrrrkGXq8Xfr8fTqezxyHyAPD0008jEAjgySefhM/nAwA88sgjOPPMM3HPPfdYCwNlZWXhkUcegcPhwJQpU3DGGWfg7bffHlBh8fbbb2PdunWoqKhAYWEhAPPSC9OnT8eaNWtw1FFHYceOHbj++usxZcoUAOaCA1E7duzAggULcMghhwAAiouL+30M/ZXQwmLOnDm9du0pioLbb78dt99+e4/3GTVqFJ5++ule/86MGTPwwQcfDPg4E83v6ThNLCzEUVUVBQUFPY5vpYFhruIxUzmYq3jMVI5u56s17wH2707MAfXRlClTcOyxx+Jvf/sb5syZgy1btuCDDz6w3tdpmoa77roLzz77LHbt2oVQKIRgMNjnVYg2btyIwsJCq6gAYA2Xj/XMM8/goYceQnl5OZqbmxGJRJCenh53KYK+/K2ZM2daRQUAHHfccdB1HZs2bbIKi+nTp8edq/z8fKxbt67Pf6fz3ywsLLSKCgCYNm0aMjMzsXHjRhx11FH4+c9/jh//+Mf4+9//jnnz5uG8887DpEmTAADXXHMNrrrqKrz55puYN28eFixYgBkzZgzoWPqK//JtwOuOKSw4FEoYRVHg9/uFTHijDsxVPGYqB3MVj5nKEV0pKi5Xfw6QNnbov/x9mzwdddlll+F///d/sX//fixbtgyTJk3Ct771LQDAfffdh9///ve44YYb8M4772Dt2rWYP39+3FKqg7Vq1SosWrQIp59+Ol5++WV88cUXuOmmmxAKheBwOIQ/V6PDkKKiq5PJctttt2H9+vU444wz8J///AfTpk3Dc889BwD48Y9/jK1bt+Kiiy7CunXrcOSRR+Lhhx+WdixAEq8KRR08jo4nPXssxNE0DeXl5Zg0aVKPK4FQ/zFX8ZipHMxVPGYqR/T6BHGjPPo4HCnRFi5ciJ/97Gd4+umn8eSTT+Kqq66y3sx/9NFHOOuss/CDH/wAgDmnYPPmzZg2bVqfHnvq1KmorKxEVVWVtYLTxx9/HHeflStXYsKECbjpppusfdu3bwdgLrHq8Xjgdru7LEHc3d9avnw5WlparF6Ljz76CKqq4qCDDurT8fZXtH2VlZVWr8WGDRvQ0NAQl1FpaSlKS0tx3XXX4cILL8SyZctwzjnnAAAKCwtx5ZVX4sorr8SNN96IP//5z7j66qulHC/AHgtb8Lo6ThN7LMSS+SnCSMZcxWOmcjBX8ZgpxfL7/Tj//PNx4403oqqqCpdeeql1W0lJCVasWIGVK1di48aN+MlPftLlEgG9mTdvHkpLS3HJJZfgyy+/xAcffBBXQET/xo4dO/Cvf/0L5eXleOihh6xP9KOF2sSJE60FhGpra+OuZRa1aNEipKSk4JJLLsHXX3+Nd955B1dffTUuuuiiLhdz7i9N07B27dq4r40bN2LevHk45JBDsGjRInz++ef45JNPcPHFF+Nb3/oWjjzySLS1tWHJkiV49913sX37dnz00UdYs2aNdY22a6+9Fm+88QYqKirw+eef45133un2+m0isbCwAS8nbxMREZFNXXbZZaivr8f8+fPj5kPcfPPNOPzwwzF//nzMmTMHeXl51sqffaGqKp577jm0tbXh6KOPxo9//GPceeedcff57ne/i+uuuw5LlizBoYceipUrV+KWW26Ju8+CBQtw6qmn4qSTTsKYMWO6XfI2NTUVb7zxBurq6nDUUUfhe9/7HubOnYtHHnmkf2F0o7m5GYcddljc15lnnglFUfDCCy8gKysLJ554IubNm4fi4mI888wzAMzrq+zbtw8XX3wxSktLsXDhQpx22mlYunQpALNgWbx4sbWKamlpKf74xz8O+nh7kzRX3k5mTU1NyMjI6NMVB2UIhMKYcuubAIAjJ2Thf646dsiPYTjSNA1lZWUoKSlhl71AzFU8ZioHcxWPmcrR0tKC8vJylJSUwOv1JvpwhgXDMBAIBJCSksI5Qei48nZRUVHc6qtA/94Hs8fCBjwuJ1zt8yxaORRKGFVVUVRUxNVLBGOu4jFTOZireMxUDlVV4XRyWqxoHo8n0Ycw7PBfvk2ktF8kL8ChUELxhVoO5ioeM5WDuYrHTMku2FMhHgsLG9B1HW7VHLHGORbi6LqOsrIyTjQUjLmKx0zlYK7iMVM5dF1HJBJJ9GEMO4FAINGHMOywsLAJj8M8VRwKRURERETJiIWFTXicZncdeyyIiIiIKBmxsLCJlPbCIhTRoelcyIuIiGik4UKeJIuo4YucYWUDqqoiK90P7DUv2NIW1uD38NQNlqqqKCkp4eolgjFX8ZipHMxVPGYqh8fjgcvlQm1tLcaMGcNJxwJEi7RAIDCi8zQMA6FQCHv37oWqqnC73YN6PL47tYlojwVgXn2bhYUYkUhk0P+IqCvmKh4zlYO5isdMxXM4HMjLy0NNTQ22bduW6MMZNgzDGNFFRazU1FSMHz9+0B8K8N2pDei6Di3UsXIBl5wVQ9d1VFRU8EJOgjFX8ZipHMxVPGYqh67rqKmpQXFxMVfcEkTTNGzfvh3jx48f8c9Vh8MBp9MppMhiYWETnpgeC64MRURENPI4HA72BgmiaRpUVUVKSsqILyxE4iBIm0hxdpwqrgxFRERERMmGhYVNeGMKi9YQL5IjCicYysFcxWOmcjBX8ZipHMxVPGYqHodC2YDD4cDY3DHAunoAnGMhisPhQGlpaaIPY9hhruIxUzmYq3jMVA7mKh4zlYOlmg0YhgEHOnop2kKcuCWCYRhobm7muuCCMVfxmKkczFU8ZioHcxWPmcrBwsIGdF1HoLnJ+plDocTQdR07d+7kChuCMVfxmKkczFU8ZioHcxWPmcrBwsImYidvcygUERERESUbFhY2EbvcLFeFIiIiIqJkw8LCBhRFgS+lY91qXsdCDEVR4Ha7edVNwZireMxUDuYqHjOVg7mKx0zl4KpQNqCqKorHjwNQCYA9FqKoqori4uJEH8aww1zFY6ZyMFfxmKkczFU8ZioHeyxswDAMRIKt1s9t7LEQwjAMNDQ0cEUIwZireMxUDuYqHjOVg7mKx0zlYGFhA7quo7mh3vqZhYUYuq6jurqaK0IIxlzFY6ZyMFfxmKkczFU8ZioHCwubSOHkbSIiIiJKYiwsbCKusGCPBRERERElGRYWNqAoCrLS/dbP7LEQQ1EU+Hw+rgghGHMVj5nKwVzFY6ZyMFfxmKkcLCxsQFVVlBRNsH5mYSGGqqooLCyEqvKfgUjMVTxmKgdzFY+ZysFcxWOmcjBNG9B1HXV1++Bpv/o2h0KJoes6amtrOXFLMOYqHjOVg7mKx0zlYK7iMVM5WFjYgGEYqK2tRarbAYA9FqJEc+VSc2IxV/GYqRzMVTxmKgdzFY+ZysHCwkZSXO2FBXssiIiIiCjJsLCwES8LCyIiIiJKUiwsbEBRFGRkZHAolGDRXLkihFjMVTxmKgdzFY+ZysFcxWOmcrCwsAFVVZGfnw9ve2ER0Q2EIpxsNFjRXLkihFjMVTxmKgdzFY+ZysFcxWOmcjBNG9B1HVVVVdYcC4C9FiJEc+WKEGIxV/GYqRzMVTxmKgdzFY+ZysHCwgYMw0BjY6M1xwIAAiwsBi2aK1eEEIu5isdM5WCu4jFTOZireMxUDhYWNuJ1dZyuVk7gJiIiIqIkwsLCRuKGQrGwICIiIqIkwsLCBhRFQXZ2NlI9Tmsf51gMXjRXrgghFnMVj5nKwVzFY6ZyMFfxmKkczgPfhRJNVVWzsHDXWvvYYzF40VxJLOYqHjOVg7mKx0zlYK7iMVM52GNhA7quo7KykqtCCRbNlStCiMVcxWOmcjBX8ZipHMxVPGYqBwsLGzAMAy0tLfA6O04XC4vBi+bKFSHEYq7iMVM5mKt4zFQO5ioeM5WDhYWNxE/ejiTwSIiIiIiI4rGwsJFUN1eFIiIiIqLkxMLCBlRVRV5eXtyqUK0cCjVo0VxVlf8MRGKu4jFTOZireMxUDuYqHjOVg6tC2YCiKMjMzIR3T9jaF2CPxaBFcyWxmKt4zFQO5ioeM5WDuYrHTOVgmWYDuq5j69atSHF2rLXMyduDF82VK0KIxVzFY6ZyMFfxmKkczFU8ZioHCwsbMAwDoVAIKTGrQrWyx2LQorlyRQixmKt4zFQO5ioeM5WDuYrHTOVgYWEjcZO32WNBREREREmEhYWNxC43G2BhQURERERJhJO3bUBVVRQUFCAEl7WPQ6EGL5orV4QQi7mKx0zlYK7iMVM5mKt4zFQOFhY2oCgK/H5/XC8Fr2MxeNFcSSzmKh4zlYO5isdM5WCu4jFTOVim2YCmadi8eTOcigGlfWEozrEYvGiumsYsRWKu4jFTOZireMxUDuYqHjOVg4WFTei6DkVR4G2fZ8EeCzG4zJwczFU8ZioHcxWPmcrBXMVjpuKxsLCZ6MpQ7LEgIiIiomTCwsJmUthjQURERERJiIWFDaiqiqKiIqiq2jEUij0WgxabK4nDXMVjpnIwV/GYqRzMVTxmKgfTtAmn01zAK3YoFK8WOXjRXEks5ioeM5WDuYrHTOVgruIxU/FYWNiArusoKyuDruvWUCjDAIIRTjoajNhcSRzmKh4zlYO5isdM5WCu4jFTOVhY2Ey0xwLgPAsiIiIiSh4sLGzGG1tYcJ4FERERESUJFhY2Ex0KBQCt7LEgIiIioiTBwsIGVFVFSUkJVFWNGwoVYI/FoMTmSuIwV/GYqRzMVTxmKgdzFY+ZysE0bSISiQCAtdwswB4LEaK5kljMVTxmKgdzFY+ZysFcxWOm4rGwsAFd11FRUQFd1+MKC86xGJzYXEkc5ioeM5WDuYrHTOVgruIxUzlYWNiM192x5jJXhSIiIiKiZMHCwma8ro5T1hZmFx4RERERJQcWFjYRnVwUt9xsiN13g8VJW3IwV/GYqRzMVTxmKgdzFY+ZisdrmduAw+FAaWkpgE5DoTjHYlBicyVxmKt4zFQO5ioeM5WDuYrHTOVgqWYDhmGgubkZhmHET94OcSjUYMTmSuIwV/GYqRzMVTxmKgdzFY+ZysHCwgZ0XcfOnTuh63rcdSzYYzE4sbmSOMxVPGYqB3MVj5nKwVzFY6ZysLCwmRQX51gQERERUfJhYWEz8dex4FAoIiIiIkoOLCxsQFEUuN1uKIoSPxSK17EYlNhcSRzmKh4zlYO5isdM5WCu4jFTObgqlA2oqori4mIA8cvNtrKwGJTYXEkc5ioeM5WDuYrHTOVgruIxUznYY2EDhmGgoaEBhmHEz7Hg5O1Bic2VxGGu4jFTOZireMxUDuYqHjOVg4WFDei6jurq6i6rQgVYWAxKbK4kDnMVj5nKwVzFY6ZyMFfxmKkcSV1YaJqGW265BUVFRfB6vZg0aRLuuOOOuOrSMAzceuutyM/Ph9frxbx581BWVhb3OHV1dVi0aBHS09ORmZmJyy67DM3NzUPdHCFcDhVO1RwPyKFQRERERJQskrqwuOeee/Doo4/ikUcewcaNG3HPPffg3nvvxcMPP2zd595778VDDz2Exx57DKtXr4bP58P8+fMRCASs+yxatAjr16/HihUr8PLLL+P999/HFVdckYgmCRGdZ8GhUERERESULJJ68vbKlStx1lln4YwzzgAATJw4Ef/85z/xySefADB7Kx588EHcfPPNOOusswAATz75JHJzc/H888/jggsuwMaNG/H6669jzZo1OPLIIwEADz/8ME4//XTcf//9GDt2bGIa1w+KosDn81krF3hdDuwPRBBgj8WgdM6VxGCu4jFTOZireMxUDuYqHjOVI6kLi2OPPRaPP/44Nm/ejNLSUnz55Zf48MMP8cADDwAAKioqUF1djXnz5lm/k5GRgVmzZmHVqlW44IILsGrVKmRmZlpFBQDMmzcPqqpi9erVOOecc7r83WAwiGAwaP3c1NQEwByapWnmm3lFUaCqKnRdjxua1dN+VVWhKEqP+6OPG7sfgDX2b+zYsTAMA4ZhWNeyaA11HI/D4YBhGHFjBaPH0tP+vh67rDYdaP9QtGncuHEwDMM61uHQpmQ4T+PGjRt2bUrkeVJV1XoNiH2u2rlNyXKeos/V4dSmRJ4nRVG6PFft3qbu9ieiTQUFBcOuTYk8T52fq8OhTbLOU38muCd1YfGrX/0KTU1NmDJlChwOBzRNw5133olFixYBAKqrqwEAubm5cb+Xm5tr3VZdXY2cnJy4251OJ0aNGmXdp7O7774bS5cu7bK/vLwcfr8fgFnA5Ofno6amBo2NjdZ9srOzkZ2djV27dqGlpcXan5eXh8zMTGzbtg2hUMjaX1BQAL/fj/Ly8rgnQ1FREZxOJ8rKymAYBtra2uD1elFaWooUl/lkaw1FUFZWBlVVUVpaipaWFuzcudN6DLfbjeLiYjQ2Nsa11efzobCwEHV1daitrbX2D2WbYpWUlCASiaCiosLaNxRtGjVqFL755hsoimJ9YmH3NiXDeTIMA5FIBNOnT0dTU9OwaBOQ2POUmpqKdevWwePxWM9Vu7cpGc6TYRhQVRUlJSXDpk1AYs9TKBTCxo0b4fV6rTcpdm9TMpwnwzDg9Xoxfvz4YdMmILHnqb6+Htu2bbOeq8OhTbLOU2pqKvpKMZJ4na1//etfuP7663Hfffdh+vTpWLt2La699lo88MADuOSSS7By5Uocd9xx2L17N/Lz863fW7hwIRRFwTPPPIO77roLTzzxBDZt2hT32Dk5OVi6dCmuuuqqLn+3ux6L6IlJT08HMLQVrKZp2LJlCyZPngyXy4Vz/7gSX1Q2AADK7pgPVVVG3CcNItpkGAY2b96MSZMmweFwDIs2JcN50jQN5eXlKC0ttY7H7m2KPZZEnCdd17Fp0yZMnjw57rlq5zYlw3mKfa5GXxPs3qaB7BfZJk3TsHnz5rjnqt3b1N3+oW5Tb89Vu7Yp9tgTcZ4ikUjcc3U4tEnWeWpubkZmZiYaGxut98E9Seoei+uvvx6/+tWvcMEFFwAADjnkEGzfvh133303LrnkEuTl5QEAampq4gqLmpoaHHrooQDMynHPnj1xjxuJRFBXV2f9fmcejwcej6fLfofDYb1QRkVPfGf93d/5cTvvV1XVeuLHXiQvpAO+9qFRiqJ0+zg97Rd17ANtU1/2y2xTtOuzP+c12ds0kP0y2hT9VH04telA+2W3Kfoa0Plv27lNyXCeos/V4dQm0fv7e+zdPVft3Kae9g91mw70XLVjmw60X3abunuu2r1NMp97fZHUq0K1trZ2aZzD4bCqsaKiIuTl5eHtt9+2bm9qasLq1asxe/ZsAMDs2bPR0NCAzz77zLrPf/7zH+i6jlmzZg1BK8SLvZYFV4YiIiIiomSQ1D0WZ555Ju68806MHz8e06dPxxdffIEHHngAP/rRjwCYFdS1116LX//61ygpKUFRURFuueUWjB07FmeffTYAYOrUqTj11FNx+eWX47HHHkM4HMaSJUtwwQUX2GJFKMBsZ0ZGhlUxxl19mytDDVjnXEkM5ioeM5WDuYrHTOVgruIxUzmSurB4+OGHccstt+CnP/0p9uzZg7Fjx+InP/kJbr31Vus+v/zlL9HS0oIrrrgCDQ0NOP744/H6668jJSXFus9TTz2FJUuWYO7cuVBVFQsWLMBDDz2UiCYNiKqqcUO9vC72WIjQOVcSg7mKx0zlYK7iMVM5mKt4zFSOpJ68nSyampqQkZHRp0krMui6jpqaGuTm5kJVVfz3C1/jiVXbAQAvLD4OMwszh/yYhoPOuZIYzFU8ZioHcxWPmcrBXMVjpn3Xn/fBTNIGDMNAY2OjNUM/JWaORSuHQg1Y51xJDOYqHjOVg7mKx0zlYK7iMVM5WFjYUKqrYwRbgEOhiIiIiCgJsLCwIa+747RxjgURERERJQMWFjagKAqys7OtlQtiJ29zKNTAdc6VxGCu4jFTOZireMxUDuYqHjOVI6lXhSKTqqrIzs62fva6O04beywGrnOuJAZzFY+ZysFcxWOmcjBX8ZipHOyxsAFd11FZWWldGDBuudlQJFGHZXudcyUxmKt4zFQO5ioeM5WDuYrHTOVgYWEDhmGgpaXFWrkgbo5FiP8gBqpzriQGcxWPmcrBXMVjpnIwV/GYqRwsLGzI6+JQKCIiIiJKLiwsbMjr5lAoIiIiIkouLCxsQFVV5OXlWVeGjJtjwR6LAeucK4nBXMVjpnIwV/GYqRzMVTxmKgdXhbIBRVGQmZlp/Zwa22MR5hyLgeqcK4nBXMVjpnIwV/GYqRzMVTxmKgfLNBvQdR1bt261Vi5I4apQQnTOlcRgruIxUzmYq3jMVA7mKh4zlYOFhQ0YhoFQKGStXBDfY8GhUAPVOVcSg7mKx0zlYK7iMVM5mKt4zFQOFhY2FN9jwcKCiIiIiBKPhYUNOVQFbqd56lpZWBARERFREmBhYQOqqqKgoCBu5YLocKgAh0INWHe50uAxV/GYqRzMVTxmKgdzFY+ZysFVoWxAURT4/f64fV6XAw0Is8diELrLlQaPuYrHTOVgruIxUzmYq3jMVA6WaTagaRo2b94MTesoIqLXsuDk7YHrLlcaPOYqHjOVg7mKx0zlYK7iMVM5WFjYROfl0LwcCiUEl5mTg7mKx0zlYK7iMVM5mKt4zFQ8FhY2Fe2xCGsGwhr/YRARERFRYrGwsCkvr2VBREREREmEhYUNqKqKoqKiuJULvDHXsghwAveAdJcrDR5zFY+ZysFcxWOmcjBX8ZipHEzTJpzO+AW8YnssuDLUwHXOlcRgruIxUzmYq3jMVA7mKh4zFY+FhQ3ouo6ysrK4SUapHAo1aN3lSoPHXMVjpnIwV/GYqRzMVTxmKgcLC5tKcbGwICIiIqLkwcLCpmLnWLRxKBQRERERJRgLi2RnGECwCa7m3cC+LdbuuKFQLCyIiIiIKME4a8UG1PtLMEkPw8g7BLjyQwDxQ6FaORRqQFRVRUlJCVeEEIy5isdM5WCu4jFTOZireMxUDqaZ7BQFSB1lbrfWW7tjV4XicrMDF4lEEn0IwxJzFY+ZysFcxWOmcjBX8ZipeCws7CAl0/zeVmft4qpQg6frOioqKrgihGDMVTxmKgdzFY+ZysFcxWOmcrCwsIP2Hgsl3AqEAwDiJ2/zOhZERERElGgsLOzAO6pju73XwuvumB7DHgsiIiIiSjQWFjZgeLM6fmgz51nE9lgEWFgMGCdtycFcxWOmcjBX8ZipHMxVPGYqHleFsgHVN7rjh9b2Hou4oVCcfDQQDocDpaWliT6MYYe5isdM5WCu4jFTOZireMxUDpZqNmCkxPZYRIdCxV7HghOPBsIwDDQ3N8MwjEQfyrDCXMVjpnIwV/GYqRzMVTxmKgcLCxswvJkdP7R2U1iE2WMxELquY+fOnVwRQjDmKh4zlYO5isdM5WCu4jFTOVhY2IDR3eRtF6+8TURERETJg4WFHcQWFu09FryOBRERERElExYWNqCkxvZYNAAAPM6OU8cei4FRFAVutxuKoiT6UIYV5ioeM5WDuYrHTOVgruIxUzm4KpQNqL7sjh/ah0IpigKvy4G2sMYeiwFSVRXFxcWJPoxhh7mKx0zlYK7iMVM5mKt4zFQO9ljYQHeTt4GO4VAsLAbGMAw0NDRwRQjBmKt4zFQO5ioeM5WDuYrHTOVgYWEDuuKE5kw1f2jrKCxS2idwcyjUwOi6jurqaq4IIRhzFY+ZysFcxWOmcjBX8ZipHCwsbEJ3Z5gb3fVYsLAgIiIiogRjYWETmifd3GirB9q77bwxQ6HYlUdEREREicTCwgYURelYctbQgGATgI6hULoBBCPsyusvRVHg8/m4IoRgzFU8ZioHcxWPmcrBXMVjpnKwsLABVVWRkpXfsaOba1kEOIG731RVRWFhIVSV/wxEYq7iMVM5mKt4zFQO5ioeM5WDadqArutoU1M7dnRz9e1WzrPoN13XUVtby4lbgjFX8ZipHMxVPGYqB3MVj5nKwcLCBgzDQIvu7tjRWg8gvrDgkrP9ZxgGamtrOT9FMOYqHjOVg7mKx0zlYK7iMVM5WFjYhBZdFQowJ3CjY/I2wJWhiIiIiCixWFjYhOaJLSy6DoVijwURERERJRILCxtQFOWAk7fZY9F/iqIgIyODK0IIxlzFY6ZyMFfxmKkczFU8ZiqHM9EHQAemqipGjZvcsaO9xyLFzR6LwVBVFfn5+Qe+I/ULcxWPmcrBXMVjpnIwV/GYqRzssbABXdexpznSsaO1m6FQ7LHoN13XUVVVxRUhBGOu4jFTOZireMxUDuYqHjOVg4WFDRiGgYZQzKlq62YoFHss+s0wDDQ2NnJFCMGYq3jMVA7mKh4zlYO5isdM5WBhYRO6yw9DaT9d7atCpbDHgoiIiIiSBAsLu1BUICXT3O5uKBR7LIiIiIgogVhY2ICiKMjOzgZSR5k72nssUt0dc+/ZY9F/0Vy5IoRYzFU8ZioHcxWPmcrBXMVjpnJwVSgbUFXVLCy87YVFsAnQwvC6O+rCVhYW/WblSkIxV/GYqRzMVTxmKgdzFY+ZysEeCxvQdR2VlZUwvFkdO9vq4+dYcChUv0Vz5YoQYjFX8ZipHMxVPGYqB3MVj5nKwcLCBgzDQEtLC4xojwUAtNXHDYUKsLDoNytXrgghFHMVj5nKwVzFY6ZyMFfxmKkcLCzsJDWmx6K1Lm7ydmso0s0vEBERERENDRYWdpISOxSqDt6461iwK4+IiIiIEoeFhQ2oqoq8vDwovtEdOzv1WAQ4ebvformqKv8ZiMRcxWOmcjBX8ZipHMxVPGYqB1eFsgFFUZCZmdmx3CwAtNXB5VDgUBVouoHWMIdC9ZeVKwnFXMVjpnIwV/GYqRzMVTxmKgfLNBvQdR1bt26FnhI/x0JRFKS291rwOhb9Z+XKFSGEYq7iMVM5mKt4zFQO5ioeM5WDhYUNGIaBUCgEIyV+uVkASHGzsBgoK1euCCEUcxWPmcrBXMVjpnIwV/GYqRwsLOzEm9mx3VZn7or2WHC5WSIiIiJKIBYWdhI7x6LV7LFIdbOwICIiIqLEY2FhA6qqoqCgAKrHDzhTzJ3tPRbRq28Hwjp0nd15/WHlyhUhhGKu4jFTOZireMxUDuYqHjOVg2nagKIo8Pv9UBQFiF59uzV+KBQABCLsteiPuFxJGOYqHjOVg7mKx0zlYK7iMVM5WFjYgKZp2Lx5MzRN6xgO1VYPGIY1FArgBO7+isuVhGGu4jFTOZireMxUDuYqHjOVg4WFTVjLoXnbV4bSgkC41VoVCgBaWVj0G5eZk4O5isdM5WCu4jFTOZireMxUPBYWduONv5ZFauxQKE7gJiIiIqIEYWFhN52uvu2NHQrFwoKIiIiIEoSFhQ2oqoqioiJz5QJv7JKzdXGTtzkUqn/iciVhmKt4zFQO5ioeM5WDuYrHTOVgmjbhdDrNjbgei3r2WAySlSsJxVzFY6ZyMFfxmKkczFU8ZioeCwsb0HUdZWVl5iSj2DkWbfE9FlwVqn/iciVhmKt4zFQO5ioeM5WDuYrHTOVgYWE33virb3u53CwRERERJQEWFnbTefK2i0OhiIiIiCjxkr6w2LVrF37wgx9g9OjR8Hq9OOSQQ/Dpp59atxuGgVtvvRX5+fnwer2YN28eysrK4h6jrq4OixYtQnp6OjIzM3HZZZehubl5qJsiRufJ2+yxICIiIqIkkNSFRX19PY477ji4XC689tpr2LBhA377298iK6tjnsG9996Lhx56CI899hhWr14Nn8+H+fPnIxAIWPdZtGgR1q9fjxUrVuDll1/G+++/jyuuuCIRTRoQVVVRUlJirlzQqccilZO3BywuVxKGuYrHTOVgruIxUzmYq3jMVI6kng5/zz33oLCwEMuWLbP2FRUVWduGYeDBBx/EzTffjLPOOgsA8OSTTyI3NxfPP/88LrjgAmzcuBGvv/461qxZgyOPPBIA8PDDD+P000/H/fffj7Fjxw5towYoEonA7XYDKZkdO9vqkcKhUINi5UpCMVfxmKkczFU8ZioHcxWPmYqX1IXFiy++iPnz5+O8887De++9h3HjxuGnP/0pLr/8cgBARUUFqqurMW/ePOt3MjIyMGvWLKxatQoXXHABVq1ahczMTKuoAIB58+ZBVVWsXr0a55xzTpe/GwwGEQwGrZ+bmpoAAJqmQdPMN++KokBVVei6DsMwrPv2tF9VVSiK0uP+6OPG7gfMVQs0TUN5eTkmT54Ml8sFeNKhBJtgtNbB41Cs32kNRuIeJ3oshmHErXrQ32OX0aa+7Hc4HD0eu4g2GYaBrVu3YtKkSXA4HMOiTclwnjRNw9atW1FaWmodj93bFHssiThPuq5brwGxz1U7tykZzlPsczX6mmD3Ng1kv8g2xf5/FX2u2r1N3e0f6jb19ly1a5tijz0R56nzc3U4tEnWeYrdPpCkLiy2bt2KRx99FD//+c/xX//1X1izZg2uueYauN1uXHLJJaiurgYA5Obmxv1ebm6udVt1dTVycnLibnc6nRg1apR1n87uvvtuLF26tMv+8vJy+P1+AGYBk5+fj5qaGjQ2Nlr3yc7ORnZ2Nnbt2oWWlhZrf15eHjIzM7Ft2zaEQiFrf0FBAfx+P8rLy+OeDEVFRXA6ndZSaHV1ddiyZQsOOuggqN4sINgEvXkv9lbttH5nf1swbn6J2+1GcXExGhsb49rq8/lQWFiIuro61NbWWvuHsk2xSkpKEIlEUFFRYe1TVRWlpaVoaWnBzp0dbRTZpqysLDQ1NWHLli3WP2C7tykZzpOu69ZxDZc2AYk9T16vF/X19XHPVbu3KRnOk67raG1tBYBh0yYgsecpFApZ/1+pqjos2pQM50nXdasdw6VNQGLPU1NTU9xzdTi0SdZ5Sk1NRV8pRn/KkCHmdrtx5JFHYuXKlda+a665BmvWrMGqVauwcuVKHHfccdi9ezfy8/Ot+yxcuBCKouCZZ57BXXfdhSeeeAKbNm2Ke+ycnBwsXboUV111VZe/212PRfTEpKenAxj6HostW7Z09Fj8+WQouz+HAQXbrtqGk373EQDguzPz8buFM7scy3D8pEFUj8XmzZvZYyGhx6K8vJw9FoJ7LDZt2sQeCwk9FtHnKnssxPVYbN68mT0WEnosenqu2rVNsceeiPMUiUTinqvDoU2yzlNzczMyMzPR2NhovQ/uSVL3WOTn52PatGlx+6ZOnYr//d//BWBWhYD5SVNsYVFTU4NDDz3Uus+ePXviHiMSiaCurs76/c48Hg88Hk+X/Q6Hw3qhjIqe+M76u7/z43be73Q6rSd+dAK3AgN+pdW6b2tI7/ZxFEXpdr+oYx9om/qyv6djF9EmTdOsc9rX85rsbRrIfhltim4PpzYdaL/sNkVfAzr/bTu3KRnOU+dC7UD3P9D+ZGiT6P39Pfbunqt2blNP+4e6TQd6rtqxTQfaL7tN3T1X7d4mGedJUZRu79ft7/b5nglw3HHHdelp2Lx5MyZMmADA7D7Ky8vD22+/bd3e1NSE1atXY/bs2QCA2bNno6GhAZ999pl1n//85z/QdR2zZs0aglYMnsPhQGlpaceTJWbJ2VRtv7Ud4OTtfumSKwnBXMVjpnIwV/GYqRzMVTxmKkdSFxbXXXcdPv74Y9x1113YsmULnn76aTz++ONYvHgxALOCuvbaa/HrX/8aL774ItatW4eLL74YY8eOxdlnnw3A7OE49dRTcfnll+OTTz7BRx99hCVLluCCCy6wzYpQhmGgubm5o1vK27HcrifUYG23hiJDfGT21iVXEoK5isdM5WCu4jFTOZireMxUjqQuLI466ig899xz+Oc//4mDDz4Yd9xxBx588EEsWrTIus8vf/lLXH311bjiiitw1FFHobm5Ga+//jpSUlKs+zz11FOYMmUK5s6di9NPPx3HH388Hn/88UQ0aUB0XcfOnTs7xs3FXMvCGWyA22Gexraw3t2vUw+65EpCMFfxmKkczFU8ZioHcxWPmcqR1HMsAOA73/kOvvOd7/R4u6IouP3223H77bf3eJ9Ro0bh6aeflnF4idHl6tujEWrTORSKiIiIiBImqXssqAedrr7tbb9IHodCEREREVGisLCwAUVR4Ha7O2blx8yxQFs9Ut1mYdEWYo9Ff3TJlYRgruIxUzmYq3jMVA7mKh4zlSPph0KRuexXcXFxx47YwqK1DintPRYBzrHoly65khDMVTxmKgdzFY+ZysFcxWOmcrDHwgYMw0BDQ0PHygWdh0K191iENB0RjcVFX3XJlYRgruIxUzmYq3jMVA7mKh4zlYOFhQ3ouo7q6uqOlQs6Td6ODoUCgDZO4O6zLrmSEMxVPGYqB3MVj5nKwVzFY6ZysLCwI08aoLaPYmvrGAoFsLAgIiIiosRgYWFHitLRa9Fab60KBXACNxERERElBgsLG1AUBT6fL37lgug8i5hVoQD2WPRHt7nSoDFX8ZipHMxVPGYqB3MVj5nKwVWhbEBVVRQWFsbvjK4MFW6Bz9FRTLSyx6LPus2VBo25isdM5WCu4jFTOZireMxUDvZY2ICu66itrY2fYBQzgXuU2mxtB1hY9Fm3udKgMVfxmKkczFU8ZioHcxWPmcrBwsIGDMNAbW1t/JJoqR3XsshCR2HBoVB9122uNGjMVTxmKgdzFY+ZysFcxWOmcrCwsKuYHosM7Le2ORSKiIiIiBKBhYVdxVwkL83oKCzYY0FEREREicDCwgYURUFGRkb8ygXejqFQaXpHYbE/EBnKQ7O1bnOlQWOu4jFTOZireMxUDuYqHjOVg6tC2YCqqsjPz4/fGTMUKkvpmGOxpykwVIdle93mSoPGXMVjpnIwV/GYqRzMVTxmKgd7LGxA13VUVVXFr1wQMxQqM2aORTULiz7rNlcaNOYqHjOVg7mKx0zlYK7iMVM5WFjYgGEYaGxsjF+5IKbHwqc3WdvVjSws+qrbXGnQmKt4zFQO5ioeM5WDuYrHTOVgYWFXMT0WrmAj0jzmqLYa9lgQERERUQKwsLCrmMnbaKtDbkYKAKCqMcDqm4iIiIiGHAsLG1AUBdnZ2fErFzg9gMtnbrfWIS/dLCyCER2NbeEEHKX9dJsrDRpzFY+ZysFcxWOmcjBX8ZipHAMqLCorK7Fz507r508++QTXXnstHn/8cWEHRh1UVUV2djZUtdPpig6HaqtDXnuPBcAJ3H3VY640KMxVPGYqB3MVj5nKwVzFY6ZyDCjN73//+3jnnXcAANXV1fj2t7+NTz75BDfddBNuv/12oQdI5soFlZWVXVcuiA6HaqtHXprH2s0J3H3TY640KMxVPGYqB3MVj5nKwVzFY6ZyDKiw+Prrr3H00UcDAJ599lkcfPDBWLlyJZ566iksX75c5PERzJULWlpaus6diPZY6BEU+DoujMcJ3H3TY640KMxVPGYqB3MVj5nKwVzFY6ZyDKiwCIfD8HjMT8jfeustfPe73wUATJkyBVVVVeKOjnoXM4F7nKejmKhijwURERERDbEBFRbTp0/HY489hg8++AArVqzAqaeeCgDYvXs3Ro8eLfQAqRcx17LId7da2+yxICIiIqKhNqDC4p577sGf/vQnzJkzBxdeeCFmzpwJAHjxxRetIVIkjqqqyMvL63nyNoBsR4u1zTkWfdNjrjQozFU8ZioHcxWPmcrBXMVjpnI4B/JLc+bMQW1tLZqampCV1TEc54orrkBqaqqwgyOToijIzMzsekNMj0W6vh8uhx9hzUB1U3DoDs7GesyVBoW5isdM5WCu4jFTOZireMxUjgGVaW1tbQgGg1ZRsX37djz44IPYtGkTcnJyhB4gmSsXbN26tevKBTE9FmqgHjlp5pKzHArVNz3mSoPCXMVjpnIwV/GYqRzMVTxmKseACouzzjoLTz75JACgoaEBs2bNwm9/+1ucffbZePTRR4UeIJkrF4RCoa4rF8T0WKCtHrnp5oT6upYQAmFtCI/QnnrMlQaFuYrHTOVgruIxUzmYq3jMVI4BFRaff/45TjjhBADA//zP/yA3Nxfbt2/Hk08+iYceekjoAVIvYlaFQmsd8jO81o97OByKiIiIiIbQgAqL1tZWpKWlAQDefPNNnHvuuVBVFccccwy2b98u9ACpF6mxPRZ1yE3n1beJiIiIKDEGVFhMnjwZzz//PCorK/HGG2/glFNOAQDs2bMH6enpQg+QzJULCgoKuq5c0KnHIi8j5urbLCwOqMdcaVCYq3jMVA7mKh4zlYO5isdM5RhQmrfeeit+8YtfYOLEiTj66KMxe/ZsAGbvxWGHHSb0AMlcucDv90NRlPgbUjIBpf0Udu6xaGwbugO0qR5zpUFhruIxUzmYq3jMVA7mKh4zlWNAhcX3vvc97NixA59++ineeOMNa//cuXPxu9/9TtjBkUnTNGzevBma1mlCtqqaxQUAtNXHzbGobuQciwPpMVcaFOYqHjOVg7mKx0zlYK7iMVM5BnQdCwDIy8tDXl4edu7cCQAoKCjgxfEk6nE5NG8W0FYHtNYjL6bHgkvO9g2XmZODuYrHTOVgruIxUzmYq3jMVLwB9Vjouo7bb78dGRkZmDBhAiZMmIDMzEzccccdPElDLTqBO9iIHL/D2s05FkREREQ0lAbUY3HTTTfhr3/9K37zm9/guOOOAwB8+OGHuO222xAIBHDnnXcKPUjqRcy1LFLCTchKdaG+NYzqRhYWRERERDR0BlRYPPHEE/jLX/6C7373u9a+GTNmYNy4cfjpT3/KwkIwVVVRVFTU/coF3Sw5W98aRk1TALpuQFU5KaknveZKA8ZcxWOmcjBX8ZipHMxVPGYqx4DSrKurw5QpU7rsnzJlCurq6gZ9UNSV09lDDRh79e3WOuRnmPMsIrqBfS2hITgye+sxVxoU5ioeM5WDuYrHTOVgruIxU/EGVFjMnDkTjzzySJf9jzzyCGbMmDHog6J4uq6jrKys+/krsdeyaKtHXgYncPdVr7nSgDFX8ZipHMxVPGYqB3MVj5nKMaBS7d5778UZZ5yBt956y7qGxapVq1BZWYlXX31V6AHSAaTGFhZ1yE2fbP1Y3RjAweMyEnBQRERERDTSDKjH4lvf+hY2b96Mc845Bw0NDWhoaMC5556L9evX4+9//7voY6TedBoKFbvkbBV7LIiIiIhoiAx4cNnYsWO7TNL+8ssv8de//hWPP/74oA+M+qjT5O287JihUFwZioiIiIiGCKfC24CqqigpKel+5YLOPRYxcyx4LYve9ZorDRhzFY+ZysFcxWOmcjBX8ZipHEzTJiKRSPc3dJ68zatv90uPudKgMFfxmKkczFU8ZioHcxWPmYrHwsIGdF1HRUVF9ysXxA2FqkeG1wWP0zytvEhe73rNlQaMuYrHTOVgruIxUzmYq3jMVI5+zbE499xze729oaFhMMdCA+FKBRweQAsCrXVQFAV5GSnYvq+VhQURERERDZl+FRYZGb0vXZqRkYGLL754UAdE/aQoZq/F/iqgzbw4YV66WVjsD0bQEozA5+EFYIiIiIhIrn6941y2bJms46AD6HVykbe9sGitAwyjywTuSWP8Q3CE9sRJW3IwV/GYqRzMVTxmKgdzFY+ZisePsm3A4XCgtLS05ztE51loQSDcFj+Bu5GFRU8OmCsNCHMVj5nKwVzFY6ZyMFfxmKkcLNVswDAMNDc3wzCM7u/gzezYbqtDbjqXnO2LA+ZKA8JcxWOmcjBX8ZipHMxVPGYqBwsLG9B1HTt37ux55YJO17LIjxkKVcUJ3D06YK40IMxVPGYqB3MVj5nKwVzFY6ZysLAYDjpdfTs3g9eyICIiIqKhxcJiOOh89e3YoVDssSAiIiKiIcDCwgYURYHb7YaiKN3fIbbHonUfxqR5EL0reyx6dsBcaUCYq3jMVA7mKh4zlYO5isdM5eCqUDagqiqKi4t7vkP62I7txp1wOVRk+z3Yuz/IORa9OGCuNCDMVTxmKgdzFY+ZysFcxWOmcrDHwgYMw0BDQ0PPKxdkjO/YbqwEAGsCd21zEBGNE5O6c8BcaUCYq3jMVA7mKh4zlYO5isdM5WBhYQO6rqO6urrnlQsyCjq2G3YAgLXkrG4Ae5uDsg/Rlg6YKw0IcxWPmcrBXMVjpnIwV/GYqRwsLIYDVwrgzzW3G8weC07gJiIiIqKhxMJiuMhsHw7VXA2EA8jjkrNERERENIRYWNiAoijw+Xy9r1yQUdix3bQrrseCE7i716dcqd+Yq3jMVA7mKh4zlYO5isdM5eCqUDagqioKCwt7v1NmzATuhu3Iy5hh/VjNHotu9SlX6jfmKh4zlYO5isdM5WCu4jFTOdhjYQO6rqO2trb3CUZxhcUOa/I2ANSwx6JbfcqV+o25isdM5WCu4jFTOZireMxUDhYWNmAYBmpra3tfEi2usKiMm2PBHovu9SlX6jfmKh4zlYO5isdM5WCu4jFTOVhYDBedeiz8Hif8HnOkG1eFIiIiIiLZWFgMF7HXsmi/SF6016K6KcCKnIiIiIikYmFhA4qiICMjo/eVC9w+IDXb3G6/SF50ZahAWEdTW0T2YdpOn3KlfmOu4jFTOZireMxUDuYqHjOVg4WFDaiqivz8fKjqAU5XZvvqBvurgEgobgI351l01edcqV+Yq3jMVA7mKh4zlYO5isdM5WCaNqDrOqqqqg68ckF0noWhm9eyyPBYN7Gw6KrPuVK/MFfxmKkczFU8ZioHcxWPmcrBwsIGDMNAY2PjgedJdJrAnZfhtX6sbmyTdHT21edcqV+Yq3jMVA7mKh4zlYO5isdM5WBhMZxkxBQWjZVxV9+ubgwm4ICIiIiIaKRgYTGcdO6x4BwLIiIiIhoiLCxsQFEUZGdnH3jlgsyYS9M3VCI3Zo5FDQuLLvqcK/ULcxWPmcrBXMVjpnIwV/GYqRzORB8AHZiqqsjOzj7wHTNiC4sdyPZ54FQVRHSDF8nrRp9zpX5hruIxUzmYq3jMVA7mKh4zlYM9Fjag6zoqKysPvHJBSjqQkmluN+6AqirWkrMcCtVVn3OlfmGu4jFTOZireMxUDuYqHjOVg4WFDRiGgZaWlr6tXBCdZ9G4C9AiyE03h0PVtYQQjGgSj9J++pUr9RlzFY+ZysFcxWOmcjBX8ZipHCwshhvrWhYasL8KeRkdE7j3NHFlKCIiIiKSg4XFcNNpZShefZuIiIiIhgILCxtQVRV5eXl9u+x8p8IiP6bHoooTuOP0K1fqM+YqHjOVg7mKx0zlYK7iMVM5bJXmb37zGyiKgmuvvdbaFwgEsHjxYowePRp+vx8LFixATU1N3O/t2LEDZ5xxBlJTU5GTk4Prr78ekUhkiI9+4BRFQWZmZt+WRItdGaqxMq7HooaFRZx+5Up9xlzFY6ZyMFfxmKkczFU8ZiqHbQqLNWvW4E9/+hNmzJgRt/+6667DSy+9hH//+9947733sHv3bpx77rnW7Zqm4YwzzkAoFMLKlSvxxBNPYPny5bj11luHugkDpus6tm7d2reVC+J6LLbzInm96Feu1GfMVTxmKgdzFY+ZysFcxWOmctiisGhubsaiRYvw5z//GVlZWdb+xsZG/PWvf8UDDzyAk08+GUcccQSWLVuGlStX4uOPPwYAvPnmm9iwYQP+8Y9/4NBDD8Vpp52GO+64A3/4wx8QCoUS1aR+MQwDoVCoj6tCxV8kL3byNguLeP3KlfqMuYrHTOVgruIxUzmYq3jMVA5bFBaLFy/GGWecgXnz5sXt/+yzzxAOh+P2T5kyBePHj8eqVasAAKtWrcIhhxyC3Nxc6z7z589HU1MT1q9fPzQNGEopmYAn3dzuNHmbQ6GIiIiISJakv/L2v/71L3z++edYs2ZNl9uqq6vhdruRmZkZtz83NxfV1dXWfWKLiujt0du6EwwGEQx2LM3a1NQEwBxWpWnmtSAURYGqqtB1Pa7a7Wm/qqpQFKXH/dHHjd0PmF11mqZZ32P3x3I4HDAMA7quQ80ogLJnA4zGnUhxKMhKdaG+NYyqxjZomtbvY5fRpr7sj21T52PpaX9/2gSYn1jEHqfd25QM50nTNOvvDJc2xR5LItoUPcbOz1U7tykZzlPsc3W4tGkg+0W2KXqMsb9j9zZ1t3+o29Tbc9WubYo99kS2aaDv65K5TQM99p7296dXJ6kLi8rKSvzsZz/DihUrkJKScuBfEOTuu+/G0qVLu+wvLy+H3+8HAGRkZCA/Px81NTVobGy07pOdnY3s7Gzs2rULLS0t1v68vDxkZmZi27ZtcUOwCgoK4Pf7UV5eHvdkKCoqgtPpRFlZGQzDQCQSQXl5OUpLSxGJRFBRUWHdV1VVlJaWoqWlBTt37sQ452ikAVD0MNBcjTE+s7CoaQpg0+bNSPP7UVhYiLq6OtTW1lqPM5RtilVSUnLANkW53W4UFxejsbExrjD0+Xz9btPo0aPhdDpRXl5uFRp2b1MynKfoC5CqqsOmTUBiz5PP54Ou63HPVbu3KRnOk2EYSElJgaqqqK6uHhZtAhJ/nqL/X0XfpAyHNiX6PBmGgYyMDKiqioqKimHRJiCx52n//v1xz9Xh0CZZ5yk1NRV9pRhJPLjs+eefxznnnAOHw2Hti/3E/Y033sC8efNQX18f12sxYcIEXHvttbjuuutw66234sUXX8TatWut2ysqKlBcXIzPP/8chx12WJe/212PRfTEpKebw4ySuYJVXv8V1DWPmzf86A1c+paKdzfvBQCsvvEkjElLYVXONrFNbBPbxDaxTWwT28Q2HXB/c3MzMjMz0djYaL0P7klS91jMnTsX69ati9v3wx/+EFOmTMENN9yAwsJCuFwuvP3221iwYAEAYNOmTdixYwdmz54NAJg9ezbuvPNO7NmzBzk5OQCAFStWID09HdOmTev273o8Hng8ni77HQ5HXJEDdJz4zvq7v/Pjxu7XNA3l5eWYNGmS9Wlld/dXFMXcnxW7MlQl8jIOsn7c2xxGbkaq0GMfSJv6ut9qUx/39+cYY3Pt63lN9jYNZL/oNmmahi1btli5Doc29WW/zDb19ly1a5t6Osb+7h9Mmzo/V/tz7MnaJhn7+3PsPT1X7dymnvYPZZs0TUNZWVmvz1W7takv+2W2KdoL3DlTO7dJ1nmKvvfsi6QuLNLS0nDwwQfH7fP5fBg9erS1/7LLLsPPf/5zjBo1Cunp6bj66qsxe/ZsHHPMMQCAU045BdOmTcNFF12Ee++9F9XV1bj55puxePHibouHZNW5Yu1V5yVnM2ZaP9Y0BXDwuAyBR2Zv/cqV+oy5isdM5WCu4jFTOZireMxUvKQuLPrid7/7HVRVxYIFCxAMBjF//nz88Y9/tG53OBx4+eWXcdVVV2H27Nnw+Xy45JJLcPvttyfwqCXrdJG8vFxefZuIiIiI5LJdYfHuu+/G/ZySkoI//OEP+MMf/tDj70yYMAGvvvqq5CNLIpkTOrYbdiC3NGbJWV7LgoiIiIgksMV1LEY6VVVRVFTU41i4LlJHAa72GfwNlfFX32aPhaXfuVKfMFfxmKkczFU8ZioHcxWPmcrBNG3C6exH55KidMyzaKxEfnrHXBJefTtev3KlPmOu4jFTOZireMxUDuYqHjMVj4WFDei6jrKysv5NMorOs4gEkKHXw+M0TzV7LDoMKFc6IOYqHjOVg7mKx0zlYK7iMVM5WFgMVzErQymNO5GXYQ6Hqm4M9OsKikREREREfcHCYrjqtOTshNE+AMD+YITDoYiIiIhIOBYWw1VmzJKzDZWYlt9xpcQNu5sScEBERERENJyxsLABVVVRUlLSv5ULOi05O30sC4vOBpQrHRBzFY+ZysFcxWOmcjBX8ZipHEzTJiKRSP9+odNF8qbFFBbrWVhY+p0r9QlzFY+ZysFcxWOmcjBX8ZipeCwsbEDXdVRUVPRv5QJ/DuBsv35Fww5MHO2D1+UAAGyoYmEBDDBXOiDmKh4zlYO5isdM5WCu4jFTOVhYDFeKAmQUmNsNlXAowJT8NADAjrpWNAXCCTw4IiIiIhpuWFgMZ9GVocItQGtd3DyLjRwORUREREQCsbCwiQFNLuq05Oy0/AzrRw6HMnHSlhzMVTxmKgdzFY+ZysFcxWOm4vFa5jbgcDhQWlra/1/sMoG72PqRK0MNIlfqFXMVj5nKwVzFY6ZyMFfxmKkcLNVswDAMNDc39/+K2Z2WnJ2SlwZVMX9kj8UgcqVeMVfxmKkczFU8ZioHcxWPmcrBwsIGdF3Hzp07+79yQaeL5KW4HJg0xg8A2FyzH6HIyF4JYcC5Uq+Yq3jMVA7mKh4zlYO5isdM5WBhMZzFzbHYAQDW9SzCmoEte5oTcVRERERENAyxsBjO/HmA6jK3GysBIP4K3BwORURERESCsLCwAUVR4Ha7oShK/35RVWOuZbEDMIy4laHW724UeJT2M+BcqVfMVTxmKgdzFY+ZysFcxWOmcrCwsAFVVVFcXDy4JWeDTUCgAVPbL5IHcGWoQeVKPWKu4jFTOZireMxUDuYqHjOVg2nagGEYaGhoGNjKBZ0mcI/2e5CXngLAHAo1kldDGFSu1CPmKh4zlYO5isdM5WCu4jFTOVhY2ICu66iurh7YygWdlpwFOuZZ7A9EsLO+TcQh2tKgcqUeMVfxmKkczFU8ZioHcxWPmcrBwmK463SRPKBjZSgAWD/Ch0MRERERkRgsLIa77paczefKUEREREQkFgsLG1AUBT6fb2ArF8TNsYgOhepYGWokT+AeVK7UI+YqHjOVg7mKx0zlYK7iMVM5nIk+ADowVVVRWFh44Dt2J20soDgAQ7MKi4IsL9I8TuwPRrBhBC85O6hcqUfMVTxmKgdzFY+ZysFcxWOmcrDHwgZ0XUdtbe3AJhg5nED6OHO7fY6FqiqY2j4candjAPUtIVGHaiuDypV6xFzFY6ZyMFfxmKkczFU8ZioHCwsbMAwDtbW1A18SLTrPoq0eCJhDn2IncG8cofMsBp0rdYu5isdM5WCu4jFTOZireMxUDhYWI0HsBG6uDEVEREREErCwGAk6XSQP4MpQRERERCQWCwsbUBQFGRkZA1+5oJslZ0ty/XCq5uON1JWhBp0rdYu5isdM5WCu4jFTOZireMxUDhYWNqCqKvLz86GqAzxdcRfJMwsLj9OBktw0AMCWvc0IhLXBHqbtDDpX6hZzFY+ZysFcxWOmcjBX8ZipHEzTBnRdR1VV1cBXLuimxwLoGA6l6QY21+wfzCHa0qBzpW4xV/GYqRzMVTxmKgdzFY+ZysHCwgYMw0BjY+PAVy5IHwegvauvfY4FED+BeyQOhxp0rtQt5ioeM5WDuYrHTOVgruIxUzlYWIwETjeQPtbcbthu7Z4+lhO4iYiIiEgMFhYjxehJ5vfWfUBTFQBYF8kDuOQsEREREQ0OCwsbUBQF2dnZg1u5YOzhHdu7PgMAZHhdKMjyAjAvkqfrI6s7UEiu1AVzFY+ZysFcxWOmcjBX8ZipHCwsbEBVVWRnZw9u5YJxR3RstxcWQMdwqNaQhu11rQN/fBsSkit1wVzFY6ZyMFfxmKkczFU8ZioH07QBXddRWVk5uJULCo7s2I4pLKblZ1jbI20Ct5BcqQvmKh4zlYO5isdM5WCu4jFTOVhY2IBhGGhpaRncygXpY4G0fHN79xdA+z+k2JWh1u9uHMxh2o6QXKkL5ioeM5WDuYrHTOVgruIxUzlYWIwk0eFQwSZgXxmATkvOcmUoIiIiIhogFhYjSTfzLMZmpCAz1QVg5A2FIiIiIiJxWFjYgKqqyMvLG/wEo24KC0VRrCtw79kfxN79wcH9DRsRlivFYa7iMVM5mKt4zFQO5ioeM5WDadqAoijIzMwc/JJoYw+DdQXunZ9au6flj8zhUMJypTjMVTxmKgdzFY+ZysFcxWOmcrCwsAFd17F169bBr1yQkg6MOcjcrvkaCAcAANPHxRQWI2g4lLBcKQ5zFY+ZysFcxWOmcjBX8ZipHCwsbMAwDIRCITErF0SHQ+kRoHodgE5Lzo6gHguhuZKFuYrHTOVgruIxUzmYq3jMVA4WFiPNuNgrcJvDoYrH+OB2mk+FkbbkLBERERGJwcJipBnX9UJ5LoeKKXlpAICK2ha0hiKJODIiIiIisjEWFjagqioKCgrErFyQOx1weMztuCtwm/MsDAP4pnr/4P+ODQjNlSzMVTxmKgdzFY+ZysFcxWOmcjBNG1AUBX6/X8zKBQ4XkD/T3K7bCrTWAeh8Be6RMc9CaK5kYa7iMVM5mKt4zFQO5ioeM5WDhYUNaJqGzZs3Q9M0MQ9YEDsc6nMA8UvObhwhE7iF50oAmKsMzFQO5ioeM5WDuYrHTOVgYWETQpdD6+ZCeQe1z7EAgG9GSGEBCM6VLMxVPGYqB3MVj5nKwVzFY6bisbAYibpZGSotxYXCUV4AwKbq/dB1Lr9GRERERH3HwmIkyioCvKPM7V2fmTO2AUzJM4dDtYQ07KxvS9TREREREZENsbCwAVVVUVRUJG7lAkXpGA7Vug9o2A4AmBozHGpj9fAfDiU8VwLAXGVgpnIwV/GYqRzMVTxmKgfTtAmn0yn2AWPnWew0h0NNiZnA/U3VyFhyVniuBIC5ysBM5WCu4jFTOZireMxUPBYWNqDrOsrKysROMupmZagpsRO4R0CPhZRciblKwEzlYK7iMVM5mKt4zFQOFhYj1djYCdzmylATRvuQ4jKfEiNlyVkiIiIiEoOFxUjlGw1kTTS3q9YCWhgOVcFBuWavxfa6VrQEIwk7PCIiIiKyFxYWI1l0nkUkAOzZAKBjZSjDADbXjIx5FkREREQ0eCwsbEBVVZSUlIhfuWBc7DwLczjU1PzYeRbDu7CQlusIx1zFY6ZyMFfxmKkczFU8ZioH07SJSETCsKS4laHMwiJ+ZajhP89CSq7EXCVgpnIwV/GYqRzMVTxmKh4LCxvQdR0VFRXiVy7InwGo7UuttfdYTIm7lsXw7rGQlusIx1zFY6ZyMFfxmKkczFU8ZioHC4uRzOUFcqeb23u/AYL7kZnqRn5GCgCzx8Jovyo3EREREVFvWFiMdNZwKAPYvRZAR69FUyCCqsZAYo6LiIiIiGyFhYVNSJtcFDvPYlfXK3AP9+tZcNKWHMxVPGYqB3MVj5nKwVzFY6biMVEbcDgcKC0thcPhEP/g3awMFX8F7uE7z0JqriMYcxWPmcrBXMVjpnIwV/GYqRwsLGzAMAw0NzfLme+QXQK42wuJXZ8DAKaOkB4LqbmOYMxVPGYqB3MVj5nKwVzFY6ZysLCwAV3XsXPnTjkrF6gOYOyh5nbTLqCpCkXZPrgd5lNjOPdYSM11BGOu4jFTOZireMxUDuYqHjOVg4UFAQXxw6FcDhUluX4AwNa9zQiEtQQdGBERERHZBQsL6jSBOzrPwhwOpRvAlj3NiTgqIiIiIrIRFhY2oCgK3G43FEWR8we6WRlqan7MhfKG6TwL6bmOUMxVPGYqB3MVj5nKwVzFY6ZyOBN9AHRgqqqiuLhY3h9IHwukjQX27wZ2fQHoutVjAQzfeRbScx2hmKt4zFQO5ioeM5WDuYrHTOVgj4UNGIaBhoYGuSsXjDvc/B7aD+wrw5QR0GMxJLmOQMxVPGYqB3MVj5nKwVzFY6ZysLCwAV3XUV1dLXflgtjhUDs/Rbbfg2y/B4BZWAzHf3hDkusIxFzFY6ZyMFfxmKkczFU8ZioHCwsyxRYWu6PXszB7Lepbw9i7P5iIoyIiIiIim2BhQab8mR3bVV8BiL8C98ZhOs+CiIiIiMRgYWEDiqLA5/PJXbnAmwlkTTS3q9cBuhY/gXsYzrMYklxHIOYqHjOVg7mKx0zlYK7iMVM5WFjYgKqqKCwshKpKPl3RXotIG1Bbhqn5w3tlqCHLdYRhruIxUzmYq3jMVA7mKh4zlYNp2oCu66itrZU/wSj/0I7tqi8xKccHp2pW8sNxZaghy3WEYa7iMVM5mKt4zFQO5ioeM5UjqQuLu+++G0cddRTS0tKQk5ODs88+G5s2bYq7TyAQwOLFizF69Gj4/X4sWLAANTU1cffZsWMHzjjjDKSmpiInJwfXX389IpHIUDZlUAzDQG1trfyVmeLmWXwJj9OBSWP8AIDyvc0IRYbXP74hy3WEYa7iMVM5mKt4zFQO5ioeM5UjqQuL9957D4sXL8bHH3+MFStWIBwO45RTTkFLS4t1n+uuuw4vvfQS/v3vf+O9997D7t27ce6551q3a5qGM844A6FQCCtXrsQTTzyB5cuX49Zbb01Ek5JbXGGxFgCs61mENQPle5sTcFBEREREZAdJfeXt119/Pe7n5cuXIycnB5999hlOPPFENDY24q9//SuefvppnHzyyQCAZcuWYerUqfj4449xzDHH4M0338SGDRvw1ltvITc3F4ceeijuuOMO3HDDDbjtttvgdrsT0bTk5MsG0guApp3mylDtV+B+AbsBAN9UN8XNuyAiIiIiikrqHovOGhsbAQCjRo0CAHz22WcIh8OYN2+edZ8pU6Zg/PjxWLVqFQBg1apVOOSQQ5Cbm2vdZ/78+WhqasL69euH8OgHTlEUZGRkDM3KBdFei9B+oL4i7grc31QNrwncQ5rrCMJcxWOmcjBX8ZipHMxVPGYqR1L3WMTSdR3XXnstjjvuOBx88MEAgOrqarjdbmRmZsbdNzc3F9XV1dZ9YouK6O3R27oTDAYRDHZcEK6pyZy4rGkaNE0DYD4hVVWFrutx4/N62q+qKhRF6XF/9HFj90fbDQA5OTkwDMP63c6TjRwOBwzDiNsfPZae9nd77PkzgU2vmH9j1+coLTjdun1jVVPccQ62TQfaL6xNvezPzc2FYRjWsQ6HNol+7g2kTbm5ucOuTYk8T6qqWq8Bsc9VO7cpWc5T9Lk6nNqUyPOkKEqX56rd29Td/kS0KS8vb9i1KZHnqfNzdTi0SdZ56s88FNsUFosXL8bXX3+NDz/8UPrfuvvuu7F06dIu+8vLy+H3m5OZMzIykJ+fj5qaGqsnBQCys7ORnZ2NXbt2xc0FycvLQ2ZmJrZt24ZQKGTtLygogN/vR3l5edyToaioCE6nE2VlZTAMA83NzfD7/SgtLUUkEkFFRYV1X1VVUVpaipaWFuzcudPa73a7UVxcjMbGxrgiyufzobCwEHV1daitrbX2m23qmGdRv+E9NLkORkaKE42BCNbvakBZWZmQNsUqKSmR3Kbuz9OoUaOwfv16OJ1O6xMLu7dJ9HNvIG0yDAPBYBAzZsxAU1PTsGgTkNjzlJqairVr1yI1NdV6rtq9TclwnqIf1kyZMmXYtAlI7HkKhUL4+uuv4ff7rTcpdm9TMpwnwzDgcrlQXFw8bNoEJPY81dfXW+/rote0sHubZJ2n1NRU9JVi2GA6/JIlS/DCCy/g/fffR1FRkbX/P//5D+bOnYv6+vq4XosJEybg2muvxXXXXYdbb70VL774ItauXWvdXlFRgeLiYnz++ec47LDDuvy97nosoicmPd2cYzCUFaymadiyZQsmT54Ml8tl7Y8lrIJtrgEemAIAMIq+Bf0Hz2HRXz7BxxV1AIBP/utkjPa5B92mvuyXXZUbhoHNmzdj0qRJcDgcw6JNyfDpiaZpKC8vR2lpqXU8dm9T7LEk4jzpuo5NmzZh8uTJcc9VO7cpGc5T7HM1+ppg9zYNZL/INmmahs2bN8c9V+3epu72D3Wbenuu2rVNsceeiPMUiUTinqvDoU2yzlNzczMyMzPR2NhovQ/uSVL3WBiGgauvvhrPPfcc3n333biiAgCOOOIIuFwuvP3221iwYAEAYNOmTdixYwdmz54NAJg9ezbuvPNO7NmzBzk5OQCAFStWID09HdOmTev273o8Hng8ni77HQ6H9UIZFT3xnfV3f+fH7bxfVVXrid/T/RVF6df+bo8lLQ/w5QAte6BUfwWHqmJKfrpVWGzZ04KcyV4hberLfiFt6mF/tOuzP+c12ds0kP0y2hR9ng6nNh1ov+w2RV8DOv9tO7cpGc5T9Lk6nNoken9/j72756qd29TT/qFu04Geq3Zs04H2y25Td89Vu7dJ5nOvL5J68vbixYvxj3/8A08//TTS0tJQXV2N6upqtLW1ATC7ci677DL8/Oc/xzvvvIPPPvsMP/zhDzF79mwcc8wxAIBTTjkF06ZNw0UXXYQvv/wSb7zxBm6++WYsXry42+JhxFOUjgncbfVAYyWmxawEtXEYXoGbiIiIiAYvqQuLRx99FI2NjZgzZw7y8/Otr2eeeca6z+9+9zt85zvfwYIFC3DiiSciLy8P//d//2fd7nA48PLLL8PhcGD27Nn4wQ9+gIsvvhi33357Ipo0IIqiIDs7u18V46CMPbRju+rLuJWhhtMVuIc81xGCuYrHTOVgruIxUzmYq3jMVA5bzLFItKamJmRkZPRpbNmwsPEl4JkfmNsnXo+242/E9P9+HboBHDwuHS9ffUJij4+IiIiIhkR/3gcndY8FmXRdR2VlZZcJPNLEXYH7S3jdDkzM9gEANtc0I6IN0XFINuS5jhDMVTxmKgdzFY+ZysFcxWOmcrCwsAHDMNDS0tKvdYQHJaMQ8GaZ21VfAgCm5pkVaiiiY9u+lp5+01aGPNcRgrmKx0zlYK7iMVM5mKt4zFQOFhbUVewE7uYaoKkKU/Ji51lwAjcRERERxWNhQd3rNBxqSszKUN9UD58J3EREREQkBgsLG1BVFXl5eT2uNyxF58Iipsfim2HSY5GQXEcA5ioeM5WDuYrHTOVgruIxUzmYpg0oioLMzMyhXRIt/9CO7aovUZDlRZrHvJ7iN8PkWhYJyXUEYK7iMVM5mKt4zFQO5ioeM5WDhYUN6LqOrVu3Du3KBVlFgLu9l6LqSyiKYl3PYldDG/Y1B4fuWCRJSK4jAHMVj5nKwVzFY6ZyMFfxmKkcLCxswDAMhEKhoV25QFWB/BnmdtNOoKUWh4/Psm5etXXf0B2LJAnJdQRgruIxUzmYq3jMVA7mKh4zlYOFBfWs03Co4yZnWz9+WFY79MdDREREREmLhQX1rNME7qMmjoLbYT5lPiirZZVPRERERBYWFjagqioKCgqGfuWCbq7AfeREczjUroY27KhrHdrjESxhuQ5zzFU8ZioHcxWPmcrBXMVjpnIwTRtQFAV+v3/oVy7ILgGcXnO7/QrcccOhtth7OFTCch3mmKt4zFQO5ioeM5WDuYrHTOVgYWEDmqZh8+bN0DRtaP+w6gDyDjG36yuAtgYcP4zmWSQs12GOuYrHTOVgruIxUzmYq3jMVA4WFjaRsOXQYodDVX+Fg8dlIMPrAgCsLN8HTbf3PAsuMycHcxWPmcrBXMVjpnIwV/GYqXgsLKh3neZZOFQFx04aDQBobAtj/e7GBB0YERERESUTFhbUu06FBTC85lkQERERkRgsLGxAVVUUFRUlZuWCMVMAh9vcbi8shss8i4TmOowxV/GYqRzMVTxmKgdzFY+ZysE0bcLpdCboD7uBnGnmdm0ZEGzGhNGpKMgyV4v6dFs92kL2nfiUsFyHOeYqHjOVg7mKx0zlYK7iMVPxWFjYgK7rKCsrS4IJ3AZQ8zUURbF6LUKajk+31yXmuAYp4bkOU8xVPGYqB3MVj5nKwVzFY6ZysLCgAxt7aMc251kQERERUTdYWNCBdTOBO7oyFGDveRZEREREJAYLCzqwnOmA4jC32wuL0X4Ppo9NBwCs392EupZQoo6OiIiIiJIACwsbUFUVJSUliVu5wJUC5Ew1t/dsBMIBAPGrQ60st1+vRcJzHaaYq3jMVA7mKh4zlYO5isdM5WCaNhGJRBJ7ANHhUIYG7FkPIH6exUc2nWeR8FyHKeYqHjOVg7mKx0zlYK7iMVPxWFjYgK7rqKioSOzKBd3Mszi6aBTcTvMp9EFZLQzDSMSRDVhS5DoMMVfxmKkczFU8ZioHcxWPmcrBwoL6Jraw2L0WAJDicuDICVkAgJ31bdhR15qAAyMiIiKiZMDCgvom92AAirnd3mMBcNlZIiIiIjKxsLCJhE8u8viB7BJze88GIGT2Thxv83kWCc91mGKu4jFTOZireMxUDuYqHjMVj4nagMPhQGlpKRwOR2IPpHCW+V0LAeueBQAcPC4DGV4XAOCjLfug6faZZ5E0uQ4zzFU8ZioHcxWPmcrBXMVjpnKwsLABwzDQ3Nyc+MnRR13Wsf3xo4BhwKEq1sXyGtvCWL+7MUEH139Jk+sww1zFY6ZyMFfxmKkczFU8ZioHCwsb0HUdO3fuTPzKBWMPA8bPNrf3fgNsfQeAfedZJE2uwwxzFY+ZysFcxWOmcjBX8ZipHCwsqH+Ouapj++NHAdh/ngURERERDR4LC+qfg84AMsab22VvArVlmDA6FQVZXgDAmm31CIS1BB4gERERESUCCwsbUBQFbrcbiqIk+lAAhxOYdUXHz6sfg6IoVq9FKKJjzba6BB1c/yRVrsMIcxWPmcrBXMVjpnIwV/GYqRwsLGxAVVUUFxcnz7Joh10EuHzm9tqngbZ6W86zSLpchwnmKh4zlYO5isdM5WCu4jFTOZimDRiGgYaGhuRZucCbCRy2yNwOtwKfPxlXWNhlnkXS5TpMMFfxmKkczFU8ZioHcxWPmcrBwsIGdF1HdXV1cq1cMOvKju3Vj2NUiorpY9MBAOt3N6GuJZSgA+u7pMx1GGCu4jFTOZireMxUDuYqHjOVg4UFDczoSUDJfHO7aSfwzUvWPAvDAFaW26PXgoiIiIjEYGFBA9dp6dnY4VCvrqtKwAERERERUaKwsLABRVHg8/mSb+WC4jnAmKnmduVqzHJXYLTPDQB47etqbK7Zn7hj64OkzdXmmKt4zFQO5ioeM5WDuYrHTOVgYWEDqqqisLAw+VYuUJS4XgvPZ4/jJ98qBmAOh/r922WJOrI+SdpcbY65isdM5WCu4jFTOZireMxUDqZpA7quo7a2NjknGM1YCHhHmdvrn8NF013I9pu9Fq+uq8Km6uTttUjqXG2MuYrHTOVgruIxUzmYq3jMVA4WFjZgGAZqa2uTc0k0lxc48kfmth6Bd+1y/OTESQDMXouH/pO8vRZJnauNMVfxmKkczFU8ZioHcxWPmcrBwoIG76gfA6rT3P50GX5wxBjb9FoQERERkRgsLGjw0vOB6eea22118H7zv7jyWzG9Fkk+14KIiIiIBo+FhQ0oioKMjIzkXrkgbunZx7Do6PHI9nsAAK+sq8I31U0JOrCe2SJXG2Ku4jFTOZireMxUDuYqHjOVg4WFDaiqivz8/OReuWDc4UDhMeb23o3w7nwfV7avEAUkZ6+FLXK1IeYqHjOVg7mKx0zlYK7iMVM5mKYN6LqOqqqq5F+5ILbX4t3fxPVavLquGhurkqvXwja52gxzFY+ZysFcxWOmcjBX8ZipHCwsbMAwDDQ2Nib/ygVTvgNkl5rblavh3fIyrpozybo52XotbJOrzTBX8ZipHMxVPGYqB3MVj5nKwcKCxHE4gW/f3vHzW/+NRUfkYkya2Wvx2tfJ12tBRERERGKwsCCxSk8FJp5gbtdvQ8oXf8NV3+rotfj9W8nVa0FEREREYrCwsAFFUZCdnW2PlQsUBZh/J4D2Y33/Xnz/ED9y2nstXl9fjQ27k6PXwla52ghzFY+ZysFcxWOmcjBX8ZipHCwsbEBVVWRnZ9tn5YL8mcCh3ze3A41IWfnbuLkWv397c4IOLJ7tcrUJ5ioeM5WDuYrHTOVgruIxUzmYpg3ouo7Kykp7rVxw8s2AK9XcXvNnfH9y2Oq1eGN9DdbvbkzgwZlsmasNMFfxmKkczFU8ZioHcxWPmcrBwsIGDMNAS0uLvVYuSB8LHHu1ua1H4HlnaXyvRRLMtbBlrjbAXMVjpnIwV/GYqRzMVTxmKgcLC5Ln2GsAf665/c3L+H7eTqvX4s0NNfjrhxUJPDgiIiIiEomFBcnj8ZtDoqI/vn0LfvHtEuvnO17egL+xuCAiIiIaFlhY2ICqqsjLy7PnBKNDFwG5B5vbu7/AQs/H+NncjuLi9pc3YNlHiSkubJ1rEmOu4jFTOZireMxUDuYqHjOVg2nagKIoyMzMtOeSaKoDOOWOjp/fvh3XzSnENTHFxdKXNmB5AooLW+eaxJireMxUDuYqHjOVg7mKx0zlYGFhA7quY+vWrfZduWDSycDkb5vbTTuBVX/AdfNK4oqL2xJQXNg+1yTFXMVjpnIwV/GYqRzMVTxmKgcLCxswDAOhUMjeKxeccgegtD/dPvwdlJa9ZnFx8mTrLre9tAFPrNw2ZIc0LHJNQsxVPGYqB3MVj5nKwVzFY6ZysLCgoZEzFTjiUnM71Az85w4oAK77dimujiku/vvF9Xhy1bZEHCERERERDQILCxo6c/4LcKeZ258/Cfz121C2voOfzyvBkpM6iotbX2BxQURERGQ3LCxsQFVVFBQU2H/lAv+YuOVnsXMN8PdzoCw/A/+vtAaLT+q4gN6tL6zHbS+uR21zUNrhDJtckwxzFY+ZysFcxWOmcjBX8ZipHIrBwWUH1NTUhIyMDDQ2NiI9PT3Rh2N/G18G3rkT2LMhbrdRdCKeTv0BbvrMb+3zuR247IRiXH5CEdJSXEN9pEREREQjWn/eB7NMswFN07B582ZompboQxFj6neAKz8CvrcMyC61disV72PR+ivw/tiHMctVDsBAS0jDQ2+X4cR738FfPtiKQFhcBsMu1yTBXMVjpnIwV/GYqRzMVTxmKocz0QdAfTPslkNTVeDgc4FpZwHr/gd47zdA3VYAwPi6VXjGsQqt7jSsCxdggz4eG4IT8Nyrm/H3Dybhp9+ejgWHF8DpGHxdPOxyTRLMVTxmKgdzFY+ZysFcxWOm4rGwoMRSHcDM84GDFwBf/Qt47x6gYQcAIFXbj1nqRsxSN1p3jwRVlL80Fu++UYzsg47DxNlnIbNgqrjj0TUg0AgEGoC2BkALA3mHAO5UcX+DiIiIaBhiYUHJweEEDvsBcMhC4Mt/AhtfAmq+BvZXxd3Nqeg4SNmJgyI7gfXvA+vvRpWaj+rcE+CffhqKjjwFzhR/D38EQGsdUL0OqF4HpXodCqu3QH031F5INALBJgCdph35coA5NwCHXwI4OM+DiIiIqDucvN0HiZ68Hb2Ii9vtHnmXnm/ZB9SsA6q/Bmq+RuuOtXDXl8GJSLd3D8CF8tTDECo6GQUzT0J2uBpKzdftxcTX5pW/B2rUJGDurebwrZF2HvphRD9fJWGmcjBX8ZipHMy1nRYG9n4D1KwHUjKAyd82P5gcAGbad/15H8zCog+SobDQdR2qqvLJD8CIBPH1F6ux96s3MLrqPUwLb4BLGfjkK0NxAN5MKCmZgDcTiP2+vwrY9Gr8L4w7Api3FCg6YeCNOOBBGeaQrP3V5jE07wE8fiBzApA5HkhJ3tXJpD9fGyqBNX8G9pUDo4qAMVPMr+zSpM5lMJLqNUCLDPg/8mSTVLkOE4POtOpL4IMHgIbtwJGXATMvHDbPt8EYkc/V4H6zgKj6Cqj+0vyAcM9GQAt13GfMFOCUXwMl3+73w4/ITAeIhYVgiS4sNE1DWVkZSkpK4HA4hvzvJ7uaPXuxZfXLQNkKTG5ahVzUdXu/JsOLjcYEbNAnYEP7921GHlqQArfDgZx0D/IzUpCX4TW/p6cgLyMFuY1fYfJX9yNjzydxj9cy/iQ0HncTUgpmIivVFf/CZBhAqMUsDoJNQKgVCMd+tZm3h9vMr0CDWUDsr+74irT13OiUTCCrvcjInGB++bLNq5oHmtrnicR8Bdv3edKB7BJgzEHmG/HsEiBjvDmZvi+iLxe9vAhLe77u+Qb46PfAumcBvfseK6SPM9sWLTScHjPnUIuZe+z3UIv5O5kTgNHFZo/U6ElAekHf8xDFMBKTaV+FWoAvngI+/iNQX2HOOyqeAxTNASbMBty+oT8mAQaVqxYBWvaYwyuzJpqFPw0806ovgXfvATa9Er8/uxQ46SZg6neH/t9lEhmS14Bgs/n/RPrY/vfKGwaw7UPgwweAmg3mB3CHLQJKTun7EGLDMJ8H6/4NbH7d/PCo89DknkyaaxYYudP6fMi9ZqqFgW9eAbasAPx5wIyF5v8tIxQLC8FYWNhHJKJh07pPsG/tK1D3bkSFlo0vQgX4JFCAncYYAAP9VMLAHHUtfuX8F6aoldZe3VCwUp8GlwqMdgaQobbBbzTDo7VANWyyhJ0zBRhdYhYZWROAcKCjEIlOZLcKlP2AogLeUUDqaLOYSW3fTs0GUkdDT8lE1d465I0bD4fLY/6norrM79Ftb6ZZBPTlP6/KNcCHv+v6hkMWh8fsCRk1ySw4Mgpj2poN+MaYP/fnU9RgM9BYaS5M0PmrsRJoqwcKjjb/85p2lplpjIS9BrTUAp88DnzyZ6Ct+4IdqgsonAUUf8ssNsYebptPmHt/YxEBKlebn5g2VwP7a+K/t9TCetPj9AIHnWaev0lzAad7aBpgGMDuL4DPnwA2vACoTmDyPKB0vnkcCejB6/dzdfdac9GOzj3DneXPNIeiTpo7IoeiSnkNMAygdjNQ9iZQtgLYvhLQw+YHM4f9AJhxgXlh2wM9RtmbwPv3Azs/6Xq7bwww43zz8XJ6WGilfrtZTHz1LFC7qZc/ppj/T+XNMAuITa+ZF9q1blbNuZAn/Rfgzzlg87vNtGk38NkTwGfLzX/nsfIPNXvQDl5w4FxiHeCDIztgYSEYCwv7C0V01DYHsXe/+bVnfxA1jW0o27kHbYoH1U1BVDe2ob413OvjqNBxtvohfu76HxQotVKOtRF+1Kmj0OTMRosnG8GUXOip2fAZrcgIVSE9sBvpgd3wBWv6V7w43PFdyInm9pv/geVMAcZM7fiePta8vfxt4MMHgW0fxP9eSiZw9BXAId8DGncCezeZY273bgL2bjQLoKGQkmkWGymZgKGZn3BpofavTtvh1r4/ruoyP+WbcR5Qeirg8vb+GmAY5qfmDdvNHpqUDPPL7R/4f2b7yoFVfwDWPgVEAvG3ZRUB9dvQ4yeJnnTzP/7YHrWs9l61tPz4T50jQXNoW8M2881Fw3bzsRt2mO3yjWn/yu60nQ14swBDByKhjqwjwfjtlPZj6VSoRXXJNRwAtr4LfPOS+aaldV//s/NmAdPPMReiKJwl51P2QKP5JuzzJ8zhId1RncCE48znUOl8szeuN1rE/BBBUc029PW5o2vmOdu7CajdBH3PN2iu3wt/wVSoWRPN3pzM8eaXy9vxez0VFGljgeOvM18P3rkb2LEy/vYJxwFz/xsYP6vndjTXmD3AbfXm654zxfy34fKa350pMV8eW7zpE/Y+INRqvqaWvWl+ta/C2C3VaT5/DrvILFhjPzDQNbOY/eABcx5k3O+5zAKls7GHm70YB3/P/Le74QXzedz5HEcfI+8Q8yt/BpA30ywmYntHDQP4+n+Bt24zP6CJcqcBJ/wcOOangCulx+ZZmU6eDMeOj4A1fzF7KQ70/6riMPOYeT5w0Okdz2stbL527t1o/nvY0/593xbztWvSScCkk80PYHzZvf+NJMPCQjAWFsNTd7m2hTTUNAVQ1RhAdVMbapqCCIZ1RHQdIU1HRDMQ1nQY4TYctfc5zN37d/j0JgBA2HBgP7xoMnxoQir2G6nW9xakoA0etBlutMGDANxoNTzmPrjRYnhRgyzsMTIRgKdPx++AhnylDgXKXhQqe5CF/diPVDQZvrjjaDJ8aFa8cHlSkecOotRZhRK1CkXYjfF6JcZGKpEd2g0Hun8xjShOBBx+BFQ/2hx+qNDhjzQiNdIAlxEUczJieTLMHo2G7fH70/IRmbUYLQcvQpuSCs0w4Hc74fM4Oq5pYhjmfJS93wD7ysx9Lp/5n5E7tX071XzT7Uo1h1TVV5j/GezbYl5LZV+5uW9IijDFfLPtcHb/H7wnHZh6JrTpC1DeloZJWSoc9RVAXXnMMZd3X0wpqvn70UKjL196BPj0b+aqbEbM+u6Kw/yU7tirzf/kW+uAivfNN+Fb3zXz6guHu70HaJT5yWDTbvR5qMNgZBSan3jnzzQLjfyZQFoeNF1H+fovMNnYCnXTK8CWt8zhhL1RXYA/F0jLNYdIuFOBLW9336OTMd4sgKeeCaTlmefD7RvYG1nDMHtQPnsCWP9c16GSrvbH7en4R5eYb2wMwzzWtnrzPLbVm0trB2OeQ6rL/MTXn2O21fqeaz5P6rd3FPO1mwGtj68D/lyzwHS4ge0fxt+WNtZ8M3jYRR1vBg3DPCdvL+1aQJWeahZu+6s6nkv7q8yiIva5eyDuNLOHcvQkYFRx+1f7tj+n41xp4faCJdpzVW2+1jRXm2+yPelmIetJBzxpMdvp5hvP1n3m7zfXtP9uTfzj6Vp7z2hM8ewbY/WSaimZ2LV7N8bl5Zqv1VrY/Peqhc038Vr7V6StY4htJNA+9DZgbrc1mJ/w93S+MsebqyDu+rT7czfzQmDmBcCuz8xe5H1b4u8zZipwwv8Dpn0X2PoesPYfwDevdi0ynCnmOeruNXb8sT323PYo3AZ8/KhZ5IT2d+zPGA9MnmueD0+6OVzRk2Z9ac5U1H75BnK2vwQl+v9FlKKaRcPhF5uvtV/9yxym1ZknHRh/jPn6vW9Lz8N0O8ubYRYZk04CCo/ptQBKBiwsBEt0YcEJRnIIyVWLAC17gZR0hJQU7GoMYNu+FmyvbcH2ulZs39eKyjrz02qPS4XbocLtVOFxOtq/mz8bBlDfGkJdi/lV3xJCS2johlK5EMF4pQb5Sh1aDQ8a4UOTkYom+BCECz0NIUtBEKOwH6OUJoxS9iML+5GlNMOFSPuXBqeidWy3789VGlCq7EShuveAx7YdY/EXfBf/GzoWrXr3Q2y8Lgf8KU74PR1fPo8THqcKh6rAqSpQ2793/VmFQ4X5XVHgdChwKjrSg3uQFahEurYPfq0B/kgDvOF6pITq4QnWwRWsgyOwD2qoGQYUwOmB4nC3D/mK+a66zE+Ao5/aZo4HMgvN7+kF5rCZ2LHF6/6naxd8orh8wBGXAMdcZR5vT+q3mW8kKt4DKj4w5x4MhhItFCVevMqXAyNrArB7LZTuPl11+YCSeebQm4wCszDw55nnsnMvhBY2i4t1z5pvpHqbH6Wo7W9sMmLegKaZz5W4+8X+m1OsHoEuxh1hDv84+FzzMbZ9CGx+A9j8Wu+fRieL7gqKznQd2PA88M6dXd/MyuT2m4V/W93Aeq+SneoCJhxr9pCWfNucz6IoQO0WsyhY+8++vRaNPRw48RdA6Wld/2207DNf19b+o+feteyDzGLikPPM3s2Bat4DvHOX2ZM30NcOfy5wxKXmv6mMcfG37fnGLDC+ehZo2tW3x3O4zV7ehh09vy44vUDBkWYBqmvmsVtfRvzP824DJh43sLYNAgsLwZKhsOCSaOIle66BsGYVG/UtYYQ0DRHNgG4Y0HRAMwzougFNN6AZBkIRHS3BCJqDEewPmF/NwTCagxE0t//cEoqgNaihJRSBngT/8lMRwGRlF0rVnShVzK8SdSfyUId1RjEejZyJFfqR0JG8kzYV6DCgQlHMAifV7UBK+3evy9xWFCCsmecoFDF7v2K/hzUdumFANwDF0HA01uMs9UPMV9cgTen5TaoOBbVqNqqcBah15cOt6PCjFX6jBal6M1L1Fni0Zni0ZjiMPn6SBqDZNQqrss/Dh5nfRZ3uQ1tIQzCioS2kQTcMjPK52788GO1zY7Tf/Hm0z4NRfjf0tiYE9mxFpG4bjPrtcDTtgGd/JVLbdiMjsAsevQ0tziy0pI5DKK0QyJwAd/ZEpOaWwJdbDCWjwLx4ZluDWbi37IXevBfh/XsQadoDo2Uv9NZ6hA0HwnAiBCdChhMBw4mA7kDAcKJNU5EWrsW4QBlyWzfDrR14OJqWkoWWiaegtfhUBMefCMWVClUF3A4VLocKp0OBq33boXa8ZhiGgbawZv47a2qAc/OrSC/7P2RWfQQFEoojT4b5RuyIS8yhIt0xDLMY2fy6WWhUftz1zVZ02JM3y5w35c0yh4E015hv0lr29v4GTXGYn/RHF0wYMwVGdilCigfu1iooDTtihri1f2+uMX83WlAcfrE5HKkvtIg5PO+9e7p5Y6eYbwrT8835W2n5Zg+AHjaHxYXbzO+R6PeAua9pV/vQuwRdgdnhMXu/HG5z3k6gQe7fSxtrFhElp5jzojxpPd9Xi5g9Rl/83Xwedf40fuIJZg9F8Zy+9cJVfWWevw0vmM+d6Webz+O8GWKHo9VsAN682RxO21cTTwCOugyY8p0DTzbXdbPH7ct/mW0JNZvnL7u0/d/CVPN7zlSzqHA4zefcjo+B8v8AW9/pvvejL85/Cpj6nYH97iCwsBAs0YUFh0LJMZJzNQwDwfZCpKW90GgNRdAW0qGqgEMxP9lXVaVju/27phsIRDQEwhqCYR2BsIa2sIZAdDsUQfXevcjIHIWIDkQ0HRHdHEIWbh9OFozoaAtr7X9TQ2vIfIzodigShsPhRKrbgVSXAyluR/u209x2OaCqQHNQM4upgFlQRb+0ZKiaBPAghLnq5zjD8TGy0IztRi4qjDxsM/JQYeRjh5GDIPoyUdiAF0GkoxVpSivS0Yp0paX9eyvS0YJ0pRU+BPCVUYwXtWP7+LgDYcCNCELo/j9vt1PFGL8HbqeKtpjnRUgb+Bs/BTomKjWYrmzDweo2TFcqMF3dhlFKM3YZo/GmdiTe0I/CGv0gaOjba4GqwCw2VAWBiN7tcy4bjTjD8TEOUSvgRxvS0Aq/Yn5Pa/+eovQ+rytWReoMrBl1Jr7OnIOw6oWqmO/HFCjt2x1vzqKbChSz6I00Iqd1C5oND+oNH+p0P+ojHrRGDLSFdQTas3aqCrJ8bmSlupGd6sBYTyvGOpqQozRiNOqRbuxHc0oe9niKUOMci4YQsD8QQVNbGPsDETS2hdDU3IIxWenwe5xIdZs9iKkeB3xuJ9KcEWTqDWj15CCoqwi1vy6EIjqCMYW3phtQYLYp2k5VUaAoCpx6EEUNHyPFocHwj4WSMRbOjDz4vKnwe5xISzF7LFPdjo7fa38spT2baFa6biAcDiCybzuMfeUw6rZCqa+AWrcVzsYKOFv2QPdmAf48ONLzoKTltfde5bZ/zzHfVAaazMUtgk0ItTQg0FyPQHMDIq0N0AItiHgyEfHlQEvNge7LtR7D4c2Ey2kWq6qqwGlE4AzUwxmohbNtH9S2Wjja9kFprUNjQx1GjcmF6nR3LIihOmO+u9vnkXjN766UmO32L0/6wN7EN+8FvnrGLDB82eb8hcKj+/84Q6mpyiyOg/tjvtrPU6gZeqARdc0hZJ1wORz5Bw/sb4TbzL+RNrZ/i1a01JrDSMv/A5S/A+zf3bffW/ikOUxsiLGwEIyFxfDEXOUQkathGAPuRYoWTfsDEYTb36BouoGI9V2P+7nzVyRu23yzEwi3Fz+dCqBAtDgKd9zWsd/8OfYV1qEq7Z9+K3A7HdZQOJfDLNxURYGqxr9RjH4w3traBsXpRjDScUyBsIZgxCzcqL8MpKMVTUjFwFeLGzwXIvCjFU7oiM43UQAo1rb5PQA3GtDLp8vUb4oC9PcdkM/tQFqKC2kpTvhTnEhLcUHXDdS1hNDQGkJdawiBsJzeD1UBfDFDPX1uh/m9fdvlUBGIeW0IxHzgY34YpMPtUOHztP9e+xw1n7u98PM4keI0X7MNwArHaN802p+L0deqzkNM476Urvuc7R9QOR0KDAMxr8kGNN380EnTDYR1AxHN/PAp0P5a2xqzHX291QzDGl5sfTnUuH1mXg74Pa724bLmts/jQKpLxc4d25FfMB4hDWgLawjGfFDW1p6hU1XgcZlDmFPav3ucKlJc5ndVVdAW87rf+f+A6GOkpbiQ7nVaz5/0FCfSU1xI8ziRojWZr0KK2v2X6mjfTsxrVX/eB9tjTUBB/vCHP+C+++5DdXU1Zs6ciYcffhhHH53kFTfRCDSYoWmKoiClfQhSohmGYb3JcDvjh8/0x4GKtYimW28oYoufzt/Dmg7V6n3qeIMQ+7PbqcLrcsDbPqTL63LA41KtYV0AUN8Swr72+UD7WkKoaw6iriWE2vb5QQ5VQYbXhXSvCxkxX+kp5nePS41bpW1vcxB7m9q/t6/apumGdRyx32OHmaV6HF3eZEU/Ifd5OhZkaAmZBWBL0PzeGjJ76VoCEdQ3NCAtPR2AYg1H0w0DRvv3SPubnLDW0esW1sx9ofbvXrfDmttjvels/+Tcn+KES1XRFAijqS2MpvZP9xvbwmgKtH9v86MtrCEU0RGIaP1+sztY0WF8KS4HwppZlI8EA8m5pf35VN0k/ngORDdgDXMlkbYf+C6SOVXF7JV3d/Tued0O+NwOpHqcSHWZr28LDi/AIQUZiT7cXo2YwuKZZ57Bz3/+czz22GOYNWsWHnzwQcyfPx+bNm1CTs6B1ztONHUEXxhIJuYqB3M1KYoCr1tMgdNbpk6HCr9Dhd8zNC/pOekpyEkf3CompbmJ//Rd0zSUl5dj0qRJSdNrabQXM9GhQcGIZs3NMdBR9EQLH/N3YrbbH6Nj23pkALCKxdhCzeOMX8AiFNGtT9+jc7zqWs2isbEtjFS3A2ntn9anRz999bYXVG4Vldu3I2dsIQKageagOa+rOWgOt2wJaWgNRszeO2f8p8ux205VhWEY3bY5+rM1r6V9OGRLKDq3LILmQBitIa39k/f2x2jPxvoE3jDMT9LbP+V2ObpuqwrQEtTQFAjHzF8zh321xiyw0TGEzIWsVHMoWfTnDK8LRnuuYc0c6hWOGAhpGsKR9oJVN+fMmT2qaJ9LZ1jfw5qOhv2tiCgOszBuH8J6oOJIjSkaPU4VIc1AS9DsZaXkEdEN80OHAxSNRxeNSvrCYsQMhZo1axaOOuooPPLIIwAAXddRWFiIq6++Gr/61a96/d1ED4UiIiKi5BLRdLQENSgqkOZxDvkiINaiAe3FW1jTzQLCZQ7TSXE64HIo3R6XphsdvXcxc+3awpo1HwVAx5yU9uGCitJR9MR9GfHDSfWYfdFFR6yhT5oBVQEcjo6V+Zxq+4p8MT9HeydjF8RIdTutwtihKlbRHdS0LotjxM4jNBcy0drn47VvByNmj6PLAY9VcKtIcXb02HqcKvT2nudg+3CyYKR9fmH7d003rLl/qW5HzLY5J9Db3hMYnYe0P2D2XO4PRNAUCFuFanSIbUv7eelu3tbyHx6FOQcN/YfhHArVSSgUwmeffYYbb7zR2qeqKubNm4dVq1Yl8Mj6xjCM/9/encdEcf5hAH9mWXa5FFAKLOKBFfEqVEEpwaapkCo1Rq21NqEN1jQGBYs9Eo2poumBaVPb2li01moTjVRM8GiqFlFpajzxwqoIlCoVEIlyVkF33t8f/JiyohbYGYaF55NsAu+M+r7PvLJ88868i4aGBri7u3fL3YscFXPVBnNVHzPVBnNVX2/K1OhkgKdb16zOPipXSZKab50xGdHRx2+c/n/Pfx+X/9gBqZtzNTn9f1W44+PoznNVCIEmq6zs4thyS2eQj/t//2Gd9YrCoqqqClarFX5+fjbtfn5+uHLlSpvzGxsb0dj47wfI1NY230xptVphtTYvH0qSBIPBAFmW0XrR53HtLZ+V8Lj2lr+3dTvQvLJitVpx/fp1DBs2DM7Ozkp7a05OTsrnMjzcl8e1t7fvWoypPe1aj0kIgdLSUpvbIBx9TN3hOlmtVpSWlmL48OFKfxx9TK37osd1kmVZ+RnQeq468pi6w3VqPVdbfiY4+pg6067mmFq/X7XMVUcf06Pau3pMT5qrjjqm1n3X4zo9PFe725hMTgaY3Azo69L2Ns2uvk4dubmpVxQWHZWWloZVq1a1aS8uLoaHhwcAwNPTExaLBTdv3kRNzb+fWOrj4wMfHx/cuHEDDQ0NSru/vz+8vLzw119/oanp30+bDAwMhIeHB4qLi20mQ1BQEIxGIwoLCyHLMm7fvo2ioiKEhITgwYMHKCkpUc41GAwYPnw4Ghoa8PfffyvtJpMJQ4cORU1NDSoq/v2QG3d3dwwcOBC3b99GVVWV0t6VY2otODhYlzF5e3ujtrYWRUVFyn9sRx9Td7hOsiwr/eopYwL0vU6urq64c+eOzVx19DF1h+skyzL++af58y16ypgAfa9TU1OT8n5lMBh6xJi6w3WSZVkZR08ZE6DvdaqtrbWZqz1hTFpdJzc3N7RXr3jGoqmpCW5ubti5cydmzJihtCckJKC6uhq7d++2Of9RKxYtF6bl3rKuXrEoKiriioXKYxJC4OrVq1yx0GDFori4mCsWKq9YFBQUcMVCgxWLlrnKFQv1ViyuXr3KFQsNViweN1cddUyt+67HdXrw4IHNXO0JY9LqOtXX18PLy4vPWLQwmUwIDw9HTk6OUljIsoycnBwkJye3Od9sNsNsbvtJoE5OTm12Dmm58A/raPvjdiRpmewuLi4wGv99OOxR50uS1KF2tfremTG1t13LMcmyDLPZDKPR2Oa4o46pM+1qj0mSJJjNZkiS1GPG1J52LcfU+mfAw8cddUyP62NH2+0ZU+u52lPGpEV7R/puMBgeOVcdeUyPa+/KMbVnrjramNrTruWYHjdXHXlMWl2nlt8926NXrFgAzdvNJiQkYMOGDZgwYQK++uor7NixA1euXGnz7MXDuCsUEREREfVG3BXqEebMmYNbt25hxYoVqKiowLPPPov9+/f/Z1HRHQghUFNTA09Pzw5VjfRkzFUbzFV9zFQbzFV9zFQbzFV9zFQbvepTrJKTk3Ht2jU0NjbixIkTiIyM1LtL7SLLMioqKtrcZ0f2Ya7aYK7qY6baYK7qY6baYK7qY6ba6FWFBRERERERaYOFBRERERER2Y2FhQOQJKlbfjKko2Ou2mCu6mOm2mCu6mOm2mCu6mOm2ug1u0LZg7tCEREREVFv1JHfg7li4QBkWUZVVRUfMFIZc9UGc1UfM9UGc1UfM9UGc1UfM9UGCwsHIIRAVVUVuLikLuaqDeaqPmaqDeaqPmaqDeaqPmaqDRYWRERERERkNxYWRERERERkNxYWDkCSJH4ypAaYqzaYq/qYqTaYq/qYqTaYq/qYqTa4K1Q7cFcoIiIiIuqNuCtUDyPLMsrLy7lzgcqYqzaYq/qYqTaYq/qYqTaYq/qYqTZYWDgAIQRqamq4c4HKmKs2mKv6mKk2mKv6mKk2mKv6mKk2WFgQEREREZHdjHp3wBG0VLO1tbW6/PtWqxX19fWora2Fk5OTLn3oiZirNpir+pipNpir+pipNpir+php+7X8/tue1R0WFu1QV1cHABg4cKDOPSEiIiIi6np1dXXw9PR84jncFaodZFlGWVkZ+vTpo8u2ZLW1tRg4cCBKS0u5K5WKmKs2mKv6mKk2mKv6mKk2mKv6mGn7CSFQV1eHgIAAGAxPfoqCKxbtYDAYEBgYqHc30LdvX05+DTBXbTBX9TFTbTBX9TFTbTBX9THT9vmvlYoWfHibiIiIiIjsxsKCiIiIiIjsxsLCAZjNZqSmpsJsNuvdlR6FuWqDuaqPmWqDuaqPmWqDuaqPmWqDD28TEREREZHduGJBRERERER2Y2FBRERERER2Y2FBRERERER2Y2HhANatW4chQ4bAxcUFkZGROHnypN5dcii//fYbpk2bhoCAAEiShF27dtkcF0JgxYoVsFgscHV1RWxsLAoLC/XprINIS0vD+PHj0adPH/j6+mLGjBkoKCiwOefevXtISkpC//794eHhgVmzZuHmzZs69bj7S09PR2hoqLKnelRUFPbt26ccZ57qWL16NSRJwuLFi5U2ZtsxK1euhCRJNq8RI0Yox5ln5924cQNvvPEG+vfvD1dXVzzzzDM4ffq0cpzvVx03ZMiQNvNVkiQkJSUB4HxVGwuLbu6nn37Ce++9h9TUVJw5cwZhYWGYPHkyKisr9e6aw2hoaEBYWBjWrVv3yOOfffYZ1q5di/Xr1+PEiRNwd3fH5MmTce/evS7uqePIzc1FUlISjh8/juzsbNy/fx8vvfQSGhoalHPeffdd7N27F5mZmcjNzUVZWRleeeUVHXvdvQUGBmL16tXIy8vD6dOnMWnSJEyfPh1//PEHAOaphlOnTmHDhg0IDQ21aWe2HTd69GiUl5crr99//105xjw7586dO4iOjoazszP27duHS5cu4YsvvoC3t7dyDt+vOu7UqVM2czU7OxsAMHv2bACcr6oT1K1NmDBBJCUlKd9brVYREBAg0tLSdOyV4wIgsrKylO9lWRb+/v7i888/V9qqq6uF2WwW27dv16GHjqmyslIAELm5uUKI5gydnZ1FZmamcs7ly5cFAHHs2DG9uulwvL29xffff888VVBXVyeCg4NFdna2eOGFF0RKSooQgnO1M1JTU0VYWNgjjzHPzluyZImYOHHiY4/z/UodKSkp4umnnxayLHO+aoArFt1YU1MT8vLyEBsbq7QZDAbExsbi2LFjOvas5ygpKUFFRYVNxp6enoiMjGTGHVBTUwMA6NevHwAgLy8P9+/ft8l1xIgRGDRoEHNtB6vVioyMDDQ0NCAqKop5qiApKQlTp061yRDgXO2swsJCBAQEYOjQoYiPj8f169cBME977NmzBxEREZg9ezZ8fX0xduxYbNy4UTnO9yv7NTU1YevWrZg3bx4kSeJ81QALi26sqqoKVqsVfn5+Nu1+fn6oqKjQqVc9S0uOzLjzZFnG4sWLER0djTFjxgBoztVkMsHLy8vmXOb6ZPn5+fDw8IDZbEZiYiKysrIwatQo5mmnjIwMnDlzBmlpaW2OMduOi4yMxJYtW7B//36kp6ejpKQEzz//POrq6pinHf7880+kp6cjODgYBw4cwIIFC/DOO+/gxx9/BMD3KzXs2rUL1dXVmDt3LgD+/9eCUe8OEJFjS0pKwsWLF23usabOCQkJwblz51BTU4OdO3ciISEBubm5enfLoZWWliIlJQXZ2dlwcXHRuzs9QlxcnPJ1aGgoIiMjMXjwYOzYsQOurq469syxybKMiIgIfPrppwCAsWPH4uLFi1i/fj0SEhJ07l3PsGnTJsTFxSEgIEDvrvRYXLHoxnx8fODk5NRmd4KbN2/C399fp171LC05MuPOSU5Oxs8//4zDhw8jMDBQaff390dTUxOqq6ttzmeuT2YymTBs2DCEh4cjLS0NYWFh+Prrr5mnHfLy8lBZWYlx48bBaDTCaDQiNzcXa9euhdFohJ+fH7O1k5eXF4YPH46ioiLOVTtYLBaMGjXKpm3kyJHKbWZ8v7LPtWvXcPDgQbz99ttKG+er+lhYdGMmkwnh4eHIyclR2mRZRk5ODqKionTsWc8RFBQEf39/m4xra2tx4sQJZvwEQggkJycjKysLhw4dQlBQkM3x8PBwODs72+RaUFCA69evM9cOkGUZjY2NzNMOMTExyM/Px7lz55RXREQE4uPjla+ZrX3q6+tRXFwMi8XCuWqH6OjoNtt2X716FYMHDwbA9yt7bd68Gb6+vpg6darSxvmqAb2fHqcny8jIEGazWWzZskVcunRJzJ8/X3h5eYmKigq9u+Yw6urqxNmzZ8XZs2cFALFmzRpx9uxZce3aNSGEEKtXrxZeXl5i9+7d4sKFC2L69OkiKChI3L17V+eed18LFiwQnp6e4siRI6K8vFx5/fPPP8o5iYmJYtCgQeLQoUPi9OnTIioqSkRFRenY6+5t6dKlIjc3V5SUlIgLFy6IpUuXCkmSxK+//iqEYJ5qar0rlBDMtqPef/99ceTIEVFSUiKOHj0qYmNjhY+Pj6isrBRCMM/OOnnypDAajeKTTz4RhYWFYtu2bcLNzU1s3bpVOYfvV51jtVrFoEGDxJIlS9oc43xVFwsLB/DNN9+IQYMGCZPJJCZMmCCOHz+ud5ccyuHDhwWANq+EhAQhRPMWfsuXLxd+fn7CbDaLmJgYUVBQoG+nu7lH5QlAbN68WTnn7t27YuHChcLb21u4ubmJmTNnivLycv063c3NmzdPDB48WJhMJvHUU0+JmJgYpagQgnmq6eHCgtl2zJw5c4TFYhEmk0kMGDBAzJkzRxQVFSnHmWfn7d27V4wZM0aYzWYxYsQI8d1339kc5/tV5xw4cEAAeGRWnK/qkoQQQpelEiIiIiIi6jH4jAUREREREdmNhQUREREREdmNhQUREREREdmNhQUREREREdmNhQUREREREdmNhQUREREREdmNhQUREREREdmNhQUREREREdmNhQUREfVIkiRh165deneDiKjXYGFBRESqmzt3LiRJavOaMmWK3l0jIiKNGPXuABER9UxTpkzB5s2bbdrMZrNOvSEiIq1xxYKIiDRhNpvh7+9v8/L29gbQfJtSeno64uLi4OrqiqFDh2Lnzp02fz4/Px+TJk2Cq6sr+vfvj/nz56O+vt7mnB9++AGjR4+G2WyGxWJBcnKyzfGqqirMnDkTbm5uCA4Oxp49e7QdNBFRL8bCgoiIdLF8+XLMmjUL58+fR3x8PF5//XVcvnwZANDQ0IDJkyfD29sbp06dQmZmJg4ePGhTOKSnpyMpKQnz589Hfn4+9uzZg2HDhtn8G6tWrcJrr72GCxcu4OWXX0Z8fDxu377dpeMkIuotJCGE0LsTRETUs8ydOxdbt26Fi4uLTfuyZcuwbNkySJKExMREpKenK8eee+45jBs3Dt9++y02btyIJUuWoLS0FO7u7gCAX375BdOmTUNZWRn8/PwwYMAAvPXWW/j4448f2QdJkvDhhx/io48+AtBcrHh4eGDfvn181oOISAN8xoKIiDTx4osv2hQOANCvXz/l66ioKJtjUVFROHfuHADg8uXLCAsLU4oKAIiOjoYsyygoKIAkSSgrK0NMTMwT+xAaGqp87e7ujr59+6KysrKzQyIioidgYUFERJpwd3dvc2uSWlxdXdt1nrOzs833kiRBlmUtukRE1OvxGQsiItLF8ePH23w/cuRIAMDIkSNx/vx5NDQ0KMePHj0Kg8GAkJAQ9OnTB0OGDEFOTk6X9pmIiB6PKxZERKSJxsZGVFRU2LQZjUb4+PgAADIzMxEREYGJEydi27ZtOHnyJDZt2gQAiI+PR2pqKhISErBy5UrcunULixYtwptvvgk/Pz8AwMqVK5GYmAhfX1/ExcWhrq4OR48exaJFi7p2oEREBICFBRERaWT//v2wWCw2bSEhIbhy5QqA5h2bMjIysHDhQlgsFmzfvh2jRo0CALi5ueHAgQNISUnB+PHj4ebmhlmzZmHNmjXK35WQkIB79+7hyy+/xAcffAAfHx+8+uqrXTdAIiKywV2hiIioy0mShKysLMyYMUPvrhARkUr4jAUREREREdmNhQUREREREdmNz1gQEVGX4124REQ9D1csiIiIiIjIbiwsiIiIiIjIbiwsiIiIiIjIbiwsiIiIiIjIbiwsiIiIiIjIbiwsiIiIiIjIbiwsiIiIiIjIbiwsiIiIiIjIbiwsiIiIiIjIbv8DLkV/9dHCQ2QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
