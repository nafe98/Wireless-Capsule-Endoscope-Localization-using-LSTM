{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered_iReg_f_obese.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225.406990</td>\n",
       "      <td>239.008790</td>\n",
       "      <td>158.191094</td>\n",
       "      <td>187.189908</td>\n",
       "      <td>275.467386</td>\n",
       "      <td>281.229012</td>\n",
       "      <td>211.308257</td>\n",
       "      <td>229.358293</td>\n",
       "      <td>201.582876</td>\n",
       "      <td>225.230211</td>\n",
       "      <td>...</td>\n",
       "      <td>169.531659</td>\n",
       "      <td>172.666548</td>\n",
       "      <td>192.453077</td>\n",
       "      <td>187.047372</td>\n",
       "      <td>242.967384</td>\n",
       "      <td>237.534152</td>\n",
       "      <td>198.792993</td>\n",
       "      <td>224.891271</td>\n",
       "      <td>107.486538</td>\n",
       "      <td>148.012190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228.633781</td>\n",
       "      <td>245.151589</td>\n",
       "      <td>156.800392</td>\n",
       "      <td>184.587306</td>\n",
       "      <td>264.466138</td>\n",
       "      <td>277.713108</td>\n",
       "      <td>213.270706</td>\n",
       "      <td>234.364622</td>\n",
       "      <td>207.477214</td>\n",
       "      <td>217.770303</td>\n",
       "      <td>...</td>\n",
       "      <td>166.147794</td>\n",
       "      <td>170.038327</td>\n",
       "      <td>196.866198</td>\n",
       "      <td>187.848953</td>\n",
       "      <td>245.784763</td>\n",
       "      <td>248.073511</td>\n",
       "      <td>198.882069</td>\n",
       "      <td>221.364753</td>\n",
       "      <td>105.383493</td>\n",
       "      <td>139.161556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224.153794</td>\n",
       "      <td>249.810077</td>\n",
       "      <td>153.038031</td>\n",
       "      <td>187.365600</td>\n",
       "      <td>261.717666</td>\n",
       "      <td>283.899837</td>\n",
       "      <td>217.474753</td>\n",
       "      <td>225.270731</td>\n",
       "      <td>200.043037</td>\n",
       "      <td>207.928725</td>\n",
       "      <td>...</td>\n",
       "      <td>169.214058</td>\n",
       "      <td>185.371351</td>\n",
       "      <td>193.593967</td>\n",
       "      <td>188.513661</td>\n",
       "      <td>247.270057</td>\n",
       "      <td>237.878404</td>\n",
       "      <td>200.563666</td>\n",
       "      <td>230.747023</td>\n",
       "      <td>107.781494</td>\n",
       "      <td>150.405524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215.946864</td>\n",
       "      <td>243.204526</td>\n",
       "      <td>150.392309</td>\n",
       "      <td>192.410319</td>\n",
       "      <td>265.338779</td>\n",
       "      <td>275.743540</td>\n",
       "      <td>209.657333</td>\n",
       "      <td>236.181002</td>\n",
       "      <td>202.469535</td>\n",
       "      <td>219.065106</td>\n",
       "      <td>...</td>\n",
       "      <td>170.679691</td>\n",
       "      <td>182.101000</td>\n",
       "      <td>195.548369</td>\n",
       "      <td>189.891649</td>\n",
       "      <td>237.982636</td>\n",
       "      <td>252.286560</td>\n",
       "      <td>202.535132</td>\n",
       "      <td>220.895367</td>\n",
       "      <td>110.265810</td>\n",
       "      <td>149.756557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226.184948</td>\n",
       "      <td>249.814628</td>\n",
       "      <td>162.709835</td>\n",
       "      <td>186.328688</td>\n",
       "      <td>264.637581</td>\n",
       "      <td>277.555411</td>\n",
       "      <td>218.032813</td>\n",
       "      <td>232.644672</td>\n",
       "      <td>209.252621</td>\n",
       "      <td>215.162594</td>\n",
       "      <td>...</td>\n",
       "      <td>175.716059</td>\n",
       "      <td>171.187222</td>\n",
       "      <td>200.664477</td>\n",
       "      <td>184.740323</td>\n",
       "      <td>243.157506</td>\n",
       "      <td>239.385167</td>\n",
       "      <td>198.765299</td>\n",
       "      <td>224.987574</td>\n",
       "      <td>108.316042</td>\n",
       "      <td>147.834524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>244.631935</td>\n",
       "      <td>227.486924</td>\n",
       "      <td>152.860450</td>\n",
       "      <td>141.746816</td>\n",
       "      <td>288.640369</td>\n",
       "      <td>283.967031</td>\n",
       "      <td>230.864109</td>\n",
       "      <td>223.355707</td>\n",
       "      <td>217.206802</td>\n",
       "      <td>213.323681</td>\n",
       "      <td>...</td>\n",
       "      <td>173.571829</td>\n",
       "      <td>193.956862</td>\n",
       "      <td>189.695903</td>\n",
       "      <td>177.222097</td>\n",
       "      <td>259.449935</td>\n",
       "      <td>235.875875</td>\n",
       "      <td>221.579495</td>\n",
       "      <td>208.014293</td>\n",
       "      <td>144.366279</td>\n",
       "      <td>115.315693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>241.439417</td>\n",
       "      <td>227.313179</td>\n",
       "      <td>160.417181</td>\n",
       "      <td>135.108209</td>\n",
       "      <td>292.941557</td>\n",
       "      <td>274.486373</td>\n",
       "      <td>232.084329</td>\n",
       "      <td>213.084474</td>\n",
       "      <td>204.916336</td>\n",
       "      <td>202.388167</td>\n",
       "      <td>...</td>\n",
       "      <td>180.144556</td>\n",
       "      <td>189.998904</td>\n",
       "      <td>192.092449</td>\n",
       "      <td>166.192675</td>\n",
       "      <td>244.962685</td>\n",
       "      <td>247.866220</td>\n",
       "      <td>225.432035</td>\n",
       "      <td>212.803153</td>\n",
       "      <td>145.580688</td>\n",
       "      <td>107.107362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>243.485176</td>\n",
       "      <td>228.839487</td>\n",
       "      <td>167.040019</td>\n",
       "      <td>139.364266</td>\n",
       "      <td>288.030906</td>\n",
       "      <td>276.184358</td>\n",
       "      <td>236.803816</td>\n",
       "      <td>216.808270</td>\n",
       "      <td>216.363399</td>\n",
       "      <td>200.870898</td>\n",
       "      <td>...</td>\n",
       "      <td>171.256528</td>\n",
       "      <td>196.366081</td>\n",
       "      <td>194.788796</td>\n",
       "      <td>171.981077</td>\n",
       "      <td>259.054124</td>\n",
       "      <td>237.921634</td>\n",
       "      <td>215.723724</td>\n",
       "      <td>212.874373</td>\n",
       "      <td>142.529206</td>\n",
       "      <td>107.861245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>238.026661</td>\n",
       "      <td>236.849963</td>\n",
       "      <td>164.718777</td>\n",
       "      <td>143.433579</td>\n",
       "      <td>291.108831</td>\n",
       "      <td>282.412229</td>\n",
       "      <td>240.958178</td>\n",
       "      <td>214.110993</td>\n",
       "      <td>213.230860</td>\n",
       "      <td>189.934369</td>\n",
       "      <td>...</td>\n",
       "      <td>171.995866</td>\n",
       "      <td>194.416994</td>\n",
       "      <td>199.046725</td>\n",
       "      <td>166.954828</td>\n",
       "      <td>253.129921</td>\n",
       "      <td>233.517925</td>\n",
       "      <td>220.636955</td>\n",
       "      <td>216.644809</td>\n",
       "      <td>142.204405</td>\n",
       "      <td>111.443804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>240.660196</td>\n",
       "      <td>229.393753</td>\n",
       "      <td>165.773564</td>\n",
       "      <td>151.618905</td>\n",
       "      <td>282.858214</td>\n",
       "      <td>280.936428</td>\n",
       "      <td>238.669200</td>\n",
       "      <td>225.183727</td>\n",
       "      <td>204.387444</td>\n",
       "      <td>210.230827</td>\n",
       "      <td>...</td>\n",
       "      <td>176.587346</td>\n",
       "      <td>192.341783</td>\n",
       "      <td>200.027368</td>\n",
       "      <td>171.198233</td>\n",
       "      <td>252.700679</td>\n",
       "      <td>243.504570</td>\n",
       "      <td>226.870974</td>\n",
       "      <td>212.239032</td>\n",
       "      <td>139.960394</td>\n",
       "      <td>115.935347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     225.406990  239.008790  158.191094  187.189908  275.467386  281.229012   \n",
       "1     228.633781  245.151589  156.800392  184.587306  264.466138  277.713108   \n",
       "2     224.153794  249.810077  153.038031  187.365600  261.717666  283.899837   \n",
       "3     215.946864  243.204526  150.392309  192.410319  265.338779  275.743540   \n",
       "4     226.184948  249.814628  162.709835  186.328688  264.637581  277.555411   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  244.631935  227.486924  152.860450  141.746816  288.640369  283.967031   \n",
       "2439  241.439417  227.313179  160.417181  135.108209  292.941557  274.486373   \n",
       "2440  243.485176  228.839487  167.040019  139.364266  288.030906  276.184358   \n",
       "2441  238.026661  236.849963  164.718777  143.433579  291.108831  282.412229   \n",
       "2442  240.660196  229.393753  165.773564  151.618905  282.858214  280.936428   \n",
       "\n",
       "              6           7           8           9   ...          38  \\\n",
       "0     211.308257  229.358293  201.582876  225.230211  ...  169.531659   \n",
       "1     213.270706  234.364622  207.477214  217.770303  ...  166.147794   \n",
       "2     217.474753  225.270731  200.043037  207.928725  ...  169.214058   \n",
       "3     209.657333  236.181002  202.469535  219.065106  ...  170.679691   \n",
       "4     218.032813  232.644672  209.252621  215.162594  ...  175.716059   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  230.864109  223.355707  217.206802  213.323681  ...  173.571829   \n",
       "2439  232.084329  213.084474  204.916336  202.388167  ...  180.144556   \n",
       "2440  236.803816  216.808270  216.363399  200.870898  ...  171.256528   \n",
       "2441  240.958178  214.110993  213.230860  189.934369  ...  171.995866   \n",
       "2442  238.669200  225.183727  204.387444  210.230827  ...  176.587346   \n",
       "\n",
       "              39          40          41          42          43          44  \\\n",
       "0     172.666548  192.453077  187.047372  242.967384  237.534152  198.792993   \n",
       "1     170.038327  196.866198  187.848953  245.784763  248.073511  198.882069   \n",
       "2     185.371351  193.593967  188.513661  247.270057  237.878404  200.563666   \n",
       "3     182.101000  195.548369  189.891649  237.982636  252.286560  202.535132   \n",
       "4     171.187222  200.664477  184.740323  243.157506  239.385167  198.765299   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  193.956862  189.695903  177.222097  259.449935  235.875875  221.579495   \n",
       "2439  189.998904  192.092449  166.192675  244.962685  247.866220  225.432035   \n",
       "2440  196.366081  194.788796  171.981077  259.054124  237.921634  215.723724   \n",
       "2441  194.416994  199.046725  166.954828  253.129921  233.517925  220.636955   \n",
       "2442  192.341783  200.027368  171.198233  252.700679  243.504570  226.870974   \n",
       "\n",
       "              45          46          47  \n",
       "0     224.891271  107.486538  148.012190  \n",
       "1     221.364753  105.383493  139.161556  \n",
       "2     230.747023  107.781494  150.405524  \n",
       "3     220.895367  110.265810  149.756557  \n",
       "4     224.987574  108.316042  147.834524  \n",
       "...          ...         ...         ...  \n",
       "2438  208.014293  144.366279  115.315693  \n",
       "2439  212.803153  145.580688  107.107362  \n",
       "2440  212.874373  142.529206  107.861245  \n",
       "2441  216.644809  142.204405  111.443804  \n",
       "2442  212.239032  139.960394  115.935347  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225.406990</td>\n",
       "      <td>239.008790</td>\n",
       "      <td>158.191094</td>\n",
       "      <td>187.189908</td>\n",
       "      <td>275.467386</td>\n",
       "      <td>281.229012</td>\n",
       "      <td>211.308257</td>\n",
       "      <td>229.358293</td>\n",
       "      <td>201.582876</td>\n",
       "      <td>225.230211</td>\n",
       "      <td>...</td>\n",
       "      <td>169.531659</td>\n",
       "      <td>172.666548</td>\n",
       "      <td>192.453077</td>\n",
       "      <td>187.047372</td>\n",
       "      <td>242.967384</td>\n",
       "      <td>237.534152</td>\n",
       "      <td>198.792993</td>\n",
       "      <td>224.891271</td>\n",
       "      <td>107.486538</td>\n",
       "      <td>148.012190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228.633781</td>\n",
       "      <td>245.151589</td>\n",
       "      <td>156.800392</td>\n",
       "      <td>184.587306</td>\n",
       "      <td>264.466138</td>\n",
       "      <td>277.713108</td>\n",
       "      <td>213.270706</td>\n",
       "      <td>234.364622</td>\n",
       "      <td>207.477214</td>\n",
       "      <td>217.770303</td>\n",
       "      <td>...</td>\n",
       "      <td>166.147794</td>\n",
       "      <td>170.038327</td>\n",
       "      <td>196.866198</td>\n",
       "      <td>187.848953</td>\n",
       "      <td>245.784763</td>\n",
       "      <td>248.073511</td>\n",
       "      <td>198.882069</td>\n",
       "      <td>221.364753</td>\n",
       "      <td>105.383493</td>\n",
       "      <td>139.161556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224.153794</td>\n",
       "      <td>249.810077</td>\n",
       "      <td>153.038031</td>\n",
       "      <td>187.365600</td>\n",
       "      <td>261.717666</td>\n",
       "      <td>283.899837</td>\n",
       "      <td>217.474753</td>\n",
       "      <td>225.270731</td>\n",
       "      <td>200.043037</td>\n",
       "      <td>207.928725</td>\n",
       "      <td>...</td>\n",
       "      <td>169.214058</td>\n",
       "      <td>185.371351</td>\n",
       "      <td>193.593967</td>\n",
       "      <td>188.513661</td>\n",
       "      <td>247.270057</td>\n",
       "      <td>237.878404</td>\n",
       "      <td>200.563666</td>\n",
       "      <td>230.747023</td>\n",
       "      <td>107.781494</td>\n",
       "      <td>150.405524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215.946864</td>\n",
       "      <td>243.204526</td>\n",
       "      <td>150.392309</td>\n",
       "      <td>192.410319</td>\n",
       "      <td>265.338779</td>\n",
       "      <td>275.743540</td>\n",
       "      <td>209.657333</td>\n",
       "      <td>236.181002</td>\n",
       "      <td>202.469535</td>\n",
       "      <td>219.065106</td>\n",
       "      <td>...</td>\n",
       "      <td>170.679691</td>\n",
       "      <td>182.101000</td>\n",
       "      <td>195.548369</td>\n",
       "      <td>189.891649</td>\n",
       "      <td>237.982636</td>\n",
       "      <td>252.286560</td>\n",
       "      <td>202.535132</td>\n",
       "      <td>220.895367</td>\n",
       "      <td>110.265810</td>\n",
       "      <td>149.756557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226.184948</td>\n",
       "      <td>249.814628</td>\n",
       "      <td>162.709835</td>\n",
       "      <td>186.328688</td>\n",
       "      <td>264.637581</td>\n",
       "      <td>277.555411</td>\n",
       "      <td>218.032813</td>\n",
       "      <td>232.644672</td>\n",
       "      <td>209.252621</td>\n",
       "      <td>215.162594</td>\n",
       "      <td>...</td>\n",
       "      <td>175.716059</td>\n",
       "      <td>171.187222</td>\n",
       "      <td>200.664477</td>\n",
       "      <td>184.740323</td>\n",
       "      <td>243.157506</td>\n",
       "      <td>239.385167</td>\n",
       "      <td>198.765299</td>\n",
       "      <td>224.987574</td>\n",
       "      <td>108.316042</td>\n",
       "      <td>147.834524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>244.631935</td>\n",
       "      <td>227.486924</td>\n",
       "      <td>152.860450</td>\n",
       "      <td>141.746816</td>\n",
       "      <td>288.640369</td>\n",
       "      <td>283.967031</td>\n",
       "      <td>230.864109</td>\n",
       "      <td>223.355707</td>\n",
       "      <td>217.206802</td>\n",
       "      <td>213.323681</td>\n",
       "      <td>...</td>\n",
       "      <td>173.571829</td>\n",
       "      <td>193.956862</td>\n",
       "      <td>189.695903</td>\n",
       "      <td>177.222097</td>\n",
       "      <td>259.449935</td>\n",
       "      <td>235.875875</td>\n",
       "      <td>221.579495</td>\n",
       "      <td>208.014293</td>\n",
       "      <td>144.366279</td>\n",
       "      <td>115.315693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>241.439417</td>\n",
       "      <td>227.313179</td>\n",
       "      <td>160.417181</td>\n",
       "      <td>135.108209</td>\n",
       "      <td>292.941557</td>\n",
       "      <td>274.486373</td>\n",
       "      <td>232.084329</td>\n",
       "      <td>213.084474</td>\n",
       "      <td>204.916336</td>\n",
       "      <td>202.388167</td>\n",
       "      <td>...</td>\n",
       "      <td>180.144556</td>\n",
       "      <td>189.998904</td>\n",
       "      <td>192.092449</td>\n",
       "      <td>166.192675</td>\n",
       "      <td>244.962685</td>\n",
       "      <td>247.866220</td>\n",
       "      <td>225.432035</td>\n",
       "      <td>212.803153</td>\n",
       "      <td>145.580688</td>\n",
       "      <td>107.107362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>243.485176</td>\n",
       "      <td>228.839487</td>\n",
       "      <td>167.040019</td>\n",
       "      <td>139.364266</td>\n",
       "      <td>288.030906</td>\n",
       "      <td>276.184358</td>\n",
       "      <td>236.803816</td>\n",
       "      <td>216.808270</td>\n",
       "      <td>216.363399</td>\n",
       "      <td>200.870898</td>\n",
       "      <td>...</td>\n",
       "      <td>171.256528</td>\n",
       "      <td>196.366081</td>\n",
       "      <td>194.788796</td>\n",
       "      <td>171.981077</td>\n",
       "      <td>259.054124</td>\n",
       "      <td>237.921634</td>\n",
       "      <td>215.723724</td>\n",
       "      <td>212.874373</td>\n",
       "      <td>142.529206</td>\n",
       "      <td>107.861245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>238.026661</td>\n",
       "      <td>236.849963</td>\n",
       "      <td>164.718777</td>\n",
       "      <td>143.433579</td>\n",
       "      <td>291.108831</td>\n",
       "      <td>282.412229</td>\n",
       "      <td>240.958178</td>\n",
       "      <td>214.110993</td>\n",
       "      <td>213.230860</td>\n",
       "      <td>189.934369</td>\n",
       "      <td>...</td>\n",
       "      <td>171.995866</td>\n",
       "      <td>194.416994</td>\n",
       "      <td>199.046725</td>\n",
       "      <td>166.954828</td>\n",
       "      <td>253.129921</td>\n",
       "      <td>233.517925</td>\n",
       "      <td>220.636955</td>\n",
       "      <td>216.644809</td>\n",
       "      <td>142.204405</td>\n",
       "      <td>111.443804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>240.660196</td>\n",
       "      <td>229.393753</td>\n",
       "      <td>165.773564</td>\n",
       "      <td>151.618905</td>\n",
       "      <td>282.858214</td>\n",
       "      <td>280.936428</td>\n",
       "      <td>238.669200</td>\n",
       "      <td>225.183727</td>\n",
       "      <td>204.387444</td>\n",
       "      <td>210.230827</td>\n",
       "      <td>...</td>\n",
       "      <td>176.587346</td>\n",
       "      <td>192.341783</td>\n",
       "      <td>200.027368</td>\n",
       "      <td>171.198233</td>\n",
       "      <td>252.700679</td>\n",
       "      <td>243.504570</td>\n",
       "      <td>226.870974</td>\n",
       "      <td>212.239032</td>\n",
       "      <td>139.960394</td>\n",
       "      <td>115.935347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     225.406990  239.008790  158.191094  187.189908  275.467386  281.229012   \n",
       "1     228.633781  245.151589  156.800392  184.587306  264.466138  277.713108   \n",
       "2     224.153794  249.810077  153.038031  187.365600  261.717666  283.899837   \n",
       "3     215.946864  243.204526  150.392309  192.410319  265.338779  275.743540   \n",
       "4     226.184948  249.814628  162.709835  186.328688  264.637581  277.555411   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  244.631935  227.486924  152.860450  141.746816  288.640369  283.967031   \n",
       "2439  241.439417  227.313179  160.417181  135.108209  292.941557  274.486373   \n",
       "2440  243.485176  228.839487  167.040019  139.364266  288.030906  276.184358   \n",
       "2441  238.026661  236.849963  164.718777  143.433579  291.108831  282.412229   \n",
       "2442  240.660196  229.393753  165.773564  151.618905  282.858214  280.936428   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor39  \\\n",
       "0     211.308257  229.358293  201.582876  225.230211  ...  169.531659   \n",
       "1     213.270706  234.364622  207.477214  217.770303  ...  166.147794   \n",
       "2     217.474753  225.270731  200.043037  207.928725  ...  169.214058   \n",
       "3     209.657333  236.181002  202.469535  219.065106  ...  170.679691   \n",
       "4     218.032813  232.644672  209.252621  215.162594  ...  175.716059   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  230.864109  223.355707  217.206802  213.323681  ...  173.571829   \n",
       "2439  232.084329  213.084474  204.916336  202.388167  ...  180.144556   \n",
       "2440  236.803816  216.808270  216.363399  200.870898  ...  171.256528   \n",
       "2441  240.958178  214.110993  213.230860  189.934369  ...  171.995866   \n",
       "2442  238.669200  225.183727  204.387444  210.230827  ...  176.587346   \n",
       "\n",
       "        sensor40    sensor41    sensor42    sensor43    sensor44    sensor45  \\\n",
       "0     172.666548  192.453077  187.047372  242.967384  237.534152  198.792993   \n",
       "1     170.038327  196.866198  187.848953  245.784763  248.073511  198.882069   \n",
       "2     185.371351  193.593967  188.513661  247.270057  237.878404  200.563666   \n",
       "3     182.101000  195.548369  189.891649  237.982636  252.286560  202.535132   \n",
       "4     171.187222  200.664477  184.740323  243.157506  239.385167  198.765299   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  193.956862  189.695903  177.222097  259.449935  235.875875  221.579495   \n",
       "2439  189.998904  192.092449  166.192675  244.962685  247.866220  225.432035   \n",
       "2440  196.366081  194.788796  171.981077  259.054124  237.921634  215.723724   \n",
       "2441  194.416994  199.046725  166.954828  253.129921  233.517925  220.636955   \n",
       "2442  192.341783  200.027368  171.198233  252.700679  243.504570  226.870974   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     224.891271  107.486538  148.012190  \n",
       "1     221.364753  105.383493  139.161556  \n",
       "2     230.747023  107.781494  150.405524  \n",
       "3     220.895367  110.265810  149.756557  \n",
       "4     224.987574  108.316042  147.834524  \n",
       "...          ...         ...         ...  \n",
       "2438  208.014293  144.366279  115.315693  \n",
       "2439  212.803153  145.580688  107.107362  \n",
       "2440  212.874373  142.529206  107.861245  \n",
       "2441  216.644809  142.204405  111.443804  \n",
       "2442  212.239032  139.960394  115.935347  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf63fe",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090b68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>225.406990</td>\n",
       "      <td>239.008790</td>\n",
       "      <td>158.191094</td>\n",
       "      <td>187.189908</td>\n",
       "      <td>275.467386</td>\n",
       "      <td>281.229012</td>\n",
       "      <td>211.308257</td>\n",
       "      <td>229.358293</td>\n",
       "      <td>201.582876</td>\n",
       "      <td>225.230211</td>\n",
       "      <td>170.671409</td>\n",
       "      <td>175.078781</td>\n",
       "      <td>254.077642</td>\n",
       "      <td>258.651756</td>\n",
       "      <td>222.371551</td>\n",
       "      <td>234.842754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228.633781</td>\n",
       "      <td>245.151589</td>\n",
       "      <td>156.800392</td>\n",
       "      <td>184.587306</td>\n",
       "      <td>264.466138</td>\n",
       "      <td>277.713108</td>\n",
       "      <td>213.270706</td>\n",
       "      <td>234.364622</td>\n",
       "      <td>207.477214</td>\n",
       "      <td>217.770303</td>\n",
       "      <td>169.382958</td>\n",
       "      <td>178.653991</td>\n",
       "      <td>254.954478</td>\n",
       "      <td>258.108941</td>\n",
       "      <td>223.475447</td>\n",
       "      <td>235.496958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224.153794</td>\n",
       "      <td>249.810077</td>\n",
       "      <td>153.038031</td>\n",
       "      <td>187.365600</td>\n",
       "      <td>261.717666</td>\n",
       "      <td>283.899837</td>\n",
       "      <td>217.474753</td>\n",
       "      <td>225.270731</td>\n",
       "      <td>200.043037</td>\n",
       "      <td>207.928725</td>\n",
       "      <td>165.788015</td>\n",
       "      <td>192.079209</td>\n",
       "      <td>251.281556</td>\n",
       "      <td>256.435562</td>\n",
       "      <td>215.830439</td>\n",
       "      <td>239.833710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215.946864</td>\n",
       "      <td>243.204526</td>\n",
       "      <td>150.392309</td>\n",
       "      <td>192.410319</td>\n",
       "      <td>265.338779</td>\n",
       "      <td>275.743540</td>\n",
       "      <td>209.657333</td>\n",
       "      <td>236.181002</td>\n",
       "      <td>202.469535</td>\n",
       "      <td>219.065106</td>\n",
       "      <td>162.909602</td>\n",
       "      <td>175.775984</td>\n",
       "      <td>253.451510</td>\n",
       "      <td>253.412845</td>\n",
       "      <td>223.947511</td>\n",
       "      <td>237.149446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226.184948</td>\n",
       "      <td>249.814628</td>\n",
       "      <td>162.709835</td>\n",
       "      <td>186.328688</td>\n",
       "      <td>264.637581</td>\n",
       "      <td>277.555411</td>\n",
       "      <td>218.032813</td>\n",
       "      <td>232.644672</td>\n",
       "      <td>209.252621</td>\n",
       "      <td>215.162594</td>\n",
       "      <td>169.400109</td>\n",
       "      <td>178.707358</td>\n",
       "      <td>251.601965</td>\n",
       "      <td>250.910998</td>\n",
       "      <td>221.942163</td>\n",
       "      <td>232.468854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>244.631935</td>\n",
       "      <td>227.486924</td>\n",
       "      <td>152.860450</td>\n",
       "      <td>141.746816</td>\n",
       "      <td>288.640369</td>\n",
       "      <td>283.967031</td>\n",
       "      <td>230.864109</td>\n",
       "      <td>223.355707</td>\n",
       "      <td>217.206802</td>\n",
       "      <td>213.323681</td>\n",
       "      <td>165.358413</td>\n",
       "      <td>147.292309</td>\n",
       "      <td>266.717897</td>\n",
       "      <td>258.449631</td>\n",
       "      <td>231.082534</td>\n",
       "      <td>223.330469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>241.439417</td>\n",
       "      <td>227.313179</td>\n",
       "      <td>160.417181</td>\n",
       "      <td>135.108209</td>\n",
       "      <td>292.941557</td>\n",
       "      <td>274.486373</td>\n",
       "      <td>232.084329</td>\n",
       "      <td>213.084474</td>\n",
       "      <td>204.916336</td>\n",
       "      <td>202.388167</td>\n",
       "      <td>162.414720</td>\n",
       "      <td>154.083115</td>\n",
       "      <td>265.271368</td>\n",
       "      <td>256.530458</td>\n",
       "      <td>238.463250</td>\n",
       "      <td>225.187956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>243.485176</td>\n",
       "      <td>228.839487</td>\n",
       "      <td>167.040019</td>\n",
       "      <td>139.364266</td>\n",
       "      <td>288.030906</td>\n",
       "      <td>276.184358</td>\n",
       "      <td>236.803816</td>\n",
       "      <td>216.808270</td>\n",
       "      <td>216.363399</td>\n",
       "      <td>200.870898</td>\n",
       "      <td>159.899036</td>\n",
       "      <td>155.485936</td>\n",
       "      <td>274.347974</td>\n",
       "      <td>260.582466</td>\n",
       "      <td>227.823348</td>\n",
       "      <td>230.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>238.026661</td>\n",
       "      <td>236.849963</td>\n",
       "      <td>164.718777</td>\n",
       "      <td>143.433579</td>\n",
       "      <td>291.108831</td>\n",
       "      <td>282.412229</td>\n",
       "      <td>240.958178</td>\n",
       "      <td>214.110993</td>\n",
       "      <td>213.230860</td>\n",
       "      <td>189.934369</td>\n",
       "      <td>164.079023</td>\n",
       "      <td>140.608827</td>\n",
       "      <td>267.509188</td>\n",
       "      <td>265.249588</td>\n",
       "      <td>226.929006</td>\n",
       "      <td>222.445933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>240.660196</td>\n",
       "      <td>229.393753</td>\n",
       "      <td>165.773564</td>\n",
       "      <td>151.618905</td>\n",
       "      <td>282.858214</td>\n",
       "      <td>280.936428</td>\n",
       "      <td>238.669200</td>\n",
       "      <td>225.183727</td>\n",
       "      <td>204.387444</td>\n",
       "      <td>210.230827</td>\n",
       "      <td>166.152378</td>\n",
       "      <td>147.575470</td>\n",
       "      <td>272.361897</td>\n",
       "      <td>268.460092</td>\n",
       "      <td>229.754354</td>\n",
       "      <td>229.385084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     225.406990  239.008790  158.191094  187.189908  275.467386  281.229012   \n",
       "1     228.633781  245.151589  156.800392  184.587306  264.466138  277.713108   \n",
       "2     224.153794  249.810077  153.038031  187.365600  261.717666  283.899837   \n",
       "3     215.946864  243.204526  150.392309  192.410319  265.338779  275.743540   \n",
       "4     226.184948  249.814628  162.709835  186.328688  264.637581  277.555411   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  244.631935  227.486924  152.860450  141.746816  288.640369  283.967031   \n",
       "2439  241.439417  227.313179  160.417181  135.108209  292.941557  274.486373   \n",
       "2440  243.485176  228.839487  167.040019  139.364266  288.030906  276.184358   \n",
       "2441  238.026661  236.849963  164.718777  143.433579  291.108831  282.412229   \n",
       "2442  240.660196  229.393753  165.773564  151.618905  282.858214  280.936428   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10    sensor11    sensor12  \\\n",
       "0     211.308257  229.358293  201.582876  225.230211  170.671409  175.078781   \n",
       "1     213.270706  234.364622  207.477214  217.770303  169.382958  178.653991   \n",
       "2     217.474753  225.270731  200.043037  207.928725  165.788015  192.079209   \n",
       "3     209.657333  236.181002  202.469535  219.065106  162.909602  175.775984   \n",
       "4     218.032813  232.644672  209.252621  215.162594  169.400109  178.707358   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  230.864109  223.355707  217.206802  213.323681  165.358413  147.292309   \n",
       "2439  232.084329  213.084474  204.916336  202.388167  162.414720  154.083115   \n",
       "2440  236.803816  216.808270  216.363399  200.870898  159.899036  155.485936   \n",
       "2441  240.958178  214.110993  213.230860  189.934369  164.079023  140.608827   \n",
       "2442  238.669200  225.183727  204.387444  210.230827  166.152378  147.575470   \n",
       "\n",
       "        sensor13    sensor14    sensor15    sensor16  \n",
       "0     254.077642  258.651756  222.371551  234.842754  \n",
       "1     254.954478  258.108941  223.475447  235.496958  \n",
       "2     251.281556  256.435562  215.830439  239.833710  \n",
       "3     253.451510  253.412845  223.947511  237.149446  \n",
       "4     251.601965  250.910998  221.942163  232.468854  \n",
       "...          ...         ...         ...         ...  \n",
       "2438  266.717897  258.449631  231.082534  223.330469  \n",
       "2439  265.271368  256.530458  238.463250  225.187956  \n",
       "2440  274.347974  260.582466  227.823348  230.913727  \n",
       "2441  267.509188  265.249588  226.929006  222.445933  \n",
       "2442  272.361897  268.460092  229.754354  229.385084  \n",
       "\n",
       "[2443 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:16]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 11s 16ms/step - loss: 1124.7952 - val_loss: 857.8041\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 731.1159 - val_loss: 594.6030\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 503.4122 - val_loss: 432.6650\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 371.4306 - val_loss: 357.5719\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 269.7223 - val_loss: 242.8830\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 186.5229 - val_loss: 163.0325\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 111.8020 - val_loss: 89.4161\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 68.7209 - val_loss: 67.4192\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 52.9518 - val_loss: 85.2432\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 41.7924 - val_loss: 44.1863\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 37.6927 - val_loss: 47.9763\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 32.9730 - val_loss: 66.5816\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.6268 - val_loss: 107.7778\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.8028 - val_loss: 36.5438\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.7059 - val_loss: 33.5468\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.5696 - val_loss: 36.1107\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.5528 - val_loss: 27.8206\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.3604 - val_loss: 94.4384\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 22.8797 - val_loss: 24.9093\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.4093 - val_loss: 65.4893\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.7635 - val_loss: 25.2001\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.0044 - val_loss: 39.9762\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.0894 - val_loss: 23.8702\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.8365 - val_loss: 32.2060\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.9785 - val_loss: 32.9278\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.5549 - val_loss: 32.0140\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 20.5664 - val_loss: 20.4321\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.6004 - val_loss: 28.4114\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.8597 - val_loss: 48.0364\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 18.3659 - val_loss: 35.9839\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.5471 - val_loss: 55.7262\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.8505 - val_loss: 23.0253\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.5037 - val_loss: 33.9833\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.1250 - val_loss: 43.2245\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.3129 - val_loss: 27.0705\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.6478 - val_loss: 17.3903\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 17.5610 - val_loss: 18.6314\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.4500 - val_loss: 21.2719\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.9257 - val_loss: 23.9930\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.1517 - val_loss: 39.0390\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 17.1225 - val_loss: 50.0292\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.1348 - val_loss: 16.5972\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.6672 - val_loss: 34.4560\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.9521 - val_loss: 24.6666\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.5332 - val_loss: 104.6458\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 16.9830 - val_loss: 57.7176\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.0198 - val_loss: 18.7466\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.2068 - val_loss: 28.3118\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.4612 - val_loss: 35.5072\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.8460 - val_loss: 61.2211\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 15.1089 - val_loss: 114.0888\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.7474 - val_loss: 27.6428\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.3704 - val_loss: 51.0183\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.6961 - val_loss: 53.8907\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.6984 - val_loss: 56.5642\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.4509 - val_loss: 21.4345\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.0744 - val_loss: 29.9011\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.6300 - val_loss: 34.1726\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.0287 - val_loss: 29.0447\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.9769 - val_loss: 36.9401\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9392 - val_loss: 19.0497\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.0304 - val_loss: 34.9230\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 12.9787 - val_loss: 17.8355\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.4196 - val_loss: 44.4770\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.6477 - val_loss: 17.4807\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.2092 - val_loss: 29.8227\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.6924 - val_loss: 19.7382\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.6943 - val_loss: 18.0240\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.7557 - val_loss: 16.5774\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.6462 - val_loss: 31.8581\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9643 - val_loss: 41.7396\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.2993 - val_loss: 17.4164\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.8932 - val_loss: 31.8405\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.3752 - val_loss: 21.1911\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 12.3689 - val_loss: 32.2893\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.0871 - val_loss: 21.5678\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.3426 - val_loss: 21.3540\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.5509 - val_loss: 14.9819\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 2s 7ms/step - loss: 12.5882 - val_loss: 15.0945\n",
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.3846 - val_loss: 16.5764\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.0861 - val_loss: 19.1860\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.3986 - val_loss: 19.4778\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1302 - val_loss: 15.6960\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.1825 - val_loss: 28.0851\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.7859 - val_loss: 38.3434\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.5513 - val_loss: 23.5802\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.1507 - val_loss: 17.6714\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.4760 - val_loss: 17.0363\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.4039 - val_loss: 38.0858\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.6156 - val_loss: 18.5348\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.5362 - val_loss: 15.5731\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.6618 - val_loss: 15.4017\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.2182 - val_loss: 22.0767\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4993 - val_loss: 53.9569\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.6267 - val_loss: 48.4199\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.9196 - val_loss: 38.4721\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.3150 - val_loss: 49.6107\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.7593 - val_loss: 38.1054\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6191 - val_loss: 16.0293\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6094 - val_loss: 20.5039\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.1031 - val_loss: 30.9147\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.1411 - val_loss: 29.4594\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.0503 - val_loss: 22.5433\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.0243 - val_loss: 20.3278\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4612 - val_loss: 54.5121\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.2007 - val_loss: 16.5639\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.2399 - val_loss: 18.9716\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.2642 - val_loss: 17.9100\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 14.98177458440857\n",
      "Mean Absolute Error (MAE): 2.3573522600345944\n",
      "Root Mean Squared Error (RMSE): 3.870629740030499\n",
      "Time taken: 298.6576638221741\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 12ms/step - loss: 1101.8431 - val_loss: 874.5842\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 702.3815 - val_loss: 589.5734\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 479.7918 - val_loss: 438.6519\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 374.2486 - val_loss: 362.7621\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 308.3814 - val_loss: 427.9101\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 261.6472 - val_loss: 315.5884\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 179.3196 - val_loss: 153.0175\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 103.9389 - val_loss: 90.3018\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 62.5821 - val_loss: 94.4220\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 47.3688 - val_loss: 54.2013\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 39.0279 - val_loss: 102.4707\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 33.4302 - val_loss: 50.4672\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 30.3498 - val_loss: 101.7409\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 27.4537 - val_loss: 29.5750\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 27.5383 - val_loss: 26.1067\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 25.6626 - val_loss: 27.4400\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 24.7385 - val_loss: 28.1202\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 25.2030 - val_loss: 48.2563\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 20.6920 - val_loss: 95.1123\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 23.5292 - val_loss: 31.7046\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 21.9097 - val_loss: 20.3387\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 20.6123 - val_loss: 33.4906\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 20.8536 - val_loss: 52.1908\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.1546 - val_loss: 20.1736\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.0147 - val_loss: 32.0684\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.3685 - val_loss: 45.2466\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.9118 - val_loss: 25.6229\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.6357 - val_loss: 22.9984\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.5072 - val_loss: 58.7191\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.3547 - val_loss: 32.0614\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 19.0212 - val_loss: 38.6911\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 17.6411 - val_loss: 26.6018\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.8459 - val_loss: 27.9967\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.9524 - val_loss: 34.9989\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.9119 - val_loss: 20.3868\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 15.9300 - val_loss: 23.1189\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.8700 - val_loss: 28.3211\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.2164 - val_loss: 25.6104\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.3843 - val_loss: 25.6374\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.9364 - val_loss: 27.6094\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.3350 - val_loss: 34.5741\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.4367 - val_loss: 21.6475\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.1035 - val_loss: 24.0703\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.5678 - val_loss: 27.1841\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.4849 - val_loss: 21.9516\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 16.1967 - val_loss: 27.1266\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.6276 - val_loss: 29.6238\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.2259 - val_loss: 32.5069\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.7018 - val_loss: 68.3052\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 15.1843 - val_loss: 29.1124\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.8649 - val_loss: 29.9406\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.9654 - val_loss: 29.4766\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.6946 - val_loss: 31.6237\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.5275 - val_loss: 38.3127\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 20.173454398886285\n",
      "Mean Absolute Error (MAE): 3.0925108580689487\n",
      "Root Mean Squared Error (RMSE): 4.491486880631657\n",
      "Time taken: 168.02685070037842\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 8s 13ms/step - loss: 1128.7307 - val_loss: 910.7783\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 712.7892 - val_loss: 579.7661\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 496.1871 - val_loss: 413.8445\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 385.2511 - val_loss: 397.9264\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 305.8734 - val_loss: 262.6837\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 230.0047 - val_loss: 194.4260\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 131.0585 - val_loss: 90.2003\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 77.5590 - val_loss: 55.1740\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 51.0854 - val_loss: 76.3433\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 38.9677 - val_loss: 118.1098\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 35.4670 - val_loss: 40.2836\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.7569 - val_loss: 32.2686\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 29.0953 - val_loss: 56.3768\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.9170 - val_loss: 30.6853\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 26.9517 - val_loss: 52.1476\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 24.6032 - val_loss: 37.4522\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.6125 - val_loss: 39.5167\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 23.6503 - val_loss: 44.5683\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.3192 - val_loss: 26.5915\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.9911 - val_loss: 30.7175\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.3222 - val_loss: 27.8501\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.3460 - val_loss: 48.8937\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.4893 - val_loss: 33.6868\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.7366 - val_loss: 52.7925\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.9410 - val_loss: 29.3809\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.5024 - val_loss: 19.3231\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.1267 - val_loss: 21.1174\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.8170 - val_loss: 40.2952\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.0165 - val_loss: 20.0772\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.5756 - val_loss: 19.2936\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.2199 - val_loss: 41.0651\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.1533 - val_loss: 26.9953\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.0902 - val_loss: 28.7841\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.8748 - val_loss: 23.8372\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.1758 - val_loss: 25.7410\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.9286 - val_loss: 44.6073\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.4956 - val_loss: 56.8354\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 16.6289 - val_loss: 38.8405\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 15.6277 - val_loss: 27.6749\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.5006 - val_loss: 58.3754\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.6604 - val_loss: 49.3121\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.5931 - val_loss: 18.3453\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.7026 - val_loss: 22.7287\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 15.9089 - val_loss: 72.4585\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 15.9923 - val_loss: 39.5795\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.6234 - val_loss: 70.9698\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.3551 - val_loss: 26.6181\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.0353 - val_loss: 25.8625\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 14.3102 - val_loss: 18.6041\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 15.0712 - val_loss: 16.0385\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.8336 - val_loss: 20.2739\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.6151 - val_loss: 70.9257\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.2883 - val_loss: 21.0197\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 15.1786 - val_loss: 37.6921\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.1994 - val_loss: 30.4916\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.2187 - val_loss: 58.3522\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.3488 - val_loss: 25.0946\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.9463 - val_loss: 19.1455\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.5243 - val_loss: 23.4521\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.0704 - val_loss: 26.7142\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9063 - val_loss: 18.3634\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.3958 - val_loss: 21.4369\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.7516 - val_loss: 24.3405\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.2234 - val_loss: 25.5381\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.7709 - val_loss: 27.4553\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.7938 - val_loss: 43.4938\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.9370 - val_loss: 21.3735\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.2971 - val_loss: 25.3199\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.2515 - val_loss: 16.7423\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.9650 - val_loss: 25.8848\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.0500 - val_loss: 19.1297\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.0195 - val_loss: 27.0702\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.6556 - val_loss: 32.9489\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.5611 - val_loss: 22.4781\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.7464 - val_loss: 16.2504\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.9038 - val_loss: 23.0997\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.8537 - val_loss: 28.6266\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6868 - val_loss: 15.3347\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 2s 8ms/step - loss: 11.1648 - val_loss: 29.8286\n",
      "Epoch 80/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.4459 - val_loss: 40.7233\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.7446 - val_loss: 19.8061\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4047 - val_loss: 52.8300\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8114 - val_loss: 22.5382\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.3809 - val_loss: 27.0061\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.0822 - val_loss: 35.1404\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.2904 - val_loss: 18.5773\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.4126 - val_loss: 23.6184\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7490 - val_loss: 18.4688\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8208 - val_loss: 19.2355\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.6533 - val_loss: 28.1852\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 10.8227 - val_loss: 31.6219\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.4147 - val_loss: 25.3457\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 9.7802 - val_loss: 31.7942\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.1467 - val_loss: 16.7466\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 9.0694 - val_loss: 20.2370\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.3333 - val_loss: 31.8435\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 10.2476 - val_loss: 30.8693\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.2754 - val_loss: 21.3478\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.9537 - val_loss: 27.5032\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.1374 - val_loss: 19.2393\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.9184 - val_loss: 23.4280\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.2927 - val_loss: 21.3810\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.5409 - val_loss: 72.7848\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.3559 - val_loss: 38.3285\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.5866 - val_loss: 19.4237\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 8.8814 - val_loss: 21.0982\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.0722 - val_loss: 23.5859\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.5508 - val_loss: 17.6953\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 15.337161123754905\n",
      "Mean Absolute Error (MAE): 2.364456910554688\n",
      "Root Mean Squared Error (RMSE): 3.9162687757296366\n",
      "Time taken: 297.31203746795654\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 8s 13ms/step - loss: 1086.5914 - val_loss: 882.5798\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 709.9335 - val_loss: 576.8380\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 472.3185 - val_loss: 451.7454\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 315.2922 - val_loss: 343.5103\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 233.3487 - val_loss: 249.8272\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 162.2516 - val_loss: 203.0408\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 108.1743 - val_loss: 78.0674\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 65.0906 - val_loss: 82.0782\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 48.9445 - val_loss: 62.1911\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 41.8752 - val_loss: 39.8549\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 34.0509 - val_loss: 114.5004\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.1686 - val_loss: 51.2920\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.7941 - val_loss: 35.2684\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.3472 - val_loss: 24.8004\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.9415 - val_loss: 41.3226\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.8057 - val_loss: 56.4658\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.1941 - val_loss: 32.9828\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.5975 - val_loss: 32.7118\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 23.5026 - val_loss: 77.9169\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 22.3371 - val_loss: 29.8371\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.5439 - val_loss: 33.1144\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 22.5796 - val_loss: 46.4068\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.8392 - val_loss: 19.5591\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.4501 - val_loss: 24.1096\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 19.5012 - val_loss: 21.1892\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 20.0325 - val_loss: 17.6440\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 20.8882 - val_loss: 65.8453\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 19.5798 - val_loss: 37.7633\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 18.8938 - val_loss: 24.0341\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 18.9563 - val_loss: 23.4178\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 18.8817 - val_loss: 26.7022\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 18.1933 - val_loss: 20.9942\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.7925 - val_loss: 19.5349\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.4349 - val_loss: 38.9352\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.2124 - val_loss: 29.1072\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.4618 - val_loss: 21.9072\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.6052 - val_loss: 31.1871\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.3350 - val_loss: 26.9865\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.7652 - val_loss: 20.9984\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.9082 - val_loss: 37.3107\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.9265 - val_loss: 28.8517\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 16.5199 - val_loss: 65.2653\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.5324 - val_loss: 20.3318\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 15.9970 - val_loss: 18.8675\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.7266 - val_loss: 24.7133\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.3125 - val_loss: 22.0368\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.4998 - val_loss: 47.8423\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.8033 - val_loss: 30.6998\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 15.1970 - val_loss: 37.8503\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 15.1802 - val_loss: 106.8044\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.1168 - val_loss: 20.2942\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.5020 - val_loss: 32.7772\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.9622 - val_loss: 25.2181\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.4861 - val_loss: 16.7894\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.6581 - val_loss: 23.7580\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.7229 - val_loss: 40.0963\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 14.7464 - val_loss: 40.3382\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.5094 - val_loss: 26.8839\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.6997 - val_loss: 29.6418\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.9065 - val_loss: 30.7061\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.8812 - val_loss: 92.6402\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.9930 - val_loss: 60.7681\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.5403 - val_loss: 17.7895\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.8585 - val_loss: 26.6229\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 13.8591 - val_loss: 16.3239\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.5271 - val_loss: 23.5896\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.1088 - val_loss: 18.4653\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.5663 - val_loss: 18.4274\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.1904 - val_loss: 85.4296\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.5198 - val_loss: 27.1154\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.1522 - val_loss: 23.3658\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 13.5315 - val_loss: 18.7104\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.9586 - val_loss: 17.8078\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.6134 - val_loss: 26.2397\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1349 - val_loss: 20.2712\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.9616 - val_loss: 31.2152\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.9896 - val_loss: 32.7420\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.8294 - val_loss: 63.6586\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 3s 8ms/step - loss: 12.1227 - val_loss: 20.9048\n",
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.4772 - val_loss: 84.4748\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.9942 - val_loss: 31.2232\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.5428 - val_loss: 19.1361\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.1283 - val_loss: 24.8982\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.4521 - val_loss: 61.8021\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.9042 - val_loss: 18.2074\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.5094 - val_loss: 15.5991\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.9305 - val_loss: 15.5009\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.9686 - val_loss: 37.0554\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.8936 - val_loss: 19.0768\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.8736 - val_loss: 23.3142\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.6076 - val_loss: 25.1238\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.5908 - val_loss: 31.2613\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.6092 - val_loss: 29.4979\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.5787 - val_loss: 19.8410\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.7929 - val_loss: 18.8246\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.3111 - val_loss: 13.4278\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.0023 - val_loss: 22.9314\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.2178 - val_loss: 31.7239\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6153 - val_loss: 27.5678\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.6820 - val_loss: 21.4493\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 10.4440 - val_loss: 28.2298\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7881 - val_loss: 23.4908\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.0601 - val_loss: 25.3163\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8553 - val_loss: 24.3847\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.9835 - val_loss: 59.3259\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.4545 - val_loss: 14.1003\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.6531 - val_loss: 34.4259\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4625 - val_loss: 22.9837\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.6594 - val_loss: 42.9957\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.2566 - val_loss: 34.4266\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.9476 - val_loss: 18.1483\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.3467 - val_loss: 28.9095\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.9655 - val_loss: 23.0543\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 9.2121 - val_loss: 14.9979\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.2585 - val_loss: 83.1639\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.0975 - val_loss: 59.4353\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 8.9267 - val_loss: 28.4266\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.3345 - val_loss: 67.1584\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 8.1698 - val_loss: 20.8311\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.3518 - val_loss: 22.7764\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 9.4695 - val_loss: 19.6896\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.5949 - val_loss: 15.4300\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.7142 - val_loss: 20.7623\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.2342 - val_loss: 15.8475\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 8.2547 - val_loss: 26.7519\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.3557 - val_loss: 24.2772\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 13.427676141341381\n",
      "Mean Absolute Error (MAE): 2.190863883059168\n",
      "Root Mean Squared Error (RMSE): 3.66437936646049\n",
      "Time taken: 346.6872982978821\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 8s 12ms/step - loss: 1063.0690 - val_loss: 937.6114\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 634.9383 - val_loss: 537.9966\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 446.6330 - val_loss: 398.0592\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 366.7384 - val_loss: 363.8764\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 322.4699 - val_loss: 310.0467\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 275.5075 - val_loss: 244.3171\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 186.9201 - val_loss: 143.4836\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 102.7096 - val_loss: 238.2364\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 67.1146 - val_loss: 51.3303\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 49.9912 - val_loss: 40.9774\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 41.2306 - val_loss: 41.6908\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 38.6403 - val_loss: 36.1019\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.5140 - val_loss: 47.1104\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 31.5071 - val_loss: 32.9241\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.4337 - val_loss: 37.2796\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 28.1328 - val_loss: 44.3757\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.2478 - val_loss: 26.0134\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.0952 - val_loss: 56.7155\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.9256 - val_loss: 28.2928\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.6426 - val_loss: 29.5107\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.4251 - val_loss: 33.8635\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.8565 - val_loss: 21.1395\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.6722 - val_loss: 49.0790\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 21.8512 - val_loss: 21.9724\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.5881 - val_loss: 69.0742\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 20.2395 - val_loss: 26.3553\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.6838 - val_loss: 36.4375\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 21.4801 - val_loss: 35.9045\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 19.0608 - val_loss: 24.1451\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 19.6270 - val_loss: 22.7227\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 20.4495 - val_loss: 21.9231\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 20.6073 - val_loss: 44.6950\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 19.3671 - val_loss: 70.4584\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.9075 - val_loss: 29.8037\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.3800 - val_loss: 28.8989\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 17.5742 - val_loss: 49.9727\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.8228 - val_loss: 67.1298\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.0092 - val_loss: 29.0769\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.6849 - val_loss: 50.4029\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.3734 - val_loss: 46.5437\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.0286 - val_loss: 29.6127\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.3854 - val_loss: 30.8712\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.9421 - val_loss: 24.2857\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.6596 - val_loss: 30.3812\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.8302 - val_loss: 21.6991\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.3754 - val_loss: 33.9417\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.5829 - val_loss: 36.0410\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.0463 - val_loss: 17.6761\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.7329 - val_loss: 45.0949\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.9409 - val_loss: 21.7723\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.6712 - val_loss: 20.5538\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 15.5301 - val_loss: 16.4080\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.3508 - val_loss: 21.5805\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 15.2255 - val_loss: 34.7128\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.5642 - val_loss: 50.1064\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 14.3090 - val_loss: 30.0463\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.1560 - val_loss: 36.2883\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 14.0170 - val_loss: 39.4781\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.5777 - val_loss: 24.9009\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.0856 - val_loss: 32.7509\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.0429 - val_loss: 50.8527\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 14.1770 - val_loss: 20.3951\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 13.5349 - val_loss: 25.9106\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 13.4988 - val_loss: 21.8637\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 12.9562 - val_loss: 36.6340\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.4689 - val_loss: 38.3377\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.5666 - val_loss: 20.3573\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 12.7542 - val_loss: 34.6452\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 13.3770 - val_loss: 28.7882\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 12.2759 - val_loss: 20.3023\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.3878 - val_loss: 22.8821\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 12.2960 - val_loss: 26.0148\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 13.2777 - val_loss: 70.1117\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.8051 - val_loss: 43.7450\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.4347 - val_loss: 20.5148\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 12.0113 - val_loss: 16.3760\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 12.2427 - val_loss: 22.4497\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.9527 - val_loss: 16.0831\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 3s 10ms/step - loss: 12.2848 - val_loss: 16.5755\n",
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 11.5993 - val_loss: 33.5831\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.2591 - val_loss: 29.8762\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.4964 - val_loss: 27.6181\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 11.1440 - val_loss: 20.0601\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.0919 - val_loss: 17.8734\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.2695 - val_loss: 47.1629\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.8701 - val_loss: 20.0824\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 11.5845 - val_loss: 46.6609\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 10.4809 - val_loss: 60.8635\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 11.8995 - val_loss: 15.9969\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4009 - val_loss: 23.9750\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 10.5167 - val_loss: 42.5420\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 11.1049 - val_loss: 28.3278\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.6138 - val_loss: 38.1407\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.8516 - val_loss: 23.2657\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.3327 - val_loss: 18.7166\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.7421 - val_loss: 16.7359\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 9.9530 - val_loss: 24.6780\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.9385 - val_loss: 19.0121\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.8556 - val_loss: 17.3546\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.4732 - val_loss: 22.3395\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.3186 - val_loss: 22.7911\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.2665 - val_loss: 22.4577\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 10.0640 - val_loss: 26.0299\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.9406 - val_loss: 17.3437\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.2273 - val_loss: 31.0302\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.2935 - val_loss: 26.4861\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.4465 - val_loss: 28.5700\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 8.5522 - val_loss: 27.1469\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.2239 - val_loss: 18.0409\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 9.3887 - val_loss: 25.5738\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 8.2898 - val_loss: 31.8139\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.9135 - val_loss: 18.7005\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 9.1049 - val_loss: 36.8797\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 9.3398 - val_loss: 16.3874\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 8.2907 - val_loss: 15.8479\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.7623 - val_loss: 24.0318\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.9836 - val_loss: 35.6370\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.6346 - val_loss: 22.1755\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 7.8979 - val_loss: 18.7526\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 7.4240 - val_loss: 24.3237\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 9.1312 - val_loss: 31.5365\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 9.0651 - val_loss: 16.4821\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.7776 - val_loss: 16.7429\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.7140 - val_loss: 41.4158\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.9323 - val_loss: 17.9314\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.4054 - val_loss: 16.2792\n",
      "Epoch 127/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 8.8697 - val_loss: 49.0598\n",
      "Epoch 128/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0126 - val_loss: 16.3295\n",
      "Epoch 129/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.9015 - val_loss: 23.0053\n",
      "Epoch 130/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 7.5052 - val_loss: 46.4793\n",
      "Epoch 131/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.0702 - val_loss: 45.8970\n",
      "Epoch 132/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.6757 - val_loss: 24.0384\n",
      "Epoch 133/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 6.5242 - val_loss: 23.3827\n",
      "Epoch 134/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 7.7482 - val_loss: 18.7415\n",
      "Epoch 135/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.8897 - val_loss: 20.6226\n",
      "Epoch 136/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.9311 - val_loss: 38.9372\n",
      "Epoch 137/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 7.5074 - val_loss: 18.3900\n",
      "Epoch 138/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.0881 - val_loss: 43.8876\n",
      "Epoch 139/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.4281 - val_loss: 24.2717\n",
      "Epoch 140/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 6.3485 - val_loss: 40.0129\n",
      "Epoch 141/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.6340 - val_loss: 18.6359\n",
      "Epoch 142/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.7460 - val_loss: 25.0861\n",
      "Epoch 143/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 6.4791 - val_loss: 22.2000\n",
      "Epoch 144/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 6.5307 - val_loss: 26.8886\n",
      "Epoch 145/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 5.8679 - val_loss: 17.4887\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 15.847799005371876\n",
      "Mean Absolute Error (MAE): 2.2762909480846463\n",
      "Root Mean Squared Error (RMSE): 3.9809294147688523\n",
      "Time taken: 408.10953307151794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=6,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 16, 512)           1052672   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16, 512)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 16, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,047,747\n",
      "Trainable params: 2,046,723\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_15216\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold        MSE       MAE      RMSE  Time taken\n",
      "0        1  14.981775  2.357352  3.870630  298.657664\n",
      "1        2  20.173454  3.092511  4.491487  168.026851\n",
      "2        3  15.337161  2.364457  3.916269  297.312037\n",
      "3        4  13.427676  2.190864  3.664379  346.687298\n",
      "4        5  15.847799  2.276291  3.980929  408.109533\n",
      "5  Average  15.953573  2.456295  3.984739  303.758677\n",
      "Results saved to 'LSTM Results PL_model_1_Scattered_iReg_f_obese.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('LSTM Results PL_model_1_Scattered_iReg_f_obese.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'LSTM Results PL_model_1_Scattered_iReg_f_obese.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
