{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_smoothing2_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.722102</td>\n",
       "      <td>133.549604</td>\n",
       "      <td>70.246654</td>\n",
       "      <td>114.393425</td>\n",
       "      <td>125.518042</td>\n",
       "      <td>148.490719</td>\n",
       "      <td>105.960735</td>\n",
       "      <td>134.734917</td>\n",
       "      <td>90.358364</td>\n",
       "      <td>107.880691</td>\n",
       "      <td>...</td>\n",
       "      <td>80.511088</td>\n",
       "      <td>86.266577</td>\n",
       "      <td>91.324276</td>\n",
       "      <td>88.413835</td>\n",
       "      <td>118.079357</td>\n",
       "      <td>112.830599</td>\n",
       "      <td>101.581432</td>\n",
       "      <td>130.484864</td>\n",
       "      <td>65.849519</td>\n",
       "      <td>112.853971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.741769</td>\n",
       "      <td>133.613840</td>\n",
       "      <td>70.333167</td>\n",
       "      <td>114.403077</td>\n",
       "      <td>125.425263</td>\n",
       "      <td>148.406322</td>\n",
       "      <td>105.788181</td>\n",
       "      <td>134.546280</td>\n",
       "      <td>90.431246</td>\n",
       "      <td>107.970290</td>\n",
       "      <td>...</td>\n",
       "      <td>80.667880</td>\n",
       "      <td>86.301348</td>\n",
       "      <td>91.369136</td>\n",
       "      <td>88.468505</td>\n",
       "      <td>117.851056</td>\n",
       "      <td>112.732842</td>\n",
       "      <td>101.535137</td>\n",
       "      <td>130.422780</td>\n",
       "      <td>65.831506</td>\n",
       "      <td>112.816370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.759517</td>\n",
       "      <td>133.678503</td>\n",
       "      <td>70.421559</td>\n",
       "      <td>114.410863</td>\n",
       "      <td>125.331731</td>\n",
       "      <td>148.320508</td>\n",
       "      <td>105.613823</td>\n",
       "      <td>134.358052</td>\n",
       "      <td>90.503448</td>\n",
       "      <td>108.058270</td>\n",
       "      <td>...</td>\n",
       "      <td>80.823085</td>\n",
       "      <td>86.337129</td>\n",
       "      <td>91.414783</td>\n",
       "      <td>88.521309</td>\n",
       "      <td>117.621052</td>\n",
       "      <td>112.638386</td>\n",
       "      <td>101.491179</td>\n",
       "      <td>130.363766</td>\n",
       "      <td>65.812886</td>\n",
       "      <td>112.778795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.775461</td>\n",
       "      <td>133.743510</td>\n",
       "      <td>70.511477</td>\n",
       "      <td>114.417015</td>\n",
       "      <td>125.237166</td>\n",
       "      <td>148.233207</td>\n",
       "      <td>105.437718</td>\n",
       "      <td>134.170555</td>\n",
       "      <td>90.574876</td>\n",
       "      <td>108.144722</td>\n",
       "      <td>...</td>\n",
       "      <td>80.976531</td>\n",
       "      <td>86.373826</td>\n",
       "      <td>91.461416</td>\n",
       "      <td>88.572363</td>\n",
       "      <td>117.389684</td>\n",
       "      <td>112.547228</td>\n",
       "      <td>101.449812</td>\n",
       "      <td>130.307871</td>\n",
       "      <td>65.793756</td>\n",
       "      <td>112.741332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.789800</td>\n",
       "      <td>133.808609</td>\n",
       "      <td>70.602435</td>\n",
       "      <td>114.421924</td>\n",
       "      <td>125.141318</td>\n",
       "      <td>148.144403</td>\n",
       "      <td>105.260017</td>\n",
       "      <td>133.984101</td>\n",
       "      <td>90.645256</td>\n",
       "      <td>108.229792</td>\n",
       "      <td>...</td>\n",
       "      <td>81.128195</td>\n",
       "      <td>86.411394</td>\n",
       "      <td>91.509328</td>\n",
       "      <td>88.621720</td>\n",
       "      <td>117.157444</td>\n",
       "      <td>112.459148</td>\n",
       "      <td>101.411458</td>\n",
       "      <td>130.254975</td>\n",
       "      <td>65.774054</td>\n",
       "      <td>112.703922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>128.394731</td>\n",
       "      <td>113.120062</td>\n",
       "      <td>102.722429</td>\n",
       "      <td>71.609424</td>\n",
       "      <td>151.352281</td>\n",
       "      <td>140.904922</td>\n",
       "      <td>128.827778</td>\n",
       "      <td>113.779812</td>\n",
       "      <td>107.558742</td>\n",
       "      <td>96.997103</td>\n",
       "      <td>...</td>\n",
       "      <td>88.095891</td>\n",
       "      <td>110.712051</td>\n",
       "      <td>89.522396</td>\n",
       "      <td>71.221952</td>\n",
       "      <td>124.108295</td>\n",
       "      <td>113.383110</td>\n",
       "      <td>130.244963</td>\n",
       "      <td>114.622501</td>\n",
       "      <td>107.532818</td>\n",
       "      <td>76.703086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>128.269154</td>\n",
       "      <td>112.982064</td>\n",
       "      <td>102.785866</td>\n",
       "      <td>71.581983</td>\n",
       "      <td>151.277725</td>\n",
       "      <td>140.892099</td>\n",
       "      <td>128.842679</td>\n",
       "      <td>113.832694</td>\n",
       "      <td>107.410332</td>\n",
       "      <td>96.815164</td>\n",
       "      <td>...</td>\n",
       "      <td>88.034588</td>\n",
       "      <td>110.548388</td>\n",
       "      <td>89.310220</td>\n",
       "      <td>71.379769</td>\n",
       "      <td>124.099541</td>\n",
       "      <td>113.470836</td>\n",
       "      <td>130.083759</td>\n",
       "      <td>114.395532</td>\n",
       "      <td>107.742386</td>\n",
       "      <td>76.682848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>128.143792</td>\n",
       "      <td>112.844766</td>\n",
       "      <td>102.852637</td>\n",
       "      <td>71.555953</td>\n",
       "      <td>151.200817</td>\n",
       "      <td>140.880374</td>\n",
       "      <td>128.857569</td>\n",
       "      <td>113.886728</td>\n",
       "      <td>107.258332</td>\n",
       "      <td>96.632920</td>\n",
       "      <td>...</td>\n",
       "      <td>87.974760</td>\n",
       "      <td>110.380633</td>\n",
       "      <td>89.095824</td>\n",
       "      <td>71.538448</td>\n",
       "      <td>124.091471</td>\n",
       "      <td>113.557163</td>\n",
       "      <td>129.920154</td>\n",
       "      <td>114.165400</td>\n",
       "      <td>107.949968</td>\n",
       "      <td>76.663408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>128.018936</td>\n",
       "      <td>112.708365</td>\n",
       "      <td>102.922962</td>\n",
       "      <td>71.531847</td>\n",
       "      <td>151.121227</td>\n",
       "      <td>140.870082</td>\n",
       "      <td>128.872267</td>\n",
       "      <td>113.942389</td>\n",
       "      <td>107.102486</td>\n",
       "      <td>96.450473</td>\n",
       "      <td>...</td>\n",
       "      <td>87.916419</td>\n",
       "      <td>110.208561</td>\n",
       "      <td>88.879379</td>\n",
       "      <td>71.697850</td>\n",
       "      <td>124.084220</td>\n",
       "      <td>113.641886</td>\n",
       "      <td>129.753926</td>\n",
       "      <td>113.932214</td>\n",
       "      <td>108.155353</td>\n",
       "      <td>76.644759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>127.894929</td>\n",
       "      <td>112.572888</td>\n",
       "      <td>102.996952</td>\n",
       "      <td>71.509933</td>\n",
       "      <td>151.038840</td>\n",
       "      <td>140.861436</td>\n",
       "      <td>128.886554</td>\n",
       "      <td>113.999895</td>\n",
       "      <td>106.942607</td>\n",
       "      <td>96.267932</td>\n",
       "      <td>...</td>\n",
       "      <td>87.859482</td>\n",
       "      <td>110.032132</td>\n",
       "      <td>88.660934</td>\n",
       "      <td>71.857879</td>\n",
       "      <td>124.077867</td>\n",
       "      <td>113.725050</td>\n",
       "      <td>129.584939</td>\n",
       "      <td>113.696233</td>\n",
       "      <td>108.358487</td>\n",
       "      <td>76.626723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     103.722102  133.549604   70.246654  114.393425  125.518042  148.490719   \n",
       "1     103.741769  133.613840   70.333167  114.403077  125.425263  148.406322   \n",
       "2     103.759517  133.678503   70.421559  114.410863  125.331731  148.320508   \n",
       "3     103.775461  133.743510   70.511477  114.417015  125.237166  148.233207   \n",
       "4     103.789800  133.808609   70.602435  114.421924  125.141318  148.144403   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  128.394731  113.120062  102.722429   71.609424  151.352281  140.904922   \n",
       "2439  128.269154  112.982064  102.785866   71.581983  151.277725  140.892099   \n",
       "2440  128.143792  112.844766  102.852637   71.555953  151.200817  140.880374   \n",
       "2441  128.018936  112.708365  102.922962   71.531847  151.121227  140.870082   \n",
       "2442  127.894929  112.572888  102.996952   71.509933  151.038840  140.861436   \n",
       "\n",
       "              6           7           8           9   ...         38  \\\n",
       "0     105.960735  134.734917   90.358364  107.880691  ...  80.511088   \n",
       "1     105.788181  134.546280   90.431246  107.970290  ...  80.667880   \n",
       "2     105.613823  134.358052   90.503448  108.058270  ...  80.823085   \n",
       "3     105.437718  134.170555   90.574876  108.144722  ...  80.976531   \n",
       "4     105.260017  133.984101   90.645256  108.229792  ...  81.128195   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  128.827778  113.779812  107.558742   96.997103  ...  88.095891   \n",
       "2439  128.842679  113.832694  107.410332   96.815164  ...  88.034588   \n",
       "2440  128.857569  113.886728  107.258332   96.632920  ...  87.974760   \n",
       "2441  128.872267  113.942389  107.102486   96.450473  ...  87.916419   \n",
       "2442  128.886554  113.999895  106.942607   96.267932  ...  87.859482   \n",
       "\n",
       "              39         40         41          42          43          44  \\\n",
       "0      86.266577  91.324276  88.413835  118.079357  112.830599  101.581432   \n",
       "1      86.301348  91.369136  88.468505  117.851056  112.732842  101.535137   \n",
       "2      86.337129  91.414783  88.521309  117.621052  112.638386  101.491179   \n",
       "3      86.373826  91.461416  88.572363  117.389684  112.547228  101.449812   \n",
       "4      86.411394  91.509328  88.621720  117.157444  112.459148  101.411458   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  110.712051  89.522396  71.221952  124.108295  113.383110  130.244963   \n",
       "2439  110.548388  89.310220  71.379769  124.099541  113.470836  130.083759   \n",
       "2440  110.380633  89.095824  71.538448  124.091471  113.557163  129.920154   \n",
       "2441  110.208561  88.879379  71.697850  124.084220  113.641886  129.753926   \n",
       "2442  110.032132  88.660934  71.857879  124.077867  113.725050  129.584939   \n",
       "\n",
       "              45          46          47  \n",
       "0     130.484864   65.849519  112.853971  \n",
       "1     130.422780   65.831506  112.816370  \n",
       "2     130.363766   65.812886  112.778795  \n",
       "3     130.307871   65.793756  112.741332  \n",
       "4     130.254975   65.774054  112.703922  \n",
       "...          ...         ...         ...  \n",
       "2438  114.622501  107.532818   76.703086  \n",
       "2439  114.395532  107.742386   76.682848  \n",
       "2440  114.165400  107.949968   76.663408  \n",
       "2441  113.932214  108.155353   76.644759  \n",
       "2442  113.696233  108.358487   76.626723  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.722102</td>\n",
       "      <td>133.549604</td>\n",
       "      <td>70.246654</td>\n",
       "      <td>114.393425</td>\n",
       "      <td>125.518042</td>\n",
       "      <td>148.490719</td>\n",
       "      <td>105.960735</td>\n",
       "      <td>134.734917</td>\n",
       "      <td>90.358364</td>\n",
       "      <td>107.880691</td>\n",
       "      <td>...</td>\n",
       "      <td>80.511088</td>\n",
       "      <td>86.266577</td>\n",
       "      <td>91.324276</td>\n",
       "      <td>88.413835</td>\n",
       "      <td>118.079357</td>\n",
       "      <td>112.830599</td>\n",
       "      <td>101.581432</td>\n",
       "      <td>130.484864</td>\n",
       "      <td>65.849519</td>\n",
       "      <td>112.853971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.741769</td>\n",
       "      <td>133.613840</td>\n",
       "      <td>70.333167</td>\n",
       "      <td>114.403077</td>\n",
       "      <td>125.425263</td>\n",
       "      <td>148.406322</td>\n",
       "      <td>105.788181</td>\n",
       "      <td>134.546280</td>\n",
       "      <td>90.431246</td>\n",
       "      <td>107.970290</td>\n",
       "      <td>...</td>\n",
       "      <td>80.667880</td>\n",
       "      <td>86.301348</td>\n",
       "      <td>91.369136</td>\n",
       "      <td>88.468505</td>\n",
       "      <td>117.851056</td>\n",
       "      <td>112.732842</td>\n",
       "      <td>101.535137</td>\n",
       "      <td>130.422780</td>\n",
       "      <td>65.831506</td>\n",
       "      <td>112.816370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.759517</td>\n",
       "      <td>133.678503</td>\n",
       "      <td>70.421559</td>\n",
       "      <td>114.410863</td>\n",
       "      <td>125.331731</td>\n",
       "      <td>148.320508</td>\n",
       "      <td>105.613823</td>\n",
       "      <td>134.358052</td>\n",
       "      <td>90.503448</td>\n",
       "      <td>108.058270</td>\n",
       "      <td>...</td>\n",
       "      <td>80.823085</td>\n",
       "      <td>86.337129</td>\n",
       "      <td>91.414783</td>\n",
       "      <td>88.521309</td>\n",
       "      <td>117.621052</td>\n",
       "      <td>112.638386</td>\n",
       "      <td>101.491179</td>\n",
       "      <td>130.363766</td>\n",
       "      <td>65.812886</td>\n",
       "      <td>112.778795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.775461</td>\n",
       "      <td>133.743510</td>\n",
       "      <td>70.511477</td>\n",
       "      <td>114.417015</td>\n",
       "      <td>125.237166</td>\n",
       "      <td>148.233207</td>\n",
       "      <td>105.437718</td>\n",
       "      <td>134.170555</td>\n",
       "      <td>90.574876</td>\n",
       "      <td>108.144722</td>\n",
       "      <td>...</td>\n",
       "      <td>80.976531</td>\n",
       "      <td>86.373826</td>\n",
       "      <td>91.461416</td>\n",
       "      <td>88.572363</td>\n",
       "      <td>117.389684</td>\n",
       "      <td>112.547228</td>\n",
       "      <td>101.449812</td>\n",
       "      <td>130.307871</td>\n",
       "      <td>65.793756</td>\n",
       "      <td>112.741332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.789800</td>\n",
       "      <td>133.808609</td>\n",
       "      <td>70.602435</td>\n",
       "      <td>114.421924</td>\n",
       "      <td>125.141318</td>\n",
       "      <td>148.144403</td>\n",
       "      <td>105.260017</td>\n",
       "      <td>133.984101</td>\n",
       "      <td>90.645256</td>\n",
       "      <td>108.229792</td>\n",
       "      <td>...</td>\n",
       "      <td>81.128195</td>\n",
       "      <td>86.411394</td>\n",
       "      <td>91.509328</td>\n",
       "      <td>88.621720</td>\n",
       "      <td>117.157444</td>\n",
       "      <td>112.459148</td>\n",
       "      <td>101.411458</td>\n",
       "      <td>130.254975</td>\n",
       "      <td>65.774054</td>\n",
       "      <td>112.703922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>128.394731</td>\n",
       "      <td>113.120062</td>\n",
       "      <td>102.722429</td>\n",
       "      <td>71.609424</td>\n",
       "      <td>151.352281</td>\n",
       "      <td>140.904922</td>\n",
       "      <td>128.827778</td>\n",
       "      <td>113.779812</td>\n",
       "      <td>107.558742</td>\n",
       "      <td>96.997103</td>\n",
       "      <td>...</td>\n",
       "      <td>88.095891</td>\n",
       "      <td>110.712051</td>\n",
       "      <td>89.522396</td>\n",
       "      <td>71.221952</td>\n",
       "      <td>124.108295</td>\n",
       "      <td>113.383110</td>\n",
       "      <td>130.244963</td>\n",
       "      <td>114.622501</td>\n",
       "      <td>107.532818</td>\n",
       "      <td>76.703086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>128.269154</td>\n",
       "      <td>112.982064</td>\n",
       "      <td>102.785866</td>\n",
       "      <td>71.581983</td>\n",
       "      <td>151.277725</td>\n",
       "      <td>140.892099</td>\n",
       "      <td>128.842679</td>\n",
       "      <td>113.832694</td>\n",
       "      <td>107.410332</td>\n",
       "      <td>96.815164</td>\n",
       "      <td>...</td>\n",
       "      <td>88.034588</td>\n",
       "      <td>110.548388</td>\n",
       "      <td>89.310220</td>\n",
       "      <td>71.379769</td>\n",
       "      <td>124.099541</td>\n",
       "      <td>113.470836</td>\n",
       "      <td>130.083759</td>\n",
       "      <td>114.395532</td>\n",
       "      <td>107.742386</td>\n",
       "      <td>76.682848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>128.143792</td>\n",
       "      <td>112.844766</td>\n",
       "      <td>102.852637</td>\n",
       "      <td>71.555953</td>\n",
       "      <td>151.200817</td>\n",
       "      <td>140.880374</td>\n",
       "      <td>128.857569</td>\n",
       "      <td>113.886728</td>\n",
       "      <td>107.258332</td>\n",
       "      <td>96.632920</td>\n",
       "      <td>...</td>\n",
       "      <td>87.974760</td>\n",
       "      <td>110.380633</td>\n",
       "      <td>89.095824</td>\n",
       "      <td>71.538448</td>\n",
       "      <td>124.091471</td>\n",
       "      <td>113.557163</td>\n",
       "      <td>129.920154</td>\n",
       "      <td>114.165400</td>\n",
       "      <td>107.949968</td>\n",
       "      <td>76.663408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>128.018936</td>\n",
       "      <td>112.708365</td>\n",
       "      <td>102.922962</td>\n",
       "      <td>71.531847</td>\n",
       "      <td>151.121227</td>\n",
       "      <td>140.870082</td>\n",
       "      <td>128.872267</td>\n",
       "      <td>113.942389</td>\n",
       "      <td>107.102486</td>\n",
       "      <td>96.450473</td>\n",
       "      <td>...</td>\n",
       "      <td>87.916419</td>\n",
       "      <td>110.208561</td>\n",
       "      <td>88.879379</td>\n",
       "      <td>71.697850</td>\n",
       "      <td>124.084220</td>\n",
       "      <td>113.641886</td>\n",
       "      <td>129.753926</td>\n",
       "      <td>113.932214</td>\n",
       "      <td>108.155353</td>\n",
       "      <td>76.644759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>127.894929</td>\n",
       "      <td>112.572888</td>\n",
       "      <td>102.996952</td>\n",
       "      <td>71.509933</td>\n",
       "      <td>151.038840</td>\n",
       "      <td>140.861436</td>\n",
       "      <td>128.886554</td>\n",
       "      <td>113.999895</td>\n",
       "      <td>106.942607</td>\n",
       "      <td>96.267932</td>\n",
       "      <td>...</td>\n",
       "      <td>87.859482</td>\n",
       "      <td>110.032132</td>\n",
       "      <td>88.660934</td>\n",
       "      <td>71.857879</td>\n",
       "      <td>124.077867</td>\n",
       "      <td>113.725050</td>\n",
       "      <td>129.584939</td>\n",
       "      <td>113.696233</td>\n",
       "      <td>108.358487</td>\n",
       "      <td>76.626723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     103.722102  133.549604   70.246654  114.393425  125.518042  148.490719   \n",
       "1     103.741769  133.613840   70.333167  114.403077  125.425263  148.406322   \n",
       "2     103.759517  133.678503   70.421559  114.410863  125.331731  148.320508   \n",
       "3     103.775461  133.743510   70.511477  114.417015  125.237166  148.233207   \n",
       "4     103.789800  133.808609   70.602435  114.421924  125.141318  148.144403   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  128.394731  113.120062  102.722429   71.609424  151.352281  140.904922   \n",
       "2439  128.269154  112.982064  102.785866   71.581983  151.277725  140.892099   \n",
       "2440  128.143792  112.844766  102.852637   71.555953  151.200817  140.880374   \n",
       "2441  128.018936  112.708365  102.922962   71.531847  151.121227  140.870082   \n",
       "2442  127.894929  112.572888  102.996952   71.509933  151.038840  140.861436   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...   sensor39  \\\n",
       "0     105.960735  134.734917   90.358364  107.880691  ...  80.511088   \n",
       "1     105.788181  134.546280   90.431246  107.970290  ...  80.667880   \n",
       "2     105.613823  134.358052   90.503448  108.058270  ...  80.823085   \n",
       "3     105.437718  134.170555   90.574876  108.144722  ...  80.976531   \n",
       "4     105.260017  133.984101   90.645256  108.229792  ...  81.128195   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  128.827778  113.779812  107.558742   96.997103  ...  88.095891   \n",
       "2439  128.842679  113.832694  107.410332   96.815164  ...  88.034588   \n",
       "2440  128.857569  113.886728  107.258332   96.632920  ...  87.974760   \n",
       "2441  128.872267  113.942389  107.102486   96.450473  ...  87.916419   \n",
       "2442  128.886554  113.999895  106.942607   96.267932  ...  87.859482   \n",
       "\n",
       "        sensor40   sensor41   sensor42    sensor43    sensor44    sensor45  \\\n",
       "0      86.266577  91.324276  88.413835  118.079357  112.830599  101.581432   \n",
       "1      86.301348  91.369136  88.468505  117.851056  112.732842  101.535137   \n",
       "2      86.337129  91.414783  88.521309  117.621052  112.638386  101.491179   \n",
       "3      86.373826  91.461416  88.572363  117.389684  112.547228  101.449812   \n",
       "4      86.411394  91.509328  88.621720  117.157444  112.459148  101.411458   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  110.712051  89.522396  71.221952  124.108295  113.383110  130.244963   \n",
       "2439  110.548388  89.310220  71.379769  124.099541  113.470836  130.083759   \n",
       "2440  110.380633  89.095824  71.538448  124.091471  113.557163  129.920154   \n",
       "2441  110.208561  88.879379  71.697850  124.084220  113.641886  129.753926   \n",
       "2442  110.032132  88.660934  71.857879  124.077867  113.725050  129.584939   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     130.484864   65.849519  112.853971  \n",
       "1     130.422780   65.831506  112.816370  \n",
       "2     130.363766   65.812886  112.778795  \n",
       "3     130.307871   65.793756  112.741332  \n",
       "4     130.254975   65.774054  112.703922  \n",
       "...          ...         ...         ...  \n",
       "2438  114.622501  107.532818   76.703086  \n",
       "2439  114.395532  107.742386   76.682848  \n",
       "2440  114.165400  107.949968   76.663408  \n",
       "2441  113.932214  108.155353   76.644759  \n",
       "2442  113.696233  108.358487   76.626723  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf63fe",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090b68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.722102</td>\n",
       "      <td>133.549604</td>\n",
       "      <td>70.246654</td>\n",
       "      <td>114.393425</td>\n",
       "      <td>125.518042</td>\n",
       "      <td>148.490719</td>\n",
       "      <td>105.960735</td>\n",
       "      <td>134.734917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.741769</td>\n",
       "      <td>133.613840</td>\n",
       "      <td>70.333167</td>\n",
       "      <td>114.403077</td>\n",
       "      <td>125.425263</td>\n",
       "      <td>148.406322</td>\n",
       "      <td>105.788181</td>\n",
       "      <td>134.546280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.759517</td>\n",
       "      <td>133.678503</td>\n",
       "      <td>70.421559</td>\n",
       "      <td>114.410863</td>\n",
       "      <td>125.331731</td>\n",
       "      <td>148.320508</td>\n",
       "      <td>105.613823</td>\n",
       "      <td>134.358052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.775461</td>\n",
       "      <td>133.743510</td>\n",
       "      <td>70.511477</td>\n",
       "      <td>114.417015</td>\n",
       "      <td>125.237166</td>\n",
       "      <td>148.233207</td>\n",
       "      <td>105.437718</td>\n",
       "      <td>134.170555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.789800</td>\n",
       "      <td>133.808609</td>\n",
       "      <td>70.602435</td>\n",
       "      <td>114.421924</td>\n",
       "      <td>125.141318</td>\n",
       "      <td>148.144403</td>\n",
       "      <td>105.260017</td>\n",
       "      <td>133.984101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>128.394731</td>\n",
       "      <td>113.120062</td>\n",
       "      <td>102.722429</td>\n",
       "      <td>71.609424</td>\n",
       "      <td>151.352281</td>\n",
       "      <td>140.904922</td>\n",
       "      <td>128.827778</td>\n",
       "      <td>113.779812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>128.269154</td>\n",
       "      <td>112.982064</td>\n",
       "      <td>102.785866</td>\n",
       "      <td>71.581983</td>\n",
       "      <td>151.277725</td>\n",
       "      <td>140.892099</td>\n",
       "      <td>128.842679</td>\n",
       "      <td>113.832694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>128.143792</td>\n",
       "      <td>112.844766</td>\n",
       "      <td>102.852637</td>\n",
       "      <td>71.555953</td>\n",
       "      <td>151.200817</td>\n",
       "      <td>140.880374</td>\n",
       "      <td>128.857569</td>\n",
       "      <td>113.886728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>128.018936</td>\n",
       "      <td>112.708365</td>\n",
       "      <td>102.922962</td>\n",
       "      <td>71.531847</td>\n",
       "      <td>151.121227</td>\n",
       "      <td>140.870082</td>\n",
       "      <td>128.872267</td>\n",
       "      <td>113.942389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>127.894929</td>\n",
       "      <td>112.572888</td>\n",
       "      <td>102.996952</td>\n",
       "      <td>71.509933</td>\n",
       "      <td>151.038840</td>\n",
       "      <td>140.861436</td>\n",
       "      <td>128.886554</td>\n",
       "      <td>113.999895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     103.722102  133.549604   70.246654  114.393425  125.518042  148.490719   \n",
       "1     103.741769  133.613840   70.333167  114.403077  125.425263  148.406322   \n",
       "2     103.759517  133.678503   70.421559  114.410863  125.331731  148.320508   \n",
       "3     103.775461  133.743510   70.511477  114.417015  125.237166  148.233207   \n",
       "4     103.789800  133.808609   70.602435  114.421924  125.141318  148.144403   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  128.394731  113.120062  102.722429   71.609424  151.352281  140.904922   \n",
       "2439  128.269154  112.982064  102.785866   71.581983  151.277725  140.892099   \n",
       "2440  128.143792  112.844766  102.852637   71.555953  151.200817  140.880374   \n",
       "2441  128.018936  112.708365  102.922962   71.531847  151.121227  140.870082   \n",
       "2442  127.894929  112.572888  102.996952   71.509933  151.038840  140.861436   \n",
       "\n",
       "         sensor7     sensor8  \n",
       "0     105.960735  134.734917  \n",
       "1     105.788181  134.546280  \n",
       "2     105.613823  134.358052  \n",
       "3     105.437718  134.170555  \n",
       "4     105.260017  133.984101  \n",
       "...          ...         ...  \n",
       "2438  128.827778  113.779812  \n",
       "2439  128.842679  113.832694  \n",
       "2440  128.857569  113.886728  \n",
       "2441  128.872267  113.942389  \n",
       "2442  128.886554  113.999895  \n",
       "\n",
       "[2443 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:8]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 9s 12ms/step - loss: 1364.1110 - val_loss: 1281.8174\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1198.6521 - val_loss: 1181.4384\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1115.2977 - val_loss: 1106.2997\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1051.2909 - val_loss: 1048.9421\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1001.3517 - val_loss: 1012.9335\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 966.8133 - val_loss: 959.4188\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 911.7217 - val_loss: 903.3059\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 857.5511 - val_loss: 856.1100\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 806.5518 - val_loss: 801.5391\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 750.0785 - val_loss: 744.8959\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 698.5916 - val_loss: 698.0886\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 647.5511 - val_loss: 641.9973\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 591.6859 - val_loss: 586.4266\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 541.5768 - val_loss: 536.9175\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 493.8058 - val_loss: 489.6458\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 451.9876 - val_loss: 449.2570\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 412.6164 - val_loss: 405.4000\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 373.2681 - val_loss: 365.1834\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 335.7585 - val_loss: 330.6895\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 303.4380 - val_loss: 297.3062\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 270.8562 - val_loss: 265.6909\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 241.0042 - val_loss: 235.5636\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 215.0320 - val_loss: 211.9697\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 191.0827 - val_loss: 187.5234\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 169.5639 - val_loss: 165.0955\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 150.0368 - val_loss: 145.2689\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 133.6069 - val_loss: 127.6641\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 115.6472 - val_loss: 111.8658\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 100.9912 - val_loss: 96.7335\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 89.3931 - val_loss: 83.6034\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 74.9735 - val_loss: 71.8448\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 64.9943 - val_loss: 62.3637\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 55.7406 - val_loss: 55.1760\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 48.6982 - val_loss: 45.6200\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 40.2800 - val_loss: 38.1026\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 34.7696 - val_loss: 32.7576\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 29.4063 - val_loss: 28.4111\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 27.8637 - val_loss: 22.6484\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 20.6186 - val_loss: 19.7808\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 18.0945 - val_loss: 16.1476\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 16.9309 - val_loss: 20.3426\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 14.0757 - val_loss: 11.2974\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 10.6419 - val_loss: 9.7869\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 9.4840 - val_loss: 10.6094\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 7.8046 - val_loss: 7.7967\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 7.4454 - val_loss: 6.5088\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 6.0980 - val_loss: 5.4429\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 4.6279 - val_loss: 4.1281\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 4.3140 - val_loss: 2.9680\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 4.5006 - val_loss: 2.7472\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.6419 - val_loss: 1.9875\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 2.8109 - val_loss: 7.4609\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 2.6044 - val_loss: 2.7198\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.6728 - val_loss: 2.2111\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.3761 - val_loss: 2.5049\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.1737 - val_loss: 1.2536\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.2614 - val_loss: 1.8160\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.7019 - val_loss: 2.5646\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.3000 - val_loss: 0.8550\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.2996 - val_loss: 1.9699\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9166 - val_loss: 0.9045\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.1276 - val_loss: 0.4171\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0464 - val_loss: 0.5710\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.5469 - val_loss: 0.5655\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 3.2671 - val_loss: 1.3758\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5731 - val_loss: 0.4257\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4029 - val_loss: 0.3424\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6162 - val_loss: 0.5842\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.3415 - val_loss: 2.0717\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8922 - val_loss: 0.4616\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6346 - val_loss: 0.9514\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.7256 - val_loss: 0.3949\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.1903 - val_loss: 2.5928\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7587 - val_loss: 0.9156\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9932 - val_loss: 0.6795\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9935 - val_loss: 1.0688\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6664 - val_loss: 0.2836\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6513 - val_loss: 1.0610\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6340 - val_loss: 2.6797\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 3s 7ms/step - loss: 1.1842 - val_loss: 1.0069\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9399 - val_loss: 2.1222\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6722 - val_loss: 0.3402\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 3.7055 - val_loss: 0.8365\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3575 - val_loss: 0.2187\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3632 - val_loss: 0.4672\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3812 - val_loss: 0.2555\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.7573 - val_loss: 0.4692\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6332 - val_loss: 0.4542\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.9926 - val_loss: 0.7258\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.6018 - val_loss: 0.5075\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3117 - val_loss: 0.3459\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.8791 - val_loss: 1.8735\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.4284 - val_loss: 0.7561\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5054 - val_loss: 0.5644\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5041 - val_loss: 0.1713\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3196 - val_loss: 0.4619\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 3.8952 - val_loss: 0.3017\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1759 - val_loss: 0.1784\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1815 - val_loss: 0.2151\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7163 - val_loss: 0.7301\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2534 - val_loss: 0.1892\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.5158 - val_loss: 1.0917\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5085 - val_loss: 0.2625\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1697 - val_loss: 0.3635\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4981 - val_loss: 0.4332\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5355 - val_loss: 5.0497\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.0135 - val_loss: 0.2947\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2726 - val_loss: 0.2868\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.3096 - val_loss: 0.5996\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2935 - val_loss: 0.1220\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.9914 - val_loss: 0.5524\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3980 - val_loss: 1.5568\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 3.5486 - val_loss: 0.1945\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1340 - val_loss: 0.0815\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1046 - val_loss: 0.3828\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2260 - val_loss: 0.3085\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2083 - val_loss: 0.1467\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.7707 - val_loss: 0.1848\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3809 - val_loss: 0.3772\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7382 - val_loss: 0.2165\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3566 - val_loss: 0.3866\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9076 - val_loss: 2.2696\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8137 - val_loss: 0.8623\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3174 - val_loss: 0.6835\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 6.7397 - val_loss: 7.5650\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.3998 - val_loss: 0.2195\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1877 - val_loss: 0.1367\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.1496 - val_loss: 0.1449\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1909 - val_loss: 0.5073\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2920 - val_loss: 0.1738\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4002 - val_loss: 0.2262\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2985 - val_loss: 1.3993\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9480 - val_loss: 0.2713\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2714 - val_loss: 0.2880\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 0.0817940736564245\n",
      "Mean Absolute Error (MAE): 0.2079514866774759\n",
      "Root Mean Squared Error (RMSE): 0.2859966322466482\n",
      "Time taken: 426.0933680534363\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 11ms/step - loss: 1376.0587 - val_loss: 1271.3149\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1191.8838 - val_loss: 1140.0176\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1078.9093 - val_loss: 1040.5144\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 988.6346 - val_loss: 957.6568\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 913.6131 - val_loss: 888.0318\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 848.2067 - val_loss: 830.5343\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 790.9123 - val_loss: 771.1000\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 736.7783 - val_loss: 718.6701\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 687.2662 - val_loss: 668.9223\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 636.0163 - val_loss: 612.9473\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 583.2543 - val_loss: 566.2605\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 539.8073 - val_loss: 524.3566\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 496.4795 - val_loss: 481.2641\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 456.7917 - val_loss: 443.4314\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 417.9862 - val_loss: 402.5015\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 379.2912 - val_loss: 363.7990\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 341.5480 - val_loss: 328.4553\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 306.8724 - val_loss: 293.9723\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 273.7384 - val_loss: 260.6605\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 243.9297 - val_loss: 231.3138\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 216.9398 - val_loss: 204.8685\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 191.9884 - val_loss: 180.3210\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 168.9030 - val_loss: 158.8879\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 148.5540 - val_loss: 140.1700\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 130.4084 - val_loss: 121.5224\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 114.6903 - val_loss: 106.1056\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 100.5345 - val_loss: 90.9394\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 85.5835 - val_loss: 80.6764\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 74.3199 - val_loss: 68.4149\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 64.3848 - val_loss: 65.4086\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 57.0045 - val_loss: 52.0645\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 46.7782 - val_loss: 42.4501\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 40.1275 - val_loss: 37.8556\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 33.7343 - val_loss: 30.7022\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 29.0223 - val_loss: 30.1592\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 25.0713 - val_loss: 25.4593\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 21.2342 - val_loss: 21.9146\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 18.0512 - val_loss: 17.0791\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 17.6237 - val_loss: 13.8715\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 12.5552 - val_loss: 11.6201\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 10.7178 - val_loss: 9.1831\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 8.8996 - val_loss: 9.0819\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 8.2070 - val_loss: 6.7171\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 6.2768 - val_loss: 7.2185\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 6.0610 - val_loss: 5.0235\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 4.9264 - val_loss: 6.4057\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 4.2453 - val_loss: 3.8079\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 5.6486 - val_loss: 4.4470\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 2.9812 - val_loss: 3.0874\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 2.6408 - val_loss: 1.8627\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 2.2566 - val_loss: 4.9119\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 2.0066 - val_loss: 4.3546\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 2.0070 - val_loss: 1.8025\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 4.8061 - val_loss: 1.0029\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.1071 - val_loss: 1.5982\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.2931 - val_loss: 0.7244\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.1221 - val_loss: 0.6829\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.0581 - val_loss: 0.9206\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 4.3858 - val_loss: 2.0979\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.9778 - val_loss: 1.8330\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.9342 - val_loss: 0.9683\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.6522 - val_loss: 0.5494\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.9878 - val_loss: 2.7265\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.7709 - val_loss: 1.6963\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 1.0754 - val_loss: 0.6735\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.0932 - val_loss: 0.7617\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.4901 - val_loss: 0.7088\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 3.5762 - val_loss: 0.8157\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.5134 - val_loss: 0.4512\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.7946 - val_loss: 1.6930\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.0719 - val_loss: 0.5451\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.1408 - val_loss: 1.2012\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.8131 - val_loss: 0.3580\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.7418 - val_loss: 1.5303\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 1.1391 - val_loss: 1.1511\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.4932 - val_loss: 1.3357\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6628 - val_loss: 0.3964\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.3745 - val_loss: 0.8275\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6835 - val_loss: 0.5034\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7346 - val_loss: 0.9499\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.2576 - val_loss: 0.4820\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.9877 - val_loss: 0.5312\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5915 - val_loss: 1.1958\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9513 - val_loss: 1.9790\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0681 - val_loss: 0.5136\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4512 - val_loss: 0.7096\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.0464 - val_loss: 0.3807\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.4709 - val_loss: 0.5398\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0160 - val_loss: 0.5752\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4684 - val_loss: 0.3648\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3833 - val_loss: 1.4678\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.9969 - val_loss: 0.3617\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6888 - val_loss: 2.1798\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 0.35423025232641625\n",
      "Mean Absolute Error (MAE): 0.41170612896624664\n",
      "Root Mean Squared Error (RMSE): 0.5951724559540842\n",
      "Time taken: 319.33589816093445\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 8s 11ms/step - loss: 1399.1705 - val_loss: 1248.9977\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1231.8069 - val_loss: 1148.3550\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1136.0751 - val_loss: 1063.6064\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1051.1125 - val_loss: 991.3401\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 979.4482 - val_loss: 925.0106\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 912.4551 - val_loss: 862.9581\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 849.0344 - val_loss: 800.1877\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 787.2554 - val_loss: 742.6027\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 731.5713 - val_loss: 683.0358\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 671.1859 - val_loss: 629.3925\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 618.9000 - val_loss: 585.7553\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 569.7840 - val_loss: 531.5574\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 523.8782 - val_loss: 487.4731\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 481.4087 - val_loss: 450.5582\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 440.5935 - val_loss: 416.1146\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 401.2646 - val_loss: 371.2261\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 362.8052 - val_loss: 333.0383\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 325.9228 - val_loss: 298.7059\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 293.2305 - val_loss: 269.9971\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 263.7232 - val_loss: 242.7867\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 236.6755 - val_loss: 215.3330\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 210.2004 - val_loss: 191.5037\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 188.4608 - val_loss: 170.7795\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 165.0141 - val_loss: 147.9290\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 145.0180 - val_loss: 129.8153\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 127.1234 - val_loss: 111.5836\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 110.8519 - val_loss: 96.2594\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 95.1558 - val_loss: 84.8865\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 82.6502 - val_loss: 75.6913\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 71.2784 - val_loss: 62.7865\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 61.4978 - val_loss: 53.9292\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 51.4279 - val_loss: 43.9537\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 43.3829 - val_loss: 40.4309\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 38.0022 - val_loss: 32.7474\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 31.6815 - val_loss: 28.4118\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 26.4079 - val_loss: 23.2267\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 22.8722 - val_loss: 32.2248\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 21.6827 - val_loss: 16.1075\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 15.4724 - val_loss: 14.7272\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 13.2760 - val_loss: 12.1623\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 11.3086 - val_loss: 13.7086\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 11.1823 - val_loss: 7.7031\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 7.8473 - val_loss: 7.4643\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 7.4269 - val_loss: 6.1767\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 5.6660 - val_loss: 5.3637\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 6.5429 - val_loss: 23.6735\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 6.5446 - val_loss: 3.2621\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.9106 - val_loss: 2.2336\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 2.7579 - val_loss: 2.2293\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 2.4113 - val_loss: 3.0787\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 2.2710 - val_loss: 2.2166\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 2.0982 - val_loss: 1.1873\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 2.3450 - val_loss: 1.4543\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.8350 - val_loss: 1.4219\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.4684 - val_loss: 1.2100\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.9507 - val_loss: 0.9861\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.1571 - val_loss: 0.7865\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.4644 - val_loss: 1.3146\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0939 - val_loss: 0.5508\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.1000 - val_loss: 0.8267\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 3.9884 - val_loss: 0.5186\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5274 - val_loss: 1.4804\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9576 - val_loss: 1.5921\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.6411 - val_loss: 0.3133\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.7449 - val_loss: 2.1058\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.0291 - val_loss: 1.6082\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.7615 - val_loss: 0.4748\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5304 - val_loss: 0.9265\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.7174 - val_loss: 1.1187\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.3877 - val_loss: 0.4066\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.9292 - val_loss: 1.4101\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.9046 - val_loss: 0.9708\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.7786 - val_loss: 0.3687\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.8607 - val_loss: 0.5997\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.8222 - val_loss: 0.4811\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.6304 - val_loss: 0.6508\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 1.1308 - val_loss: 0.5592\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.7077 - val_loss: 0.2993\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.6939 - val_loss: 0.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8376 - val_loss: 11.4237\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 3.8485 - val_loss: 0.3282\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3030 - val_loss: 0.3008\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3594 - val_loss: 0.4430\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6696 - val_loss: 0.6888\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6377 - val_loss: 0.4948\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0847 - val_loss: 1.4779\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6156 - val_loss: 1.0732\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.3245 - val_loss: 2.2016\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.0990 - val_loss: 0.2033\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8290 - val_loss: 1.0423\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9613 - val_loss: 0.2673\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3095 - val_loss: 0.2027\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8044 - val_loss: 0.7670\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9276 - val_loss: 0.7094\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.1295 - val_loss: 0.8823\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6681 - val_loss: 1.4208\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.3873 - val_loss: 0.8492\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2647 - val_loss: 0.8082\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.7489 - val_loss: 1.3021\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2885 - val_loss: 0.1265\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1813 - val_loss: 0.4947\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6742 - val_loss: 1.1404\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8280 - val_loss: 3.0143\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.1191 - val_loss: 0.4720\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2040 - val_loss: 0.4128\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.9163 - val_loss: 1.8883\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5454 - val_loss: 0.4733\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2945 - val_loss: 0.6934\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.4582 - val_loss: 0.5199\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.4725 - val_loss: 0.2357\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.7676 - val_loss: 0.1934\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.4396 - val_loss: 0.5616\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.0699 - val_loss: 0.5212\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.8987 - val_loss: 0.1955\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3255 - val_loss: 0.5576\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4537 - val_loss: 0.5409\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3265 - val_loss: 0.3343\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8758 - val_loss: 0.2046\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6138 - val_loss: 0.5378\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9561 - val_loss: 0.7042\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 0.1263986616058074\n",
      "Mean Absolute Error (MAE): 0.2509766953938019\n",
      "Root Mean Squared Error (RMSE): 0.35552589442374993\n",
      "Time taken: 408.6269633769989\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 10ms/step - loss: 1390.0612 - val_loss: 1271.1022\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1226.3204 - val_loss: 1170.1707\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1130.3369 - val_loss: 1080.1077\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1046.8798 - val_loss: 1004.2872\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 978.3752 - val_loss: 943.1790\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 920.1638 - val_loss: 889.8944\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 868.6002 - val_loss: 840.1871\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 822.0507 - val_loss: 796.3542\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 780.2564 - val_loss: 755.7556\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 741.2878 - val_loss: 715.0096\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 689.4808 - val_loss: 657.7446\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 628.7389 - val_loss: 600.5793\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 579.5024 - val_loss: 557.7825\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 536.4821 - val_loss: 515.5660\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 495.0147 - val_loss: 473.6841\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 453.7439 - val_loss: 435.1212\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 415.4023 - val_loss: 400.2898\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 379.9576 - val_loss: 365.1140\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 345.3502 - val_loss: 331.6342\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 313.3998 - val_loss: 301.6016\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 284.0567 - val_loss: 273.0692\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 256.4168 - val_loss: 246.1309\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 230.8927 - val_loss: 221.2762\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 209.5958 - val_loss: 197.8281\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 184.6028 - val_loss: 176.4015\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 166.4402 - val_loss: 157.9786\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 144.7422 - val_loss: 141.6225\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 128.0802 - val_loss: 123.6097\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 113.3439 - val_loss: 108.6683\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 98.5437 - val_loss: 94.8010\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 86.7680 - val_loss: 82.2646\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 74.3310 - val_loss: 71.3189\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 65.1536 - val_loss: 65.8742\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 56.8708 - val_loss: 54.6085\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 47.6079 - val_loss: 46.1333\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 41.0757 - val_loss: 38.8579\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 34.8158 - val_loss: 32.4928\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 29.5959 - val_loss: 28.5665\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 25.6211 - val_loss: 37.5182\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 22.7474 - val_loss: 21.7307\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 17.7907 - val_loss: 17.7421\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 15.3488 - val_loss: 14.7955\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 12.5178 - val_loss: 15.6394\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 12.1470 - val_loss: 11.3899\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 9.4556 - val_loss: 9.2607\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 8.6807 - val_loss: 7.7577\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 7.1180 - val_loss: 6.8860\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 5.8203 - val_loss: 7.9885\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 6.9918 - val_loss: 5.3963\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 4.5101 - val_loss: 4.6952\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 4.3812 - val_loss: 4.3189\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 3.1735 - val_loss: 4.0594\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 4.2483 - val_loss: 2.9979\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.3149 - val_loss: 2.1304\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 3.9377 - val_loss: 17.4562\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 2.9620 - val_loss: 3.1094\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.8371 - val_loss: 1.8327\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.6921 - val_loss: 3.2433\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.7391 - val_loss: 1.6915\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.4978 - val_loss: 1.6919\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 2.2883 - val_loss: 1.3865\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.4289 - val_loss: 0.6580\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9956 - val_loss: 1.1328\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.6343 - val_loss: 1.2733\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.6821 - val_loss: 1.0227\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9939 - val_loss: 1.1459\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 3.5162 - val_loss: 1.2407\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5992 - val_loss: 0.6602\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6774 - val_loss: 0.8066\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9180 - val_loss: 0.3330\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.2807 - val_loss: 0.8515\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.0551 - val_loss: 7.0383\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.2938 - val_loss: 1.6409\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7760 - val_loss: 0.8086\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.9815 - val_loss: 0.3176\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.1085 - val_loss: 0.7248\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.7719 - val_loss: 0.5019\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.2763 - val_loss: 0.6896\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8799 - val_loss: 0.8534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.4276 - val_loss: 0.4972\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.7134 - val_loss: 13.0378\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 2.0917 - val_loss: 0.3593\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7395 - val_loss: 0.4243\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4256 - val_loss: 0.6076\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5153 - val_loss: 0.3054\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.3047 - val_loss: 0.6123\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8333 - val_loss: 0.7865\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.3182 - val_loss: 1.1657\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9330 - val_loss: 0.2390\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9873 - val_loss: 0.3913\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5624 - val_loss: 0.5004\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9871 - val_loss: 1.0267\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.3150 - val_loss: 0.2597\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6450 - val_loss: 2.0005\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8000 - val_loss: 1.4326\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9912 - val_loss: 0.4158\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.3868 - val_loss: 0.8131\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5913 - val_loss: 0.6437\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6244 - val_loss: 1.1140\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.4288 - val_loss: 1.0803\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.7896 - val_loss: 0.5730\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5995 - val_loss: 0.2318\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 4.2045 - val_loss: 8.8275\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8034 - val_loss: 0.2647\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1953 - val_loss: 0.2985\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2799 - val_loss: 0.5652\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6806 - val_loss: 1.8685\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6755 - val_loss: 0.4066\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5191 - val_loss: 0.1567\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6049 - val_loss: 0.7413\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9769 - val_loss: 1.6740\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6950 - val_loss: 1.1070\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4296 - val_loss: 0.2111\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9801 - val_loss: 2.1784\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0327 - val_loss: 0.3694\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4674 - val_loss: 0.7186\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8837 - val_loss: 4.0885\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.8945 - val_loss: 0.2015\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2595 - val_loss: 0.1520\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2422 - val_loss: 1.0034\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3847 - val_loss: 0.2161\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6277 - val_loss: 0.3048\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3583 - val_loss: 0.6350\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.2443 - val_loss: 1.3906\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6238 - val_loss: 0.3871\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.5397 - val_loss: 0.2460\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7160 - val_loss: 0.4668\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5865 - val_loss: 0.7910\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4874 - val_loss: 1.1534\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.0890 - val_loss: 0.5065\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6002 - val_loss: 0.4061\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3586 - val_loss: 0.3524\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8252 - val_loss: 1.3210\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4953 - val_loss: 0.8897\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.3587 - val_loss: 0.4266\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3605 - val_loss: 0.2139\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.6005 - val_loss: 0.6777\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 7.1453 - val_loss: 0.3651\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2728 - val_loss: 0.1518\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1715 - val_loss: 0.1045\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1568 - val_loss: 0.2035\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3403 - val_loss: 0.5117\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4696 - val_loss: 0.2724\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4120 - val_loss: 0.8808\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3964 - val_loss: 0.7573\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5097 - val_loss: 0.4063\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4223 - val_loss: 0.1831\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.7070 - val_loss: 5.6076\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7632 - val_loss: 0.2856\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2586 - val_loss: 0.1258\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5348 - val_loss: 2.0049\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8910 - val_loss: 0.6699\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4710 - val_loss: 0.2997\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 4.3633 - val_loss: 0.3702\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1728 - val_loss: 0.2018\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1993 - val_loss: 0.1988\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2531 - val_loss: 0.2084\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5651 - val_loss: 0.3203\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2284 - val_loss: 0.1548\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.7801 - val_loss: 0.9278\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 0.104685824346176\n",
      "Mean Absolute Error (MAE): 0.2351474654158081\n",
      "Root Mean Squared Error (RMSE): 0.3235518881820596\n",
      "Time taken: 468.10146927833557\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 10ms/step - loss: 1359.5824 - val_loss: 1252.5167\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1199.7815 - val_loss: 1152.7100\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1118.2168 - val_loss: 1079.2382\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1057.6189 - val_loss: 1023.8361\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1012.8250 - val_loss: 982.9349\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 980.4111 - val_loss: 953.4779\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 957.7577 - val_loss: 933.0208\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 942.8084 - val_loss: 919.4879\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 933.5939 - val_loss: 911.2243\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 928.4355 - val_loss: 906.3875\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 925.8449 - val_loss: 903.9782\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 924.6008 - val_loss: 902.5823\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 924.0740 - val_loss: 901.9604\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 923.9734 - val_loss: 901.6273\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 923.5436 - val_loss: 899.9448\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 903.4904 - val_loss: 845.9334\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 823.3262 - val_loss: 770.2499\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 756.1921 - val_loss: 712.0410\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 701.7800 - val_loss: 661.8441\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 652.4435 - val_loss: 618.5582\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 606.7142 - val_loss: 574.6301\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 566.4694 - val_loss: 532.9985\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 525.7161 - val_loss: 493.5565\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 484.3318 - val_loss: 454.1088\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 446.6457 - val_loss: 416.6739\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 409.8469 - val_loss: 382.6427\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 370.5210 - val_loss: 343.0165\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 335.9900 - val_loss: 310.7125\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 301.7869 - val_loss: 281.6893\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 271.2450 - val_loss: 249.6712\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 242.0640 - val_loss: 222.8298\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 215.3043 - val_loss: 198.1700\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 192.8408 - val_loss: 175.7171\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 168.3618 - val_loss: 152.6770\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 146.7532 - val_loss: 134.6647\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 129.4108 - val_loss: 117.2160\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 113.0526 - val_loss: 103.0654\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 101.1014 - val_loss: 89.9354\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 85.5470 - val_loss: 76.9030\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 74.8039 - val_loss: 66.0363\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 67.2740 - val_loss: 58.6291\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 56.1109 - val_loss: 49.8442\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 48.2902 - val_loss: 44.6452\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 41.2261 - val_loss: 36.2074\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 35.9477 - val_loss: 31.7694\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 31.0578 - val_loss: 26.5826\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 27.0798 - val_loss: 23.6925\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 22.2536 - val_loss: 18.7154\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 18.9120 - val_loss: 17.0566\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 16.6676 - val_loss: 16.8684\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 14.3882 - val_loss: 11.4153\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 12.2360 - val_loss: 9.8558\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 11.4162 - val_loss: 22.7337\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 10.0338 - val_loss: 10.7527\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 7.6385 - val_loss: 5.7999\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 6.7094 - val_loss: 6.8762\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 5.6905 - val_loss: 4.2840\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 5.1353 - val_loss: 3.7631\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 4.3681 - val_loss: 3.4181\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 3.5450 - val_loss: 4.0525\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 3.6618 - val_loss: 1.9748\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 4.0171 - val_loss: 3.7651\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.9219 - val_loss: 1.5103\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.6488 - val_loss: 2.8848\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.2113 - val_loss: 1.0190\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.7667 - val_loss: 1.5039\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.6141 - val_loss: 1.5557\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 1.3304 - val_loss: 1.5224\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.1263 - val_loss: 0.7877\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.5186 - val_loss: 4.0793\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.7894 - val_loss: 1.9446\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7210 - val_loss: 0.4836\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8388 - val_loss: 0.9398\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 2.0264 - val_loss: 0.3790\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6414 - val_loss: 1.8316\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8677 - val_loss: 0.8909\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.1839 - val_loss: 1.1088\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.7707 - val_loss: 0.3531\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 3s 9ms/step - loss: 0.8618 - val_loss: 0.5206\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6553 - val_loss: 0.3753\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5444 - val_loss: 0.7460\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5923 - val_loss: 0.5386\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 2.9442 - val_loss: 0.8215\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3942 - val_loss: 0.2596\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4168 - val_loss: 0.4700\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5738 - val_loss: 1.3093\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 2.2935 - val_loss: 0.2774\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3268 - val_loss: 0.3118\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5856 - val_loss: 0.5494\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.6993 - val_loss: 0.7470\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.0797 - val_loss: 11.4106\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.1589 - val_loss: 0.6209\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8477 - val_loss: 0.3255\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.4349 - val_loss: 0.3994\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7727 - val_loss: 0.4863\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 4.0238 - val_loss: 3.8941\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5633 - val_loss: 0.1560\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1762 - val_loss: 0.1217\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2748 - val_loss: 0.2174\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3365 - val_loss: 0.9527\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.9190 - val_loss: 0.2661\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2787 - val_loss: 0.1673\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7730 - val_loss: 1.3433\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6788 - val_loss: 0.2913\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0495 - val_loss: 0.5761\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6645 - val_loss: 3.3601\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 1.3745 - val_loss: 0.4038\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3797 - val_loss: 2.4180\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7631 - val_loss: 0.9350\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3483 - val_loss: 0.3302\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7284 - val_loss: 1.5077\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.6009 - val_loss: 0.1950\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3277 - val_loss: 0.6311\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 2.4926 - val_loss: 0.2673\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1840 - val_loss: 0.1197\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2291 - val_loss: 0.3209\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2677 - val_loss: 0.5075\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.8662 - val_loss: 1.4992\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.8916 - val_loss: 0.1316\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.4472 - val_loss: 0.5560\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4504 - val_loss: 0.5736\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.3516 - val_loss: 0.8269\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.6602 - val_loss: 0.2791\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.8635 - val_loss: 0.8849\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 4.5620 - val_loss: 0.1337\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1128 - val_loss: 0.0830\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1044 - val_loss: 0.1242\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1525 - val_loss: 0.1817\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2798 - val_loss: 1.3846\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6737 - val_loss: 0.1022\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2817 - val_loss: 0.2142\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4399 - val_loss: 0.4092\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5148 - val_loss: 0.7243\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.1313 - val_loss: 0.2396\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3249 - val_loss: 0.2502\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5603 - val_loss: 0.3676\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.0010 - val_loss: 2.4492\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4516 - val_loss: 0.2854\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1899 - val_loss: 0.1976\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.4479 - val_loss: 0.1389\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 1.4349 - val_loss: 5.7796\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.6730 - val_loss: 0.1037\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1125 - val_loss: 0.3883\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3221 - val_loss: 0.1000\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5001 - val_loss: 0.9738\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.3721 - val_loss: 0.1726\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 0.08124937275883441\n",
      "Mean Absolute Error (MAE): 0.21999382199559803\n",
      "Root Mean Squared Error (RMSE): 0.2850427560188724\n",
      "Time taken: 450.3784146308899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=5,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 8, 512)            1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 8, 256)            787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_9028\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold       MSE       MAE      RMSE  Time taken\n",
      "0        1  0.081794  0.207951  0.285997  426.093368\n",
      "1        2  0.354230  0.411706  0.595172  319.335898\n",
      "2        3  0.126399  0.250977  0.355526  408.626963\n",
      "3        4  0.104686  0.235147  0.323552  468.101469\n",
      "4        5  0.081249  0.219994  0.285043  450.378415\n",
      "5  Average  0.149672  0.265155  0.369058  414.507223\n",
      "Results saved to 'PL_model_1_smoothing2_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_1_smoothing2_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'PL_model_1_smoothing2_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ca437",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
