{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_smoothing2_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.722102</td>\n",
       "      <td>133.549604</td>\n",
       "      <td>70.246654</td>\n",
       "      <td>114.393425</td>\n",
       "      <td>125.518042</td>\n",
       "      <td>148.490719</td>\n",
       "      <td>105.960735</td>\n",
       "      <td>134.734917</td>\n",
       "      <td>90.358364</td>\n",
       "      <td>107.880691</td>\n",
       "      <td>...</td>\n",
       "      <td>80.511088</td>\n",
       "      <td>86.266577</td>\n",
       "      <td>91.324276</td>\n",
       "      <td>88.413835</td>\n",
       "      <td>118.079357</td>\n",
       "      <td>112.830599</td>\n",
       "      <td>101.581432</td>\n",
       "      <td>130.484864</td>\n",
       "      <td>65.849519</td>\n",
       "      <td>112.853971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.741769</td>\n",
       "      <td>133.613840</td>\n",
       "      <td>70.333167</td>\n",
       "      <td>114.403077</td>\n",
       "      <td>125.425263</td>\n",
       "      <td>148.406322</td>\n",
       "      <td>105.788181</td>\n",
       "      <td>134.546280</td>\n",
       "      <td>90.431246</td>\n",
       "      <td>107.970290</td>\n",
       "      <td>...</td>\n",
       "      <td>80.667880</td>\n",
       "      <td>86.301348</td>\n",
       "      <td>91.369136</td>\n",
       "      <td>88.468505</td>\n",
       "      <td>117.851056</td>\n",
       "      <td>112.732842</td>\n",
       "      <td>101.535137</td>\n",
       "      <td>130.422780</td>\n",
       "      <td>65.831506</td>\n",
       "      <td>112.816370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.759517</td>\n",
       "      <td>133.678503</td>\n",
       "      <td>70.421559</td>\n",
       "      <td>114.410863</td>\n",
       "      <td>125.331731</td>\n",
       "      <td>148.320508</td>\n",
       "      <td>105.613823</td>\n",
       "      <td>134.358052</td>\n",
       "      <td>90.503448</td>\n",
       "      <td>108.058270</td>\n",
       "      <td>...</td>\n",
       "      <td>80.823085</td>\n",
       "      <td>86.337129</td>\n",
       "      <td>91.414783</td>\n",
       "      <td>88.521309</td>\n",
       "      <td>117.621052</td>\n",
       "      <td>112.638386</td>\n",
       "      <td>101.491179</td>\n",
       "      <td>130.363766</td>\n",
       "      <td>65.812886</td>\n",
       "      <td>112.778795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.775461</td>\n",
       "      <td>133.743510</td>\n",
       "      <td>70.511477</td>\n",
       "      <td>114.417015</td>\n",
       "      <td>125.237166</td>\n",
       "      <td>148.233207</td>\n",
       "      <td>105.437718</td>\n",
       "      <td>134.170555</td>\n",
       "      <td>90.574876</td>\n",
       "      <td>108.144722</td>\n",
       "      <td>...</td>\n",
       "      <td>80.976531</td>\n",
       "      <td>86.373826</td>\n",
       "      <td>91.461416</td>\n",
       "      <td>88.572363</td>\n",
       "      <td>117.389684</td>\n",
       "      <td>112.547228</td>\n",
       "      <td>101.449812</td>\n",
       "      <td>130.307871</td>\n",
       "      <td>65.793756</td>\n",
       "      <td>112.741332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.789800</td>\n",
       "      <td>133.808609</td>\n",
       "      <td>70.602435</td>\n",
       "      <td>114.421924</td>\n",
       "      <td>125.141318</td>\n",
       "      <td>148.144403</td>\n",
       "      <td>105.260017</td>\n",
       "      <td>133.984101</td>\n",
       "      <td>90.645256</td>\n",
       "      <td>108.229792</td>\n",
       "      <td>...</td>\n",
       "      <td>81.128195</td>\n",
       "      <td>86.411394</td>\n",
       "      <td>91.509328</td>\n",
       "      <td>88.621720</td>\n",
       "      <td>117.157444</td>\n",
       "      <td>112.459148</td>\n",
       "      <td>101.411458</td>\n",
       "      <td>130.254975</td>\n",
       "      <td>65.774054</td>\n",
       "      <td>112.703922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>128.394731</td>\n",
       "      <td>113.120062</td>\n",
       "      <td>102.722429</td>\n",
       "      <td>71.609424</td>\n",
       "      <td>151.352281</td>\n",
       "      <td>140.904922</td>\n",
       "      <td>128.827778</td>\n",
       "      <td>113.779812</td>\n",
       "      <td>107.558742</td>\n",
       "      <td>96.997103</td>\n",
       "      <td>...</td>\n",
       "      <td>88.095891</td>\n",
       "      <td>110.712051</td>\n",
       "      <td>89.522396</td>\n",
       "      <td>71.221952</td>\n",
       "      <td>124.108295</td>\n",
       "      <td>113.383110</td>\n",
       "      <td>130.244963</td>\n",
       "      <td>114.622501</td>\n",
       "      <td>107.532818</td>\n",
       "      <td>76.703086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>128.269154</td>\n",
       "      <td>112.982064</td>\n",
       "      <td>102.785866</td>\n",
       "      <td>71.581983</td>\n",
       "      <td>151.277725</td>\n",
       "      <td>140.892099</td>\n",
       "      <td>128.842679</td>\n",
       "      <td>113.832694</td>\n",
       "      <td>107.410332</td>\n",
       "      <td>96.815164</td>\n",
       "      <td>...</td>\n",
       "      <td>88.034588</td>\n",
       "      <td>110.548388</td>\n",
       "      <td>89.310220</td>\n",
       "      <td>71.379769</td>\n",
       "      <td>124.099541</td>\n",
       "      <td>113.470836</td>\n",
       "      <td>130.083759</td>\n",
       "      <td>114.395532</td>\n",
       "      <td>107.742386</td>\n",
       "      <td>76.682848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>128.143792</td>\n",
       "      <td>112.844766</td>\n",
       "      <td>102.852637</td>\n",
       "      <td>71.555953</td>\n",
       "      <td>151.200817</td>\n",
       "      <td>140.880374</td>\n",
       "      <td>128.857569</td>\n",
       "      <td>113.886728</td>\n",
       "      <td>107.258332</td>\n",
       "      <td>96.632920</td>\n",
       "      <td>...</td>\n",
       "      <td>87.974760</td>\n",
       "      <td>110.380633</td>\n",
       "      <td>89.095824</td>\n",
       "      <td>71.538448</td>\n",
       "      <td>124.091471</td>\n",
       "      <td>113.557163</td>\n",
       "      <td>129.920154</td>\n",
       "      <td>114.165400</td>\n",
       "      <td>107.949968</td>\n",
       "      <td>76.663408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>128.018936</td>\n",
       "      <td>112.708365</td>\n",
       "      <td>102.922962</td>\n",
       "      <td>71.531847</td>\n",
       "      <td>151.121227</td>\n",
       "      <td>140.870082</td>\n",
       "      <td>128.872267</td>\n",
       "      <td>113.942389</td>\n",
       "      <td>107.102486</td>\n",
       "      <td>96.450473</td>\n",
       "      <td>...</td>\n",
       "      <td>87.916419</td>\n",
       "      <td>110.208561</td>\n",
       "      <td>88.879379</td>\n",
       "      <td>71.697850</td>\n",
       "      <td>124.084220</td>\n",
       "      <td>113.641886</td>\n",
       "      <td>129.753926</td>\n",
       "      <td>113.932214</td>\n",
       "      <td>108.155353</td>\n",
       "      <td>76.644759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>127.894929</td>\n",
       "      <td>112.572888</td>\n",
       "      <td>102.996952</td>\n",
       "      <td>71.509933</td>\n",
       "      <td>151.038840</td>\n",
       "      <td>140.861436</td>\n",
       "      <td>128.886554</td>\n",
       "      <td>113.999895</td>\n",
       "      <td>106.942607</td>\n",
       "      <td>96.267932</td>\n",
       "      <td>...</td>\n",
       "      <td>87.859482</td>\n",
       "      <td>110.032132</td>\n",
       "      <td>88.660934</td>\n",
       "      <td>71.857879</td>\n",
       "      <td>124.077867</td>\n",
       "      <td>113.725050</td>\n",
       "      <td>129.584939</td>\n",
       "      <td>113.696233</td>\n",
       "      <td>108.358487</td>\n",
       "      <td>76.626723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     103.722102  133.549604   70.246654  114.393425  125.518042  148.490719   \n",
       "1     103.741769  133.613840   70.333167  114.403077  125.425263  148.406322   \n",
       "2     103.759517  133.678503   70.421559  114.410863  125.331731  148.320508   \n",
       "3     103.775461  133.743510   70.511477  114.417015  125.237166  148.233207   \n",
       "4     103.789800  133.808609   70.602435  114.421924  125.141318  148.144403   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  128.394731  113.120062  102.722429   71.609424  151.352281  140.904922   \n",
       "2439  128.269154  112.982064  102.785866   71.581983  151.277725  140.892099   \n",
       "2440  128.143792  112.844766  102.852637   71.555953  151.200817  140.880374   \n",
       "2441  128.018936  112.708365  102.922962   71.531847  151.121227  140.870082   \n",
       "2442  127.894929  112.572888  102.996952   71.509933  151.038840  140.861436   \n",
       "\n",
       "              6           7           8           9   ...         38  \\\n",
       "0     105.960735  134.734917   90.358364  107.880691  ...  80.511088   \n",
       "1     105.788181  134.546280   90.431246  107.970290  ...  80.667880   \n",
       "2     105.613823  134.358052   90.503448  108.058270  ...  80.823085   \n",
       "3     105.437718  134.170555   90.574876  108.144722  ...  80.976531   \n",
       "4     105.260017  133.984101   90.645256  108.229792  ...  81.128195   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  128.827778  113.779812  107.558742   96.997103  ...  88.095891   \n",
       "2439  128.842679  113.832694  107.410332   96.815164  ...  88.034588   \n",
       "2440  128.857569  113.886728  107.258332   96.632920  ...  87.974760   \n",
       "2441  128.872267  113.942389  107.102486   96.450473  ...  87.916419   \n",
       "2442  128.886554  113.999895  106.942607   96.267932  ...  87.859482   \n",
       "\n",
       "              39         40         41          42          43          44  \\\n",
       "0      86.266577  91.324276  88.413835  118.079357  112.830599  101.581432   \n",
       "1      86.301348  91.369136  88.468505  117.851056  112.732842  101.535137   \n",
       "2      86.337129  91.414783  88.521309  117.621052  112.638386  101.491179   \n",
       "3      86.373826  91.461416  88.572363  117.389684  112.547228  101.449812   \n",
       "4      86.411394  91.509328  88.621720  117.157444  112.459148  101.411458   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  110.712051  89.522396  71.221952  124.108295  113.383110  130.244963   \n",
       "2439  110.548388  89.310220  71.379769  124.099541  113.470836  130.083759   \n",
       "2440  110.380633  89.095824  71.538448  124.091471  113.557163  129.920154   \n",
       "2441  110.208561  88.879379  71.697850  124.084220  113.641886  129.753926   \n",
       "2442  110.032132  88.660934  71.857879  124.077867  113.725050  129.584939   \n",
       "\n",
       "              45          46          47  \n",
       "0     130.484864   65.849519  112.853971  \n",
       "1     130.422780   65.831506  112.816370  \n",
       "2     130.363766   65.812886  112.778795  \n",
       "3     130.307871   65.793756  112.741332  \n",
       "4     130.254975   65.774054  112.703922  \n",
       "...          ...         ...         ...  \n",
       "2438  114.622501  107.532818   76.703086  \n",
       "2439  114.395532  107.742386   76.682848  \n",
       "2440  114.165400  107.949968   76.663408  \n",
       "2441  113.932214  108.155353   76.644759  \n",
       "2442  113.696233  108.358487   76.626723  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.722102</td>\n",
       "      <td>133.549604</td>\n",
       "      <td>70.246654</td>\n",
       "      <td>114.393425</td>\n",
       "      <td>125.518042</td>\n",
       "      <td>148.490719</td>\n",
       "      <td>105.960735</td>\n",
       "      <td>134.734917</td>\n",
       "      <td>90.358364</td>\n",
       "      <td>107.880691</td>\n",
       "      <td>...</td>\n",
       "      <td>80.511088</td>\n",
       "      <td>86.266577</td>\n",
       "      <td>91.324276</td>\n",
       "      <td>88.413835</td>\n",
       "      <td>118.079357</td>\n",
       "      <td>112.830599</td>\n",
       "      <td>101.581432</td>\n",
       "      <td>130.484864</td>\n",
       "      <td>65.849519</td>\n",
       "      <td>112.853971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.741769</td>\n",
       "      <td>133.613840</td>\n",
       "      <td>70.333167</td>\n",
       "      <td>114.403077</td>\n",
       "      <td>125.425263</td>\n",
       "      <td>148.406322</td>\n",
       "      <td>105.788181</td>\n",
       "      <td>134.546280</td>\n",
       "      <td>90.431246</td>\n",
       "      <td>107.970290</td>\n",
       "      <td>...</td>\n",
       "      <td>80.667880</td>\n",
       "      <td>86.301348</td>\n",
       "      <td>91.369136</td>\n",
       "      <td>88.468505</td>\n",
       "      <td>117.851056</td>\n",
       "      <td>112.732842</td>\n",
       "      <td>101.535137</td>\n",
       "      <td>130.422780</td>\n",
       "      <td>65.831506</td>\n",
       "      <td>112.816370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.759517</td>\n",
       "      <td>133.678503</td>\n",
       "      <td>70.421559</td>\n",
       "      <td>114.410863</td>\n",
       "      <td>125.331731</td>\n",
       "      <td>148.320508</td>\n",
       "      <td>105.613823</td>\n",
       "      <td>134.358052</td>\n",
       "      <td>90.503448</td>\n",
       "      <td>108.058270</td>\n",
       "      <td>...</td>\n",
       "      <td>80.823085</td>\n",
       "      <td>86.337129</td>\n",
       "      <td>91.414783</td>\n",
       "      <td>88.521309</td>\n",
       "      <td>117.621052</td>\n",
       "      <td>112.638386</td>\n",
       "      <td>101.491179</td>\n",
       "      <td>130.363766</td>\n",
       "      <td>65.812886</td>\n",
       "      <td>112.778795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.775461</td>\n",
       "      <td>133.743510</td>\n",
       "      <td>70.511477</td>\n",
       "      <td>114.417015</td>\n",
       "      <td>125.237166</td>\n",
       "      <td>148.233207</td>\n",
       "      <td>105.437718</td>\n",
       "      <td>134.170555</td>\n",
       "      <td>90.574876</td>\n",
       "      <td>108.144722</td>\n",
       "      <td>...</td>\n",
       "      <td>80.976531</td>\n",
       "      <td>86.373826</td>\n",
       "      <td>91.461416</td>\n",
       "      <td>88.572363</td>\n",
       "      <td>117.389684</td>\n",
       "      <td>112.547228</td>\n",
       "      <td>101.449812</td>\n",
       "      <td>130.307871</td>\n",
       "      <td>65.793756</td>\n",
       "      <td>112.741332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.789800</td>\n",
       "      <td>133.808609</td>\n",
       "      <td>70.602435</td>\n",
       "      <td>114.421924</td>\n",
       "      <td>125.141318</td>\n",
       "      <td>148.144403</td>\n",
       "      <td>105.260017</td>\n",
       "      <td>133.984101</td>\n",
       "      <td>90.645256</td>\n",
       "      <td>108.229792</td>\n",
       "      <td>...</td>\n",
       "      <td>81.128195</td>\n",
       "      <td>86.411394</td>\n",
       "      <td>91.509328</td>\n",
       "      <td>88.621720</td>\n",
       "      <td>117.157444</td>\n",
       "      <td>112.459148</td>\n",
       "      <td>101.411458</td>\n",
       "      <td>130.254975</td>\n",
       "      <td>65.774054</td>\n",
       "      <td>112.703922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>128.394731</td>\n",
       "      <td>113.120062</td>\n",
       "      <td>102.722429</td>\n",
       "      <td>71.609424</td>\n",
       "      <td>151.352281</td>\n",
       "      <td>140.904922</td>\n",
       "      <td>128.827778</td>\n",
       "      <td>113.779812</td>\n",
       "      <td>107.558742</td>\n",
       "      <td>96.997103</td>\n",
       "      <td>...</td>\n",
       "      <td>88.095891</td>\n",
       "      <td>110.712051</td>\n",
       "      <td>89.522396</td>\n",
       "      <td>71.221952</td>\n",
       "      <td>124.108295</td>\n",
       "      <td>113.383110</td>\n",
       "      <td>130.244963</td>\n",
       "      <td>114.622501</td>\n",
       "      <td>107.532818</td>\n",
       "      <td>76.703086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>128.269154</td>\n",
       "      <td>112.982064</td>\n",
       "      <td>102.785866</td>\n",
       "      <td>71.581983</td>\n",
       "      <td>151.277725</td>\n",
       "      <td>140.892099</td>\n",
       "      <td>128.842679</td>\n",
       "      <td>113.832694</td>\n",
       "      <td>107.410332</td>\n",
       "      <td>96.815164</td>\n",
       "      <td>...</td>\n",
       "      <td>88.034588</td>\n",
       "      <td>110.548388</td>\n",
       "      <td>89.310220</td>\n",
       "      <td>71.379769</td>\n",
       "      <td>124.099541</td>\n",
       "      <td>113.470836</td>\n",
       "      <td>130.083759</td>\n",
       "      <td>114.395532</td>\n",
       "      <td>107.742386</td>\n",
       "      <td>76.682848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>128.143792</td>\n",
       "      <td>112.844766</td>\n",
       "      <td>102.852637</td>\n",
       "      <td>71.555953</td>\n",
       "      <td>151.200817</td>\n",
       "      <td>140.880374</td>\n",
       "      <td>128.857569</td>\n",
       "      <td>113.886728</td>\n",
       "      <td>107.258332</td>\n",
       "      <td>96.632920</td>\n",
       "      <td>...</td>\n",
       "      <td>87.974760</td>\n",
       "      <td>110.380633</td>\n",
       "      <td>89.095824</td>\n",
       "      <td>71.538448</td>\n",
       "      <td>124.091471</td>\n",
       "      <td>113.557163</td>\n",
       "      <td>129.920154</td>\n",
       "      <td>114.165400</td>\n",
       "      <td>107.949968</td>\n",
       "      <td>76.663408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>128.018936</td>\n",
       "      <td>112.708365</td>\n",
       "      <td>102.922962</td>\n",
       "      <td>71.531847</td>\n",
       "      <td>151.121227</td>\n",
       "      <td>140.870082</td>\n",
       "      <td>128.872267</td>\n",
       "      <td>113.942389</td>\n",
       "      <td>107.102486</td>\n",
       "      <td>96.450473</td>\n",
       "      <td>...</td>\n",
       "      <td>87.916419</td>\n",
       "      <td>110.208561</td>\n",
       "      <td>88.879379</td>\n",
       "      <td>71.697850</td>\n",
       "      <td>124.084220</td>\n",
       "      <td>113.641886</td>\n",
       "      <td>129.753926</td>\n",
       "      <td>113.932214</td>\n",
       "      <td>108.155353</td>\n",
       "      <td>76.644759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>127.894929</td>\n",
       "      <td>112.572888</td>\n",
       "      <td>102.996952</td>\n",
       "      <td>71.509933</td>\n",
       "      <td>151.038840</td>\n",
       "      <td>140.861436</td>\n",
       "      <td>128.886554</td>\n",
       "      <td>113.999895</td>\n",
       "      <td>106.942607</td>\n",
       "      <td>96.267932</td>\n",
       "      <td>...</td>\n",
       "      <td>87.859482</td>\n",
       "      <td>110.032132</td>\n",
       "      <td>88.660934</td>\n",
       "      <td>71.857879</td>\n",
       "      <td>124.077867</td>\n",
       "      <td>113.725050</td>\n",
       "      <td>129.584939</td>\n",
       "      <td>113.696233</td>\n",
       "      <td>108.358487</td>\n",
       "      <td>76.626723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     103.722102  133.549604   70.246654  114.393425  125.518042  148.490719   \n",
       "1     103.741769  133.613840   70.333167  114.403077  125.425263  148.406322   \n",
       "2     103.759517  133.678503   70.421559  114.410863  125.331731  148.320508   \n",
       "3     103.775461  133.743510   70.511477  114.417015  125.237166  148.233207   \n",
       "4     103.789800  133.808609   70.602435  114.421924  125.141318  148.144403   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  128.394731  113.120062  102.722429   71.609424  151.352281  140.904922   \n",
       "2439  128.269154  112.982064  102.785866   71.581983  151.277725  140.892099   \n",
       "2440  128.143792  112.844766  102.852637   71.555953  151.200817  140.880374   \n",
       "2441  128.018936  112.708365  102.922962   71.531847  151.121227  140.870082   \n",
       "2442  127.894929  112.572888  102.996952   71.509933  151.038840  140.861436   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...   sensor39  \\\n",
       "0     105.960735  134.734917   90.358364  107.880691  ...  80.511088   \n",
       "1     105.788181  134.546280   90.431246  107.970290  ...  80.667880   \n",
       "2     105.613823  134.358052   90.503448  108.058270  ...  80.823085   \n",
       "3     105.437718  134.170555   90.574876  108.144722  ...  80.976531   \n",
       "4     105.260017  133.984101   90.645256  108.229792  ...  81.128195   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  128.827778  113.779812  107.558742   96.997103  ...  88.095891   \n",
       "2439  128.842679  113.832694  107.410332   96.815164  ...  88.034588   \n",
       "2440  128.857569  113.886728  107.258332   96.632920  ...  87.974760   \n",
       "2441  128.872267  113.942389  107.102486   96.450473  ...  87.916419   \n",
       "2442  128.886554  113.999895  106.942607   96.267932  ...  87.859482   \n",
       "\n",
       "        sensor40   sensor41   sensor42    sensor43    sensor44    sensor45  \\\n",
       "0      86.266577  91.324276  88.413835  118.079357  112.830599  101.581432   \n",
       "1      86.301348  91.369136  88.468505  117.851056  112.732842  101.535137   \n",
       "2      86.337129  91.414783  88.521309  117.621052  112.638386  101.491179   \n",
       "3      86.373826  91.461416  88.572363  117.389684  112.547228  101.449812   \n",
       "4      86.411394  91.509328  88.621720  117.157444  112.459148  101.411458   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  110.712051  89.522396  71.221952  124.108295  113.383110  130.244963   \n",
       "2439  110.548388  89.310220  71.379769  124.099541  113.470836  130.083759   \n",
       "2440  110.380633  89.095824  71.538448  124.091471  113.557163  129.920154   \n",
       "2441  110.208561  88.879379  71.697850  124.084220  113.641886  129.753926   \n",
       "2442  110.032132  88.660934  71.857879  124.077867  113.725050  129.584939   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     130.484864   65.849519  112.853971  \n",
       "1     130.422780   65.831506  112.816370  \n",
       "2     130.363766   65.812886  112.778795  \n",
       "3     130.307871   65.793756  112.741332  \n",
       "4     130.254975   65.774054  112.703922  \n",
       "...          ...         ...         ...  \n",
       "2438  114.622501  107.532818   76.703086  \n",
       "2439  114.395532  107.742386   76.682848  \n",
       "2440  114.165400  107.949968   76.663408  \n",
       "2441  113.932214  108.155353   76.644759  \n",
       "2442  113.696233  108.358487   76.626723  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf63fe",
   "metadata": {},
   "source": [
    "# Taking 4 Sensors (41,42,43,44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090b68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.324276</td>\n",
       "      <td>88.413835</td>\n",
       "      <td>118.079357</td>\n",
       "      <td>112.830599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91.369136</td>\n",
       "      <td>88.468505</td>\n",
       "      <td>117.851056</td>\n",
       "      <td>112.732842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.414783</td>\n",
       "      <td>88.521309</td>\n",
       "      <td>117.621052</td>\n",
       "      <td>112.638386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.461416</td>\n",
       "      <td>88.572363</td>\n",
       "      <td>117.389684</td>\n",
       "      <td>112.547228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.509328</td>\n",
       "      <td>88.621720</td>\n",
       "      <td>117.157444</td>\n",
       "      <td>112.459148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>89.522396</td>\n",
       "      <td>71.221952</td>\n",
       "      <td>124.108295</td>\n",
       "      <td>113.383110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>89.310220</td>\n",
       "      <td>71.379769</td>\n",
       "      <td>124.099541</td>\n",
       "      <td>113.470836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>89.095824</td>\n",
       "      <td>71.538448</td>\n",
       "      <td>124.091471</td>\n",
       "      <td>113.557163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>88.879379</td>\n",
       "      <td>71.697850</td>\n",
       "      <td>124.084220</td>\n",
       "      <td>113.641886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>88.660934</td>\n",
       "      <td>71.857879</td>\n",
       "      <td>124.077867</td>\n",
       "      <td>113.725050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sensor41   sensor42    sensor43    sensor44\n",
       "0     91.324276  88.413835  118.079357  112.830599\n",
       "1     91.369136  88.468505  117.851056  112.732842\n",
       "2     91.414783  88.521309  117.621052  112.638386\n",
       "3     91.461416  88.572363  117.389684  112.547228\n",
       "4     91.509328  88.621720  117.157444  112.459148\n",
       "...         ...        ...         ...         ...\n",
       "2438  89.522396  71.221952  124.108295  113.383110\n",
       "2439  89.310220  71.379769  124.099541  113.470836\n",
       "2440  89.095824  71.538448  124.091471  113.557163\n",
       "2441  88.879379  71.697850  124.084220  113.641886\n",
       "2442  88.660934  71.857879  124.077867  113.725050\n",
       "\n",
       "[2443 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data  = sensors_data.iloc[:, [40, 41, 42, 43]]\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 8ms/step - loss: 1367.8746 - val_loss: 1236.2832\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1202.3159 - val_loss: 1139.6549\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1118.6986 - val_loss: 1067.8174\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1056.8732 - val_loss: 1015.6400\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1011.8685 - val_loss: 977.7076\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 979.4406 - val_loss: 950.9066\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 956.2375 - val_loss: 931.8533\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 941.0302 - val_loss: 920.4802\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 931.8603 - val_loss: 913.8067\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 926.7623 - val_loss: 910.3273\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 924.1747 - val_loss: 908.6586\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.9935 - val_loss: 907.9526\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.4477 - val_loss: 907.7637\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.2595 - val_loss: 907.6974\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 922.2068 - val_loss: 907.6689\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.1949 - val_loss: 907.6539\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.1973 - val_loss: 907.6561\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 902.7233 - val_loss: 845.3721\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 830.6503 - val_loss: 797.5514\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 792.0950 - val_loss: 764.1092\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 755.4508 - val_loss: 734.5597\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 722.1515 - val_loss: 693.1169\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 689.7063 - val_loss: 661.8626\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 658.1921 - val_loss: 630.7322\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 629.6783 - val_loss: 601.9340\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 602.0819 - val_loss: 576.2722\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 575.6214 - val_loss: 548.1476\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 550.2311 - val_loss: 524.4669\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 526.9565 - val_loss: 502.8840\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 505.6588 - val_loss: 482.9232\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 485.4799 - val_loss: 462.3301\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 466.3211 - val_loss: 444.3681\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 448.2170 - val_loss: 428.2281\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 432.3457 - val_loss: 407.6443\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 415.1992 - val_loss: 390.6474\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 399.5454 - val_loss: 372.7672\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 378.3383 - val_loss: 354.3233\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 361.4217 - val_loss: 332.5541\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 341.5872 - val_loss: 316.5020\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 325.0851 - val_loss: 300.1629\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 311.1985 - val_loss: 286.6762\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 300.2707 - val_loss: 278.7944\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 290.2719 - val_loss: 269.6749\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 283.9530 - val_loss: 265.2899\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 277.5154 - val_loss: 259.3836\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 272.3144 - val_loss: 254.6758\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 269.0054 - val_loss: 250.2762\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 262.6972 - val_loss: 241.1845\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 258.3802 - val_loss: 236.8775\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 252.0577 - val_loss: 236.5191\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 248.6883 - val_loss: 227.7796\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 238.8310 - val_loss: 213.1889\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.1591 - val_loss: 213.1387\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.0202 - val_loss: 196.1932\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 221.6704 - val_loss: 194.3274\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 209.6495 - val_loss: 191.1485\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 211.9269 - val_loss: 187.0852\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 198.8617 - val_loss: 174.2786\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 202.3667 - val_loss: 185.3590\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 188.2201 - val_loss: 178.8011\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 187.3543 - val_loss: 159.9485\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 176.9611 - val_loss: 161.5779\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 176.7895 - val_loss: 156.4383\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 173.6430 - val_loss: 149.4056\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 179.6147 - val_loss: 147.9434\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 166.9087 - val_loss: 156.4799\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.4561 - val_loss: 203.1830\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 178.8331 - val_loss: 141.9518\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 160.5820 - val_loss: 156.0780\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 161.2323 - val_loss: 136.6279\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 161.8224 - val_loss: 134.1698\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 145.0540 - val_loss: 155.1200\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 150.2700 - val_loss: 127.9509\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 138.8284 - val_loss: 143.6524\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 143.5474 - val_loss: 125.3812\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 141.5468 - val_loss: 148.1209\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 137.2431 - val_loss: 124.9105\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 6ms/step - loss: 140.6830 - val_loss: 149.4767\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 133.8651 - val_loss: 129.0214\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 169.2995 - val_loss: 118.1571\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 129.3226 - val_loss: 174.7028\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 132.7312 - val_loss: 112.6293\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 136.4295 - val_loss: 135.9097\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 127.9648 - val_loss: 113.6846\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 130.0623 - val_loss: 112.1803\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 141.2217 - val_loss: 123.2957\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 121.8295 - val_loss: 120.8286\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 128.2986 - val_loss: 124.3550\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 129.5542 - val_loss: 119.3207\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 129.1542 - val_loss: 113.4450\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 128.3300 - val_loss: 104.6586\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 129.3218 - val_loss: 137.1912\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 110.9163 - val_loss: 122.1824\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 123.7838 - val_loss: 119.6152\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 116.0711 - val_loss: 130.5963\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 124.9333 - val_loss: 114.7106\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 123.4994 - val_loss: 103.9109\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 131.4923 - val_loss: 131.2264\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 116.2508 - val_loss: 121.3137\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 123.3986 - val_loss: 95.7705\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 118.0441 - val_loss: 107.4716\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 111.4320 - val_loss: 163.4427\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 115.5456 - val_loss: 145.6611\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 119.1922 - val_loss: 91.6828\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 116.9970 - val_loss: 99.1112\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 125.4881 - val_loss: 163.3398\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 141.1030 - val_loss: 93.1301\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 107.1755 - val_loss: 101.3242\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 111.5227 - val_loss: 113.1972\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 109.1219 - val_loss: 99.8249\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 111.6032 - val_loss: 105.3193\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 123.2710 - val_loss: 89.6643\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 112.2950 - val_loss: 86.6825\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 135.6629 - val_loss: 144.4851\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 121.7307 - val_loss: 117.7387\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 109.9559 - val_loss: 88.1123\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 110.3183 - val_loss: 108.0463\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 120.0703 - val_loss: 83.0203\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 105.9546 - val_loss: 92.6511\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 109.3135 - val_loss: 79.0948\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 122.7417 - val_loss: 147.3502\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 129.9135 - val_loss: 114.6753\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 121.2613 - val_loss: 93.6593\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 103.5723 - val_loss: 143.3438\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 121.2765 - val_loss: 111.4213\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 101.5419 - val_loss: 101.5662\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 106.6258 - val_loss: 157.1041\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 117.8014 - val_loss: 87.0366\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 106.8617 - val_loss: 103.1232\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 101.1828 - val_loss: 85.1486\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 103.0887 - val_loss: 145.6474\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 118.9462 - val_loss: 81.3960\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 114.5308 - val_loss: 138.6142\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 125.0140 - val_loss: 90.9337\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 107.7219 - val_loss: 83.8394\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 94.5331 - val_loss: 114.6876\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 110.8295 - val_loss: 149.8028\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 106.2805 - val_loss: 89.0048\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 113.1344 - val_loss: 78.5134\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 94.3970 - val_loss: 151.5025\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 106.7207 - val_loss: 77.9201\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 102.9808 - val_loss: 224.5991\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 120.9312 - val_loss: 96.0136\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.1831 - val_loss: 76.4063\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 97.0486 - val_loss: 70.0097\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 102.1603 - val_loss: 130.2930\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 124.7201 - val_loss: 114.9055\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 115.3664 - val_loss: 104.5894\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 117.1172 - val_loss: 175.5910\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 109.2664 - val_loss: 90.5238\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 103.9780 - val_loss: 74.7188\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 106.4842 - val_loss: 137.9180\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.7131 - val_loss: 71.6600\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 87.5172 - val_loss: 88.6267\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 6ms/step - loss: 138.8659 - val_loss: 95.8797\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 100.2354 - val_loss: 107.8756\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 113.7027 - val_loss: 107.7590\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 109.9993 - val_loss: 98.0804\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 100.6574 - val_loss: 136.2241\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 128.8107 - val_loss: 96.8515\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 102.6584 - val_loss: 77.2818\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 94.1140 - val_loss: 95.9315\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 95.8692 - val_loss: 69.3625\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 107.7080 - val_loss: 79.5175\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 95.4846 - val_loss: 80.1615\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 109.7931 - val_loss: 117.0665\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 112.9022 - val_loss: 69.5806\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 94.0873 - val_loss: 105.9067\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 95.4291 - val_loss: 82.5470\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 86.5459 - val_loss: 75.6472\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 102.4783 - val_loss: 266.5307\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 93.1813 - val_loss: 97.4977\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 90.8032 - val_loss: 112.3838\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 93.4575 - val_loss: 134.1292\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 92.4240 - val_loss: 132.6075\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.0063 - val_loss: 72.7506\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 85.8566 - val_loss: 74.9125\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 93.4879 - val_loss: 93.9217\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 107.3587 - val_loss: 102.9644\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 101.3140 - val_loss: 162.5467\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 127.5142 - val_loss: 101.6329\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 99.7638 - val_loss: 105.9950\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 104.4274 - val_loss: 100.9043\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 106.0700 - val_loss: 113.9556\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 97.7052 - val_loss: 78.6798\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 122.5373 - val_loss: 162.3248\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 112.7061 - val_loss: 144.1380\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 95.0916 - val_loss: 103.5327\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 82.1255 - val_loss: 64.3355\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 93.6889 - val_loss: 103.3151\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 100.0297 - val_loss: 224.7079\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 120.8456 - val_loss: 75.5821\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 84.3782 - val_loss: 87.6279\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 81.0002 - val_loss: 60.2726\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 85.2520 - val_loss: 63.0990\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 90.0724 - val_loss: 199.8792\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 100.2603 - val_loss: 66.5863\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 109.0661 - val_loss: 101.6771\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 84.7054 - val_loss: 106.5609\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 82.1268 - val_loss: 63.4576\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 63.47525201926437\n",
      "Mean Absolute Error (MAE): 4.039255493672681\n",
      "Root Mean Squared Error (RMSE): 7.967135747510794\n",
      "Time taken: 482.98261737823486\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 9ms/step - loss: 1395.5914 - val_loss: 1277.1176\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1218.0339 - val_loss: 1174.0784\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1129.2948 - val_loss: 1100.2736\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1064.2454 - val_loss: 1045.5891\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1016.1202 - val_loss: 1005.4918\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 980.9093 - val_loss: 976.5877\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 956.1472 - val_loss: 956.6339\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 939.4915 - val_loss: 943.7963\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 928.9827 - val_loss: 936.1288\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 922.8524 - val_loss: 931.9642\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 919.6371 - val_loss: 929.9316\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 918.0821 - val_loss: 929.1847\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 917.4058 - val_loss: 928.8161\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 917.1188 - val_loss: 928.8405\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 917.0362 - val_loss: 928.7261\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 917.0250 - val_loss: 928.7069\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 915.1340 - val_loss: 919.2790\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 883.5862 - val_loss: 872.2098\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 853.5385 - val_loss: 854.1602\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 831.4979 - val_loss: 833.0410\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 796.0463 - val_loss: 769.5060\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 711.6337 - val_loss: 696.6686\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 659.3082 - val_loss: 653.3574\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 617.9457 - val_loss: 615.3174\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 580.5052 - val_loss: 580.9785\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 546.6968 - val_loss: 552.1761\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 515.9144 - val_loss: 521.2905\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 486.7828 - val_loss: 493.8416\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 460.0656 - val_loss: 469.4594\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 435.4955 - val_loss: 445.7935\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 412.7174 - val_loss: 424.1021\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 391.6425 - val_loss: 406.5499\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 372.5526 - val_loss: 387.3482\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 355.3471 - val_loss: 374.6770\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 340.4297 - val_loss: 357.7788\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 327.0425 - val_loss: 346.4859\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 315.9566 - val_loss: 333.3520\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 305.0706 - val_loss: 323.0939\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 296.1935 - val_loss: 314.2312\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 286.5512 - val_loss: 309.8395\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 279.7233 - val_loss: 299.2585\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 273.4665 - val_loss: 294.3760\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 267.6086 - val_loss: 288.1437\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 262.7811 - val_loss: 283.6732\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 258.0326 - val_loss: 280.0182\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 253.9226 - val_loss: 273.9520\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 251.2675 - val_loss: 270.8328\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.8844 - val_loss: 270.4749\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.5493 - val_loss: 266.8136\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 240.5386 - val_loss: 262.2669\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 237.5974 - val_loss: 261.4679\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 236.2133 - val_loss: 270.4747\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.5470 - val_loss: 245.2298\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.3449 - val_loss: 245.5193\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 220.8355 - val_loss: 245.2246\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 212.5913 - val_loss: 225.2644\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 211.4324 - val_loss: 224.5875\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 203.3715 - val_loss: 213.4654\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 202.0601 - val_loss: 208.9043\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 199.0255 - val_loss: 213.7524\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 188.9569 - val_loss: 195.3259\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 184.7744 - val_loss: 195.0448\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 187.1970 - val_loss: 278.5063\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 182.6153 - val_loss: 204.9867\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 173.4300 - val_loss: 180.1258\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 175.5493 - val_loss: 174.0054\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 170.0562 - val_loss: 171.9649\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 163.7066 - val_loss: 164.3240\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 162.0517 - val_loss: 162.0691\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 164.1666 - val_loss: 163.4762\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 154.8725 - val_loss: 156.7843\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 148.6571 - val_loss: 149.7357\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 154.7469 - val_loss: 161.9233\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 153.4393 - val_loss: 149.9585\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 143.1297 - val_loss: 141.7603\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 146.6410 - val_loss: 151.4504\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 140.7563 - val_loss: 165.8132\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 147.4008 - val_loss: 150.5442\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 140.9901 - val_loss: 172.0467\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 144.8191 - val_loss: 145.1108\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 133.2810 - val_loss: 131.8567\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 142.2534 - val_loss: 154.0337\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 140.0865 - val_loss: 129.2247\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 131.0611 - val_loss: 130.4885\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 132.5134 - val_loss: 219.5563\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 143.0751 - val_loss: 186.8896\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 135.2805 - val_loss: 118.5420\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 139.1215 - val_loss: 124.5701\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 132.6151 - val_loss: 122.6108\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 130.5092 - val_loss: 122.0557\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 139.4402 - val_loss: 127.7007\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 125.6296 - val_loss: 121.8022\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 152.3152 - val_loss: 171.0618\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 139.7613 - val_loss: 120.3151\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 121.6713 - val_loss: 131.4863\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 130.1548 - val_loss: 131.0909\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 128.8061 - val_loss: 170.3803\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 140.6717 - val_loss: 213.2627\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 121.1691 - val_loss: 119.6901\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 115.4977 - val_loss: 130.3600\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 131.4715 - val_loss: 123.4820\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 116.7194 - val_loss: 133.7169\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 128.2686 - val_loss: 114.8652\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 133.6938 - val_loss: 124.1021\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 115.5792 - val_loss: 137.9035\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 118.7397 - val_loss: 134.1808\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 116.4144 - val_loss: 105.9848\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 126.6555 - val_loss: 119.1684\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 124.9131 - val_loss: 116.1429\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 117.8251 - val_loss: 115.4529\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 128.9537 - val_loss: 157.3622\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 123.8951 - val_loss: 142.8156\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 128.3840 - val_loss: 176.9207\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 117.9567 - val_loss: 103.6971\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 120.6263 - val_loss: 114.3007\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 120.5595 - val_loss: 119.3637\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 118.3399 - val_loss: 171.5102\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 112.4305 - val_loss: 107.0480\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 129.7556 - val_loss: 139.7711\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 107.9959 - val_loss: 104.9895\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 122.4378 - val_loss: 105.4714\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 112.0559 - val_loss: 101.1687\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 131.7987 - val_loss: 110.7882\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 111.9532 - val_loss: 153.4509\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 116.1227 - val_loss: 105.2397\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 121.4208 - val_loss: 121.9378\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 117.1803 - val_loss: 124.2114\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 109.3522 - val_loss: 159.1566\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 123.8086 - val_loss: 102.9945\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 117.7263 - val_loss: 115.5454\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 115.5545 - val_loss: 106.8677\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 126.1120 - val_loss: 128.5808\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 114.3574 - val_loss: 136.4859\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 112.0151 - val_loss: 113.2909\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 118.2436 - val_loss: 135.6503\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 124.0468 - val_loss: 104.5001\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 118.1037 - val_loss: 113.5069\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 114.2178 - val_loss: 95.7675\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 112.1449 - val_loss: 181.1851\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 109.5920 - val_loss: 135.9246\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 121.7439 - val_loss: 109.2362\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.5304 - val_loss: 113.2686\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 105.7321 - val_loss: 115.2142\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 113.0748 - val_loss: 134.8318\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 114.2833 - val_loss: 165.1795\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 105.3900 - val_loss: 97.4266\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.2360 - val_loss: 103.1965\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.6464 - val_loss: 105.6268\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 102.8925 - val_loss: 118.5542\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 97.9358 - val_loss: 98.7178\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 125.5155 - val_loss: 117.9977\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 96.9364 - val_loss: 88.4230\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 115.0423 - val_loss: 106.9835\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 107.1631 - val_loss: 90.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 95.2440 - val_loss: 93.1868\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 103.4180 - val_loss: 94.1527\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 99.2820 - val_loss: 126.4092\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 107.1188 - val_loss: 106.2567\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.8463 - val_loss: 100.7196\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 99.9364 - val_loss: 101.7558\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.8300 - val_loss: 90.4215\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.8250 - val_loss: 76.8312\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 109.7706 - val_loss: 119.4648\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.0459 - val_loss: 91.3100\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 99.3305 - val_loss: 77.4226\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 95.1739 - val_loss: 145.2683\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 109.3107 - val_loss: 144.0667\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.9793 - val_loss: 98.5440\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 101.7235 - val_loss: 90.8303\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.4062 - val_loss: 133.1534\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 111.6870 - val_loss: 100.5373\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 93.0578 - val_loss: 135.2579\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 115.0221 - val_loss: 217.8884\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 118.3498 - val_loss: 90.2076\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 101.1609 - val_loss: 175.7597\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 120.3909 - val_loss: 197.9978\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 99.7977 - val_loss: 101.9281\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 95.2836 - val_loss: 109.4025\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.1878 - val_loss: 97.9977\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 96.6579 - val_loss: 135.6204\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 91.9211 - val_loss: 76.7346\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 96.6740 - val_loss: 170.2336\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 94.5968 - val_loss: 91.0095\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 83.7769 - val_loss: 102.9622\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 101.0523 - val_loss: 157.7701\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 134.3833 - val_loss: 93.2059\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 88.9267 - val_loss: 78.2391\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 89.4959 - val_loss: 76.2788\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 98.0833 - val_loss: 105.5481\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 140.3463 - val_loss: 165.9783\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 117.4936 - val_loss: 156.7560\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 91.1341 - val_loss: 77.6116\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 106.7880 - val_loss: 87.1136\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 107.9548 - val_loss: 91.2613\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 86.9625 - val_loss: 70.8747\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 91.2144 - val_loss: 98.7532\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 121.2857 - val_loss: 116.1857\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 95.3266 - val_loss: 87.5483\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 93.7614 - val_loss: 97.4694\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 108.0859 - val_loss: 86.1237\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 86.0955332889237\n",
      "Mean Absolute Error (MAE): 4.602192458455175\n",
      "Root Mean Squared Error (RMSE): 9.278767875581526\n",
      "Time taken: 473.11538100242615\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 9ms/step - loss: 1382.5983 - val_loss: 1280.7906\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1214.2108 - val_loss: 1181.9854\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1127.7983 - val_loss: 1109.1566\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1062.5327 - val_loss: 1053.5479\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1014.0338 - val_loss: 1013.4496\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 978.9506 - val_loss: 984.8777\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 954.2397 - val_loss: 965.3308\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 937.5171 - val_loss: 952.6304\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 926.9079 - val_loss: 944.9619\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 920.7000 - val_loss: 940.7771\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 917.3033 - val_loss: 938.7678\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 915.7285 - val_loss: 937.9800\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 915.0195 - val_loss: 937.6818\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 914.7809 - val_loss: 937.6280\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 914.6830 - val_loss: 937.6618\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 914.6891 - val_loss: 937.6656\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 914.6765 - val_loss: 937.7093\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 914.6653 - val_loss: 937.7237\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 903.6406 - val_loss: 863.0270\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 821.9476 - val_loss: 812.7971\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 780.0507 - val_loss: 774.4379\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 742.7292 - val_loss: 738.8641\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 708.6490 - val_loss: 707.8825\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 675.5039 - val_loss: 675.0295\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 643.0068 - val_loss: 640.0889\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 612.4380 - val_loss: 610.6719\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 583.0723 - val_loss: 583.3711\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 557.2820 - val_loss: 557.9666\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 530.2386 - val_loss: 529.4275\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 507.5571 - val_loss: 509.6638\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 483.9730 - val_loss: 487.0101\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 461.6450 - val_loss: 463.3027\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 442.2658 - val_loss: 443.3502\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 422.0669 - val_loss: 426.7692\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 404.5939 - val_loss: 408.6842\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 388.5263 - val_loss: 392.1618\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 373.0354 - val_loss: 373.6196\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 345.3665 - val_loss: 337.4294\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 320.7120 - val_loss: 324.3145\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 307.8105 - val_loss: 311.6824\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 297.2445 - val_loss: 301.2838\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 288.3394 - val_loss: 291.9403\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 280.6378 - val_loss: 284.7147\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 274.4196 - val_loss: 278.8170\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 269.0851 - val_loss: 277.0421\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 265.1138 - val_loss: 269.3177\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 259.5957 - val_loss: 268.1309\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 256.7965 - val_loss: 262.2843\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 253.0678 - val_loss: 256.3676\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 248.9432 - val_loss: 252.0049\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 242.8742 - val_loss: 250.4482\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.6127 - val_loss: 239.5025\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.0112 - val_loss: 262.2658\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.2174 - val_loss: 235.8759\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 217.3891 - val_loss: 213.5609\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 229.3375 - val_loss: 217.0859\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 208.6155 - val_loss: 224.7738\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 203.9085 - val_loss: 222.9834\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 192.8633 - val_loss: 194.2295\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 191.3417 - val_loss: 189.9187\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 183.9892 - val_loss: 185.0091\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 188.7995 - val_loss: 182.5667\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 183.4895 - val_loss: 192.2681\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 170.1765 - val_loss: 169.3929\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 189.0854 - val_loss: 171.2439\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 175.7012 - val_loss: 166.5511\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 161.5275 - val_loss: 156.1137\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 183.5849 - val_loss: 154.3031\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 159.3345 - val_loss: 162.6041\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 155.1519 - val_loss: 202.4726\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 153.3297 - val_loss: 229.1187\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 149.8349 - val_loss: 197.4509\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 147.6579 - val_loss: 137.5154\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 144.6746 - val_loss: 143.8745\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 152.4743 - val_loss: 181.9834\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 141.0780 - val_loss: 142.3263\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 139.6861 - val_loss: 148.5513\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 134.5307 - val_loss: 135.8988\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 144.1675 - val_loss: 144.4527\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 145.1465 - val_loss: 138.9469\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 135.0888 - val_loss: 117.3920\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 132.9826 - val_loss: 148.1369\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 128.8209 - val_loss: 120.7382\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 131.1189 - val_loss: 160.6527\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 130.4612 - val_loss: 136.3547\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 124.4529 - val_loss: 116.5819\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 126.4472 - val_loss: 126.3300\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 122.4883 - val_loss: 108.8668\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 126.9885 - val_loss: 128.3696\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 119.8034 - val_loss: 112.1715\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 132.8662 - val_loss: 194.8585\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 140.8588 - val_loss: 179.9361\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 123.9350 - val_loss: 207.4846\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 124.1626 - val_loss: 125.3164\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 129.5197 - val_loss: 137.5081\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 123.6843 - val_loss: 127.3380\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 113.6724 - val_loss: 217.6121\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 125.5557 - val_loss: 152.3063\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 124.1468 - val_loss: 112.5932\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 126.9013 - val_loss: 151.9409\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 125.4644 - val_loss: 152.1874\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 129.7390 - val_loss: 144.9836\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 120.4489 - val_loss: 122.7034\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 113.1691 - val_loss: 134.8933\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 118.7816 - val_loss: 131.8997\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 125.7259 - val_loss: 102.9997\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 118.8195 - val_loss: 108.2366\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 127.1664 - val_loss: 217.3872\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 112.1326 - val_loss: 117.3068\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 126.0548 - val_loss: 115.1084\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 104.7020 - val_loss: 102.4212\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 119.0685 - val_loss: 119.3953\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 112.2544 - val_loss: 93.4446\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 103.3937 - val_loss: 88.1916\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 117.3217 - val_loss: 127.6634\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 116.7127 - val_loss: 104.1593\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 120.9124 - val_loss: 124.7342\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 112.0980 - val_loss: 130.7894\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 110.9248 - val_loss: 127.0000\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 107.0375 - val_loss: 121.1906\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.3160 - val_loss: 144.2468\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 119.1026 - val_loss: 87.3206\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 95.7262 - val_loss: 94.0488\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 108.1754 - val_loss: 87.3156\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 133.2807 - val_loss: 92.9955\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 128.2694 - val_loss: 228.7474\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 123.1555 - val_loss: 153.4599\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 99.4782 - val_loss: 111.1021\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 111.7358 - val_loss: 130.7136\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 117.4189 - val_loss: 98.3431\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 93.9321 - val_loss: 78.2758\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.5010 - val_loss: 104.7042\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 103.0351 - val_loss: 84.9589\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 103.1499 - val_loss: 111.5198\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 110.3980 - val_loss: 147.0232\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 98.2091 - val_loss: 134.4451\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 105.6436 - val_loss: 79.2117\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 93.1039 - val_loss: 105.1273\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.2362 - val_loss: 129.7456\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 107.3769 - val_loss: 200.2583\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 108.7023 - val_loss: 174.2588\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 98.5477 - val_loss: 87.3094\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 86.2511 - val_loss: 173.7735\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 108.3410 - val_loss: 94.2261\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 98.6904 - val_loss: 126.2085\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 116.7491 - val_loss: 76.7054\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 93.5849 - val_loss: 91.3721\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 99.9334 - val_loss: 78.5760\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 86.8066 - val_loss: 86.7607\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 111.3517 - val_loss: 116.6023\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 89.1710 - val_loss: 66.5164\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 86.0466 - val_loss: 127.7341\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 97.6474 - val_loss: 144.1613\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 93.2731 - val_loss: 72.0194\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 88.1594 - val_loss: 109.2414\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 111.3348 - val_loss: 84.4596\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 92.8436 - val_loss: 71.8784\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 97.5166 - val_loss: 76.8377\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 88.8684 - val_loss: 148.0809\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 95.8293 - val_loss: 92.7982\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 90.9940 - val_loss: 68.3120\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 90.2683 - val_loss: 84.4738\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 121.0971 - val_loss: 113.0359\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 99.6309 - val_loss: 73.9352\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 85.0410 - val_loss: 77.4814\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 96.6437 - val_loss: 71.5859\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 84.6019 - val_loss: 81.7861\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 89.5987 - val_loss: 88.1272\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 103.9172 - val_loss: 68.2211\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 102.2152 - val_loss: 98.3539\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 85.6089 - val_loss: 70.7611\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 113.9997 - val_loss: 73.5279\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 80.9394 - val_loss: 187.5147\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 96.8301 - val_loss: 78.4145\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 81.1506 - val_loss: 88.2965\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 102.1114 - val_loss: 158.2276\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 91.9565 - val_loss: 175.8123\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 105.5350 - val_loss: 147.2796\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 134.0446 - val_loss: 117.5165\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 108.5805 - val_loss: 93.4383\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 105.8416 - val_loss: 83.1173\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 95.2027 - val_loss: 92.9390\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 95.4775 - val_loss: 114.2119\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 88.3817 - val_loss: 87.8187\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 104.8614 - val_loss: 62.9061\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 108.5828 - val_loss: 107.8107\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 84.0409 - val_loss: 131.5130\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 100.8062 - val_loss: 71.0238\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 81.3348 - val_loss: 75.4880\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 84.8308 - val_loss: 81.3436\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 109.5107 - val_loss: 62.2944\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 95.1929 - val_loss: 109.6463\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 88.4104 - val_loss: 76.7096\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 74.6178 - val_loss: 102.1029\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 83.1022 - val_loss: 78.1263\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 83.7809 - val_loss: 78.9803\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 102.3668 - val_loss: 62.7241\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 94.6710 - val_loss: 69.8367\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 79.3554 - val_loss: 69.6247\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 101.9480 - val_loss: 121.5702\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 121.62666479780296\n",
      "Mean Absolute Error (MAE): 5.513145334300062\n",
      "Root Mean Squared Error (RMSE): 11.028447977743875\n",
      "Time taken: 470.66077494621277\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 8ms/step - loss: 1363.2938 - val_loss: 1205.6509\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1188.0353 - val_loss: 1111.1724\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1105.9127 - val_loss: 1045.4026\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1046.5391 - val_loss: 997.7870\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1003.4695 - val_loss: 963.8687\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 972.9271 - val_loss: 940.9060\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 951.9530 - val_loss: 925.7922\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 938.3774 - val_loss: 916.7568\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 930.2310 - val_loss: 912.0158\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 925.7567 - val_loss: 909.9282\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 923.6125 - val_loss: 909.1887\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.5438 - val_loss: 909.0774\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.1456 - val_loss: 909.1898\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 921.9995 - val_loss: 909.3269\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 921.9767 - val_loss: 909.3406\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 921.9795 - val_loss: 909.4083\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 911.8948 - val_loss: 835.1478\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 826.3769 - val_loss: 778.7382\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 782.9253 - val_loss: 743.3549\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 745.9607 - val_loss: 706.1509\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 711.3242 - val_loss: 679.6339\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 678.7002 - val_loss: 647.1234\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 648.2509 - val_loss: 615.7073\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 620.5688 - val_loss: 589.2261\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 594.1462 - val_loss: 566.4681\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 569.2101 - val_loss: 539.6240\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 545.2131 - val_loss: 517.1880\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 523.0664 - val_loss: 500.6333\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 503.0963 - val_loss: 479.6621\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 482.8725 - val_loss: 458.3426\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 463.8045 - val_loss: 439.1106\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 443.0113 - val_loss: 418.7303\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 424.5230 - val_loss: 397.5809\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 404.0930 - val_loss: 376.6886\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 374.4300 - val_loss: 342.2651\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 346.4892 - val_loss: 323.2191\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 329.0316 - val_loss: 308.0426\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 315.4483 - val_loss: 294.0970\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 304.4289 - val_loss: 284.7451\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 294.9753 - val_loss: 276.2445\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 285.6030 - val_loss: 267.4215\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 277.2312 - val_loss: 259.1083\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 271.0022 - val_loss: 251.6963\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 262.2745 - val_loss: 261.7120\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 253.6874 - val_loss: 244.4843\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 244.8448 - val_loss: 224.6223\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 236.1718 - val_loss: 216.8650\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 237.1010 - val_loss: 211.9742\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 221.6841 - val_loss: 205.0468\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 220.6195 - val_loss: 202.3409\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 210.4499 - val_loss: 192.2775\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 202.2613 - val_loss: 186.6843\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 200.1561 - val_loss: 180.6579\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 191.8179 - val_loss: 175.7747\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 187.7415 - val_loss: 193.6553\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 188.3951 - val_loss: 169.6797\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 181.7421 - val_loss: 180.0054\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 183.0764 - val_loss: 164.3266\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 186.9980 - val_loss: 165.5252\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 164.9216 - val_loss: 154.5680\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 166.7026 - val_loss: 144.1333\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 165.8208 - val_loss: 141.0633\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 163.0566 - val_loss: 155.2966\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 154.3347 - val_loss: 141.3673\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 151.1813 - val_loss: 146.9690\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 155.8324 - val_loss: 126.7964\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 143.5107 - val_loss: 166.5562\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 161.4462 - val_loss: 293.8031\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 160.3786 - val_loss: 123.8800\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 146.8698 - val_loss: 124.8495\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 139.9147 - val_loss: 136.6953\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 136.9850 - val_loss: 141.7464\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 135.8607 - val_loss: 125.7729\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 139.8954 - val_loss: 122.3271\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 139.3200 - val_loss: 119.6696\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 147.8775 - val_loss: 115.0716\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 124.7572 - val_loss: 118.9544\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 133.1922 - val_loss: 112.6044\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 131.1119 - val_loss: 140.3084\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 129.8332 - val_loss: 112.3707\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 120.7190 - val_loss: 107.0481\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 144.5629 - val_loss: 117.8182\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 114.3569 - val_loss: 151.8134\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 129.9115 - val_loss: 128.4269\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 123.1662 - val_loss: 97.5309\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 126.1531 - val_loss: 133.9878\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 129.0827 - val_loss: 116.2383\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 114.6545 - val_loss: 107.0081\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 116.2135 - val_loss: 117.9985\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 116.1660 - val_loss: 109.6785\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 112.3534 - val_loss: 96.1523\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 113.8903 - val_loss: 140.3469\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 128.6071 - val_loss: 171.0812\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 121.0869 - val_loss: 110.2397\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 111.4860 - val_loss: 97.7248\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 120.6568 - val_loss: 97.0325\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 116.0330 - val_loss: 175.0209\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 109.2925 - val_loss: 113.6093\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 108.5198 - val_loss: 89.2283\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 116.4764 - val_loss: 106.0365\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 111.9483 - val_loss: 114.3055\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 107.2503 - val_loss: 86.3165\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 102.8058 - val_loss: 101.8261\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 103.1314 - val_loss: 115.7959\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 97.3975 - val_loss: 183.0660\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 102.1651 - val_loss: 81.9493\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 103.0322 - val_loss: 87.7809\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 110.0502 - val_loss: 144.1720\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 106.6506 - val_loss: 93.2486\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 108.4024 - val_loss: 88.3883\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 101.2291 - val_loss: 86.6008\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 102.8520 - val_loss: 85.4436\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 94.6835 - val_loss: 80.1322\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 114.8962 - val_loss: 76.3725\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 101.3477 - val_loss: 159.2353\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 98.5633 - val_loss: 75.6200\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 102.8707 - val_loss: 77.5869\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 101.6946 - val_loss: 92.0569\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 119.0540 - val_loss: 159.5627\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 118.9445 - val_loss: 94.0450\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 107.6624 - val_loss: 149.2201\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 103.9971 - val_loss: 79.6369\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 93.7664 - val_loss: 97.2840\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 92.2958 - val_loss: 90.9542\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 106.6489 - val_loss: 85.7156\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 94.3548 - val_loss: 81.4756\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 90.4362 - val_loss: 106.5615\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 91.6449 - val_loss: 72.4889\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 91.7808 - val_loss: 106.7762\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 94.5166 - val_loss: 98.1854\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 106.3819 - val_loss: 77.2336\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 93.7799 - val_loss: 72.9536\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 82.3847 - val_loss: 69.4108\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 90.5473 - val_loss: 96.8624\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 131.1661 - val_loss: 70.6356\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 91.6961 - val_loss: 77.1765\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 94.7498 - val_loss: 80.9736\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 87.8055 - val_loss: 98.5049\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 90.0402 - val_loss: 96.6284\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 97.1693 - val_loss: 251.8086\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 141.8820 - val_loss: 138.7296\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 101.7577 - val_loss: 81.7307\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 89.5847 - val_loss: 96.5455\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 92.2582 - val_loss: 83.1558\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 99.8749 - val_loss: 165.4291\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 136.5885 - val_loss: 118.9966\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 119.8696 - val_loss: 111.4029\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 107.6500 - val_loss: 98.1702\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 106.8672 - val_loss: 136.7268\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 114.4433 - val_loss: 93.1451\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 116.3851 - val_loss: 112.6025\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 103.1016 - val_loss: 95.2295\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 89.7008 - val_loss: 192.2460\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 92.0948 - val_loss: 79.0183\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 118.3978 - val_loss: 174.5495\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 133.8987 - val_loss: 179.4112\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 115.9671 - val_loss: 71.2791\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 121.2974 - val_loss: 126.4504\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 103.4950 - val_loss: 108.1020\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 93.2905 - val_loss: 74.9639\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 75.8008 - val_loss: 99.1083\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 99.3705 - val_loss: 82.8188\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 92.9263 - val_loss: 84.2071\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 90.7974 - val_loss: 92.0243\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 87.6480 - val_loss: 79.8973\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 90.7861 - val_loss: 107.1625\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 89.9707 - val_loss: 136.1705\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 89.0250 - val_loss: 62.0714\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 88.4773 - val_loss: 112.3220\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 85.5403 - val_loss: 81.4163\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 90.9935 - val_loss: 103.0061\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 92.6372 - val_loss: 62.0927\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 88.1636 - val_loss: 77.6525\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 78.0346 - val_loss: 80.3086\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 78.5319 - val_loss: 275.3347\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 94.6824 - val_loss: 62.7424\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 95.3407 - val_loss: 76.0832\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 101.2372 - val_loss: 78.2274\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 76.4005 - val_loss: 95.8891\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 84.4088 - val_loss: 75.3482\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 73.5710 - val_loss: 93.5564\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 92.4760 - val_loss: 78.2548\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 91.9050 - val_loss: 72.1818\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 77.0914 - val_loss: 80.4445\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 87.5582 - val_loss: 87.9569\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 73.5034 - val_loss: 89.0993\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 74.0791 - val_loss: 55.8657\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 78.4084 - val_loss: 156.1610\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 132.2901 - val_loss: 119.6459\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 111.8923 - val_loss: 218.8576\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 112.9487 - val_loss: 91.1035\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 97.5475 - val_loss: 78.2703\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 84.5077 - val_loss: 69.7363\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 78.6324 - val_loss: 89.3267\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 107.2190 - val_loss: 75.0833\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 88.8092 - val_loss: 61.7512\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 81.9081 - val_loss: 76.0288\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 78.7291 - val_loss: 79.2436\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 72.3503 - val_loss: 53.8406\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 82.8761 - val_loss: 70.1346\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 70.05142198741062\n",
      "Mean Absolute Error (MAE): 4.114308861486189\n",
      "Root Mean Squared Error (RMSE): 8.369672752707277\n",
      "Time taken: 416.27447414398193\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 8ms/step - loss: 1380.3193 - val_loss: 1295.1746\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1206.6532 - val_loss: 1183.1779\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1117.8318 - val_loss: 1103.7478\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1054.3705 - val_loss: 1045.1053\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1008.3172 - val_loss: 1002.4471\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 975.6818 - val_loss: 971.2510\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 953.1429 - val_loss: 950.1469\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 938.5805 - val_loss: 936.1017\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 929.6995 - val_loss: 927.3434\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 924.6290 - val_loss: 922.0242\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.0569 - val_loss: 919.0748\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 920.9240 - val_loss: 917.4896\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 920.4936 - val_loss: 916.5741\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 920.2904 - val_loss: 916.2064\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 919.6389 - val_loss: 914.7032\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 913.5486 - val_loss: 899.2549\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 874.9117 - val_loss: 847.0369\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 818.5151 - val_loss: 797.7315\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 767.3673 - val_loss: 749.8242\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 725.9050 - val_loss: 712.2576\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 691.3729 - val_loss: 685.8984\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 661.4059 - val_loss: 649.8810\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 632.6469 - val_loss: 621.2230\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 607.1694 - val_loss: 596.3292\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 581.9932 - val_loss: 569.8400\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 556.4501 - val_loss: 544.2450\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 528.6974 - val_loss: 510.5338\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 492.5407 - val_loss: 487.0625\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 467.9472 - val_loss: 457.8553\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 444.9773 - val_loss: 436.8053\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 423.6537 - val_loss: 415.6737\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 404.8051 - val_loss: 397.6146\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 387.7747 - val_loss: 379.8042\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 371.0160 - val_loss: 363.4410\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 356.4359 - val_loss: 349.8448\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 343.6395 - val_loss: 336.6689\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 331.3821 - val_loss: 325.5554\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 320.5255 - val_loss: 316.8685\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 310.8307 - val_loss: 304.8297\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 301.8363 - val_loss: 297.0131\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 293.2163 - val_loss: 288.8865\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 285.8848 - val_loss: 279.4672\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 278.5187 - val_loss: 270.8554\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 270.4701 - val_loss: 265.2700\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 266.5410 - val_loss: 256.9970\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 255.6257 - val_loss: 260.0364\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 249.7146 - val_loss: 249.4298\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.9673 - val_loss: 237.0110\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 236.9193 - val_loss: 230.5220\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.2901 - val_loss: 220.7350\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.9306 - val_loss: 230.2176\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 217.4381 - val_loss: 247.5968\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 215.3414 - val_loss: 209.8737\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 210.9962 - val_loss: 202.4857\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 198.2574 - val_loss: 197.5058\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 195.8585 - val_loss: 187.8033\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 189.6949 - val_loss: 180.0394\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 187.8831 - val_loss: 178.5603\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 187.1331 - val_loss: 175.5383\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 178.2883 - val_loss: 181.2488\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 170.7299 - val_loss: 160.0976\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 169.9426 - val_loss: 174.9881\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 165.6588 - val_loss: 201.9461\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 161.4840 - val_loss: 195.1616\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 161.5947 - val_loss: 166.7287\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 153.2123 - val_loss: 145.0370\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 155.2733 - val_loss: 144.4791\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 159.2319 - val_loss: 139.9115\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 152.0282 - val_loss: 142.1328\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 146.7225 - val_loss: 278.5905\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 153.5427 - val_loss: 195.9772\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 138.3222 - val_loss: 137.4656\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 143.6353 - val_loss: 130.2189\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 147.7804 - val_loss: 135.2869\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 134.0344 - val_loss: 133.7161\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 139.9321 - val_loss: 126.6157\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 136.5016 - val_loss: 125.9525\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 6ms/step - loss: 135.4930 - val_loss: 128.2288\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 134.8143 - val_loss: 138.3044\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 151.5527 - val_loss: 130.2482\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 129.7479 - val_loss: 168.2304\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 138.1056 - val_loss: 126.0781\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 116.6626 - val_loss: 115.9505\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 128.4585 - val_loss: 110.5633\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 125.2414 - val_loss: 106.5843\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 135.3194 - val_loss: 142.3459\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 133.4255 - val_loss: 158.1020\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 125.3213 - val_loss: 106.0498\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 129.2173 - val_loss: 124.3899\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 129.5858 - val_loss: 118.0158\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 130.5527 - val_loss: 145.5278\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 128.9479 - val_loss: 116.5016\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 123.2860 - val_loss: 110.0817\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 114.4904 - val_loss: 104.6288\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 118.1253 - val_loss: 118.9231\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 121.3616 - val_loss: 121.9632\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 117.7999 - val_loss: 112.0116\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 129.0478 - val_loss: 103.4090\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 120.3271 - val_loss: 143.0477\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 128.2919 - val_loss: 109.1148\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 120.8453 - val_loss: 104.3825\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 129.1258 - val_loss: 120.2230\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 115.5620 - val_loss: 111.3540\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 116.3612 - val_loss: 118.8181\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 114.1482 - val_loss: 109.0824\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 119.7450 - val_loss: 94.3789\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 107.4613 - val_loss: 112.4384\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 121.1627 - val_loss: 229.6110\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 112.6465 - val_loss: 103.1649\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 111.6777 - val_loss: 103.5134\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 123.4641 - val_loss: 104.5056\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 111.6714 - val_loss: 124.7831\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 112.6098 - val_loss: 112.1630\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 110.1001 - val_loss: 124.8965\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 108.9573 - val_loss: 94.1865\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 118.4835 - val_loss: 96.8220\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 106.8972 - val_loss: 139.8432\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 115.8601 - val_loss: 92.5546\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 104.5835 - val_loss: 102.8950\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 102.2521 - val_loss: 105.8846\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 99.1758 - val_loss: 90.2573\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.9411 - val_loss: 89.4762\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 102.6576 - val_loss: 184.5447\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 113.0118 - val_loss: 105.7414\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 108.8438 - val_loss: 101.7781\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 105.9150 - val_loss: 106.5367\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 110.4458 - val_loss: 112.2487\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 129.2809 - val_loss: 94.3016\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 115.1052 - val_loss: 112.5132\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 107.5517 - val_loss: 100.0482\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 116.7934 - val_loss: 112.4227\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 135.7872 - val_loss: 91.2208\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 106.6427 - val_loss: 92.6046\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 106.6654 - val_loss: 86.6219\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 95.8057 - val_loss: 147.0756\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 107.1288 - val_loss: 103.5473\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 90.2406 - val_loss: 111.8960\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 111.3837 - val_loss: 93.6534\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 106.9394 - val_loss: 101.6932\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 89.8686 - val_loss: 98.1917\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 96.9721 - val_loss: 115.4989\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 95.4772 - val_loss: 100.2736\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 98.1382 - val_loss: 80.5253\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 96.4870 - val_loss: 97.8898\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 89.6394 - val_loss: 76.5713\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 130.9985 - val_loss: 148.8961\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 98.6108 - val_loss: 153.5306\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 92.9692 - val_loss: 91.1153\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 95.1297 - val_loss: 169.2276\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 113.3005 - val_loss: 86.3483\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 125.9199 - val_loss: 139.1990\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 115.9748 - val_loss: 104.4965\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 91.7360 - val_loss: 134.2663\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 109.9939 - val_loss: 121.6021\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 96.0496 - val_loss: 104.0752\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 106.1751 - val_loss: 136.7266\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 121.0317 - val_loss: 101.1132\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 134.0685 - val_loss: 179.3445\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 93.5561 - val_loss: 111.9384\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 118.2686 - val_loss: 124.2576\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 105.6866 - val_loss: 85.4508\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 94.4559 - val_loss: 79.8599\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 112.4990 - val_loss: 110.0136\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 115.1486 - val_loss: 138.2291\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 99.1934 - val_loss: 102.5812\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 87.1987 - val_loss: 91.4908\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 87.9704 - val_loss: 160.4349\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 99.7007 - val_loss: 102.1949\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 90.3639 - val_loss: 150.8261\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 85.9500 - val_loss: 71.4172\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 85.5694 - val_loss: 101.5518\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 127.7130 - val_loss: 88.6905\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 98.5142 - val_loss: 93.3643\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 81.1293 - val_loss: 80.5884\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 97.2252 - val_loss: 87.0976\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 78.6740 - val_loss: 101.2921\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 91.2925 - val_loss: 81.1798\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 80.1302 - val_loss: 67.1818\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 90.7995 - val_loss: 101.4845\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 88.3344 - val_loss: 87.2878\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 76.2500 - val_loss: 80.0159\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 112.8031 - val_loss: 80.3584\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 77.6944 - val_loss: 92.9151\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 81.7664 - val_loss: 99.1966\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 92.2669 - val_loss: 71.7455\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 104.1999 - val_loss: 98.4824\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 86.3848 - val_loss: 65.6580\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 80.6267 - val_loss: 62.3690\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 81.9244 - val_loss: 77.7998\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 78.7212 - val_loss: 73.7169\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 86.3664 - val_loss: 76.5406\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 86.7180 - val_loss: 65.5114\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 71.8705 - val_loss: 71.3547\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 89.2823 - val_loss: 67.5790\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 76.6403 - val_loss: 90.7420\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 82.2170 - val_loss: 68.1611\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 111.6231 - val_loss: 141.4384\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 90.3066 - val_loss: 74.7962\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 67.2710 - val_loss: 61.6011\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 90.3840 - val_loss: 95.6349\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 95.94013467249069\n",
      "Mean Absolute Error (MAE): 4.995040349612267\n",
      "Root Mean Squared Error (RMSE): 9.79490350501171\n",
      "Time taken: 438.2505874633789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 4, 512)            1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 4, 256)            787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_2648\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold         MSE       MAE       RMSE  Time taken\n",
      "0        1   63.475252  4.039255   7.967136  482.982617\n",
      "1        2   86.095533  4.602192   9.278768  473.115381\n",
      "2        3  121.626665  5.513145  11.028448  470.660775\n",
      "3        4   70.051422  4.114309   8.369673  416.274474\n",
      "4        5   95.940135  4.995040   9.794904  438.250587\n",
      "5  Average   87.437801  4.652788   9.287786  456.256767\n",
      "Results saved to 'PL_model_1_smoothing2_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_1_smoothing2_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'PL_model_1_smoothing2_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
