{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "              6           7           8           9   ...         38  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "              39         40         41          42          43          44  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "              45          46          47  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...   sensor39  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "        sensor40   sensor41   sensor42    sensor43    sensor44    sensor45  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe88f5b",
   "metadata": {},
   "source": [
    "# Taking 4 Sensors (41,42,43,44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fad6410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sensor41   sensor42    sensor43    sensor44\n",
       "0     86.513881  81.048996  114.964811  120.010616\n",
       "1     94.438277  89.628271  114.498751  106.887589\n",
       "2     87.572150  90.919428  116.186110  121.150696\n",
       "3     93.313344  84.668294  111.953201  119.676628\n",
       "4     97.655142  89.118820  126.637608  114.886056\n",
       "...         ...        ...         ...         ...\n",
       "2438  87.948166  77.602308  127.656991  114.668824\n",
       "2439  88.541794  75.344392  125.557441  111.031434\n",
       "2440  93.400271  71.177932  123.918015  105.789520\n",
       "2441  88.494586  63.991014  129.409898  109.907911\n",
       "2442  86.795897  75.659668  122.322131  117.782888\n",
       "\n",
       "[2443 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data  = sensors_data.iloc[:, [40, 41, 42, 43]]\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 11s 11ms/step - loss: 1371.4514 - val_loss: 1229.0243\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1200.3427 - val_loss: 1134.6968\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1116.5098 - val_loss: 1066.9979\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1054.9614 - val_loss: 1016.8453\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1009.7354 - val_loss: 980.4853\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 977.2065 - val_loss: 954.9821\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 954.5704 - val_loss: 937.8394\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 939.6729 - val_loss: 927.0042\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 930.3396 - val_loss: 920.7413\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 925.0439 - val_loss: 917.4932\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 922.2688 - val_loss: 916.0558\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 921.0662 - val_loss: 915.4984\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 920.5225 - val_loss: 915.4119\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 920.3854 - val_loss: 915.3436\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 920.2943 - val_loss: 915.4540\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 920.2140 - val_loss: 914.7246\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 892.6426 - val_loss: 847.2623\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 839.5507 - val_loss: 815.9390\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 810.3006 - val_loss: 789.9632\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 780.4539 - val_loss: 755.1318\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 747.5506 - val_loss: 724.8252\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 718.1234 - val_loss: 696.8237\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 687.4778 - val_loss: 664.7581\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 657.3292 - val_loss: 643.2279\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 629.5916 - val_loss: 614.4167\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 604.1036 - val_loss: 587.3607\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 578.7597 - val_loss: 565.7272\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 555.6633 - val_loss: 552.9877\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 534.3222 - val_loss: 525.3591\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 512.4010 - val_loss: 503.4453\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 489.3126 - val_loss: 479.3248\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 467.2828 - val_loss: 460.9854\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 445.6512 - val_loss: 436.3701\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 423.3023 - val_loss: 417.0464\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 398.0054 - val_loss: 397.7522\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 378.0068 - val_loss: 372.0083\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 364.2335 - val_loss: 364.1640\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 351.2678 - val_loss: 349.4803\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 341.4806 - val_loss: 339.4523\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 331.7029 - val_loss: 336.0229\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 322.9889 - val_loss: 325.8444\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 314.0582 - val_loss: 316.3219\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 308.4343 - val_loss: 309.4424\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 303.5496 - val_loss: 309.8119\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 298.0787 - val_loss: 302.9788\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 295.4822 - val_loss: 296.9989\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 290.3819 - val_loss: 297.8945\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 287.1248 - val_loss: 306.0838\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 285.7657 - val_loss: 288.2733\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 283.4033 - val_loss: 294.4741\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 281.3747 - val_loss: 296.4690\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 279.5958 - val_loss: 286.8954\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 277.4505 - val_loss: 285.9532\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 276.8401 - val_loss: 278.0042\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 273.9115 - val_loss: 284.7476\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 273.3683 - val_loss: 276.6942\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 270.9024 - val_loss: 280.4768\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 270.1595 - val_loss: 279.3006\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 268.6325 - val_loss: 272.2209\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 266.7499 - val_loss: 268.9386\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 266.2157 - val_loss: 278.7620\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 265.5844 - val_loss: 265.1599\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 263.4424 - val_loss: 295.6181\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 263.1550 - val_loss: 266.1208\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 262.1667 - val_loss: 264.6972\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 259.3219 - val_loss: 267.9923\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 260.2813 - val_loss: 287.9485\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 258.4105 - val_loss: 272.4247\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 256.6826 - val_loss: 262.0123\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 256.2853 - val_loss: 262.7677\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 254.6278 - val_loss: 257.4414\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 255.8208 - val_loss: 257.7625\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 252.9767 - val_loss: 263.3607\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 252.5775 - val_loss: 261.3380\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 252.2501 - val_loss: 264.0537\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 253.5640 - val_loss: 265.4424\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 252.4718 - val_loss: 258.6639\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 6ms/step - loss: 252.1312 - val_loss: 258.2193\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 250.6447 - val_loss: 260.5439\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 249.5502 - val_loss: 253.9958\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 249.3350 - val_loss: 275.2627\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 250.7930 - val_loss: 251.7425\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.9173 - val_loss: 257.5237\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 249.4879 - val_loss: 250.5256\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 245.0032 - val_loss: 258.8622\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 246.6016 - val_loss: 255.9786\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 246.6036 - val_loss: 248.0761\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 247.5818 - val_loss: 250.7827\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.5744 - val_loss: 250.4827\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.1489 - val_loss: 265.5369\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 242.4448 - val_loss: 256.8968\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 246.9390 - val_loss: 250.6255\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 242.8360 - val_loss: 251.2822\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 244.5392 - val_loss: 251.9478\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.0411 - val_loss: 253.2253\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 240.8679 - val_loss: 250.0916\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 241.1076 - val_loss: 249.3944\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.8325 - val_loss: 249.8541\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 242.7349 - val_loss: 251.3055\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.3356 - val_loss: 256.9388\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 239.6553 - val_loss: 248.6000\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 242.6430 - val_loss: 253.5645\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 238.4850 - val_loss: 282.1101\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.8188 - val_loss: 247.5396\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 238.8051 - val_loss: 263.7232\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 238.6497 - val_loss: 248.1311\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.7238 - val_loss: 266.7084\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 239.7424 - val_loss: 251.0454\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 236.8270 - val_loss: 254.8468\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 240.8928 - val_loss: 254.5777\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 238.0801 - val_loss: 248.5622\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.0449 - val_loss: 248.9288\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.7658 - val_loss: 258.0033\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.8120 - val_loss: 245.9946\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 236.1597 - val_loss: 257.5294\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 236.0848 - val_loss: 249.3027\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 235.6385 - val_loss: 268.1019\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 237.0956 - val_loss: 245.0966\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 238.0462 - val_loss: 246.3442\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.2098 - val_loss: 246.1680\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 234.7890 - val_loss: 252.0702\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 238.0872 - val_loss: 248.0207\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.8702 - val_loss: 268.3123\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 236.8318 - val_loss: 256.0021\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 236.9967 - val_loss: 241.9204\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.7415 - val_loss: 242.0886\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.8626 - val_loss: 248.2320\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.8624 - val_loss: 257.5173\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.8976 - val_loss: 252.5066\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.9346 - val_loss: 247.8657\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.2519 - val_loss: 246.8410\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.4261 - val_loss: 244.7132\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.3413 - val_loss: 263.0735\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.6346 - val_loss: 253.9477\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.7171 - val_loss: 245.2269\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.6010 - val_loss: 252.3284\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 233.2901 - val_loss: 245.5846\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 234.3496 - val_loss: 242.3875\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 232.7557 - val_loss: 245.8428\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 237.0460 - val_loss: 249.8831\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.6443 - val_loss: 242.7389\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.8429 - val_loss: 246.3341\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.8898 - val_loss: 246.2374\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.3751 - val_loss: 243.3059\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.9119 - val_loss: 246.8619\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.3954 - val_loss: 243.9247\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 234.9007 - val_loss: 251.9423\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.4935 - val_loss: 247.8148\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.2027 - val_loss: 253.6117\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.7450 - val_loss: 246.0853\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.9240 - val_loss: 253.8440\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.1063 - val_loss: 244.6371\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.1653 - val_loss: 259.4397\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.3183 - val_loss: 246.5320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.6248 - val_loss: 264.1295\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 227.3176 - val_loss: 262.4311\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.8279 - val_loss: 274.4830\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.0717 - val_loss: 245.6382\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.9447 - val_loss: 253.2769\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.3214 - val_loss: 250.7701\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.4924 - val_loss: 246.5097\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.2426 - val_loss: 244.2547\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 228.6332 - val_loss: 248.2673\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 227.3523 - val_loss: 262.1946\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 229.6435 - val_loss: 247.2165\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 232.1064 - val_loss: 243.0567\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 230.2298 - val_loss: 258.5063\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 227.3585 - val_loss: 244.9386\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 225.7169 - val_loss: 251.9375\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 227.3213 - val_loss: 253.1813\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.7363 - val_loss: 244.9380\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 231.6342 - val_loss: 245.4546\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 227.8007 - val_loss: 252.0200\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.0797 - val_loss: 261.8007\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.6024 - val_loss: 242.3604\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.9907 - val_loss: 244.5126\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.3434 - val_loss: 249.9780\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 225.3537 - val_loss: 245.3856\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 225.6621 - val_loss: 247.2924\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.3864 - val_loss: 250.8708\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.5794 - val_loss: 254.5751\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.9527 - val_loss: 246.4479\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 227.1700 - val_loss: 247.6311\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.6546 - val_loss: 259.3589\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 224.4500 - val_loss: 269.6035\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 225.4693 - val_loss: 254.2752\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 224.0316 - val_loss: 244.0369\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.6107 - val_loss: 248.5221\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 225.6531 - val_loss: 253.4832\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.7694 - val_loss: 246.0225\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.2273 - val_loss: 252.7104\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.0921 - val_loss: 252.3838\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 225.2463 - val_loss: 248.6105\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 224.4757 - val_loss: 245.4212\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 225.9698 - val_loss: 249.5654\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 224.0219 - val_loss: 251.2939\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 224.9228 - val_loss: 254.9780\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.6849 - val_loss: 248.0962\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.8812 - val_loss: 263.2434\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.1444 - val_loss: 248.1333\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 248.0984984282395\n",
      "Mean Absolute Error (MAE): 10.501636231651265\n",
      "Root Mean Squared Error (RMSE): 15.751142765788122\n",
      "Time taken: 484.2474706172943\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 8ms/step - loss: 1366.9525 - val_loss: 1298.4359\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1196.2535 - val_loss: 1195.3303\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1113.5765 - val_loss: 1119.5374\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1052.4596 - val_loss: 1062.5659\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1007.2960 - val_loss: 1020.2089\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 974.5375 - val_loss: 989.2811\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 951.1509 - val_loss: 966.5124\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 935.2428 - val_loss: 951.9318\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 925.9095 - val_loss: 942.9426\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 920.7787 - val_loss: 937.6562\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 918.1421 - val_loss: 934.6894\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 916.9619 - val_loss: 933.2578\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 916.4534 - val_loss: 932.4390\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 916.2177 - val_loss: 932.0122\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 914.9197 - val_loss: 928.4302\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 898.3164 - val_loss: 895.3209\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 858.8187 - val_loss: 870.5692\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 838.0145 - val_loss: 851.4572\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 820.8239 - val_loss: 835.0540\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 804.9086 - val_loss: 817.9249\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 786.5834 - val_loss: 795.6404\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 762.6930 - val_loss: 771.2378\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 735.7088 - val_loss: 738.6506\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 701.3042 - val_loss: 701.6841\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 666.7267 - val_loss: 671.9192\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 636.1027 - val_loss: 641.8457\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 606.2943 - val_loss: 613.9370\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 578.8945 - val_loss: 586.8222\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 549.7817 - val_loss: 552.5470\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 520.9531 - val_loss: 525.3943\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 496.6479 - val_loss: 499.5589\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 474.2433 - val_loss: 480.0715\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 454.1587 - val_loss: 457.7191\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 435.4086 - val_loss: 440.6397\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 417.7590 - val_loss: 422.0301\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 403.2158 - val_loss: 409.2727\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 389.0108 - val_loss: 393.0727\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 375.5925 - val_loss: 379.8227\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 362.0295 - val_loss: 367.4939\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 350.8874 - val_loss: 358.9851\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 341.9153 - val_loss: 347.6081\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 333.0257 - val_loss: 339.0142\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 324.5747 - val_loss: 332.9784\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 318.9611 - val_loss: 325.3803\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 312.9374 - val_loss: 324.5706\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 307.5811 - val_loss: 313.6154\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 303.2595 - val_loss: 309.2034\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 297.9578 - val_loss: 305.3073\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 296.2226 - val_loss: 304.0432\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 293.4810 - val_loss: 299.4352\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 291.7545 - val_loss: 300.4306\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 289.8219 - val_loss: 296.8134\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 286.9936 - val_loss: 296.1480\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 287.5840 - val_loss: 294.2303\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 285.8439 - val_loss: 295.8416\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 284.9037 - val_loss: 290.2051\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 283.1318 - val_loss: 290.1251\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 282.1706 - val_loss: 291.2515\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 282.1931 - val_loss: 291.5583\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 282.3407 - val_loss: 291.0901\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 280.7724 - val_loss: 290.5203\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 280.1318 - val_loss: 290.4727\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 278.8794 - val_loss: 286.5533\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 279.2816 - val_loss: 283.9336\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 278.3930 - val_loss: 287.6047\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 277.3164 - val_loss: 284.3355\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 275.9619 - val_loss: 287.3272\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 275.5343 - val_loss: 281.4238\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 274.9627 - val_loss: 282.5660\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 275.3295 - val_loss: 291.4062\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 273.1664 - val_loss: 281.7701\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 272.4898 - val_loss: 281.1083\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 272.2861 - val_loss: 288.3566\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 270.6564 - val_loss: 280.8024\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 269.9850 - val_loss: 272.0721\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 268.2095 - val_loss: 273.4544\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 268.6190 - val_loss: 272.0246\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 6ms/step - loss: 267.1186 - val_loss: 273.9945\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 266.3318 - val_loss: 271.8668\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 264.2551 - val_loss: 274.6342\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 266.4620 - val_loss: 274.6797\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 263.7451 - val_loss: 270.7646\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 262.6704 - val_loss: 266.3291\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 262.1571 - val_loss: 273.1715\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 259.9730 - val_loss: 277.7882\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 260.6789 - val_loss: 262.1164\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 260.0005 - val_loss: 262.5296\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 256.2973 - val_loss: 278.3160\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 257.9470 - val_loss: 260.7896\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 256.2439 - val_loss: 275.2034\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 254.4595 - val_loss: 260.9582\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 253.8590 - val_loss: 258.8419\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 252.7927 - val_loss: 259.9539\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 253.2853 - val_loss: 255.7436\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 255.6369 - val_loss: 261.1748\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 251.9855 - val_loss: 257.7985\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 251.5362 - val_loss: 257.5195\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 250.5887 - val_loss: 264.6026\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 250.9730 - val_loss: 252.2559\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 248.2141 - val_loss: 252.3868\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 250.8629 - val_loss: 249.0645\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 248.5020 - val_loss: 257.0626\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 248.7670 - val_loss: 252.2393\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.8410 - val_loss: 255.9629\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 249.5638 - val_loss: 256.9531\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 246.2457 - val_loss: 269.7098\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 247.3929 - val_loss: 257.2922\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 245.8949 - val_loss: 258.2477\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.2980 - val_loss: 251.5312\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 245.2913 - val_loss: 261.6530\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 244.1590 - val_loss: 248.6643\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 244.8632 - val_loss: 249.5556\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 245.6813 - val_loss: 261.9283\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.0189 - val_loss: 253.9108\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 244.6971 - val_loss: 254.6593\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.1214 - val_loss: 248.1465\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.1060 - val_loss: 248.5103\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 242.2108 - val_loss: 245.4415\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 241.3752 - val_loss: 271.7225\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 242.4743 - val_loss: 242.7045\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 241.6892 - val_loss: 244.0096\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 241.0645 - val_loss: 253.1711\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 238.8728 - val_loss: 242.1502\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 238.9604 - val_loss: 250.4657\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 240.4777 - val_loss: 252.4315\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 238.5392 - val_loss: 243.4590\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.4466 - val_loss: 246.2188\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 240.1972 - val_loss: 261.5335\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.3714 - val_loss: 245.9990\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 240.2437 - val_loss: 267.9251\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 240.3880 - val_loss: 242.0797\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 235.5057 - val_loss: 244.1107\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.6889 - val_loss: 252.2088\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.2384 - val_loss: 255.7524\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 237.7427 - val_loss: 246.2586\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 236.5698 - val_loss: 254.2884\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 238.8765 - val_loss: 242.3810\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 234.7632 - val_loss: 243.6890\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.8417 - val_loss: 245.4604\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 234.8847 - val_loss: 245.0458\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.9329 - val_loss: 242.9419\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.3119 - val_loss: 245.1267\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.6333 - val_loss: 248.7952\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.2242 - val_loss: 245.0252\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 234.4073 - val_loss: 243.5463\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.1061 - val_loss: 257.0839\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 237.4240 - val_loss: 244.4380\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.7629 - val_loss: 243.5775\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 237.3491 - val_loss: 242.2001\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.0443 - val_loss: 240.4634\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.4834 - val_loss: 243.0677\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 235.3926 - val_loss: 250.9177\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 235.4336 - val_loss: 249.0595\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.3402 - val_loss: 244.3369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.9167 - val_loss: 248.5504\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.0983 - val_loss: 250.9419\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.3399 - val_loss: 241.8657\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.2938 - val_loss: 260.1540\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.8281 - val_loss: 254.0928\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.8527 - val_loss: 258.2695\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.6619 - val_loss: 239.8459\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.0749 - val_loss: 239.7873\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.9418 - val_loss: 244.3512\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.3888 - val_loss: 239.7931\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.0319 - val_loss: 252.6083\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.6286 - val_loss: 244.5541\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.5226 - val_loss: 243.0302\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.8177 - val_loss: 237.5005\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.9907 - val_loss: 237.9716\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 231.4736 - val_loss: 249.1945\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.3230 - val_loss: 238.3987\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.2459 - val_loss: 240.4707\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 231.2838 - val_loss: 248.1624\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 232.2966 - val_loss: 239.9456\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.4235 - val_loss: 243.2601\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 232.8481 - val_loss: 241.0193\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 231.2405 - val_loss: 242.7398\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 230.1494 - val_loss: 243.1366\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.9983 - val_loss: 244.6844\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.7815 - val_loss: 244.1286\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.6376 - val_loss: 243.5716\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.8038 - val_loss: 240.5444\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.6924 - val_loss: 249.4671\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.3916 - val_loss: 246.2297\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.9871 - val_loss: 245.1022\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.8914 - val_loss: 238.9572\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 230.2534 - val_loss: 245.0327\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 233.3919 - val_loss: 241.8125\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.2981 - val_loss: 248.8301\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.6645 - val_loss: 240.6535\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.5646 - val_loss: 247.7847\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.4574 - val_loss: 245.4829\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.1094 - val_loss: 243.2217\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.0266 - val_loss: 245.6195\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 227.5634 - val_loss: 240.7128\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.5962 - val_loss: 242.5044\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 227.4878 - val_loss: 244.1002\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.8704 - val_loss: 242.0136\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.5133 - val_loss: 247.6441\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 226.7157 - val_loss: 259.7155\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 259.6934245689426\n",
      "Mean Absolute Error (MAE): 10.994975567033151\n",
      "Root Mean Squared Error (RMSE): 16.115006192023092\n",
      "Time taken: 463.02931571006775\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 8ms/step - loss: 1409.0995 - val_loss: 1242.2863\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1235.6978 - val_loss: 1137.2501\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1144.7577 - val_loss: 1060.6896\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1075.8781 - val_loss: 1001.9705\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1024.0928 - val_loss: 957.5165\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 980.5169 - val_loss: 916.1594\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 938.1917 - val_loss: 877.1586\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 898.4080 - val_loss: 838.8920\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 859.4601 - val_loss: 804.1199\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 824.6346 - val_loss: 768.7690\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 784.0828 - val_loss: 728.0830\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 747.4337 - val_loss: 695.3915\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 714.5172 - val_loss: 665.0904\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 683.1710 - val_loss: 637.2964\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 655.5775 - val_loss: 610.1179\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 627.5935 - val_loss: 583.3990\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 600.7842 - val_loss: 558.4266\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 574.3315 - val_loss: 532.2212\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 548.8387 - val_loss: 509.3983\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 523.7478 - val_loss: 483.2050\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 499.5585 - val_loss: 461.6831\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 478.6654 - val_loss: 444.0894\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 459.2647 - val_loss: 425.6165\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 441.3824 - val_loss: 414.9727\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 423.9212 - val_loss: 393.0026\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 408.5307 - val_loss: 380.5139\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 393.2388 - val_loss: 366.8996\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 380.5691 - val_loss: 357.4404\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 368.6780 - val_loss: 344.2747\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 358.2694 - val_loss: 338.8972\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 348.9130 - val_loss: 326.3279\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 340.3504 - val_loss: 321.8750\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 333.2371 - val_loss: 312.2758\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 327.6700 - val_loss: 308.8283\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 320.2888 - val_loss: 306.5701\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 316.3424 - val_loss: 298.3137\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 311.4384 - val_loss: 295.3100\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 307.7201 - val_loss: 289.8386\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 304.2228 - val_loss: 288.0916\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 301.9660 - val_loss: 286.5429\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 299.5906 - val_loss: 285.0567\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 297.5457 - val_loss: 282.0215\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 296.2124 - val_loss: 285.2946\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 294.9267 - val_loss: 286.5758\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 293.9818 - val_loss: 281.9771\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 292.7929 - val_loss: 279.1210\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 291.3266 - val_loss: 281.8998\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 291.0940 - val_loss: 277.3617\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 290.1779 - val_loss: 274.3245\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 289.1065 - val_loss: 277.5823\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 288.4643 - val_loss: 276.9933\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 287.5359 - val_loss: 274.7349\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 286.9600 - val_loss: 272.3136\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 286.3337 - val_loss: 270.6689\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 285.5947 - val_loss: 273.3545\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 284.9892 - val_loss: 271.8081\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 283.0647 - val_loss: 273.1072\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 281.3485 - val_loss: 271.7715\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 280.1159 - val_loss: 264.0404\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 279.3856 - val_loss: 263.2914\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 278.6423 - val_loss: 261.6934\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 276.5220 - val_loss: 264.0358\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 275.7028 - val_loss: 259.3204\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 273.9011 - val_loss: 263.7203\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 274.1268 - val_loss: 266.7240\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 271.8892 - val_loss: 258.5957\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 269.9989 - val_loss: 255.9041\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 269.7702 - val_loss: 255.5325\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 267.8802 - val_loss: 253.0091\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 268.9610 - val_loss: 266.0357\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 266.3894 - val_loss: 254.3280\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 264.1358 - val_loss: 254.4048\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 265.5161 - val_loss: 246.6239\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 264.8152 - val_loss: 254.4548\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 263.3565 - val_loss: 250.3157\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 262.0471 - val_loss: 245.1486\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 261.1494 - val_loss: 246.4757\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 6ms/step - loss: 259.5858 - val_loss: 243.6207\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 259.3986 - val_loss: 253.0824\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 259.2220 - val_loss: 248.3499\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 256.5724 - val_loss: 247.3840\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 256.8466 - val_loss: 243.0833\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 255.5613 - val_loss: 249.1792\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 254.8844 - val_loss: 240.1552\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 254.0407 - val_loss: 276.5056\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 255.3121 - val_loss: 249.6259\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 252.2080 - val_loss: 255.2880\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 253.0475 - val_loss: 244.3568\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 254.8600 - val_loss: 241.5194\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 251.5665 - val_loss: 243.3849\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 251.5126 - val_loss: 240.5126\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 251.5391 - val_loss: 238.1158\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 251.0578 - val_loss: 245.7110\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 250.8493 - val_loss: 239.0661\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 248.6662 - val_loss: 234.7705\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 249.8215 - val_loss: 237.8254\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 247.6326 - val_loss: 238.0542\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 249.0797 - val_loss: 235.5957\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 249.5930 - val_loss: 240.7674\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 247.5469 - val_loss: 240.1849\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 247.4140 - val_loss: 236.5688\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 243.8604 - val_loss: 235.3105\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 247.8332 - val_loss: 236.4030\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 245.8668 - val_loss: 235.7939\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.1465 - val_loss: 233.2823\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 243.5530 - val_loss: 241.2325\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 244.9806 - val_loss: 235.8598\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 247.0869 - val_loss: 234.7687\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 244.4552 - val_loss: 237.2915\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 243.7276 - val_loss: 244.9211\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 247.1835 - val_loss: 229.6567\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.2957 - val_loss: 231.8234\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 245.1965 - val_loss: 231.4776\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 242.8440 - val_loss: 231.0531\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 242.3255 - val_loss: 234.1030\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 245.7773 - val_loss: 234.9088\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.5047 - val_loss: 235.2943\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 243.6036 - val_loss: 231.1909\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.2150 - val_loss: 249.1653\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 242.9161 - val_loss: 230.1458\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 240.0952 - val_loss: 231.6448\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 240.3474 - val_loss: 236.0250\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.6941 - val_loss: 234.9615\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.0872 - val_loss: 230.4181\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 241.6587 - val_loss: 232.5056\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 238.6349 - val_loss: 237.5797\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 238.8624 - val_loss: 229.5976\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 239.8630 - val_loss: 229.8980\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 240.0963 - val_loss: 238.7355\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 239.5798 - val_loss: 234.2468\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 240.8030 - val_loss: 235.9423\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 239.4070 - val_loss: 229.4569\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 239.2886 - val_loss: 230.8009\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 238.4715 - val_loss: 233.5099\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 240.3301 - val_loss: 230.8005\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 237.6977 - val_loss: 232.0022\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.8654 - val_loss: 230.3217\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 236.4590 - val_loss: 231.6349\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.0861 - val_loss: 231.9377\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.9039 - val_loss: 266.9386\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 237.6782 - val_loss: 240.9137\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 238.0251 - val_loss: 231.2456\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.5398 - val_loss: 233.3916\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 239.0108 - val_loss: 231.7113\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 238.2777 - val_loss: 236.2677\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 235.5401 - val_loss: 235.3685\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 238.0523 - val_loss: 234.3054\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 237.5296 - val_loss: 231.1670\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.4268 - val_loss: 234.7507\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 235.6523 - val_loss: 242.1743\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 234.4350 - val_loss: 230.3353\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.0525 - val_loss: 234.1775\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.1798 - val_loss: 230.5825\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.3795 - val_loss: 230.3780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.6525 - val_loss: 234.0804\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.5540 - val_loss: 247.4074\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 236.3315 - val_loss: 236.8993\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 234.9666 - val_loss: 231.2749\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.5392 - val_loss: 231.0929\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.3693 - val_loss: 238.8171\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.0822 - val_loss: 233.1523\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.0648 - val_loss: 231.0323\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.2244 - val_loss: 235.5110\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 234.2177 - val_loss: 236.0286\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.0692 - val_loss: 241.6486\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.4943 - val_loss: 232.9766\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.5302 - val_loss: 235.1743\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.0227 - val_loss: 232.5835\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.6244 - val_loss: 232.4955\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.0562 - val_loss: 230.5943\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.3337 - val_loss: 235.2896\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.6683 - val_loss: 231.2108\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.6671 - val_loss: 236.1812\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.7189 - val_loss: 235.4318\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.5688 - val_loss: 231.7106\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 232.2665 - val_loss: 233.9970\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.7361 - val_loss: 234.1938\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.5311 - val_loss: 236.3494\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.8418 - val_loss: 234.5040\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 229.7175 - val_loss: 230.3536\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 231.2137 - val_loss: 235.3694\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 231.2005 - val_loss: 242.2223\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.0460 - val_loss: 240.7895\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 230.4009 - val_loss: 236.2861\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 232.0609 - val_loss: 240.2210\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 232.5182 - val_loss: 234.2112\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 231.7410 - val_loss: 238.1660\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 228.2333 - val_loss: 235.3531\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 232.2082 - val_loss: 234.0591\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.6568 - val_loss: 233.3956\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.8957 - val_loss: 233.0159\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.8615 - val_loss: 237.1904\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.4733 - val_loss: 232.4510\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.2756 - val_loss: 233.5461\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.5546 - val_loss: 234.2941\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 227.9806 - val_loss: 235.8889\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.3967 - val_loss: 234.1046\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.4621 - val_loss: 234.2845\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.8063 - val_loss: 246.0601\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.9963 - val_loss: 256.3201\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 256.31995072166313\n",
      "Mean Absolute Error (MAE): 10.227460560641136\n",
      "Root Mean Squared Error (RMSE): 16.009995337965066\n",
      "Time taken: 458.1503872871399\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 7ms/step - loss: 1379.8242 - val_loss: 1324.4167\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1203.7155 - val_loss: 1218.5101\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1114.9042 - val_loss: 1142.8680\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1049.2731 - val_loss: 1085.6541\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1001.4326 - val_loss: 1044.7830\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 967.3047 - val_loss: 1015.9815\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 943.5078 - val_loss: 996.1824\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 927.7892 - val_loss: 983.2513\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 918.0358 - val_loss: 975.8269\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 912.4244 - val_loss: 971.5054\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 909.3265 - val_loss: 969.2102\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 907.3647 - val_loss: 967.0560\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 903.4613 - val_loss: 955.9257\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 868.7636 - val_loss: 898.3826\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 835.0818 - val_loss: 875.9606\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 811.2269 - val_loss: 846.3870\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 787.4555 - val_loss: 822.3763\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 761.8341 - val_loss: 791.7314\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 729.2444 - val_loss: 759.5727\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 697.0939 - val_loss: 724.3818\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 664.1089 - val_loss: 687.4967\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 629.1509 - val_loss: 650.5640\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 595.0054 - val_loss: 615.4028\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 564.6296 - val_loss: 590.2094\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 535.2209 - val_loss: 556.9893\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 505.3887 - val_loss: 523.3451\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 476.5519 - val_loss: 491.9124\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 452.4285 - val_loss: 470.6827\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 430.9140 - val_loss: 451.1630\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 411.3495 - val_loss: 431.4644\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 394.3214 - val_loss: 408.8781\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 379.1193 - val_loss: 395.2634\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 364.3967 - val_loss: 381.1148\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 351.1786 - val_loss: 361.6761\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 339.3136 - val_loss: 354.4629\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 329.9681 - val_loss: 343.3574\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 321.2543 - val_loss: 332.6418\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 314.2778 - val_loss: 325.3592\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 308.8809 - val_loss: 317.9651\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 303.2418 - val_loss: 313.9418\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 297.5223 - val_loss: 312.1410\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 294.2821 - val_loss: 304.2915\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 289.2537 - val_loss: 300.4082\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 287.0981 - val_loss: 298.5201\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 285.1039 - val_loss: 298.0515\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 281.9546 - val_loss: 291.8467\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 280.3832 - val_loss: 289.6336\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 277.4067 - val_loss: 290.9338\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 276.2281 - val_loss: 285.1452\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 274.4226 - val_loss: 292.8366\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 273.7708 - val_loss: 285.9146\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 272.5472 - val_loss: 280.2461\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 270.3624 - val_loss: 280.1184\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 267.0244 - val_loss: 277.9258\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 266.6765 - val_loss: 279.6243\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 266.1031 - val_loss: 275.4304\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 265.7934 - val_loss: 275.5927\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 262.7560 - val_loss: 276.4408\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 262.3166 - val_loss: 273.2822\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 259.5244 - val_loss: 285.9041\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 260.3644 - val_loss: 275.4900\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 256.8312 - val_loss: 272.7097\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 258.7603 - val_loss: 271.2841\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 258.0107 - val_loss: 266.8391\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 256.0665 - val_loss: 270.2894\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 256.0439 - val_loss: 267.2641\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 255.4899 - val_loss: 260.8922\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 253.5387 - val_loss: 265.4784\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 252.0177 - val_loss: 269.6779\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 250.8348 - val_loss: 262.0347\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 251.7901 - val_loss: 270.8881\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 250.2033 - val_loss: 255.3605\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 251.9203 - val_loss: 262.7244\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 251.6329 - val_loss: 271.1822\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 248.6568 - val_loss: 258.5186\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 249.0621 - val_loss: 267.3832\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 248.5448 - val_loss: 258.2206\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 246.3009 - val_loss: 265.3243\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 246.7949 - val_loss: 259.7422\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 245.2150 - val_loss: 263.0961\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 244.9947 - val_loss: 255.8129\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 246.6429 - val_loss: 261.8221\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 245.7303 - val_loss: 271.5132\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 244.2119 - val_loss: 257.7906\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 245.2318 - val_loss: 254.6918\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 241.9342 - val_loss: 264.8258\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 241.1531 - val_loss: 269.1233\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.3956 - val_loss: 258.8258\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 242.1751 - val_loss: 252.5638\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 245.8469 - val_loss: 265.0954\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.8516 - val_loss: 266.2354\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 240.4422 - val_loss: 270.9135\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 242.6121 - val_loss: 254.5678\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 238.2203 - val_loss: 255.5280\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 237.8378 - val_loss: 259.5004\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.7623 - val_loss: 259.4212\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 237.4610 - val_loss: 260.4957\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 240.2607 - val_loss: 269.6295\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.0606 - val_loss: 278.1094\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.9594 - val_loss: 253.0214\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.0882 - val_loss: 250.1283\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 236.2958 - val_loss: 267.7004\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.0801 - val_loss: 258.5441\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 237.8307 - val_loss: 259.6832\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.9044 - val_loss: 253.0853\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.8622 - val_loss: 251.8631\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 236.1157 - val_loss: 250.0968\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.9967 - val_loss: 269.1818\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 236.3786 - val_loss: 257.9384\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 235.8019 - val_loss: 264.0345\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 234.2593 - val_loss: 250.3649\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.9757 - val_loss: 258.2255\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.1769 - val_loss: 252.5855\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.6306 - val_loss: 249.9899\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.2268 - val_loss: 253.5380\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.1555 - val_loss: 248.8705\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.8258 - val_loss: 263.4474\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.9590 - val_loss: 250.8483\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.4839 - val_loss: 246.1865\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.7505 - val_loss: 247.8345\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.9222 - val_loss: 255.8236\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.3311 - val_loss: 252.6374\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.4707 - val_loss: 250.3620\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.9349 - val_loss: 253.5143\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.9003 - val_loss: 248.6246\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.9708 - val_loss: 253.9628\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.4226 - val_loss: 275.9406\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.7903 - val_loss: 255.2673\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.0930 - val_loss: 252.9431\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.4256 - val_loss: 250.3354\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.3395 - val_loss: 258.3237\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.5457 - val_loss: 251.2415\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.2674 - val_loss: 248.6104\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.7170 - val_loss: 279.4191\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.1584 - val_loss: 250.0929\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 228.6744 - val_loss: 245.7557\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.4865 - val_loss: 248.2188\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.0814 - val_loss: 252.4332\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.8441 - val_loss: 250.0819\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.8593 - val_loss: 251.1209\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.2977 - val_loss: 255.1230\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.0901 - val_loss: 250.1648\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.5569 - val_loss: 245.6891\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.0383 - val_loss: 251.7561\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.0746 - val_loss: 251.4944\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.7503 - val_loss: 253.3977\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.8572 - val_loss: 246.5698\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.3048 - val_loss: 264.6659\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 229.4922 - val_loss: 248.8171\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 227.1006 - val_loss: 249.6685\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.0502 - val_loss: 261.5480\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.9698 - val_loss: 251.5951\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 225.2489 - val_loss: 263.6402\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 227.8244 - val_loss: 250.3618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.9080 - val_loss: 256.8538\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 226.8788 - val_loss: 252.8408\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.8578 - val_loss: 252.3061\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 227.1319 - val_loss: 252.8576\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.4378 - val_loss: 259.7926\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.8436 - val_loss: 251.0402\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.0401 - val_loss: 247.4054\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.5848 - val_loss: 258.7753\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 226.3471 - val_loss: 253.8266\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 224.9158 - val_loss: 264.4850\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 226.5028 - val_loss: 256.4242\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.8553 - val_loss: 266.6210\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.6344 - val_loss: 253.2644\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 226.6450 - val_loss: 249.2090\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.4064 - val_loss: 257.0516\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 223.8253 - val_loss: 247.8375\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 223.4447 - val_loss: 254.5951\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.8163 - val_loss: 255.1833\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.4884 - val_loss: 253.1144\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 221.9934 - val_loss: 246.8134\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 221.4251 - val_loss: 246.2097\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.6094 - val_loss: 247.2128\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 226.5252 - val_loss: 252.8540\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.5441 - val_loss: 248.8178\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.9123 - val_loss: 259.9225\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 226.2872 - val_loss: 255.3879\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.6021 - val_loss: 250.3679\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.5821 - val_loss: 249.3362\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.9730 - val_loss: 257.2465\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.1322 - val_loss: 252.7214\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 221.8337 - val_loss: 253.9680\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.5472 - val_loss: 254.1186\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 224.1209 - val_loss: 253.5576\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 221.3038 - val_loss: 252.6852\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 220.9961 - val_loss: 250.6518\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 220.7241 - val_loss: 276.6306\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 222.0601 - val_loss: 253.4560\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 222.2049 - val_loss: 270.7899\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 221.4691 - val_loss: 249.6289\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.2296 - val_loss: 254.2086\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.6810 - val_loss: 252.3637\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 221.1248 - val_loss: 252.8700\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 222.0324 - val_loss: 252.5482\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 221.7313 - val_loss: 249.4374\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 223.4337 - val_loss: 278.2488\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 221.4401 - val_loss: 248.2487\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 248.2129014297262\n",
      "Mean Absolute Error (MAE): 10.29412996228376\n",
      "Root Mean Squared Error (RMSE): 15.75477392505923\n",
      "Time taken: 415.2498800754547\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 6s 8ms/step - loss: 1393.7864 - val_loss: 1233.3781\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1224.1754 - val_loss: 1136.3483\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1138.6990 - val_loss: 1064.2196\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 1074.4995 - val_loss: 1009.9305\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 1026.3098 - val_loss: 969.7730\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 990.8674 - val_loss: 941.0638\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 965.7519 - val_loss: 921.2108\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 948.8001 - val_loss: 908.4783\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 938.0479 - val_loss: 900.8238\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 931.6364 - val_loss: 896.7164\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 927.8733 - val_loss: 893.1146\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 923.0427 - val_loss: 886.9159\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 905.9011 - val_loss: 851.6656\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 870.6625 - val_loss: 822.1662\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 841.3982 - val_loss: 795.6827\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 812.3385 - val_loss: 766.9009\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 782.8947 - val_loss: 733.0889\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 750.4438 - val_loss: 702.7105\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 718.4995 - val_loss: 673.0337\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 688.9485 - val_loss: 645.2825\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 661.4728 - val_loss: 621.0466\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 634.0610 - val_loss: 593.2369\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 608.2524 - val_loss: 568.2510\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 582.0170 - val_loss: 541.0296\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 552.7142 - val_loss: 515.1807\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 525.7165 - val_loss: 489.3429\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 502.6930 - val_loss: 467.5760\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 481.4628 - val_loss: 448.5096\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 461.5081 - val_loss: 432.0806\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 444.0266 - val_loss: 414.0630\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 426.9296 - val_loss: 405.9693\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 410.9705 - val_loss: 383.6829\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 395.9583 - val_loss: 372.2371\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 383.4185 - val_loss: 360.1356\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 371.2929 - val_loss: 348.3557\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 360.5734 - val_loss: 344.3593\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 350.8888 - val_loss: 335.9098\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 341.3995 - val_loss: 324.0583\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 334.5369 - val_loss: 318.8436\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 328.5126 - val_loss: 317.3647\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 322.7600 - val_loss: 308.5212\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 316.3960 - val_loss: 304.6071\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 312.2378 - val_loss: 300.8402\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 308.1726 - val_loss: 296.9562\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 305.3033 - val_loss: 291.7363\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 302.3196 - val_loss: 291.7009\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 299.9101 - val_loss: 290.9370\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 299.0808 - val_loss: 288.7855\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 296.4717 - val_loss: 285.2827\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 293.7865 - val_loss: 294.0190\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 294.2406 - val_loss: 283.7003\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 291.9807 - val_loss: 284.7023\n",
      "Epoch 53/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 291.3796 - val_loss: 282.6816\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 290.2562 - val_loss: 284.9113\n",
      "Epoch 55/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 289.9804 - val_loss: 281.1802\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 289.2157 - val_loss: 283.1566\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 288.2069 - val_loss: 285.0151\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 287.2314 - val_loss: 279.3453\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 286.8294 - val_loss: 280.1736\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 285.6610 - val_loss: 280.7488\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 285.4878 - val_loss: 278.5523\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 283.5934 - val_loss: 276.9643\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 282.5101 - val_loss: 274.9368\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 281.1888 - val_loss: 277.4641\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 279.8422 - val_loss: 275.9355\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 278.5019 - val_loss: 273.2013\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 277.7697 - val_loss: 273.4628\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 274.2787 - val_loss: 274.4087\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 273.3866 - val_loss: 272.8017\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 272.1387 - val_loss: 269.4426\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 269.8069 - val_loss: 274.1663\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 269.9033 - val_loss: 273.7023\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 268.8514 - val_loss: 264.0481\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 272.1466 - val_loss: 269.5956\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 266.1158 - val_loss: 266.3008\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 267.7645 - val_loss: 259.7254\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 265.9068 - val_loss: 260.9389\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 264.1860 - val_loss: 257.1709\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 263.4096 - val_loss: 259.1472\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 259.3974 - val_loss: 256.1779\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 259.8201 - val_loss: 256.8304\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 260.2933 - val_loss: 255.2162\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 259.9295 - val_loss: 261.9324\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 259.1749 - val_loss: 252.8636\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 259.0343 - val_loss: 255.7708\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 257.5472 - val_loss: 258.6166\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 254.8049 - val_loss: 261.8295\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 255.5265 - val_loss: 258.1251\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 255.3068 - val_loss: 258.0604\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 253.7589 - val_loss: 252.3166\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 250.8389 - val_loss: 265.6753\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 254.7942 - val_loss: 251.9908\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 252.0294 - val_loss: 252.6975\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 251.3326 - val_loss: 257.2735\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 250.2022 - val_loss: 259.9055\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 248.6296 - val_loss: 247.9550\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 249.9480 - val_loss: 250.2058\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.6224 - val_loss: 262.0960\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 248.1297 - val_loss: 249.4818\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.6731 - val_loss: 246.3545\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 249.2485 - val_loss: 255.2406\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 247.1122 - val_loss: 249.1135\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 246.1761 - val_loss: 251.6095\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 246.7145 - val_loss: 257.4377\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.2707 - val_loss: 251.6385\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.9030 - val_loss: 247.4659\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.0077 - val_loss: 263.5734\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 244.6096 - val_loss: 259.5354\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 243.5751 - val_loss: 248.5098\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.8254 - val_loss: 257.8602\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 242.1748 - val_loss: 256.9250\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.9870 - val_loss: 260.0179\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 244.5665 - val_loss: 248.8825\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 241.4505 - val_loss: 254.8030\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 241.6872 - val_loss: 246.2779\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 242.8638 - val_loss: 246.5993\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 241.0775 - val_loss: 248.2616\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 242.1670 - val_loss: 252.3262\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 242.6379 - val_loss: 245.8378\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 240.9275 - val_loss: 248.3263\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 238.3742 - val_loss: 245.7998\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 237.0601 - val_loss: 242.1637\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 241.7079 - val_loss: 243.3566\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 237.3745 - val_loss: 279.7522\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 240.1011 - val_loss: 243.4845\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.0938 - val_loss: 243.6906\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.6411 - val_loss: 246.8541\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 240.1996 - val_loss: 252.7881\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 239.9983 - val_loss: 242.8908\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 236.3721 - val_loss: 254.0864\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 234.9035 - val_loss: 242.6051\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 238.6327 - val_loss: 246.4905\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 238.8761 - val_loss: 243.6808\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 239.2892 - val_loss: 246.1791\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.9612 - val_loss: 242.6407\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 237.0861 - val_loss: 244.9292\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 235.8076 - val_loss: 245.8589\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.6573 - val_loss: 242.4999\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.3271 - val_loss: 244.3604\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 233.6148 - val_loss: 243.0995\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.4511 - val_loss: 252.5100\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.8477 - val_loss: 245.8526\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.3062 - val_loss: 244.1788\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.7748 - val_loss: 249.3882\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.5143 - val_loss: 259.1371\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.6492 - val_loss: 246.1540\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.9441 - val_loss: 245.9747\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.6535 - val_loss: 246.5872\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.9096 - val_loss: 251.9638\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.0509 - val_loss: 258.9905\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.8212 - val_loss: 253.3940\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.8014 - val_loss: 251.0564\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.7409 - val_loss: 245.8308\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 233.3531 - val_loss: 265.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 235.3938 - val_loss: 243.9914\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.7656 - val_loss: 245.5295\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.6313 - val_loss: 249.4401\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.2093 - val_loss: 244.5961\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.7446 - val_loss: 253.7380\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.7716 - val_loss: 242.2347\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.8296 - val_loss: 250.9526\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 234.2259 - val_loss: 250.8370\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.1796 - val_loss: 255.0577\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 232.7257 - val_loss: 249.1801\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.1627 - val_loss: 246.7768\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 231.1012 - val_loss: 243.0979\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.4844 - val_loss: 245.8345\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.5338 - val_loss: 241.0796\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.1412 - val_loss: 244.9412\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 230.6862 - val_loss: 268.9667\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.8181 - val_loss: 241.8357\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.8297 - val_loss: 255.4229\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 229.1698 - val_loss: 246.8725\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.1404 - val_loss: 246.8155\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.6078 - val_loss: 244.5008\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.1349 - val_loss: 247.4190\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 230.5884 - val_loss: 244.4225\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 228.2558 - val_loss: 248.9658\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 228.6227 - val_loss: 248.2315\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.1353 - val_loss: 268.3396\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 226.3748 - val_loss: 243.5014\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.7089 - val_loss: 252.8144\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 229.4446 - val_loss: 249.8522\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.7144 - val_loss: 243.9024\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 226.1025 - val_loss: 244.9553\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 226.3625 - val_loss: 246.2338\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.8522 - val_loss: 245.9225\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 230.5066 - val_loss: 245.8457\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.7872 - val_loss: 248.2000\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.1969 - val_loss: 244.5671\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.4438 - val_loss: 251.9940\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 227.2798 - val_loss: 247.1637\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.2186 - val_loss: 244.4063\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 225.6173 - val_loss: 265.6026\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 228.6380 - val_loss: 243.1299\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 226.6395 - val_loss: 247.4487\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.9617 - val_loss: 247.8616\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.3340 - val_loss: 245.6437\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 229.1767 - val_loss: 248.1871\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 225.4843 - val_loss: 260.0158\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 259.9734138591214\n",
      "Mean Absolute Error (MAE): 10.339686563532586\n",
      "Root Mean Squared Error (RMSE): 16.123691074289454\n",
      "Time taken: 435.1661765575409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3))\n",
    "\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test))\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 4, 512)            1052672   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 4, 256)            787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,037,635\n",
      "Trainable params: 2,037,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_6988\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold         MSE        MAE       RMSE  Time taken\n",
      "0        1  248.098498  10.501636  15.751143  484.247471\n",
      "1        2  259.693425  10.994976  16.115006  463.029316\n",
      "2        3  256.319951  10.227461  16.009995  458.150387\n",
      "3        4  248.212901  10.294130  15.754774  415.249880\n",
      "4        5  259.973414  10.339687  16.123691  435.166177\n",
      "5  Average  254.459638  10.471578  15.950922  451.168646\n",
      "Results saved to 'DL_Result_PL_model_1_Scattered_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('DL_Result_PL_model_1_Scattered_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'DL_Result_PL_model_1_Scattered_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
