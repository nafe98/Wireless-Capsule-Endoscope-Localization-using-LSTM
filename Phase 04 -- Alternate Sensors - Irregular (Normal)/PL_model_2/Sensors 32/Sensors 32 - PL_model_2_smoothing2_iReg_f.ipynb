{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_2_smoothing2_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.448072</td>\n",
       "      <td>71.866212</td>\n",
       "      <td>55.379099</td>\n",
       "      <td>67.169250</td>\n",
       "      <td>68.703894</td>\n",
       "      <td>73.546136</td>\n",
       "      <td>67.810228</td>\n",
       "      <td>77.510547</td>\n",
       "      <td>61.298868</td>\n",
       "      <td>68.717478</td>\n",
       "      <td>...</td>\n",
       "      <td>59.015999</td>\n",
       "      <td>62.518813</td>\n",
       "      <td>59.411256</td>\n",
       "      <td>60.758988</td>\n",
       "      <td>68.038102</td>\n",
       "      <td>72.988410</td>\n",
       "      <td>63.830242</td>\n",
       "      <td>75.252439</td>\n",
       "      <td>52.602491</td>\n",
       "      <td>67.851956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.418672</td>\n",
       "      <td>71.935271</td>\n",
       "      <td>55.344122</td>\n",
       "      <td>67.311666</td>\n",
       "      <td>68.862156</td>\n",
       "      <td>73.638498</td>\n",
       "      <td>67.636949</td>\n",
       "      <td>77.055207</td>\n",
       "      <td>61.417464</td>\n",
       "      <td>68.656037</td>\n",
       "      <td>...</td>\n",
       "      <td>59.062238</td>\n",
       "      <td>62.619356</td>\n",
       "      <td>59.705588</td>\n",
       "      <td>60.845566</td>\n",
       "      <td>67.996626</td>\n",
       "      <td>72.754005</td>\n",
       "      <td>63.917271</td>\n",
       "      <td>75.285079</td>\n",
       "      <td>52.570382</td>\n",
       "      <td>67.864368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.389637</td>\n",
       "      <td>72.007924</td>\n",
       "      <td>55.310861</td>\n",
       "      <td>67.452753</td>\n",
       "      <td>69.019299</td>\n",
       "      <td>73.733994</td>\n",
       "      <td>67.468015</td>\n",
       "      <td>76.608876</td>\n",
       "      <td>61.529876</td>\n",
       "      <td>68.599884</td>\n",
       "      <td>...</td>\n",
       "      <td>59.111119</td>\n",
       "      <td>62.720162</td>\n",
       "      <td>59.994576</td>\n",
       "      <td>60.937070</td>\n",
       "      <td>67.958247</td>\n",
       "      <td>72.523518</td>\n",
       "      <td>64.005781</td>\n",
       "      <td>75.315011</td>\n",
       "      <td>52.539130</td>\n",
       "      <td>67.878903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.360882</td>\n",
       "      <td>72.083804</td>\n",
       "      <td>55.280242</td>\n",
       "      <td>67.592834</td>\n",
       "      <td>69.175079</td>\n",
       "      <td>73.832377</td>\n",
       "      <td>67.304084</td>\n",
       "      <td>76.171754</td>\n",
       "      <td>61.636534</td>\n",
       "      <td>68.548849</td>\n",
       "      <td>...</td>\n",
       "      <td>59.162988</td>\n",
       "      <td>62.821366</td>\n",
       "      <td>60.277882</td>\n",
       "      <td>61.033224</td>\n",
       "      <td>67.922592</td>\n",
       "      <td>72.296890</td>\n",
       "      <td>64.095845</td>\n",
       "      <td>75.342087</td>\n",
       "      <td>52.508766</td>\n",
       "      <td>67.896058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.332575</td>\n",
       "      <td>72.162679</td>\n",
       "      <td>55.252883</td>\n",
       "      <td>67.732185</td>\n",
       "      <td>69.329214</td>\n",
       "      <td>73.933638</td>\n",
       "      <td>67.145806</td>\n",
       "      <td>75.743710</td>\n",
       "      <td>61.738066</td>\n",
       "      <td>68.502746</td>\n",
       "      <td>...</td>\n",
       "      <td>59.218087</td>\n",
       "      <td>62.922934</td>\n",
       "      <td>60.555414</td>\n",
       "      <td>61.133664</td>\n",
       "      <td>67.889440</td>\n",
       "      <td>72.073711</td>\n",
       "      <td>64.187436</td>\n",
       "      <td>75.366102</td>\n",
       "      <td>52.479200</td>\n",
       "      <td>67.916340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>71.350987</td>\n",
       "      <td>70.538258</td>\n",
       "      <td>68.544841</td>\n",
       "      <td>53.906213</td>\n",
       "      <td>73.763653</td>\n",
       "      <td>76.608353</td>\n",
       "      <td>69.085982</td>\n",
       "      <td>71.842437</td>\n",
       "      <td>70.823796</td>\n",
       "      <td>62.002797</td>\n",
       "      <td>...</td>\n",
       "      <td>66.743266</td>\n",
       "      <td>68.095627</td>\n",
       "      <td>59.788287</td>\n",
       "      <td>55.782259</td>\n",
       "      <td>73.302487</td>\n",
       "      <td>69.777199</td>\n",
       "      <td>70.634276</td>\n",
       "      <td>72.344860</td>\n",
       "      <td>66.105552</td>\n",
       "      <td>57.730447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>71.073659</td>\n",
       "      <td>70.368423</td>\n",
       "      <td>68.696703</td>\n",
       "      <td>53.930584</td>\n",
       "      <td>73.653961</td>\n",
       "      <td>76.505011</td>\n",
       "      <td>68.987498</td>\n",
       "      <td>71.977737</td>\n",
       "      <td>71.021247</td>\n",
       "      <td>61.899134</td>\n",
       "      <td>...</td>\n",
       "      <td>66.884332</td>\n",
       "      <td>68.147865</td>\n",
       "      <td>59.701153</td>\n",
       "      <td>55.875421</td>\n",
       "      <td>73.314650</td>\n",
       "      <td>69.681036</td>\n",
       "      <td>70.473344</td>\n",
       "      <td>72.306974</td>\n",
       "      <td>66.184077</td>\n",
       "      <td>57.778432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>70.796726</td>\n",
       "      <td>70.197133</td>\n",
       "      <td>68.850197</td>\n",
       "      <td>53.955863</td>\n",
       "      <td>73.544931</td>\n",
       "      <td>76.398826</td>\n",
       "      <td>68.891677</td>\n",
       "      <td>72.111296</td>\n",
       "      <td>71.217271</td>\n",
       "      <td>61.795862</td>\n",
       "      <td>...</td>\n",
       "      <td>67.027974</td>\n",
       "      <td>68.198538</td>\n",
       "      <td>59.614914</td>\n",
       "      <td>55.967148</td>\n",
       "      <td>73.321655</td>\n",
       "      <td>69.583333</td>\n",
       "      <td>70.310319</td>\n",
       "      <td>72.267957</td>\n",
       "      <td>66.266954</td>\n",
       "      <td>57.829265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>70.520438</td>\n",
       "      <td>70.024321</td>\n",
       "      <td>69.005341</td>\n",
       "      <td>53.982231</td>\n",
       "      <td>73.436429</td>\n",
       "      <td>76.289524</td>\n",
       "      <td>68.798594</td>\n",
       "      <td>72.242943</td>\n",
       "      <td>71.411729</td>\n",
       "      <td>61.693438</td>\n",
       "      <td>...</td>\n",
       "      <td>67.173718</td>\n",
       "      <td>68.247988</td>\n",
       "      <td>59.530568</td>\n",
       "      <td>56.057411</td>\n",
       "      <td>73.323308</td>\n",
       "      <td>69.484466</td>\n",
       "      <td>70.145269</td>\n",
       "      <td>72.228032</td>\n",
       "      <td>66.353304</td>\n",
       "      <td>57.883165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>70.245255</td>\n",
       "      <td>69.849882</td>\n",
       "      <td>69.162132</td>\n",
       "      <td>54.009588</td>\n",
       "      <td>73.328562</td>\n",
       "      <td>76.177104</td>\n",
       "      <td>68.708527</td>\n",
       "      <td>72.372422</td>\n",
       "      <td>71.604788</td>\n",
       "      <td>61.592348</td>\n",
       "      <td>...</td>\n",
       "      <td>67.321086</td>\n",
       "      <td>68.296467</td>\n",
       "      <td>59.448892</td>\n",
       "      <td>56.146465</td>\n",
       "      <td>73.319703</td>\n",
       "      <td>69.384572</td>\n",
       "      <td>69.978262</td>\n",
       "      <td>72.187434</td>\n",
       "      <td>66.442219</td>\n",
       "      <td>57.940128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5   \\\n",
       "0     69.448072  71.866212  55.379099  67.169250  68.703894  73.546136   \n",
       "1     69.418672  71.935271  55.344122  67.311666  68.862156  73.638498   \n",
       "2     69.389637  72.007924  55.310861  67.452753  69.019299  73.733994   \n",
       "3     69.360882  72.083804  55.280242  67.592834  69.175079  73.832377   \n",
       "4     69.332575  72.162679  55.252883  67.732185  69.329214  73.933638   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  71.350987  70.538258  68.544841  53.906213  73.763653  76.608353   \n",
       "2439  71.073659  70.368423  68.696703  53.930584  73.653961  76.505011   \n",
       "2440  70.796726  70.197133  68.850197  53.955863  73.544931  76.398826   \n",
       "2441  70.520438  70.024321  69.005341  53.982231  73.436429  76.289524   \n",
       "2442  70.245255  69.849882  69.162132  54.009588  73.328562  76.177104   \n",
       "\n",
       "             6          7          8          9   ...         38         39  \\\n",
       "0     67.810228  77.510547  61.298868  68.717478  ...  59.015999  62.518813   \n",
       "1     67.636949  77.055207  61.417464  68.656037  ...  59.062238  62.619356   \n",
       "2     67.468015  76.608876  61.529876  68.599884  ...  59.111119  62.720162   \n",
       "3     67.304084  76.171754  61.636534  68.548849  ...  59.162988  62.821366   \n",
       "4     67.145806  75.743710  61.738066  68.502746  ...  59.218087  62.922934   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  69.085982  71.842437  70.823796  62.002797  ...  66.743266  68.095627   \n",
       "2439  68.987498  71.977737  71.021247  61.899134  ...  66.884332  68.147865   \n",
       "2440  68.891677  72.111296  71.217271  61.795862  ...  67.027974  68.198538   \n",
       "2441  68.798594  72.242943  71.411729  61.693438  ...  67.173718  68.247988   \n",
       "2442  68.708527  72.372422  71.604788  61.592348  ...  67.321086  68.296467   \n",
       "\n",
       "             40         41         42         43         44         45  \\\n",
       "0     59.411256  60.758988  68.038102  72.988410  63.830242  75.252439   \n",
       "1     59.705588  60.845566  67.996626  72.754005  63.917271  75.285079   \n",
       "2     59.994576  60.937070  67.958247  72.523518  64.005781  75.315011   \n",
       "3     60.277882  61.033224  67.922592  72.296890  64.095845  75.342087   \n",
       "4     60.555414  61.133664  67.889440  72.073711  64.187436  75.366102   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  59.788287  55.782259  73.302487  69.777199  70.634276  72.344860   \n",
       "2439  59.701153  55.875421  73.314650  69.681036  70.473344  72.306974   \n",
       "2440  59.614914  55.967148  73.321655  69.583333  70.310319  72.267957   \n",
       "2441  59.530568  56.057411  73.323308  69.484466  70.145269  72.228032   \n",
       "2442  59.448892  56.146465  73.319703  69.384572  69.978262  72.187434   \n",
       "\n",
       "             46         47  \n",
       "0     52.602491  67.851956  \n",
       "1     52.570382  67.864368  \n",
       "2     52.539130  67.878903  \n",
       "3     52.508766  67.896058  \n",
       "4     52.479200  67.916340  \n",
       "...         ...        ...  \n",
       "2438  66.105552  57.730447  \n",
       "2439  66.184077  57.778432  \n",
       "2440  66.266954  57.829265  \n",
       "2441  66.353304  57.883165  \n",
       "2442  66.442219  57.940128  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.448072</td>\n",
       "      <td>71.866212</td>\n",
       "      <td>55.379099</td>\n",
       "      <td>67.169250</td>\n",
       "      <td>68.703894</td>\n",
       "      <td>73.546136</td>\n",
       "      <td>67.810228</td>\n",
       "      <td>77.510547</td>\n",
       "      <td>61.298868</td>\n",
       "      <td>68.717478</td>\n",
       "      <td>...</td>\n",
       "      <td>59.015999</td>\n",
       "      <td>62.518813</td>\n",
       "      <td>59.411256</td>\n",
       "      <td>60.758988</td>\n",
       "      <td>68.038102</td>\n",
       "      <td>72.988410</td>\n",
       "      <td>63.830242</td>\n",
       "      <td>75.252439</td>\n",
       "      <td>52.602491</td>\n",
       "      <td>67.851956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.418672</td>\n",
       "      <td>71.935271</td>\n",
       "      <td>55.344122</td>\n",
       "      <td>67.311666</td>\n",
       "      <td>68.862156</td>\n",
       "      <td>73.638498</td>\n",
       "      <td>67.636949</td>\n",
       "      <td>77.055207</td>\n",
       "      <td>61.417464</td>\n",
       "      <td>68.656037</td>\n",
       "      <td>...</td>\n",
       "      <td>59.062238</td>\n",
       "      <td>62.619356</td>\n",
       "      <td>59.705588</td>\n",
       "      <td>60.845566</td>\n",
       "      <td>67.996626</td>\n",
       "      <td>72.754005</td>\n",
       "      <td>63.917271</td>\n",
       "      <td>75.285079</td>\n",
       "      <td>52.570382</td>\n",
       "      <td>67.864368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.389637</td>\n",
       "      <td>72.007924</td>\n",
       "      <td>55.310861</td>\n",
       "      <td>67.452753</td>\n",
       "      <td>69.019299</td>\n",
       "      <td>73.733994</td>\n",
       "      <td>67.468015</td>\n",
       "      <td>76.608876</td>\n",
       "      <td>61.529876</td>\n",
       "      <td>68.599884</td>\n",
       "      <td>...</td>\n",
       "      <td>59.111119</td>\n",
       "      <td>62.720162</td>\n",
       "      <td>59.994576</td>\n",
       "      <td>60.937070</td>\n",
       "      <td>67.958247</td>\n",
       "      <td>72.523518</td>\n",
       "      <td>64.005781</td>\n",
       "      <td>75.315011</td>\n",
       "      <td>52.539130</td>\n",
       "      <td>67.878903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.360882</td>\n",
       "      <td>72.083804</td>\n",
       "      <td>55.280242</td>\n",
       "      <td>67.592834</td>\n",
       "      <td>69.175079</td>\n",
       "      <td>73.832377</td>\n",
       "      <td>67.304084</td>\n",
       "      <td>76.171754</td>\n",
       "      <td>61.636534</td>\n",
       "      <td>68.548849</td>\n",
       "      <td>...</td>\n",
       "      <td>59.162988</td>\n",
       "      <td>62.821366</td>\n",
       "      <td>60.277882</td>\n",
       "      <td>61.033224</td>\n",
       "      <td>67.922592</td>\n",
       "      <td>72.296890</td>\n",
       "      <td>64.095845</td>\n",
       "      <td>75.342087</td>\n",
       "      <td>52.508766</td>\n",
       "      <td>67.896058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.332575</td>\n",
       "      <td>72.162679</td>\n",
       "      <td>55.252883</td>\n",
       "      <td>67.732185</td>\n",
       "      <td>69.329214</td>\n",
       "      <td>73.933638</td>\n",
       "      <td>67.145806</td>\n",
       "      <td>75.743710</td>\n",
       "      <td>61.738066</td>\n",
       "      <td>68.502746</td>\n",
       "      <td>...</td>\n",
       "      <td>59.218087</td>\n",
       "      <td>62.922934</td>\n",
       "      <td>60.555414</td>\n",
       "      <td>61.133664</td>\n",
       "      <td>67.889440</td>\n",
       "      <td>72.073711</td>\n",
       "      <td>64.187436</td>\n",
       "      <td>75.366102</td>\n",
       "      <td>52.479200</td>\n",
       "      <td>67.916340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>71.350987</td>\n",
       "      <td>70.538258</td>\n",
       "      <td>68.544841</td>\n",
       "      <td>53.906213</td>\n",
       "      <td>73.763653</td>\n",
       "      <td>76.608353</td>\n",
       "      <td>69.085982</td>\n",
       "      <td>71.842437</td>\n",
       "      <td>70.823796</td>\n",
       "      <td>62.002797</td>\n",
       "      <td>...</td>\n",
       "      <td>66.743266</td>\n",
       "      <td>68.095627</td>\n",
       "      <td>59.788287</td>\n",
       "      <td>55.782259</td>\n",
       "      <td>73.302487</td>\n",
       "      <td>69.777199</td>\n",
       "      <td>70.634276</td>\n",
       "      <td>72.344860</td>\n",
       "      <td>66.105552</td>\n",
       "      <td>57.730447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>71.073659</td>\n",
       "      <td>70.368423</td>\n",
       "      <td>68.696703</td>\n",
       "      <td>53.930584</td>\n",
       "      <td>73.653961</td>\n",
       "      <td>76.505011</td>\n",
       "      <td>68.987498</td>\n",
       "      <td>71.977737</td>\n",
       "      <td>71.021247</td>\n",
       "      <td>61.899134</td>\n",
       "      <td>...</td>\n",
       "      <td>66.884332</td>\n",
       "      <td>68.147865</td>\n",
       "      <td>59.701153</td>\n",
       "      <td>55.875421</td>\n",
       "      <td>73.314650</td>\n",
       "      <td>69.681036</td>\n",
       "      <td>70.473344</td>\n",
       "      <td>72.306974</td>\n",
       "      <td>66.184077</td>\n",
       "      <td>57.778432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>70.796726</td>\n",
       "      <td>70.197133</td>\n",
       "      <td>68.850197</td>\n",
       "      <td>53.955863</td>\n",
       "      <td>73.544931</td>\n",
       "      <td>76.398826</td>\n",
       "      <td>68.891677</td>\n",
       "      <td>72.111296</td>\n",
       "      <td>71.217271</td>\n",
       "      <td>61.795862</td>\n",
       "      <td>...</td>\n",
       "      <td>67.027974</td>\n",
       "      <td>68.198538</td>\n",
       "      <td>59.614914</td>\n",
       "      <td>55.967148</td>\n",
       "      <td>73.321655</td>\n",
       "      <td>69.583333</td>\n",
       "      <td>70.310319</td>\n",
       "      <td>72.267957</td>\n",
       "      <td>66.266954</td>\n",
       "      <td>57.829265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>70.520438</td>\n",
       "      <td>70.024321</td>\n",
       "      <td>69.005341</td>\n",
       "      <td>53.982231</td>\n",
       "      <td>73.436429</td>\n",
       "      <td>76.289524</td>\n",
       "      <td>68.798594</td>\n",
       "      <td>72.242943</td>\n",
       "      <td>71.411729</td>\n",
       "      <td>61.693438</td>\n",
       "      <td>...</td>\n",
       "      <td>67.173718</td>\n",
       "      <td>68.247988</td>\n",
       "      <td>59.530568</td>\n",
       "      <td>56.057411</td>\n",
       "      <td>73.323308</td>\n",
       "      <td>69.484466</td>\n",
       "      <td>70.145269</td>\n",
       "      <td>72.228032</td>\n",
       "      <td>66.353304</td>\n",
       "      <td>57.883165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>70.245255</td>\n",
       "      <td>69.849882</td>\n",
       "      <td>69.162132</td>\n",
       "      <td>54.009588</td>\n",
       "      <td>73.328562</td>\n",
       "      <td>76.177104</td>\n",
       "      <td>68.708527</td>\n",
       "      <td>72.372422</td>\n",
       "      <td>71.604788</td>\n",
       "      <td>61.592348</td>\n",
       "      <td>...</td>\n",
       "      <td>67.321086</td>\n",
       "      <td>68.296467</td>\n",
       "      <td>59.448892</td>\n",
       "      <td>56.146465</td>\n",
       "      <td>73.319703</td>\n",
       "      <td>69.384572</td>\n",
       "      <td>69.978262</td>\n",
       "      <td>72.187434</td>\n",
       "      <td>66.442219</td>\n",
       "      <td>57.940128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor1    sensor2    sensor3    sensor4    sensor5    sensor6  \\\n",
       "0     69.448072  71.866212  55.379099  67.169250  68.703894  73.546136   \n",
       "1     69.418672  71.935271  55.344122  67.311666  68.862156  73.638498   \n",
       "2     69.389637  72.007924  55.310861  67.452753  69.019299  73.733994   \n",
       "3     69.360882  72.083804  55.280242  67.592834  69.175079  73.832377   \n",
       "4     69.332575  72.162679  55.252883  67.732185  69.329214  73.933638   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  71.350987  70.538258  68.544841  53.906213  73.763653  76.608353   \n",
       "2439  71.073659  70.368423  68.696703  53.930584  73.653961  76.505011   \n",
       "2440  70.796726  70.197133  68.850197  53.955863  73.544931  76.398826   \n",
       "2441  70.520438  70.024321  69.005341  53.982231  73.436429  76.289524   \n",
       "2442  70.245255  69.849882  69.162132  54.009588  73.328562  76.177104   \n",
       "\n",
       "        sensor7    sensor8    sensor9   sensor10  ...   sensor39   sensor40  \\\n",
       "0     67.810228  77.510547  61.298868  68.717478  ...  59.015999  62.518813   \n",
       "1     67.636949  77.055207  61.417464  68.656037  ...  59.062238  62.619356   \n",
       "2     67.468015  76.608876  61.529876  68.599884  ...  59.111119  62.720162   \n",
       "3     67.304084  76.171754  61.636534  68.548849  ...  59.162988  62.821366   \n",
       "4     67.145806  75.743710  61.738066  68.502746  ...  59.218087  62.922934   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  69.085982  71.842437  70.823796  62.002797  ...  66.743266  68.095627   \n",
       "2439  68.987498  71.977737  71.021247  61.899134  ...  66.884332  68.147865   \n",
       "2440  68.891677  72.111296  71.217271  61.795862  ...  67.027974  68.198538   \n",
       "2441  68.798594  72.242943  71.411729  61.693438  ...  67.173718  68.247988   \n",
       "2442  68.708527  72.372422  71.604788  61.592348  ...  67.321086  68.296467   \n",
       "\n",
       "       sensor41   sensor42   sensor43   sensor44   sensor45   sensor46  \\\n",
       "0     59.411256  60.758988  68.038102  72.988410  63.830242  75.252439   \n",
       "1     59.705588  60.845566  67.996626  72.754005  63.917271  75.285079   \n",
       "2     59.994576  60.937070  67.958247  72.523518  64.005781  75.315011   \n",
       "3     60.277882  61.033224  67.922592  72.296890  64.095845  75.342087   \n",
       "4     60.555414  61.133664  67.889440  72.073711  64.187436  75.366102   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  59.788287  55.782259  73.302487  69.777199  70.634276  72.344860   \n",
       "2439  59.701153  55.875421  73.314650  69.681036  70.473344  72.306974   \n",
       "2440  59.614914  55.967148  73.321655  69.583333  70.310319  72.267957   \n",
       "2441  59.530568  56.057411  73.323308  69.484466  70.145269  72.228032   \n",
       "2442  59.448892  56.146465  73.319703  69.384572  69.978262  72.187434   \n",
       "\n",
       "       sensor47   sensor48  \n",
       "0     52.602491  67.851956  \n",
       "1     52.570382  67.864368  \n",
       "2     52.539130  67.878903  \n",
       "3     52.508766  67.896058  \n",
       "4     52.479200  67.916340  \n",
       "...         ...        ...  \n",
       "2438  66.105552  57.730447  \n",
       "2439  66.184077  57.778432  \n",
       "2440  66.266954  57.829265  \n",
       "2441  66.353304  57.883165  \n",
       "2442  66.442219  57.940128  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf63fe",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090b68f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor23</th>\n",
       "      <th>sensor24</th>\n",
       "      <th>sensor25</th>\n",
       "      <th>sensor26</th>\n",
       "      <th>sensor27</th>\n",
       "      <th>sensor28</th>\n",
       "      <th>sensor29</th>\n",
       "      <th>sensor30</th>\n",
       "      <th>sensor31</th>\n",
       "      <th>sensor32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.448072</td>\n",
       "      <td>71.866212</td>\n",
       "      <td>55.379099</td>\n",
       "      <td>67.169250</td>\n",
       "      <td>68.703894</td>\n",
       "      <td>73.546136</td>\n",
       "      <td>67.810228</td>\n",
       "      <td>77.510547</td>\n",
       "      <td>61.298868</td>\n",
       "      <td>68.717478</td>\n",
       "      <td>...</td>\n",
       "      <td>61.617424</td>\n",
       "      <td>71.352761</td>\n",
       "      <td>44.988390</td>\n",
       "      <td>60.897140</td>\n",
       "      <td>63.941093</td>\n",
       "      <td>64.669714</td>\n",
       "      <td>62.472069</td>\n",
       "      <td>69.532677</td>\n",
       "      <td>66.071604</td>\n",
       "      <td>68.156040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.418672</td>\n",
       "      <td>71.935271</td>\n",
       "      <td>55.344122</td>\n",
       "      <td>67.311666</td>\n",
       "      <td>68.862156</td>\n",
       "      <td>73.638498</td>\n",
       "      <td>67.636949</td>\n",
       "      <td>77.055207</td>\n",
       "      <td>61.417464</td>\n",
       "      <td>68.656037</td>\n",
       "      <td>...</td>\n",
       "      <td>61.417515</td>\n",
       "      <td>71.408016</td>\n",
       "      <td>44.912100</td>\n",
       "      <td>60.950077</td>\n",
       "      <td>63.642115</td>\n",
       "      <td>64.847298</td>\n",
       "      <td>62.567469</td>\n",
       "      <td>69.394385</td>\n",
       "      <td>65.889377</td>\n",
       "      <td>68.318221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.389637</td>\n",
       "      <td>72.007924</td>\n",
       "      <td>55.310861</td>\n",
       "      <td>67.452753</td>\n",
       "      <td>69.019299</td>\n",
       "      <td>73.733994</td>\n",
       "      <td>67.468015</td>\n",
       "      <td>76.608876</td>\n",
       "      <td>61.529876</td>\n",
       "      <td>68.599884</td>\n",
       "      <td>...</td>\n",
       "      <td>61.218926</td>\n",
       "      <td>71.464419</td>\n",
       "      <td>44.841220</td>\n",
       "      <td>61.005044</td>\n",
       "      <td>63.345513</td>\n",
       "      <td>65.025287</td>\n",
       "      <td>62.656474</td>\n",
       "      <td>69.256797</td>\n",
       "      <td>65.710188</td>\n",
       "      <td>68.479716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.360882</td>\n",
       "      <td>72.083804</td>\n",
       "      <td>55.280242</td>\n",
       "      <td>67.592834</td>\n",
       "      <td>69.175079</td>\n",
       "      <td>73.832377</td>\n",
       "      <td>67.304084</td>\n",
       "      <td>76.171754</td>\n",
       "      <td>61.636534</td>\n",
       "      <td>68.548849</td>\n",
       "      <td>...</td>\n",
       "      <td>61.021928</td>\n",
       "      <td>71.521580</td>\n",
       "      <td>44.775412</td>\n",
       "      <td>61.061846</td>\n",
       "      <td>63.051005</td>\n",
       "      <td>65.202738</td>\n",
       "      <td>62.738968</td>\n",
       "      <td>69.120142</td>\n",
       "      <td>65.534390</td>\n",
       "      <td>68.640083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.332575</td>\n",
       "      <td>72.162679</td>\n",
       "      <td>55.252883</td>\n",
       "      <td>67.732185</td>\n",
       "      <td>69.329214</td>\n",
       "      <td>73.933638</td>\n",
       "      <td>67.145806</td>\n",
       "      <td>75.743710</td>\n",
       "      <td>61.738066</td>\n",
       "      <td>68.502746</td>\n",
       "      <td>...</td>\n",
       "      <td>60.826849</td>\n",
       "      <td>71.578954</td>\n",
       "      <td>44.714199</td>\n",
       "      <td>61.120104</td>\n",
       "      <td>62.758331</td>\n",
       "      <td>65.378656</td>\n",
       "      <td>62.815263</td>\n",
       "      <td>68.984412</td>\n",
       "      <td>65.362021</td>\n",
       "      <td>68.798812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>71.350987</td>\n",
       "      <td>70.538258</td>\n",
       "      <td>68.544841</td>\n",
       "      <td>53.906213</td>\n",
       "      <td>73.763653</td>\n",
       "      <td>76.608353</td>\n",
       "      <td>69.085982</td>\n",
       "      <td>71.842437</td>\n",
       "      <td>70.823796</td>\n",
       "      <td>62.002797</td>\n",
       "      <td>...</td>\n",
       "      <td>70.645923</td>\n",
       "      <td>62.372587</td>\n",
       "      <td>62.655147</td>\n",
       "      <td>32.573937</td>\n",
       "      <td>64.538244</td>\n",
       "      <td>57.561803</td>\n",
       "      <td>66.500537</td>\n",
       "      <td>61.011540</td>\n",
       "      <td>73.017234</td>\n",
       "      <td>68.733032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>71.073659</td>\n",
       "      <td>70.368423</td>\n",
       "      <td>68.696703</td>\n",
       "      <td>53.930584</td>\n",
       "      <td>73.653961</td>\n",
       "      <td>76.505011</td>\n",
       "      <td>68.987498</td>\n",
       "      <td>71.977737</td>\n",
       "      <td>71.021247</td>\n",
       "      <td>61.899134</td>\n",
       "      <td>...</td>\n",
       "      <td>70.774777</td>\n",
       "      <td>62.370815</td>\n",
       "      <td>62.989742</td>\n",
       "      <td>32.687229</td>\n",
       "      <td>64.456411</td>\n",
       "      <td>57.323991</td>\n",
       "      <td>66.527387</td>\n",
       "      <td>60.791943</td>\n",
       "      <td>73.062015</td>\n",
       "      <td>68.582853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>70.796726</td>\n",
       "      <td>70.197133</td>\n",
       "      <td>68.850197</td>\n",
       "      <td>53.955863</td>\n",
       "      <td>73.544931</td>\n",
       "      <td>76.398826</td>\n",
       "      <td>68.891677</td>\n",
       "      <td>72.111296</td>\n",
       "      <td>71.217271</td>\n",
       "      <td>61.795862</td>\n",
       "      <td>...</td>\n",
       "      <td>70.906763</td>\n",
       "      <td>62.371777</td>\n",
       "      <td>63.324557</td>\n",
       "      <td>32.797749</td>\n",
       "      <td>64.373578</td>\n",
       "      <td>57.080766</td>\n",
       "      <td>66.551626</td>\n",
       "      <td>60.574792</td>\n",
       "      <td>73.109695</td>\n",
       "      <td>68.434048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>70.520438</td>\n",
       "      <td>70.024321</td>\n",
       "      <td>69.005341</td>\n",
       "      <td>53.982231</td>\n",
       "      <td>73.436429</td>\n",
       "      <td>76.289524</td>\n",
       "      <td>68.798594</td>\n",
       "      <td>72.242943</td>\n",
       "      <td>71.411729</td>\n",
       "      <td>61.693438</td>\n",
       "      <td>...</td>\n",
       "      <td>71.042271</td>\n",
       "      <td>62.375594</td>\n",
       "      <td>63.658953</td>\n",
       "      <td>32.905504</td>\n",
       "      <td>64.289679</td>\n",
       "      <td>56.831862</td>\n",
       "      <td>66.572935</td>\n",
       "      <td>60.359916</td>\n",
       "      <td>73.160283</td>\n",
       "      <td>68.286710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>70.245255</td>\n",
       "      <td>69.849882</td>\n",
       "      <td>69.162132</td>\n",
       "      <td>54.009588</td>\n",
       "      <td>73.328562</td>\n",
       "      <td>76.177104</td>\n",
       "      <td>68.708527</td>\n",
       "      <td>72.372422</td>\n",
       "      <td>71.604788</td>\n",
       "      <td>61.592348</td>\n",
       "      <td>...</td>\n",
       "      <td>71.181410</td>\n",
       "      <td>62.382246</td>\n",
       "      <td>63.992725</td>\n",
       "      <td>33.010669</td>\n",
       "      <td>64.204881</td>\n",
       "      <td>56.577137</td>\n",
       "      <td>66.591237</td>\n",
       "      <td>60.147182</td>\n",
       "      <td>73.213698</td>\n",
       "      <td>68.140945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor1    sensor2    sensor3    sensor4    sensor5    sensor6  \\\n",
       "0     69.448072  71.866212  55.379099  67.169250  68.703894  73.546136   \n",
       "1     69.418672  71.935271  55.344122  67.311666  68.862156  73.638498   \n",
       "2     69.389637  72.007924  55.310861  67.452753  69.019299  73.733994   \n",
       "3     69.360882  72.083804  55.280242  67.592834  69.175079  73.832377   \n",
       "4     69.332575  72.162679  55.252883  67.732185  69.329214  73.933638   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  71.350987  70.538258  68.544841  53.906213  73.763653  76.608353   \n",
       "2439  71.073659  70.368423  68.696703  53.930584  73.653961  76.505011   \n",
       "2440  70.796726  70.197133  68.850197  53.955863  73.544931  76.398826   \n",
       "2441  70.520438  70.024321  69.005341  53.982231  73.436429  76.289524   \n",
       "2442  70.245255  69.849882  69.162132  54.009588  73.328562  76.177104   \n",
       "\n",
       "        sensor7    sensor8    sensor9   sensor10  ...   sensor23   sensor24  \\\n",
       "0     67.810228  77.510547  61.298868  68.717478  ...  61.617424  71.352761   \n",
       "1     67.636949  77.055207  61.417464  68.656037  ...  61.417515  71.408016   \n",
       "2     67.468015  76.608876  61.529876  68.599884  ...  61.218926  71.464419   \n",
       "3     67.304084  76.171754  61.636534  68.548849  ...  61.021928  71.521580   \n",
       "4     67.145806  75.743710  61.738066  68.502746  ...  60.826849  71.578954   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2438  69.085982  71.842437  70.823796  62.002797  ...  70.645923  62.372587   \n",
       "2439  68.987498  71.977737  71.021247  61.899134  ...  70.774777  62.370815   \n",
       "2440  68.891677  72.111296  71.217271  61.795862  ...  70.906763  62.371777   \n",
       "2441  68.798594  72.242943  71.411729  61.693438  ...  71.042271  62.375594   \n",
       "2442  68.708527  72.372422  71.604788  61.592348  ...  71.181410  62.382246   \n",
       "\n",
       "       sensor25   sensor26   sensor27   sensor28   sensor29   sensor30  \\\n",
       "0     44.988390  60.897140  63.941093  64.669714  62.472069  69.532677   \n",
       "1     44.912100  60.950077  63.642115  64.847298  62.567469  69.394385   \n",
       "2     44.841220  61.005044  63.345513  65.025287  62.656474  69.256797   \n",
       "3     44.775412  61.061846  63.051005  65.202738  62.738968  69.120142   \n",
       "4     44.714199  61.120104  62.758331  65.378656  62.815263  68.984412   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2438  62.655147  32.573937  64.538244  57.561803  66.500537  61.011540   \n",
       "2439  62.989742  32.687229  64.456411  57.323991  66.527387  60.791943   \n",
       "2440  63.324557  32.797749  64.373578  57.080766  66.551626  60.574792   \n",
       "2441  63.658953  32.905504  64.289679  56.831862  66.572935  60.359916   \n",
       "2442  63.992725  33.010669  64.204881  56.577137  66.591237  60.147182   \n",
       "\n",
       "       sensor31   sensor32  \n",
       "0     66.071604  68.156040  \n",
       "1     65.889377  68.318221  \n",
       "2     65.710188  68.479716  \n",
       "3     65.534390  68.640083  \n",
       "4     65.362021  68.798812  \n",
       "...         ...        ...  \n",
       "2438  73.017234  68.733032  \n",
       "2439  73.062015  68.582853  \n",
       "2440  73.109695  68.434048  \n",
       "2441  73.160283  68.286710  \n",
       "2442  73.213698  68.140945  \n",
       "\n",
       "[2443 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:32]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 8s 16ms/step - loss: 1117.9839 - val_loss: 911.2529\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 922.9182 - val_loss: 907.6015\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 819.2146 - val_loss: 778.2308\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 503.5879 - val_loss: 545.7537\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 243.8078 - val_loss: 159.4694\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 112.0637 - val_loss: 73.7033\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 49.1968 - val_loss: 39.5565\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 23.9436 - val_loss: 34.7212\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 12.9836 - val_loss: 21.6487\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 9.4007 - val_loss: 14.3914\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.7307 - val_loss: 7.4080\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.9704 - val_loss: 5.4521\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.7084 - val_loss: 3.5551\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.1106 - val_loss: 4.4744\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 2.5956 - val_loss: 2.5793\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 2.5258 - val_loss: 9.0551\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.7892 - val_loss: 7.0779\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.0790 - val_loss: 2.3811\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.8079 - val_loss: 4.4828\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.6965 - val_loss: 2.1966\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.0281 - val_loss: 3.0019\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.3005 - val_loss: 2.9786\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.2809 - val_loss: 1.0805\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.5754 - val_loss: 15.7555\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.9043 - val_loss: 5.3433\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.2673 - val_loss: 1.3089\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.2822 - val_loss: 4.6253\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.3570 - val_loss: 2.6764\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.0178 - val_loss: 1.1315\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.8848 - val_loss: 3.0166\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.9914 - val_loss: 2.9829\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.9922 - val_loss: 2.3135\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.2268 - val_loss: 1.3900\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.7007 - val_loss: 1.3001\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.8536 - val_loss: 2.3572\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.8409 - val_loss: 1.2296\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.9927 - val_loss: 1.2744\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.0365 - val_loss: 0.7643\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4571 - val_loss: 0.5946\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5002 - val_loss: 1.5695\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.5811 - val_loss: 1.0337\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6478 - val_loss: 0.9289\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6230 - val_loss: 0.8497\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7607 - val_loss: 3.0400\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5731 - val_loss: 0.8279\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6218 - val_loss: 0.8987\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5900 - val_loss: 0.9142\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.0266 - val_loss: 0.6697\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6492 - val_loss: 0.8247\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4545 - val_loss: 0.8345\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4969 - val_loss: 0.6251\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.6087 - val_loss: 2.2950\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.5726 - val_loss: 1.2095\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6260 - val_loss: 0.8743\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6767 - val_loss: 0.8346\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4718 - val_loss: 0.6073\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3498 - val_loss: 0.8995\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6407 - val_loss: 0.5848\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5616 - val_loss: 0.4487\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3457 - val_loss: 0.6324\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.5527 - val_loss: 1.1653\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.6456 - val_loss: 4.3179\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.4529 - val_loss: 0.6221\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.4248 - val_loss: 3.8471\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.6853 - val_loss: 1.6722\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3539 - val_loss: 0.3755\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3053 - val_loss: 0.9444\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3367 - val_loss: 1.1287\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3604 - val_loss: 1.3190\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3542 - val_loss: 1.5422\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.5594 - val_loss: 0.7740\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4664 - val_loss: 2.7265\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3578 - val_loss: 0.7407\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.2717 - val_loss: 0.3294\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3931 - val_loss: 0.8442\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2883 - val_loss: 0.7297\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4157 - val_loss: 1.6275\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.5597 - val_loss: 0.4327\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1621 - val_loss: 0.1096\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1303 - val_loss: 0.3756\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1461 - val_loss: 0.1593\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1511 - val_loss: 0.2101\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1666 - val_loss: 0.2095\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1748 - val_loss: 0.3342\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1969 - val_loss: 0.4363\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4538 - val_loss: 0.8197\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2268 - val_loss: 0.4272\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2042 - val_loss: 0.5185\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.2910 - val_loss: 0.3970\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2921 - val_loss: 0.3094\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 0.3031 - val_loss: 1.8085\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3636 - val_loss: 0.4125\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3138 - val_loss: 0.9964\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2865 - val_loss: 0.3894\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2066 - val_loss: 0.5533\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3413 - val_loss: 1.1194\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4031 - val_loss: 0.6820\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2057 - val_loss: 0.2996\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.2222 - val_loss: 2.8143\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3606 - val_loss: 0.5235\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2538 - val_loss: 0.7904\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2175 - val_loss: 0.5841\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2089 - val_loss: 0.4426\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3075 - val_loss: 0.2256\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2893 - val_loss: 0.2615\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2166 - val_loss: 0.3000\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3122 - val_loss: 0.7605\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2308 - val_loss: 1.5995\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3294 - val_loss: 1.3053\n",
      "16/16 [==============================] - 1s 23ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 0.10956566654962725\n",
      "Mean Absolute Error (MAE): 0.25730733995388916\n",
      "Root Mean Squared Error (RMSE): 0.3310070490935612\n",
      "Time taken: 477.5498580932617\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 18ms/step - loss: 1160.3689 - val_loss: 917.9257\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 917.2889 - val_loss: 867.7362\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 764.1359 - val_loss: 727.8646\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 504.9009 - val_loss: 423.4932\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 343.6136 - val_loss: 350.0199\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 283.3651 - val_loss: 265.7509\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 220.7225 - val_loss: 282.8213\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 125.5363 - val_loss: 88.3847\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 59.9239 - val_loss: 52.0744\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 30.7831 - val_loss: 42.2859\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 18.8433 - val_loss: 17.7818\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.7772 - val_loss: 8.0644\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 6.4331 - val_loss: 57.4192\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.9381 - val_loss: 14.5610\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.9805 - val_loss: 6.9770\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.6554 - val_loss: 11.5125\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.8015 - val_loss: 4.1393\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.6709 - val_loss: 8.1660\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.3796 - val_loss: 8.6388\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.2016 - val_loss: 12.4987\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.5435 - val_loss: 4.2248\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.7606 - val_loss: 7.1672\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.9206 - val_loss: 9.0131\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.9288 - val_loss: 4.4190\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.2935 - val_loss: 7.4193\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.2859 - val_loss: 2.8748\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.2161 - val_loss: 4.8883\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3039 - val_loss: 1.1499\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.4834 - val_loss: 73.1420\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.9081 - val_loss: 1.6672\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.0757 - val_loss: 5.7238\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.1947 - val_loss: 1.1165\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.2922 - val_loss: 4.5820\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.8140 - val_loss: 3.7833\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.9626 - val_loss: 4.6094\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.2116 - val_loss: 2.1826\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8183 - val_loss: 5.8063\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 1.4496 - val_loss: 3.1849\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8923 - val_loss: 3.5240\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8303 - val_loss: 0.8538\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.9014 - val_loss: 2.0387\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7624 - val_loss: 5.7611\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.5996 - val_loss: 1.8929\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.7383 - val_loss: 1.9203\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6610 - val_loss: 0.9319\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.9100 - val_loss: 1.5825\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6017 - val_loss: 1.4026\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6697 - val_loss: 0.8753\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.6004 - val_loss: 2.2241\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.6532 - val_loss: 3.6609\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4794 - val_loss: 0.7280\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4842 - val_loss: 0.8357\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.6163 - val_loss: 0.9783\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6061 - val_loss: 0.7868\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.4243 - val_loss: 0.5832\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8156 - val_loss: 3.2716\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.5292 - val_loss: 1.1776\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3390 - val_loss: 0.4710\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.2847 - val_loss: 0.5360\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.2674 - val_loss: 0.3675\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3341 - val_loss: 0.5762\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4042 - val_loss: 0.4883\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4053 - val_loss: 1.7812\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4378 - val_loss: 0.2979\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5012 - val_loss: 11.2164\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7171 - val_loss: 0.6452\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3207 - val_loss: 0.5697\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3670 - val_loss: 0.3686\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4368 - val_loss: 0.5805\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4364 - val_loss: 0.9008\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4039 - val_loss: 0.4703\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4399 - val_loss: 1.8275\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4567 - val_loss: 0.7408\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3269 - val_loss: 1.0061\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.5162 - val_loss: 1.5087\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4647 - val_loss: 1.4769\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3963 - val_loss: 1.3140\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3410 - val_loss: 0.3942\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4209 - val_loss: 2.3774\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 11ms/step - loss: 0.3505 - val_loss: 0.9504\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3008 - val_loss: 1.2923\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5483 - val_loss: 0.6948\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3052 - val_loss: 1.2028\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3486 - val_loss: 1.3755\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3105 - val_loss: 0.5835\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.3168 - val_loss: 0.6500\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.7568 - val_loss: 18.2714\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.2127 - val_loss: 0.4040\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.1809 - val_loss: 0.2010\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1421 - val_loss: 0.1533\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1264 - val_loss: 0.2609\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1491 - val_loss: 0.2184\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1319 - val_loss: 0.1489\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1731 - val_loss: 0.2188\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1976 - val_loss: 0.2854\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2318 - val_loss: 0.4515\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2834 - val_loss: 0.6563\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3388 - val_loss: 0.2951\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1512 - val_loss: 0.2608\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1735 - val_loss: 0.2351\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2905 - val_loss: 0.9990\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3425 - val_loss: 1.0719\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2909 - val_loss: 0.4782\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2267 - val_loss: 0.5405\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2588 - val_loss: 0.6863\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2945 - val_loss: 0.2124\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2445 - val_loss: 0.2630\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2492 - val_loss: 0.2351\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2488 - val_loss: 1.3529\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3118 - val_loss: 0.7058\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.2030 - val_loss: 0.2693\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2426 - val_loss: 0.3514\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2545 - val_loss: 0.1620\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.2133 - val_loss: 0.3333\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.1675 - val_loss: 0.2340\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4473 - val_loss: 2.0469\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2660 - val_loss: 0.1621\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1491 - val_loss: 0.4749\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1654 - val_loss: 0.3023\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1215 - val_loss: 0.3538\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2806 - val_loss: 0.5439\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2011 - val_loss: 0.4698\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.2264 - val_loss: 0.2814\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 0.1488765611975856\n",
      "Mean Absolute Error (MAE): 0.2619096813495276\n",
      "Root Mean Squared Error (RMSE): 0.3858452555074192\n",
      "Time taken: 534.3623461723328\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 17ms/step - loss: 1124.4326 - val_loss: 947.6485\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 905.0587 - val_loss: 942.4060\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 774.5081 - val_loss: 641.9899\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 508.0718 - val_loss: 394.3179\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 311.5415 - val_loss: 332.3971\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 174.3062 - val_loss: 146.7723\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 81.0248 - val_loss: 71.6347\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 41.0499 - val_loss: 90.1894\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 20.9031 - val_loss: 30.8442\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 13.4636 - val_loss: 12.7279\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 10.7953 - val_loss: 14.0403\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.4725 - val_loss: 11.2846\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.6476 - val_loss: 7.4108\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.5457 - val_loss: 20.6429\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.4529 - val_loss: 7.7257\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6873 - val_loss: 4.4874\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4680 - val_loss: 3.0619\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4927 - val_loss: 4.7158\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.2513 - val_loss: 8.4816\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.3773 - val_loss: 36.2366\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.5826 - val_loss: 3.4148\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.9175 - val_loss: 3.9729\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.0961 - val_loss: 6.4072\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.0981 - val_loss: 6.3631\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.3206 - val_loss: 18.4466\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.5063 - val_loss: 2.8517\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.3874 - val_loss: 7.2126\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.2528 - val_loss: 6.4842\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.6941 - val_loss: 3.8242\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.0812 - val_loss: 2.9320\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.5043 - val_loss: 1.5181\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8687 - val_loss: 1.1832\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6338 - val_loss: 3.3440\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.3509 - val_loss: 3.7156\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.8919 - val_loss: 1.6974\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8800 - val_loss: 1.6139\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.4285 - val_loss: 6.8630\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.9233 - val_loss: 0.8033\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 1.0917 - val_loss: 2.0859\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6677 - val_loss: 1.4846\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.7595 - val_loss: 3.3891\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.0229 - val_loss: 3.2411\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.0998 - val_loss: 1.2241\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7202 - val_loss: 22.2728\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7196 - val_loss: 2.3580\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.4403 - val_loss: 0.4015\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4400 - val_loss: 0.4136\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3895 - val_loss: 0.8075\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7866 - val_loss: 0.5914\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8616 - val_loss: 1.7059\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.7185 - val_loss: 0.8651\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5403 - val_loss: 1.6356\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.4553 - val_loss: 0.9228\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4619 - val_loss: 12.5745\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8113 - val_loss: 1.6318\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6512 - val_loss: 1.4410\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.5352 - val_loss: 1.6233\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5183 - val_loss: 0.6730\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3905 - val_loss: 0.4941\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3692 - val_loss: 1.1551\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8536 - val_loss: 1.7250\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4611 - val_loss: 1.5938\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.5354 - val_loss: 0.7919\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4536 - val_loss: 0.6941\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.6443 - val_loss: 0.9538\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3928 - val_loss: 2.2935\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3517 - val_loss: 0.3660\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4468 - val_loss: 2.4484\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4533 - val_loss: 0.9597\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.6815 - val_loss: 1.0398\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.3204 - val_loss: 0.3388\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.3278 - val_loss: 0.5077\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.4730 - val_loss: 0.7768\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.5400 - val_loss: 1.9655\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3871 - val_loss: 0.6761\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3502 - val_loss: 0.9184\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3369 - val_loss: 0.6153\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3188 - val_loss: 1.2047\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5448 - val_loss: 5.9602\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3405 - val_loss: 0.1793\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2434 - val_loss: 0.8214\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4002 - val_loss: 1.1580\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3923 - val_loss: 0.3399\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2780 - val_loss: 0.3881\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2847 - val_loss: 1.8203\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.4116 - val_loss: 0.5380\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3180 - val_loss: 2.3710\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2920 - val_loss: 6.6282\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2873 - val_loss: 0.2147\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2710 - val_loss: 0.4048\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3840 - val_loss: 1.1314\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3441 - val_loss: 0.2607\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2485 - val_loss: 0.7202\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3072 - val_loss: 0.4803\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2217 - val_loss: 0.4049\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3226 - val_loss: 0.7051\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4200 - val_loss: 2.4274\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1878 - val_loss: 0.4219\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2165 - val_loss: 0.3968\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2270 - val_loss: 0.6263\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2093 - val_loss: 0.2727\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.6607 - val_loss: 0.7441\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2201 - val_loss: 0.1753\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.1365 - val_loss: 0.2079\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.1265 - val_loss: 0.1420\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1270 - val_loss: 0.2889\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1528 - val_loss: 0.2426\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.1232 - val_loss: 0.2311\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1720 - val_loss: 0.3591\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.1783 - val_loss: 0.2935\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2301 - val_loss: 0.3095\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3719 - val_loss: 0.2049\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2021 - val_loss: 0.2328\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1195 - val_loss: 0.2410\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1482 - val_loss: 0.6275\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2689 - val_loss: 1.2152\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2511 - val_loss: 0.4928\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2301 - val_loss: 0.3890\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1821 - val_loss: 0.5326\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1949 - val_loss: 0.4761\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2402 - val_loss: 0.3368\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1996 - val_loss: 0.3053\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1643 - val_loss: 0.4723\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3314 - val_loss: 0.8273\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2171 - val_loss: 0.2659\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.1613 - val_loss: 0.3518\n",
      "Epoch 127/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2047 - val_loss: 0.2503\n",
      "Epoch 128/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.1517 - val_loss: 0.4412\n",
      "Epoch 129/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.2314 - val_loss: 0.5041\n",
      "Epoch 130/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2185 - val_loss: 1.3929\n",
      "Epoch 131/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.1226 - val_loss: 0.3482\n",
      "Epoch 132/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2018 - val_loss: 0.3663\n",
      "Epoch 133/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2502 - val_loss: 0.5327\n",
      "Epoch 134/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2676 - val_loss: 0.8840\n",
      "Epoch 135/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.1799 - val_loss: 0.1817\n",
      "16/16 [==============================] - 1s 26ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 0.14199920327273186\n",
      "Mean Absolute Error (MAE): 0.2813582781272143\n",
      "Root Mean Squared Error (RMSE): 0.376827816479532\n",
      "Time taken: 586.7103183269501\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 16ms/step - loss: 1119.8323 - val_loss: 941.2567\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 918.2227 - val_loss: 931.5672\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 877.7278 - val_loss: 882.4258\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 540.1524 - val_loss: 442.0761\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 333.3921 - val_loss: 338.9790\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 244.3887 - val_loss: 219.8929\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 138.4659 - val_loss: 95.2759\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 66.3326 - val_loss: 52.6680\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 31.9794 - val_loss: 24.6119\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 16.2002 - val_loss: 71.8832\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 9.9862 - val_loss: 12.9140\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 7.1436 - val_loss: 5.4126\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.3317 - val_loss: 10.5242\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.1232 - val_loss: 2.8389\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.1588 - val_loss: 3.1827\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.7211 - val_loss: 6.6765\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.0637 - val_loss: 3.2271\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.3737 - val_loss: 2.8612\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 2.3091 - val_loss: 2.0382\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.7771 - val_loss: 4.4294\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.5210 - val_loss: 6.4383\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.3291 - val_loss: 3.6764\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.4205 - val_loss: 4.2706\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.5962 - val_loss: 3.6808\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.7040 - val_loss: 3.3311\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.2562 - val_loss: 2.0802\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.2873 - val_loss: 53.4675\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.2487 - val_loss: 1.9268\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.0281 - val_loss: 4.3365\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8840 - val_loss: 2.8757\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8631 - val_loss: 2.1009\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.3757 - val_loss: 2.8867\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 1.2261 - val_loss: 1.1475\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.8219 - val_loss: 1.8221\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.4540 - val_loss: 1.3946\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.9218 - val_loss: 1.0497\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.8284 - val_loss: 14.2012\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.7485 - val_loss: 0.8528\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.6535 - val_loss: 1.0682\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.5799 - val_loss: 0.5909\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.8093 - val_loss: 0.8514\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.6260 - val_loss: 2.5211\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.6705 - val_loss: 2.5898\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.7240 - val_loss: 1.5509\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.9449 - val_loss: 5.7166\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5734 - val_loss: 0.4469\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7350 - val_loss: 1.9576\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.5981 - val_loss: 0.9300\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5981 - val_loss: 0.9452\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.9564 - val_loss: 0.6630\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4629 - val_loss: 0.7525\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.4619 - val_loss: 0.5388\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5608 - val_loss: 1.1349\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.9378 - val_loss: 0.7517\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5148 - val_loss: 1.3536\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5371 - val_loss: 0.5997\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4888 - val_loss: 1.3846\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.8521 - val_loss: 3.9947\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7326 - val_loss: 0.8810\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4729 - val_loss: 0.7501\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4630 - val_loss: 1.0802\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6486 - val_loss: 0.4175\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8393 - val_loss: 6.3904\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.8604 - val_loss: 0.5371\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.2777 - val_loss: 0.5941\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2824 - val_loss: 0.3881\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2440 - val_loss: 0.3517\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2291 - val_loss: 0.3569\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3006 - val_loss: 0.6652\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.5337 - val_loss: 0.3713\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3125 - val_loss: 0.2840\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2466 - val_loss: 0.9437\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6630 - val_loss: 2.1029\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.5627 - val_loss: 0.4200\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3042 - val_loss: 0.8812\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3712 - val_loss: 0.9058\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3620 - val_loss: 1.2222\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6422 - val_loss: 1.4189\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3448 - val_loss: 0.5624\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3397 - val_loss: 0.8003\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2874 - val_loss: 0.4361\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3415 - val_loss: 1.0480\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4561 - val_loss: 1.0362\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3588 - val_loss: 0.1904\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3549 - val_loss: 0.4932\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4203 - val_loss: 0.8065\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3087 - val_loss: 1.2086\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5447 - val_loss: 0.6582\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3032 - val_loss: 0.7613\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2742 - val_loss: 0.5824\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3872 - val_loss: 1.7593\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.2898 - val_loss: 0.4167\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3978 - val_loss: 0.5972\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3497 - val_loss: 0.7532\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4231 - val_loss: 0.4132\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.2158 - val_loss: 0.4012\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2955 - val_loss: 0.4222\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4277 - val_loss: 1.2789\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3290 - val_loss: 0.4512\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2961 - val_loss: 0.2319\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1767 - val_loss: 1.1050\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2767 - val_loss: 0.3142\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.5243 - val_loss: 1.0391\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2435 - val_loss: 0.2404\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1984 - val_loss: 0.3725\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2144 - val_loss: 1.0128\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2661 - val_loss: 2.0761\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3372 - val_loss: 0.3594\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.2990 - val_loss: 0.4147\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2051 - val_loss: 2.0118\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2610 - val_loss: 0.5231\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2423 - val_loss: 0.9163\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2775 - val_loss: 0.4635\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2670 - val_loss: 1.0846\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 0.1904020394046445\n",
      "Mean Absolute Error (MAE): 0.32611239138212\n",
      "Root Mean Squared Error (RMSE): 0.4363508214781365\n",
      "Time taken: 501.57445645332336\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 15ms/step - loss: 1147.8811 - val_loss: 933.6832\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 921.3383 - val_loss: 924.2318\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 913.3338 - val_loss: 905.2990\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 770.9476 - val_loss: 601.6312\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 410.1722 - val_loss: 278.2149\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 176.0615 - val_loss: 127.0403\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 70.4197 - val_loss: 68.3490\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 29.6860 - val_loss: 25.7838\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 14.4019 - val_loss: 12.8264\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.1382 - val_loss: 17.3877\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.8337 - val_loss: 16.9175\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.2150 - val_loss: 4.8903\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.0159 - val_loss: 2.8939\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.5795 - val_loss: 3.2954\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.9997 - val_loss: 3.6530\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.4807 - val_loss: 16.8966\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.0831 - val_loss: 3.5820\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.9715 - val_loss: 3.6353\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.7483 - val_loss: 3.0253\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.6518 - val_loss: 6.7421\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.5390 - val_loss: 3.4709\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.4981 - val_loss: 4.3893\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.6083 - val_loss: 4.2976\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.0712 - val_loss: 1.8323\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.6471 - val_loss: 10.1758\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8737 - val_loss: 0.7587\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.9317 - val_loss: 2.3935\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.9733 - val_loss: 1.3292\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.0742 - val_loss: 0.8875\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.6946 - val_loss: 1.2935\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6358 - val_loss: 0.9062\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4865 - val_loss: 0.6250\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7121 - val_loss: 1.0000\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.7211 - val_loss: 1.6944\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.6185 - val_loss: 1.2248\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.8381 - val_loss: 1.1923\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.7260 - val_loss: 1.0440\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5635 - val_loss: 0.8027\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.7421 - val_loss: 1.8867\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.0039 - val_loss: 1.6047\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6645 - val_loss: 1.6173\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.7766 - val_loss: 1.1015\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6429 - val_loss: 0.6946\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.7492 - val_loss: 0.9429\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.0298 - val_loss: 3.0743\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5348 - val_loss: 0.5362\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4548 - val_loss: 1.1298\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5825 - val_loss: 1.0006\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.0761 - val_loss: 2.5439\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3973 - val_loss: 0.4935\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4577 - val_loss: 0.9413\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5753 - val_loss: 1.1728\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4770 - val_loss: 0.8307\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.6162 - val_loss: 0.4240\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4305 - val_loss: 0.5271\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 1.2220 - val_loss: 3.7408\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4196 - val_loss: 0.3425\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3865 - val_loss: 1.0163\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3983 - val_loss: 0.6522\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.3640 - val_loss: 0.5182\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4088 - val_loss: 0.6732\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.4261 - val_loss: 0.4728\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4116 - val_loss: 1.0622\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.6088 - val_loss: 0.9207\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4130 - val_loss: 0.8156\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.4162 - val_loss: 0.5165\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3283 - val_loss: 0.5531\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.5410 - val_loss: 0.5363\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3692 - val_loss: 1.0061\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3797 - val_loss: 0.9105\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3667 - val_loss: 1.4060\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3076 - val_loss: 1.6567\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4263 - val_loss: 0.8414\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4235 - val_loss: 1.1121\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.4429 - val_loss: 0.2978\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3457 - val_loss: 0.5482\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3630 - val_loss: 2.9574\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4252 - val_loss: 0.3046\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2847 - val_loss: 0.4431\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 12ms/step - loss: 0.3812 - val_loss: 0.3953\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2122 - val_loss: 0.3389\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.4569 - val_loss: 0.8321\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3337 - val_loss: 0.5165\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.2392 - val_loss: 0.7281\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3232 - val_loss: 0.5406\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2438 - val_loss: 0.4543\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.1166 - val_loss: 1.2485\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2011 - val_loss: 0.1881\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.1360 - val_loss: 0.1259\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.1065 - val_loss: 0.1826\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.1030 - val_loss: 0.1870\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.1408 - val_loss: 0.1740\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.1348 - val_loss: 0.1274\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2343 - val_loss: 0.3818\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2414 - val_loss: 0.2202\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2144 - val_loss: 0.7857\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3202 - val_loss: 0.1959\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.1838 - val_loss: 0.2943\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2289 - val_loss: 0.7208\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3168 - val_loss: 2.1266\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.3472 - val_loss: 0.4512\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3248 - val_loss: 1.2470\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2435 - val_loss: 0.1713\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2185 - val_loss: 0.6570\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2800 - val_loss: 0.4174\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1875 - val_loss: 0.6248\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2943 - val_loss: 0.5393\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2362 - val_loss: 0.4070\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2396 - val_loss: 0.3404\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.3039 - val_loss: 0.5785\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2053 - val_loss: 0.2240\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.2550 - val_loss: 0.6375\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2045 - val_loss: 0.3607\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.2684 - val_loss: 0.4143\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1886 - val_loss: 0.2589\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 0.2724 - val_loss: 0.5689\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.2319 - val_loss: 0.4503\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.1496 - val_loss: 0.5581\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 0.2344 - val_loss: 0.3226\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 0.12594510417321278\n",
      "Mean Absolute Error (MAE): 0.2613892550067384\n",
      "Root Mean Squared Error (RMSE): 0.35488745282583994\n",
      "Time taken: 511.5631139278412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=6,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 32, 512)           1052672   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 512)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 32, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,047,747\n",
      "Trainable params: 2,046,723\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_10788\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold       MSE       MAE      RMSE  Time taken\n",
      "0        1  0.109566  0.257307  0.331007  477.549858\n",
      "1        2  0.148877  0.261910  0.385845  534.362346\n",
      "2        3  0.141999  0.281358  0.376828  586.710318\n",
      "3        4  0.190402  0.326112  0.436351  501.574456\n",
      "4        5  0.125945  0.261389  0.354887  511.563114\n",
      "5  Average  0.143358  0.277615  0.376984  522.352019\n",
      "Results saved to 'Sensors 32_PL_model_2_smoothing2_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('Sensors 32_PL_model_2_smoothing2_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'Sensors 32_PL_model_2_smoothing2_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
