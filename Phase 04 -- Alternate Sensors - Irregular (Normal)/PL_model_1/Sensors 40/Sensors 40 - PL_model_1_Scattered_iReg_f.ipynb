{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "              6           7           8           9   ...         38  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "              39         40         41          42          43          44  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "              45          46          47  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...   sensor39  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "        sensor40   sensor41   sensor42    sensor43    sensor44    sensor45  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe88f5b",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fad6410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor31</th>\n",
       "      <th>sensor32</th>\n",
       "      <th>sensor33</th>\n",
       "      <th>sensor34</th>\n",
       "      <th>sensor35</th>\n",
       "      <th>sensor36</th>\n",
       "      <th>sensor37</th>\n",
       "      <th>sensor38</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>102.762255</td>\n",
       "      <td>114.447460</td>\n",
       "      <td>93.832218</td>\n",
       "      <td>103.040549</td>\n",
       "      <td>72.897176</td>\n",
       "      <td>93.429638</td>\n",
       "      <td>101.154085</td>\n",
       "      <td>88.854896</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>99.323340</td>\n",
       "      <td>120.554118</td>\n",
       "      <td>85.636480</td>\n",
       "      <td>111.479687</td>\n",
       "      <td>55.839311</td>\n",
       "      <td>97.703942</td>\n",
       "      <td>100.285399</td>\n",
       "      <td>80.851679</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>90.319502</td>\n",
       "      <td>110.650880</td>\n",
       "      <td>92.704267</td>\n",
       "      <td>119.222086</td>\n",
       "      <td>61.900815</td>\n",
       "      <td>95.703549</td>\n",
       "      <td>102.251326</td>\n",
       "      <td>77.020662</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>89.159566</td>\n",
       "      <td>112.068859</td>\n",
       "      <td>95.584025</td>\n",
       "      <td>97.331801</td>\n",
       "      <td>65.975278</td>\n",
       "      <td>96.274919</td>\n",
       "      <td>100.740244</td>\n",
       "      <td>80.774870</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>97.218949</td>\n",
       "      <td>119.727171</td>\n",
       "      <td>102.472627</td>\n",
       "      <td>106.593340</td>\n",
       "      <td>65.984974</td>\n",
       "      <td>91.674780</td>\n",
       "      <td>98.358506</td>\n",
       "      <td>81.000998</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>114.478872</td>\n",
       "      <td>111.426888</td>\n",
       "      <td>63.270079</td>\n",
       "      <td>105.819624</td>\n",
       "      <td>89.369660</td>\n",
       "      <td>93.156371</td>\n",
       "      <td>99.435010</td>\n",
       "      <td>61.900941</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>124.608772</td>\n",
       "      <td>111.535307</td>\n",
       "      <td>63.682781</td>\n",
       "      <td>98.221437</td>\n",
       "      <td>77.762117</td>\n",
       "      <td>99.594948</td>\n",
       "      <td>108.159696</td>\n",
       "      <td>69.627962</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>114.616802</td>\n",
       "      <td>105.551149</td>\n",
       "      <td>68.655660</td>\n",
       "      <td>102.265662</td>\n",
       "      <td>92.982414</td>\n",
       "      <td>93.985207</td>\n",
       "      <td>104.171206</td>\n",
       "      <td>67.329323</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>121.333353</td>\n",
       "      <td>108.467974</td>\n",
       "      <td>62.921062</td>\n",
       "      <td>96.758944</td>\n",
       "      <td>86.241896</td>\n",
       "      <td>95.671903</td>\n",
       "      <td>106.824081</td>\n",
       "      <td>69.005989</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>118.065500</td>\n",
       "      <td>111.120071</td>\n",
       "      <td>72.573362</td>\n",
       "      <td>98.568498</td>\n",
       "      <td>94.853881</td>\n",
       "      <td>96.838632</td>\n",
       "      <td>108.668059</td>\n",
       "      <td>63.155241</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor31  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  102.762255   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...   99.323340   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...   90.319502   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...   89.159566   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...   97.218949   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  114.478872   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  124.608772   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  114.616802   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  121.333353   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  118.065500   \n",
       "\n",
       "        sensor32    sensor33    sensor34   sensor35   sensor36    sensor37  \\\n",
       "0     114.447460   93.832218  103.040549  72.897176  93.429638  101.154085   \n",
       "1     120.554118   85.636480  111.479687  55.839311  97.703942  100.285399   \n",
       "2     110.650880   92.704267  119.222086  61.900815  95.703549  102.251326   \n",
       "3     112.068859   95.584025   97.331801  65.975278  96.274919  100.740244   \n",
       "4     119.727171  102.472627  106.593340  65.984974  91.674780   98.358506   \n",
       "...          ...         ...         ...        ...        ...         ...   \n",
       "2438  111.426888   63.270079  105.819624  89.369660  93.156371   99.435010   \n",
       "2439  111.535307   63.682781   98.221437  77.762117  99.594948  108.159696   \n",
       "2440  105.551149   68.655660  102.265662  92.982414  93.985207  104.171206   \n",
       "2441  108.467974   62.921062   96.758944  86.241896  95.671903  106.824081   \n",
       "2442  111.120071   72.573362   98.568498  94.853881  96.838632  108.668059   \n",
       "\n",
       "       sensor38   sensor39    sensor40  \n",
       "0     88.854896  81.685404   84.830110  \n",
       "1     80.851679  81.526583   92.908051  \n",
       "2     77.020662  75.930487   82.432658  \n",
       "3     80.774870  79.984057   99.957787  \n",
       "4     81.000998  75.279364   87.349475  \n",
       "...         ...        ...         ...  \n",
       "2438  61.900941  91.496394  121.729389  \n",
       "2439  69.627962  92.880258  108.747017  \n",
       "2440  67.329323  89.648431  106.485343  \n",
       "2441  69.005989  86.126272  106.959002  \n",
       "2442  63.155241  88.589209  107.322913  \n",
       "\n",
       "[2443 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:40]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 15s 20ms/step - loss: 1148.9573 - val_loss: 962.4013\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 914.1257 - val_loss: 945.2389\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 818.9841 - val_loss: 775.8799\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 543.7929 - val_loss: 525.2297\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 358.4041 - val_loss: 364.1758\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 227.6391 - val_loss: 164.4707\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 120.5114 - val_loss: 91.0780\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 65.9909 - val_loss: 48.6224\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 41.8540 - val_loss: 26.1389\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 28.0196 - val_loss: 24.4310\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 21.9581 - val_loss: 30.5139\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 19.2956 - val_loss: 29.4479\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 15.7929 - val_loss: 25.2973\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 15.5602 - val_loss: 14.5813\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 14.8966 - val_loss: 21.2297\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 13.1878 - val_loss: 16.6070\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 11.7216 - val_loss: 13.4407\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 10.5428 - val_loss: 13.3423\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 10.4203 - val_loss: 11.6261\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 8.1671 - val_loss: 9.4076\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 9.5904 - val_loss: 8.3701\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 8.9563 - val_loss: 9.0946\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.6896 - val_loss: 10.0040\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.4883 - val_loss: 9.9640\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 8.4560 - val_loss: 10.4978\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.2148 - val_loss: 9.1744\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 7.8469 - val_loss: 28.7734\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.5959 - val_loss: 8.7949\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 8.4292 - val_loss: 15.3778\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.8565 - val_loss: 7.1917\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.1041 - val_loss: 6.2595\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.6448 - val_loss: 8.0330\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.7333 - val_loss: 8.7111\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.3040 - val_loss: 8.2356\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.6465 - val_loss: 6.2131\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.6171 - val_loss: 6.9407\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 5.6645 - val_loss: 10.7744\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 5.0584 - val_loss: 11.1556\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 6.0045 - val_loss: 10.6472\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 4.8780 - val_loss: 6.8323\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 4.7960 - val_loss: 5.9873\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 6.7723 - val_loss: 11.1503\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.8039 - val_loss: 9.2688\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.7361 - val_loss: 6.4945\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.3366 - val_loss: 6.5129\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2952 - val_loss: 6.2328\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.6535 - val_loss: 17.2710\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 6s 17ms/step - loss: 4.2628 - val_loss: 7.7525\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.8640 - val_loss: 10.8250\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.8721 - val_loss: 5.3751\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.6527 - val_loss: 8.4991\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 6s 17ms/step - loss: 4.1601 - val_loss: 5.3229\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 6s 18ms/step - loss: 4.2822 - val_loss: 5.6814\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 6s 18ms/step - loss: 4.0784 - val_loss: 7.3423\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.6914 - val_loss: 7.0084\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.7150 - val_loss: 7.3713\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.9338 - val_loss: 8.3002\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.9235 - val_loss: 6.3688\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.5973 - val_loss: 6.4386\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.8042 - val_loss: 10.2332\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 6.9366 - val_loss: 6.5174\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.7831 - val_loss: 5.4944\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 17ms/step - loss: 3.6295 - val_loss: 5.7084\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.1694 - val_loss: 5.7190\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.3274 - val_loss: 5.7235\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.4689 - val_loss: 6.2161\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.2068 - val_loss: 5.9684\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.2717 - val_loss: 4.7766\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.2198 - val_loss: 4.9517\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.6940 - val_loss: 5.4270\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.0505 - val_loss: 7.5483\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.0565 - val_loss: 5.0505\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.9198 - val_loss: 8.1707\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.2155 - val_loss: 11.8106\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.7219 - val_loss: 5.5396\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.5012 - val_loss: 5.1746\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.4671 - val_loss: 5.5093\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.6288 - val_loss: 4.9214\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.6906 - val_loss: 4.6557\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 5s 14ms/step - loss: 2.7189 - val_loss: 6.3060\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.3976 - val_loss: 9.7270\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7123 - val_loss: 8.3153\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.3849 - val_loss: 5.0689\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4345 - val_loss: 5.2116\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7126 - val_loss: 5.1300\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.5219 - val_loss: 6.4532\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.2814 - val_loss: 5.3549\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.6527 - val_loss: 6.4658\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.1730 - val_loss: 5.4600\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7256 - val_loss: 5.1382\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.0585 - val_loss: 6.7156\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.9264 - val_loss: 8.4685\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.2362 - val_loss: 5.1442\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.0513 - val_loss: 5.4837\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.9507 - val_loss: 5.5199\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8763 - val_loss: 6.4814\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.9325 - val_loss: 7.8958\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1851 - val_loss: 5.6624\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8798 - val_loss: 6.8120\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.9984 - val_loss: 5.4532\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.8902 - val_loss: 5.4396\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.7757 - val_loss: 6.0159\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8987 - val_loss: 4.8936\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.4472 - val_loss: 5.5549\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6775 - val_loss: 5.8005\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.7293 - val_loss: 7.0151\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.0229 - val_loss: 6.4012\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.0355 - val_loss: 10.2951\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6098 - val_loss: 5.5353\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 4.656484347271444\n",
      "Mean Absolute Error (MAE): 1.4599590477931879\n",
      "Root Mean Squared Error (RMSE): 2.157888863512541\n",
      "Time taken: 546.8783667087555\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 10s 20ms/step - loss: 1155.9102 - val_loss: 948.2834\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 917.6934 - val_loss: 929.7018\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 836.3073 - val_loss: 835.8727\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 505.6281 - val_loss: 365.4340\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 246.0318 - val_loss: 161.3344\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 114.9948 - val_loss: 86.4902\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 57.7036 - val_loss: 66.3938\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 36.8959 - val_loss: 47.4058\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 26.1549 - val_loss: 30.8503\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 19.8102 - val_loss: 18.9934\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 16.1228 - val_loss: 21.2057\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 15.0173 - val_loss: 16.1557\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 12.6171 - val_loss: 17.9400\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 13.1821 - val_loss: 17.8079\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 11.7821 - val_loss: 15.1653\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 9.8716 - val_loss: 14.0138\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 10.9065 - val_loss: 22.5567\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 9.2448 - val_loss: 19.8773\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 9.8588 - val_loss: 9.9601\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 8.1302 - val_loss: 36.6523\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 8.8476 - val_loss: 12.7750\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.4435 - val_loss: 23.2112\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 8.3921 - val_loss: 12.2348\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 7.5510 - val_loss: 9.1691\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 7.3383 - val_loss: 9.6902\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 6.5937 - val_loss: 13.3550\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 7.9661 - val_loss: 27.9913\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 6.3426 - val_loss: 7.8282\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.0543 - val_loss: 8.2954\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.7217 - val_loss: 21.1728\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.5093 - val_loss: 10.0235\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.8012 - val_loss: 10.7221\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.6609 - val_loss: 8.4103\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 5.8888 - val_loss: 8.1658\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.1859 - val_loss: 8.1714\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.7380 - val_loss: 7.9021\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 6.4594 - val_loss: 8.2756\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.0632 - val_loss: 8.6506\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.9918 - val_loss: 9.9228\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.5372 - val_loss: 6.2388\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.3511 - val_loss: 11.2069\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.2745 - val_loss: 8.1680\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.0333 - val_loss: 12.8049\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.5599 - val_loss: 8.6125\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.1819 - val_loss: 8.0461\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.5301 - val_loss: 17.1639\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 5.0396 - val_loss: 25.4987\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.3814 - val_loss: 6.0996\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2093 - val_loss: 6.6958\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.6922 - val_loss: 7.2606\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.7195 - val_loss: 6.2136\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.6505 - val_loss: 7.0053\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.9395 - val_loss: 6.8344\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.4773 - val_loss: 7.7679\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.3331 - val_loss: 8.7112\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.0128 - val_loss: 34.1152\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6297 - val_loss: 6.0909\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.2820 - val_loss: 7.0067\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.4101 - val_loss: 6.1918\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.3998 - val_loss: 12.5146\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.1743 - val_loss: 6.9112\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.9048 - val_loss: 6.0049\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.1406 - val_loss: 6.5379\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.8885 - val_loss: 6.4908\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7855 - val_loss: 7.9767\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.2077 - val_loss: 6.8324\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.8080 - val_loss: 7.7955\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2752 - val_loss: 8.5858\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.8295 - val_loss: 9.2316\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.9935 - val_loss: 8.0430\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.6152 - val_loss: 6.1248\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.5724 - val_loss: 5.8814\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.3702 - val_loss: 6.5991\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.3175 - val_loss: 6.7753\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.5272 - val_loss: 8.3274\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.8611 - val_loss: 7.9130\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.9067 - val_loss: 6.6031\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.1414 - val_loss: 6.1692\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.2256 - val_loss: 5.8082\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 5s 15ms/step - loss: 2.0323 - val_loss: 7.0515\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6286 - val_loss: 7.0463\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.8747 - val_loss: 6.9745\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.0807 - val_loss: 6.5510\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1477 - val_loss: 7.9960\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.8744 - val_loss: 5.7871\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.9275 - val_loss: 6.2482\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 1.9790 - val_loss: 6.0240\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.1188 - val_loss: 6.5289\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.4980 - val_loss: 7.9821\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1726 - val_loss: 6.0398\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8774 - val_loss: 8.5120\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.3874 - val_loss: 5.8114\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6781 - val_loss: 5.7922\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.6289 - val_loss: 7.1942\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.7158 - val_loss: 6.5550\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.7529 - val_loss: 6.7256\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.7355 - val_loss: 6.7568\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.9174 - val_loss: 7.2459\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.0607 - val_loss: 7.1377\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.9877 - val_loss: 6.3275\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.5091 - val_loss: 6.6701\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.6679 - val_loss: 6.4853\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.6041 - val_loss: 6.5301\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.7350 - val_loss: 6.5030\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.4537 - val_loss: 8.1522\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3304 - val_loss: 6.2967\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3745 - val_loss: 6.1201\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.4163 - val_loss: 6.7869\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.2582 - val_loss: 6.0210\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.3105 - val_loss: 6.0906\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.4389 - val_loss: 6.4559\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.4815 - val_loss: 6.2336\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3302 - val_loss: 6.5029\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.5350 - val_loss: 6.3588\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.2177 - val_loss: 7.4849\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 5.7890445091100675\n",
      "Mean Absolute Error (MAE): 1.5917303590693044\n",
      "Root Mean Squared Error (RMSE): 2.406043330680075\n",
      "Time taken: 562.2054867744446\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 17ms/step - loss: 1118.8000 - val_loss: 921.2623\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 921.4123 - val_loss: 916.0903\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 893.2620 - val_loss: 854.9004\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 635.2639 - val_loss: 477.1424\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 360.9375 - val_loss: 267.2516\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 183.4521 - val_loss: 132.9764\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 90.0546 - val_loss: 63.0568\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 50.6969 - val_loss: 106.4653\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 33.4438 - val_loss: 41.4820\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 24.4401 - val_loss: 23.6362\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 22.6896 - val_loss: 30.1963\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 18.7706 - val_loss: 21.5837\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 17.0750 - val_loss: 13.4427\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 14.2173 - val_loss: 29.6444\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 13.2844 - val_loss: 27.2315\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 12.2203 - val_loss: 13.5187\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 11.3903 - val_loss: 11.8656\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 10.9255 - val_loss: 17.8063\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 10.9411 - val_loss: 28.2383\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 10.0814 - val_loss: 15.8685\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 8.9684 - val_loss: 22.4251\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 9.2652 - val_loss: 9.2594\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.9604 - val_loss: 8.6361\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.7017 - val_loss: 11.1313\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.7369 - val_loss: 12.6314\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 7.9214 - val_loss: 17.8033\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.6146 - val_loss: 8.4047\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.9372 - val_loss: 9.7798\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 6s 17ms/step - loss: 6.4153 - val_loss: 9.7015\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 7.0532 - val_loss: 10.3545\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.1830 - val_loss: 9.8812\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.3505 - val_loss: 7.2788\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.6650 - val_loss: 20.9504\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.8723 - val_loss: 8.2498\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 6.2512 - val_loss: 59.3633\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 6.1663 - val_loss: 7.5142\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.2655 - val_loss: 7.0548\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.5724 - val_loss: 7.9698\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.7365 - val_loss: 7.4509\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.9282 - val_loss: 7.8677\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.0012 - val_loss: 7.8596\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.9317 - val_loss: 7.7458\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.7798 - val_loss: 9.6100\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.5501 - val_loss: 9.9742\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2461 - val_loss: 7.3267\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.3055 - val_loss: 7.5731\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.5498 - val_loss: 10.9177\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.6027 - val_loss: 7.5368\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.0028 - val_loss: 6.4224\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.7608 - val_loss: 7.8395\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.4394 - val_loss: 12.1662\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.3594 - val_loss: 7.0596\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.1670 - val_loss: 6.9912\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.7871 - val_loss: 9.1145\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.5790 - val_loss: 9.3906\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.4994 - val_loss: 7.3774\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.0372 - val_loss: 6.9993\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.3992 - val_loss: 6.3853\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.3925 - val_loss: 9.1042\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 5s 17ms/step - loss: 3.8334 - val_loss: 6.0948\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.3440 - val_loss: 6.6989\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.1463 - val_loss: 6.4824\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.7189 - val_loss: 8.8294\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.5848 - val_loss: 5.9603\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.3805 - val_loss: 7.9004\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.2989 - val_loss: 6.2815\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.9900 - val_loss: 9.2198\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.9911 - val_loss: 8.4836\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.1637 - val_loss: 8.6756\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.9517 - val_loss: 6.1279\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.8573 - val_loss: 7.5960\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.1586 - val_loss: 14.6500\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.5185 - val_loss: 7.7404\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.6529 - val_loss: 6.2653\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4813 - val_loss: 6.4701\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.4541 - val_loss: 7.7083\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.7247 - val_loss: 6.6554\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.4544 - val_loss: 6.7557\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.9909 - val_loss: 13.7078\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2415 - val_loss: 8.3299\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.7453 - val_loss: 6.9705\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.3231 - val_loss: 8.1243\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.2636 - val_loss: 6.5479\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.8947 - val_loss: 5.9179\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.1963 - val_loss: 6.0940\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.1367 - val_loss: 5.8149\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.1729 - val_loss: 6.1645\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.2228 - val_loss: 11.9814\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7280 - val_loss: 6.5432\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4888 - val_loss: 9.4306\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.8630 - val_loss: 7.1148\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.0527 - val_loss: 7.4636\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.9472 - val_loss: 6.2051\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6740 - val_loss: 5.7724\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8099 - val_loss: 6.5271\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4569 - val_loss: 6.0747\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8158 - val_loss: 5.6530\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8519 - val_loss: 8.9668\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4869 - val_loss: 8.7578\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8346 - val_loss: 6.9030\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8733 - val_loss: 5.4175\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6928 - val_loss: 6.0792\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6935 - val_loss: 6.1320\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6300 - val_loss: 7.6294\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.9419 - val_loss: 5.8101\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 4.0467 - val_loss: 7.0702\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 5s 17ms/step - loss: 1.7437 - val_loss: 5.9096\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3295 - val_loss: 5.6992\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.4057 - val_loss: 5.6148\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.3929 - val_loss: 6.9888\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.4427 - val_loss: 5.9937\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6488 - val_loss: 6.0413\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3648 - val_loss: 6.5452\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.4610 - val_loss: 7.2953\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.5292 - val_loss: 6.9370\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.4330 - val_loss: 7.4135\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.3289 - val_loss: 7.1866\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.3438 - val_loss: 6.6457\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.1179 - val_loss: 6.4113\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.2155 - val_loss: 6.2234\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.4441 - val_loss: 6.3660\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.2866 - val_loss: 6.7223\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.4110 - val_loss: 6.7118\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.2733 - val_loss: 6.7601\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.0579 - val_loss: 6.1078\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.4386 - val_loss: 6.0146\n",
      "Epoch 127/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.9923 - val_loss: 10.0215\n",
      "Epoch 128/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3252 - val_loss: 6.3631\n",
      "Epoch 129/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.1283 - val_loss: 8.8298\n",
      "Epoch 130/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.1319 - val_loss: 5.8044\n",
      "Epoch 131/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 0.9642 - val_loss: 7.6118\n",
      "16/16 [==============================] - 1s 24ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 5.418213680945783\n",
      "Mean Absolute Error (MAE): 1.5736921939421549\n",
      "Root Mean Squared Error (RMSE): 2.3277056688820825\n",
      "Time taken: 644.7891647815704\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 18ms/step - loss: 1125.6111 - val_loss: 914.2477\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 896.3969 - val_loss: 949.6630\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 685.9086 - val_loss: 518.4924\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 392.5470 - val_loss: 331.8405\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 221.0423 - val_loss: 159.1928\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 107.4426 - val_loss: 77.3784\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 63.3647 - val_loss: 90.5813\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 38.4669 - val_loss: 34.2371\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 27.5453 - val_loss: 28.9222\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 22.0884 - val_loss: 27.2425\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 19.6164 - val_loss: 25.1390\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 16.6424 - val_loss: 19.7048\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 15.1357 - val_loss: 16.9956\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 13.4919 - val_loss: 18.7668\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 12.7033 - val_loss: 15.3362\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 13.0547 - val_loss: 17.4555\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 10.5950 - val_loss: 13.3667\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 11.0651 - val_loss: 13.8448\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 9.8954 - val_loss: 13.9459\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 9.9458 - val_loss: 17.8420\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 9.2044 - val_loss: 9.0557\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.5681 - val_loss: 13.2952\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.5213 - val_loss: 15.0167\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.7353 - val_loss: 12.2007\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 7.5835 - val_loss: 14.0514\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 9.4732 - val_loss: 8.9012\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.2746 - val_loss: 10.3324\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.5324 - val_loss: 7.1355\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.2837 - val_loss: 7.7352\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 7.8083 - val_loss: 8.1791\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.8800 - val_loss: 6.4980\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.2825 - val_loss: 9.7008\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 10.1944 - val_loss: 11.4358\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.3851 - val_loss: 6.3987\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.6082 - val_loss: 5.9541\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.9192 - val_loss: 13.3564\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.0290 - val_loss: 6.0073\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.2031 - val_loss: 7.7438\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.1322 - val_loss: 7.2659\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 5.3694 - val_loss: 29.2321\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 5.4704 - val_loss: 8.5903\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.9038 - val_loss: 6.5687\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.4309 - val_loss: 11.2657\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.1912 - val_loss: 6.0798\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.7007 - val_loss: 8.0820\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.5953 - val_loss: 9.9837\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.4109 - val_loss: 6.0821\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.2380 - val_loss: 8.7121\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2868 - val_loss: 6.1237\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.3983 - val_loss: 5.4305\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.8082 - val_loss: 6.6205\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.9230 - val_loss: 7.9824\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2035 - val_loss: 8.5082\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.7859 - val_loss: 5.8673\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.0889 - val_loss: 5.9485\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.8668 - val_loss: 7.5597\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.4475 - val_loss: 5.0498\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.7702 - val_loss: 5.7983\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.0420 - val_loss: 6.2206\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.4587 - val_loss: 8.7565\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.6542 - val_loss: 5.7800\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.4878 - val_loss: 7.8605\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.3380 - val_loss: 5.9436\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.3080 - val_loss: 5.7048\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.1435 - val_loss: 7.3312\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 4.3444 - val_loss: 9.7263\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.8039 - val_loss: 7.0765\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 6s 19ms/step - loss: 3.4103 - val_loss: 9.4920\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.9276 - val_loss: 6.0321\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.1433 - val_loss: 5.5267\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.0374 - val_loss: 6.0189\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.5888 - val_loss: 5.6301\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.2316 - val_loss: 5.4929\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7763 - val_loss: 6.9206\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.9034 - val_loss: 6.3824\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.7748 - val_loss: 6.9166\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.6194 - val_loss: 6.2150\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7748 - val_loss: 7.6319\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.6339 - val_loss: 7.3054\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 5s 14ms/step - loss: 3.4771 - val_loss: 5.4722\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.4200 - val_loss: 12.4329\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.6045 - val_loss: 5.6838\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.6919 - val_loss: 5.9770\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.4175 - val_loss: 5.7778\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.1184 - val_loss: 4.9073\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.3290 - val_loss: 5.2828\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7021 - val_loss: 6.1515\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.1508 - val_loss: 7.1298\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.1184 - val_loss: 5.7619\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.2237 - val_loss: 5.1578\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.1415 - val_loss: 5.3645\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1243 - val_loss: 5.2838\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.0256 - val_loss: 5.9037\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1769 - val_loss: 8.4892\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1812 - val_loss: 5.7693\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.5328 - val_loss: 5.7171\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.0661 - val_loss: 6.0806\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1298 - val_loss: 6.4846\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1824 - val_loss: 7.1429\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.9643 - val_loss: 5.5889\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.0694 - val_loss: 5.1087\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.3724 - val_loss: 7.7676\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7451 - val_loss: 5.4722\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.0600 - val_loss: 5.1472\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8906 - val_loss: 6.3263\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.7201 - val_loss: 6.7291\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.9675 - val_loss: 5.5943\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.7236 - val_loss: 5.8016\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.5328 - val_loss: 5.3046\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.7035 - val_loss: 6.0936\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.7938 - val_loss: 6.6622\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.0089 - val_loss: 15.3817\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.3929 - val_loss: 16.7044\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.5225 - val_loss: 6.6212\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.7485 - val_loss: 4.9882\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 4.907657909631673\n",
      "Mean Absolute Error (MAE): 1.4755994046405094\n",
      "Root Mean Squared Error (RMSE): 2.2153234322851536\n",
      "Time taken: 564.4559979438782\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 10s 18ms/step - loss: 1132.8497 - val_loss: 914.7222\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 909.9250 - val_loss: 862.3037\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 631.5991 - val_loss: 436.4558\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 325.4047 - val_loss: 261.4233\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 164.5618 - val_loss: 118.3633\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 83.8053 - val_loss: 65.2833\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 46.9293 - val_loss: 35.7425\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 32.0335 - val_loss: 32.8859\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 27.3784 - val_loss: 32.4320\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 20.7042 - val_loss: 25.6558\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 19.1816 - val_loss: 16.9768\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 16.2347 - val_loss: 18.8286\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 14.8555 - val_loss: 42.1666\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 15.2114 - val_loss: 14.9385\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 13.5543 - val_loss: 17.8114\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 11.2856 - val_loss: 12.1518\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 11.6612 - val_loss: 11.0096\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 10.7430 - val_loss: 11.3925\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 9.5004 - val_loss: 20.7377\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 11.7159 - val_loss: 11.4074\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 9.4738 - val_loss: 15.7531\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.4901 - val_loss: 14.0443\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 8.5756 - val_loss: 9.7834\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 9.2111 - val_loss: 9.2319\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.1516 - val_loss: 8.3098\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 8.1495 - val_loss: 28.7155\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.5230 - val_loss: 23.0918\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 7.5535 - val_loss: 8.0006\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 7.1508 - val_loss: 48.3216\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.3208 - val_loss: 10.6162\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 6.0469 - val_loss: 9.9580\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.9105 - val_loss: 17.6461\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.6024 - val_loss: 7.4974\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.7721 - val_loss: 7.4325\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.7327 - val_loss: 12.9880\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.4428 - val_loss: 9.3457\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.9524 - val_loss: 8.6681\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.7778 - val_loss: 6.8137\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.2385 - val_loss: 9.5922\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 5.4258 - val_loss: 7.0951\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.2218 - val_loss: 8.2644\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.0934 - val_loss: 97.7375\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.8703 - val_loss: 6.5976\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.8776 - val_loss: 5.8670\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.6630 - val_loss: 10.6572\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.1601 - val_loss: 11.2385\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 5.2828 - val_loss: 8.2578\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 4.7229 - val_loss: 10.5423\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 4.5145 - val_loss: 6.6870\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.3443 - val_loss: 7.5792\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.4267 - val_loss: 6.1462\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.5080 - val_loss: 6.8792\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.6960 - val_loss: 7.6259\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.0278 - val_loss: 8.9673\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.5266 - val_loss: 6.1799\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.9657 - val_loss: 7.2879\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2763 - val_loss: 7.2377\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.5238 - val_loss: 7.1537\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.4371 - val_loss: 12.2433\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.0874 - val_loss: 10.3694\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.8791 - val_loss: 7.1510\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6820 - val_loss: 10.2160\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.7443 - val_loss: 6.0448\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6903 - val_loss: 9.1730\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6464 - val_loss: 6.3342\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.7688 - val_loss: 6.3259\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.9634 - val_loss: 6.6375\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6148 - val_loss: 7.4008\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.1929 - val_loss: 6.8060\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.4212 - val_loss: 7.5201\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.3423 - val_loss: 5.5601\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.0628 - val_loss: 5.5328\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.4183 - val_loss: 8.1523\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 3.3797 - val_loss: 6.5272\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.2553 - val_loss: 7.6593\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.1126 - val_loss: 5.7559\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.9991 - val_loss: 17.7129\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2093 - val_loss: 6.5953\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.8368 - val_loss: 6.0136\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 5s 16ms/step - loss: 3.7379 - val_loss: 7.6513\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.1602 - val_loss: 8.2155\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.6722 - val_loss: 7.1289\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.0687 - val_loss: 5.6251\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.8224 - val_loss: 5.3082\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.5682 - val_loss: 5.8826\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4028 - val_loss: 5.8250\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.5016 - val_loss: 7.2770\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.0894 - val_loss: 9.5020\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.4300 - val_loss: 11.2760\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.7484 - val_loss: 6.3341\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.3176 - val_loss: 5.1475\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.1948 - val_loss: 5.4503\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.4833 - val_loss: 5.5726\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.3835 - val_loss: 5.6768\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.9213 - val_loss: 5.8255\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.4364 - val_loss: 6.9202\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.2215 - val_loss: 9.2029\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.2402 - val_loss: 4.9457\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.2276 - val_loss: 5.3330\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.9125 - val_loss: 6.9246\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1699 - val_loss: 5.2550\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.0131 - val_loss: 6.7435\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.1649 - val_loss: 7.5619\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.1291 - val_loss: 6.0333\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.2439 - val_loss: 5.9009\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8311 - val_loss: 5.5368\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.8515 - val_loss: 5.4647\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.8703 - val_loss: 5.7996\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.3465 - val_loss: 5.3382\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.8835 - val_loss: 7.2140\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.8592 - val_loss: 5.7648\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.7893 - val_loss: 6.0030\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6186 - val_loss: 6.0120\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.7986 - val_loss: 5.1332\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.7072 - val_loss: 5.7302\n",
      "Epoch 116/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.7321 - val_loss: 5.6064\n",
      "Epoch 117/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 1.6690 - val_loss: 6.3092\n",
      "Epoch 118/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.6959 - val_loss: 6.2954\n",
      "Epoch 119/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6289 - val_loss: 6.0034\n",
      "Epoch 120/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.6676 - val_loss: 6.3270\n",
      "Epoch 121/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.5706 - val_loss: 5.7453\n",
      "Epoch 122/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7019 - val_loss: 75.2806\n",
      "Epoch 123/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 4.6885 - val_loss: 5.0496\n",
      "Epoch 124/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.4355 - val_loss: 5.5705\n",
      "Epoch 125/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3888 - val_loss: 6.4394\n",
      "Epoch 126/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.3012 - val_loss: 5.2548\n",
      "Epoch 127/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 1.2801 - val_loss: 6.3190\n",
      "Epoch 128/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 1.2819 - val_loss: 5.6490\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 4.946657090225892\n",
      "Mean Absolute Error (MAE): 1.486072046509988\n",
      "Root Mean Squared Error (RMSE): 2.224108156143916\n",
      "Time taken: 626.7292358875275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=6,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 40, 512)           1052672   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 40, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 40, 512)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 40, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,047,747\n",
      "Trainable params: 2,046,723\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_4880\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold       MSE       MAE      RMSE  Time taken\n",
      "0        1  4.656484  1.459959  2.157889  546.878367\n",
      "1        2  5.789045  1.591730  2.406043  562.205487\n",
      "2        3  5.418214  1.573692  2.327706  644.789165\n",
      "3        4  4.907658  1.475599  2.215323  564.455998\n",
      "4        5  4.946657  1.486072  2.224108  626.729236\n",
      "5  Average  5.143612  1.517411  2.266214  589.011650\n",
      "Results saved to 'Sensors 40_PL_model_1_Scattered_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('Sensors 40_PL_model_1_Scattered_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'Sensors 40_PL_model_1_Scattered_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
