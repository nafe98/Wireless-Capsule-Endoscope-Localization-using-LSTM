{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "              6           7           8           9   ...         38  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "              39         40         41          42          43          44  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "              45          46          47  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...   sensor39  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "        sensor40   sensor41   sensor42    sensor43    sensor44    sensor45  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe88f5b",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fad6410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor23</th>\n",
       "      <th>sensor24</th>\n",
       "      <th>sensor25</th>\n",
       "      <th>sensor26</th>\n",
       "      <th>sensor27</th>\n",
       "      <th>sensor28</th>\n",
       "      <th>sensor29</th>\n",
       "      <th>sensor30</th>\n",
       "      <th>sensor31</th>\n",
       "      <th>sensor32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>82.867633</td>\n",
       "      <td>121.244903</td>\n",
       "      <td>61.678369</td>\n",
       "      <td>88.987986</td>\n",
       "      <td>83.750290</td>\n",
       "      <td>104.199904</td>\n",
       "      <td>78.012855</td>\n",
       "      <td>106.128341</td>\n",
       "      <td>102.762255</td>\n",
       "      <td>114.447460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>87.815198</td>\n",
       "      <td>127.885537</td>\n",
       "      <td>60.866441</td>\n",
       "      <td>91.164567</td>\n",
       "      <td>79.950607</td>\n",
       "      <td>110.887240</td>\n",
       "      <td>82.110782</td>\n",
       "      <td>103.486894</td>\n",
       "      <td>99.323340</td>\n",
       "      <td>120.554118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>79.962744</td>\n",
       "      <td>120.686542</td>\n",
       "      <td>62.327849</td>\n",
       "      <td>90.834187</td>\n",
       "      <td>86.260268</td>\n",
       "      <td>102.448958</td>\n",
       "      <td>84.877343</td>\n",
       "      <td>92.475694</td>\n",
       "      <td>90.319502</td>\n",
       "      <td>110.650880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>89.381611</td>\n",
       "      <td>122.638217</td>\n",
       "      <td>64.375830</td>\n",
       "      <td>87.117325</td>\n",
       "      <td>85.321327</td>\n",
       "      <td>101.953217</td>\n",
       "      <td>79.649080</td>\n",
       "      <td>110.518927</td>\n",
       "      <td>89.159566</td>\n",
       "      <td>112.068859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>85.307319</td>\n",
       "      <td>120.171501</td>\n",
       "      <td>54.592383</td>\n",
       "      <td>87.817519</td>\n",
       "      <td>82.382208</td>\n",
       "      <td>112.645901</td>\n",
       "      <td>79.400548</td>\n",
       "      <td>110.674554</td>\n",
       "      <td>97.218949</td>\n",
       "      <td>119.727171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>111.415908</td>\n",
       "      <td>83.023104</td>\n",
       "      <td>84.509942</td>\n",
       "      <td>44.864239</td>\n",
       "      <td>111.395841</td>\n",
       "      <td>90.978805</td>\n",
       "      <td>97.043260</td>\n",
       "      <td>94.616714</td>\n",
       "      <td>114.478872</td>\n",
       "      <td>111.426888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>120.217169</td>\n",
       "      <td>90.140067</td>\n",
       "      <td>84.794620</td>\n",
       "      <td>45.743111</td>\n",
       "      <td>98.873778</td>\n",
       "      <td>92.676679</td>\n",
       "      <td>106.613637</td>\n",
       "      <td>91.157714</td>\n",
       "      <td>124.608772</td>\n",
       "      <td>111.535307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>114.306234</td>\n",
       "      <td>95.384183</td>\n",
       "      <td>77.937239</td>\n",
       "      <td>48.461894</td>\n",
       "      <td>102.282983</td>\n",
       "      <td>93.083461</td>\n",
       "      <td>103.310116</td>\n",
       "      <td>95.400984</td>\n",
       "      <td>114.616802</td>\n",
       "      <td>105.551149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>123.237372</td>\n",
       "      <td>101.313107</td>\n",
       "      <td>84.309651</td>\n",
       "      <td>57.512206</td>\n",
       "      <td>100.694751</td>\n",
       "      <td>80.733401</td>\n",
       "      <td>100.969301</td>\n",
       "      <td>95.594096</td>\n",
       "      <td>121.333353</td>\n",
       "      <td>108.467974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>119.761631</td>\n",
       "      <td>88.441370</td>\n",
       "      <td>80.450256</td>\n",
       "      <td>49.557286</td>\n",
       "      <td>94.516091</td>\n",
       "      <td>84.106616</td>\n",
       "      <td>107.354636</td>\n",
       "      <td>95.281774</td>\n",
       "      <td>118.065500</td>\n",
       "      <td>111.120071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...    sensor23  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...   82.867633   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...   87.815198   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...   79.962744   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...   89.381611   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...   85.307319   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  111.415908   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  120.217169   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  114.306234   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  123.237372   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  119.761631   \n",
       "\n",
       "        sensor24   sensor25   sensor26    sensor27    sensor28    sensor29  \\\n",
       "0     121.244903  61.678369  88.987986   83.750290  104.199904   78.012855   \n",
       "1     127.885537  60.866441  91.164567   79.950607  110.887240   82.110782   \n",
       "2     120.686542  62.327849  90.834187   86.260268  102.448958   84.877343   \n",
       "3     122.638217  64.375830  87.117325   85.321327  101.953217   79.649080   \n",
       "4     120.171501  54.592383  87.817519   82.382208  112.645901   79.400548   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438   83.023104  84.509942  44.864239  111.395841   90.978805   97.043260   \n",
       "2439   90.140067  84.794620  45.743111   98.873778   92.676679  106.613637   \n",
       "2440   95.384183  77.937239  48.461894  102.282983   93.083461  103.310116   \n",
       "2441  101.313107  84.309651  57.512206  100.694751   80.733401  100.969301   \n",
       "2442   88.441370  80.450256  49.557286   94.516091   84.106616  107.354636   \n",
       "\n",
       "        sensor30    sensor31    sensor32  \n",
       "0     106.128341  102.762255  114.447460  \n",
       "1     103.486894   99.323340  120.554118  \n",
       "2      92.475694   90.319502  110.650880  \n",
       "3     110.518927   89.159566  112.068859  \n",
       "4     110.674554   97.218949  119.727171  \n",
       "...          ...         ...         ...  \n",
       "2438   94.616714  114.478872  111.426888  \n",
       "2439   91.157714  124.608772  111.535307  \n",
       "2440   95.400984  114.616802  105.551149  \n",
       "2441   95.594096  121.333353  108.467974  \n",
       "2442   95.281774  118.065500  111.120071  \n",
       "\n",
       "[2443 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:32]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 16ms/step - loss: 1128.4413 - val_loss: 919.1357\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 917.2937 - val_loss: 896.6784\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 747.9337 - val_loss: 625.3356\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 441.7253 - val_loss: 318.8710\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 245.9946 - val_loss: 180.4560\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 128.5244 - val_loss: 103.7801\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 71.0912 - val_loss: 56.6107\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 42.6503 - val_loss: 41.1999\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 29.6672 - val_loss: 36.7060\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 25.6548 - val_loss: 29.1431\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 18.9944 - val_loss: 19.7989\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 15.8509 - val_loss: 27.9423\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 14.8678 - val_loss: 17.3838\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 13.6721 - val_loss: 19.7758\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 12.6696 - val_loss: 13.9873\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 11.0063 - val_loss: 13.4771\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 12.6728 - val_loss: 11.7610\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 11.2530 - val_loss: 15.9325\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 10.4044 - val_loss: 11.0738\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.8858 - val_loss: 14.8614\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 9.9359 - val_loss: 18.4642\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.7569 - val_loss: 10.9450\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.5157 - val_loss: 17.5374\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.9297 - val_loss: 9.7121\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.2210 - val_loss: 11.4607\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.6669 - val_loss: 22.6389\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.0963 - val_loss: 16.7360\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.1589 - val_loss: 11.1498\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.3557 - val_loss: 13.3544\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.5580 - val_loss: 9.6504\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.9992 - val_loss: 13.4249\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.0007 - val_loss: 9.0523\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.6674 - val_loss: 11.7887\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 8.2091 - val_loss: 8.5439\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.4978 - val_loss: 10.4492\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.5042 - val_loss: 7.4062\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 6.2508 - val_loss: 14.7147\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 7.4486 - val_loss: 12.5864\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.1005 - val_loss: 11.6952\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 5.5315 - val_loss: 7.9512\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.5490 - val_loss: 16.6279\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.3399 - val_loss: 7.8542\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 6.6016 - val_loss: 8.3490\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.7522 - val_loss: 7.6440\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.4230 - val_loss: 8.6626\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 5.6812 - val_loss: 17.5340\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.4666 - val_loss: 8.9609\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.4500 - val_loss: 9.7727\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.5235 - val_loss: 7.2758\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.6517 - val_loss: 8.9212\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.9891 - val_loss: 6.3780\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.2307 - val_loss: 7.6704\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.9617 - val_loss: 8.3750\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.3438 - val_loss: 8.4529\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.9117 - val_loss: 7.2635\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.1807 - val_loss: 6.4601\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.7597 - val_loss: 7.0184\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.7263 - val_loss: 10.6591\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.8899 - val_loss: 10.6600\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.8230 - val_loss: 6.3442\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.5860 - val_loss: 11.6081\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.1310 - val_loss: 7.8032\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.0544 - val_loss: 8.3920\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.2371 - val_loss: 7.6954\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.1825 - val_loss: 6.8001\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.3546 - val_loss: 8.6288\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.6833 - val_loss: 8.2407\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.7221 - val_loss: 7.2939\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.7715 - val_loss: 6.2197\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.3056 - val_loss: 9.3139\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.0344 - val_loss: 7.1127\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.6180 - val_loss: 6.6864\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.7758 - val_loss: 8.8885\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.8355 - val_loss: 6.5501\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 5.1880 - val_loss: 6.5542\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.1320 - val_loss: 7.9474\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.5145 - val_loss: 7.2886\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.6984 - val_loss: 7.1444\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.2238 - val_loss: 6.5013\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 13ms/step - loss: 3.2696 - val_loss: 7.4315\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.5523 - val_loss: 18.4777\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.5790 - val_loss: 6.9942\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 3.4314 - val_loss: 7.9115\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.4756 - val_loss: 6.0078\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.4954 - val_loss: 8.5809\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.1497 - val_loss: 6.4044\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.6196 - val_loss: 9.9400\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.1305 - val_loss: 8.4708\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.9322 - val_loss: 7.4184\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.2769 - val_loss: 8.1181\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.1618 - val_loss: 7.8002\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.7839 - val_loss: 9.1787\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.0485 - val_loss: 8.6905\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.9779 - val_loss: 10.6039\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.9746 - val_loss: 6.0429\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.7172 - val_loss: 7.4173\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 2.7968 - val_loss: 8.3879\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.5702 - val_loss: 6.1313\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 2.5592 - val_loss: 6.5617\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.4250 - val_loss: 6.7067\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.5422 - val_loss: 6.0255\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.6846 - val_loss: 6.2710\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.6601 - val_loss: 6.6756\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.8637 - val_loss: 36.7296\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.2612 - val_loss: 7.3762\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 5s 16ms/step - loss: 2.7896 - val_loss: 6.5058\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.1580 - val_loss: 6.9699\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.4945 - val_loss: 7.4814\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.2147 - val_loss: 6.1238\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.2328 - val_loss: 6.7764\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.3090 - val_loss: 7.9398\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.3313 - val_loss: 7.2707\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.6176 - val_loss: 6.2792\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.0854 - val_loss: 7.4054\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 6.008038543130334\n",
      "Mean Absolute Error (MAE): 1.6360719468238516\n",
      "Root Mean Squared Error (RMSE): 2.4511300543076726\n",
      "Time taken: 487.18419313430786\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 8s 15ms/step - loss: 1101.4924 - val_loss: 936.0217\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 822.3958 - val_loss: 729.6698\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 548.1643 - val_loss: 430.7387\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 341.6161 - val_loss: 280.1779\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 203.8006 - val_loss: 162.5348\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 101.5845 - val_loss: 75.0197\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 59.1301 - val_loss: 65.6787\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 39.6689 - val_loss: 34.4228\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 28.9214 - val_loss: 32.3340\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 24.1791 - val_loss: 39.2872\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 21.4836 - val_loss: 20.7935\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 18.7563 - val_loss: 33.7047\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 17.6985 - val_loss: 18.9457\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 15.9415 - val_loss: 14.4034\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 13.7341 - val_loss: 32.6460\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 12.6694 - val_loss: 10.6462\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 11.9126 - val_loss: 20.6655\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 12.0046 - val_loss: 18.0790\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 11.3160 - val_loss: 33.2997\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 11.0133 - val_loss: 47.8109\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 11.4301 - val_loss: 13.2690\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.9061 - val_loss: 22.3911\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.6663 - val_loss: 14.0454\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 9.8146 - val_loss: 15.0621\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.5236 - val_loss: 12.3528\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.8126 - val_loss: 10.0033\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.1957 - val_loss: 8.9897\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.0820 - val_loss: 13.9499\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.1925 - val_loss: 11.3813\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.5229 - val_loss: 10.8009\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.9100 - val_loss: 7.8685\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.2288 - val_loss: 28.7102\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 8.3247 - val_loss: 7.7935\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.6721 - val_loss: 8.9422\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.6934 - val_loss: 7.8827\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.7426 - val_loss: 8.7266\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.9715 - val_loss: 8.1380\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.1713 - val_loss: 8.3326\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.3226 - val_loss: 8.5789\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.9993 - val_loss: 10.0121\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.6817 - val_loss: 8.6016\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.1941 - val_loss: 8.7012\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.1323 - val_loss: 7.1669\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.0169 - val_loss: 8.0906\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.9114 - val_loss: 7.6207\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.6367 - val_loss: 7.3607\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.5973 - val_loss: 11.7846\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.5526 - val_loss: 7.6348\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.5319 - val_loss: 22.0075\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.2537 - val_loss: 10.5178\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 5.0968 - val_loss: 8.4903\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.1248 - val_loss: 8.2326\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 5.4606 - val_loss: 7.6709\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.7690 - val_loss: 7.0493\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.1091 - val_loss: 26.9086\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.6022 - val_loss: 8.3157\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.0970 - val_loss: 9.2619\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.9315 - val_loss: 7.5570\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.0569 - val_loss: 7.7737\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.2463 - val_loss: 8.7513\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.3898 - val_loss: 8.1812\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.4457 - val_loss: 7.8211\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.4450 - val_loss: 7.5721\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.2092 - val_loss: 6.8413\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.9524 - val_loss: 11.8803\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.9138 - val_loss: 7.9284\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.1871 - val_loss: 7.7679\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.8252 - val_loss: 7.0476\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.7264 - val_loss: 7.2730\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.9916 - val_loss: 7.8431\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.0954 - val_loss: 6.3652\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.8335 - val_loss: 7.6709\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.9783 - val_loss: 8.2458\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.7821 - val_loss: 6.6539\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.9295 - val_loss: 9.9723\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.6067 - val_loss: 7.2726\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.4112 - val_loss: 6.8302\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.8147 - val_loss: 9.8143\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.4094 - val_loss: 10.0568\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 13ms/step - loss: 3.6389 - val_loss: 9.1498\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.4941 - val_loss: 8.4417\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.2497 - val_loss: 10.4074\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.0405 - val_loss: 6.8775\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.2526 - val_loss: 10.0701\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.8885 - val_loss: 13.2425\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.7704 - val_loss: 8.4352\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.2948 - val_loss: 7.9442\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.0257 - val_loss: 6.3826\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.8793 - val_loss: 6.7513\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.9803 - val_loss: 7.0531\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.9282 - val_loss: 7.2247\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.7564 - val_loss: 6.7656\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.0107 - val_loss: 8.7046\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.9026 - val_loss: 6.7083\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.6543 - val_loss: 7.3678\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.8513 - val_loss: 7.0357\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 2.6380 - val_loss: 7.1738\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.7892 - val_loss: 9.5244\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.1149 - val_loss: 19.1652\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.2871 - val_loss: 6.9077\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.7045 - val_loss: 7.0806\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 6.365081656443461\n",
      "Mean Absolute Error (MAE): 1.702755911933811\n",
      "Root Mean Squared Error (RMSE): 2.522911345339638\n",
      "Time taken: 423.9104299545288\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 17ms/step - loss: 1175.7308 - val_loss: 962.5406\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 902.4390 - val_loss: 913.7601\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 676.3671 - val_loss: 537.8128\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 358.4980 - val_loss: 267.9111\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 169.7885 - val_loss: 119.4701\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 83.0053 - val_loss: 60.6758\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 47.4754 - val_loss: 39.4421\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 32.4859 - val_loss: 30.6891\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 25.3219 - val_loss: 31.0828\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 20.7268 - val_loss: 22.1309\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 17.9966 - val_loss: 35.9141\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 15.6422 - val_loss: 23.0874\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 14.5785 - val_loss: 21.6332\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 13.4631 - val_loss: 36.5554\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 13.2661 - val_loss: 14.7809\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 11.0258 - val_loss: 12.7494\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 11.0911 - val_loss: 9.8548\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 11.7255 - val_loss: 21.6599\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 10.6275 - val_loss: 10.8740\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 9.3594 - val_loss: 15.1921\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 9.1990 - val_loss: 15.5037\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.7989 - val_loss: 14.4481\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 10.4827 - val_loss: 11.0972\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 8.6945 - val_loss: 9.3529\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.0694 - val_loss: 7.7014\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.8756 - val_loss: 9.9159\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.1791 - val_loss: 15.0641\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.5891 - val_loss: 10.0937\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.0685 - val_loss: 8.8949\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.4819 - val_loss: 9.5023\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.1991 - val_loss: 8.8886\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.9984 - val_loss: 12.8628\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.3474 - val_loss: 11.7270\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.0379 - val_loss: 7.0376\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.6469 - val_loss: 18.1854\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.1247 - val_loss: 7.5962\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.9519 - val_loss: 12.9729\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.9476 - val_loss: 9.1347\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 6.5124 - val_loss: 10.0992\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 6.3688 - val_loss: 7.6663\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.7004 - val_loss: 9.1375\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.1432 - val_loss: 19.7000\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.0115 - val_loss: 7.0102\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.2889 - val_loss: 7.6229\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.1524 - val_loss: 16.0266\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.1588 - val_loss: 8.4278\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.4289 - val_loss: 8.8221\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.3355 - val_loss: 9.3534\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.6697 - val_loss: 13.0690\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.0664 - val_loss: 7.1912\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.1237 - val_loss: 8.8105\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.2395 - val_loss: 7.1908\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.2621 - val_loss: 9.0845\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.8849 - val_loss: 6.8447\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.7223 - val_loss: 11.1839\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.2090 - val_loss: 9.8354\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.7678 - val_loss: 15.5594\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.1673 - val_loss: 6.6656\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.6922 - val_loss: 8.2958\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.8699 - val_loss: 7.9535\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.0430 - val_loss: 6.2059\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.4611 - val_loss: 8.0953\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.4158 - val_loss: 8.1183\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.1302 - val_loss: 10.3616\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.2531 - val_loss: 8.3699\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.1889 - val_loss: 8.5539\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.0519 - val_loss: 10.6145\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.7884 - val_loss: 7.5471\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.1479 - val_loss: 7.9314\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.9421 - val_loss: 10.9345\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.6791 - val_loss: 7.4058\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.8176 - val_loss: 9.3148\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.7130 - val_loss: 7.0714\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.5845 - val_loss: 6.9856\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.4847 - val_loss: 7.4152\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.6098 - val_loss: 9.0105\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.5677 - val_loss: 8.6143\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.5118 - val_loss: 7.1797\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.7022 - val_loss: 6.7724\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6649 - val_loss: 8.0530\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.7392 - val_loss: 8.5365\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.7424 - val_loss: 6.7130\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 3.6010 - val_loss: 10.6180\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.3636 - val_loss: 13.5595\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 3.4339 - val_loss: 8.1852\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.0347 - val_loss: 6.6761\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 3.1701 - val_loss: 8.0213\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.6032 - val_loss: 8.1361\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 3.3074 - val_loss: 6.6083\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.1886 - val_loss: 6.9673\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.4238 - val_loss: 10.3242\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 6.205851238878139\n",
      "Mean Absolute Error (MAE): 1.6964268701406742\n",
      "Root Mean Squared Error (RMSE): 2.491154599553817\n",
      "Time taken: 376.7354154586792\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 16ms/step - loss: 1127.4435 - val_loss: 887.5229\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 762.6442 - val_loss: 609.1718\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 557.3715 - val_loss: 436.1051\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 404.2617 - val_loss: 410.8456\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 324.8910 - val_loss: 295.1748\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 289.8289 - val_loss: 246.7205\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 218.2135 - val_loss: 149.9934\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 118.3557 - val_loss: 81.2314\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 68.1536 - val_loss: 65.0729\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 43.1187 - val_loss: 43.1617\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 29.2193 - val_loss: 38.7463\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 24.6869 - val_loss: 21.6834\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 21.9336 - val_loss: 21.5824\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 16.9595 - val_loss: 23.8952\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 16.9578 - val_loss: 16.4148\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 15.4043 - val_loss: 12.8638\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 15.2358 - val_loss: 25.2987\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 14.3007 - val_loss: 33.7931\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 12.8210 - val_loss: 11.2460\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 12.2742 - val_loss: 22.0875\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 11.9157 - val_loss: 15.1100\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 11.4196 - val_loss: 17.9716\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 10.9109 - val_loss: 13.3474\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 10.0220 - val_loss: 15.1408\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 10.6635 - val_loss: 24.6860\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.8956 - val_loss: 9.1020\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 9.9555 - val_loss: 24.4870\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.9269 - val_loss: 12.2483\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 9.0920 - val_loss: 10.4086\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.1167 - val_loss: 13.1976\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.3354 - val_loss: 8.7746\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.5019 - val_loss: 8.5899\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.9663 - val_loss: 8.6924\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.1185 - val_loss: 11.3533\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.1192 - val_loss: 7.6925\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.5728 - val_loss: 14.3136\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.3757 - val_loss: 9.2190\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.0216 - val_loss: 8.2401\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 6.9677 - val_loss: 7.4843\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.3884 - val_loss: 8.7021\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.0290 - val_loss: 9.7267\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 6.3992 - val_loss: 10.2563\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 6.1705 - val_loss: 7.5423\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 6.7464 - val_loss: 10.1999\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 7.2176 - val_loss: 8.2839\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 5.5479 - val_loss: 8.0482\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 5.8939 - val_loss: 9.2969\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.7664 - val_loss: 8.0273\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.4354 - val_loss: 9.4933\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.8371 - val_loss: 7.1728\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.4792 - val_loss: 11.8518\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.3018 - val_loss: 7.9824\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.6413 - val_loss: 9.7562\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.2282 - val_loss: 8.4817\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.5196 - val_loss: 11.2165\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.3320 - val_loss: 9.2409\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.0274 - val_loss: 8.7326\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.1885 - val_loss: 7.6559\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.0343 - val_loss: 8.0277\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.8027 - val_loss: 7.1218\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.9029 - val_loss: 8.7990\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.6723 - val_loss: 17.9595\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.0440 - val_loss: 7.6222\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.1736 - val_loss: 9.0059\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.2451 - val_loss: 20.2400\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.0561 - val_loss: 7.7386\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.3509 - val_loss: 9.2091\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.0867 - val_loss: 8.5737\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.1652 - val_loss: 7.1075\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.2172 - val_loss: 10.0394\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.7259 - val_loss: 11.0161\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 4.3710 - val_loss: 7.1340\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.9774 - val_loss: 7.9793\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 4.2788 - val_loss: 7.2820\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 4.5895 - val_loss: 12.5903\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.9965 - val_loss: 12.9120\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 4.8583 - val_loss: 7.1716\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.8640 - val_loss: 7.5619\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.0182 - val_loss: 9.1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.6976 - val_loss: 7.0383\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 3.6126 - val_loss: 6.9416\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.9343 - val_loss: 7.1727\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.2791 - val_loss: 6.5935\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.5427 - val_loss: 7.5926\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.2139 - val_loss: 6.2117\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.3576 - val_loss: 6.9968\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.9989 - val_loss: 6.7086\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.2518 - val_loss: 6.6107\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.0381 - val_loss: 7.3725\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.1875 - val_loss: 6.9508\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.7337 - val_loss: 6.2928\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.4373 - val_loss: 9.8662\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.0464 - val_loss: 6.9519\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.4421 - val_loss: 9.4559\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.7188 - val_loss: 6.9359\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.9421 - val_loss: 6.8623\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.7894 - val_loss: 12.2776\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 3.0386 - val_loss: 6.3657\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.8997 - val_loss: 7.5292\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.0956 - val_loss: 6.7786\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.2662 - val_loss: 7.4878\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.8535 - val_loss: 9.0149\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.6757 - val_loss: 6.9889\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.8122 - val_loss: 9.8001\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.5372 - val_loss: 6.4251\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.5385 - val_loss: 6.5406\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.5767 - val_loss: 6.4569\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.3897 - val_loss: 6.9256\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.4754 - val_loss: 7.6145\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.2893 - val_loss: 6.8406\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.3723 - val_loss: 9.3576\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.7256 - val_loss: 7.7976\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.4083 - val_loss: 6.8575\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.3157 - val_loss: 7.8138\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.9183 - val_loss: 8.4222\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 6.211410286419631\n",
      "Mean Absolute Error (MAE): 1.6805314630651556\n",
      "Root Mean Squared Error (RMSE): 2.4922701070348756\n",
      "Time taken: 478.40454745292664\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 9s 16ms/step - loss: 1128.8613 - val_loss: 916.9965\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 900.6114 - val_loss: 819.5702\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 684.3404 - val_loss: 535.0616\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 427.3375 - val_loss: 348.9180\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 254.0476 - val_loss: 193.5594\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 127.1071 - val_loss: 92.5120\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 68.4034 - val_loss: 55.7706\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 39.7596 - val_loss: 36.2593\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 29.4303 - val_loss: 25.5598\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 23.2623 - val_loss: 24.3811\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 20.2048 - val_loss: 26.9250\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 18.0023 - val_loss: 19.1658\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 15.4061 - val_loss: 13.4176\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 15.3131 - val_loss: 15.7442\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 13.1573 - val_loss: 12.5443\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 14.5651 - val_loss: 12.5678\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 11.4294 - val_loss: 12.3739\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 10.3925 - val_loss: 10.9674\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 10.0825 - val_loss: 11.0364\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 11.9509 - val_loss: 10.8596\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.5644 - val_loss: 10.6741\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 9.9594 - val_loss: 17.3119\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 9.5093 - val_loss: 9.4340\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.6881 - val_loss: 11.2957\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.6677 - val_loss: 17.4962\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 8.3848 - val_loss: 9.5285\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.3735 - val_loss: 23.9857\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 10.1504 - val_loss: 18.6075\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.4823 - val_loss: 11.9711\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 8.3238 - val_loss: 9.4878\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.1073 - val_loss: 10.5509\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 7.5050 - val_loss: 7.9489\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.9309 - val_loss: 11.4794\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.6530 - val_loss: 12.0075\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.7003 - val_loss: 10.7233\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.7402 - val_loss: 8.8216\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.7747 - val_loss: 10.2680\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.5603 - val_loss: 7.1822\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 6.0643 - val_loss: 22.0020\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 7.3674 - val_loss: 7.8601\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 6.6602 - val_loss: 9.0018\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.2443 - val_loss: 8.4944\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.8183 - val_loss: 10.0076\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.9728 - val_loss: 7.5423\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 5s 15ms/step - loss: 5.7660 - val_loss: 9.8921\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.7153 - val_loss: 11.0167\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.3155 - val_loss: 8.2059\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 6.2068 - val_loss: 7.2835\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.3660 - val_loss: 10.2563\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.9820 - val_loss: 7.0824\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.8824 - val_loss: 8.9667\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.1356 - val_loss: 8.7545\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.9581 - val_loss: 7.0522\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.8948 - val_loss: 8.2191\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.7294 - val_loss: 7.3813\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 5.0339 - val_loss: 11.3548\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.6819 - val_loss: 6.9115\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.5523 - val_loss: 6.6099\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.6407 - val_loss: 6.7461\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 4.8226 - val_loss: 7.9163\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.0741 - val_loss: 7.0966\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.7757 - val_loss: 9.3021\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 4.0520 - val_loss: 6.9232\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.2547 - val_loss: 6.2513\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 4.6173 - val_loss: 25.3289\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 5.2569 - val_loss: 9.0075\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.6837 - val_loss: 6.7238\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 5.1645 - val_loss: 6.7836\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.9390 - val_loss: 7.4408\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.7874 - val_loss: 6.6962\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.8073 - val_loss: 8.5061\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.6098 - val_loss: 7.2216\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.4787 - val_loss: 11.7597\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 3.4282 - val_loss: 6.7473\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.3384 - val_loss: 6.3282\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 3.4584 - val_loss: 6.5900\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 4.7601 - val_loss: 11.6481\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.6560 - val_loss: 7.7936\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.5665 - val_loss: 6.4821\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 4s 13ms/step - loss: 3.5801 - val_loss: 7.8707\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.4800 - val_loss: 6.6438\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.1697 - val_loss: 6.4767\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.3753 - val_loss: 7.6563\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.0284 - val_loss: 9.3623\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.9177 - val_loss: 5.7562\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.0260 - val_loss: 6.4740\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.0232 - val_loss: 6.2903\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.3219 - val_loss: 6.5801\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 3.0918 - val_loss: 7.7435\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.0161 - val_loss: 7.5299\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.1461 - val_loss: 11.4860\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.5052 - val_loss: 5.9270\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.7076 - val_loss: 6.3744\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.1199 - val_loss: 6.6889\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.7108 - val_loss: 6.5416\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.0571 - val_loss: 12.5066\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 3.4091 - val_loss: 7.7778\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.4539 - val_loss: 6.9052\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.4534 - val_loss: 7.4620\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.5388 - val_loss: 7.2932\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.3069 - val_loss: 6.2883\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.5762 - val_loss: 9.6753\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.2642 - val_loss: 7.1539\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 4s 14ms/step - loss: 2.2766 - val_loss: 7.0864\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.7403 - val_loss: 6.7785\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 2.3258 - val_loss: 6.4448\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.1535 - val_loss: 6.5414\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.3397 - val_loss: 7.5908\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 2.3193 - val_loss: 7.9039\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 1.9786 - val_loss: 6.9621\n",
      "Epoch 111/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.2048 - val_loss: 7.6952\n",
      "Epoch 112/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.1848 - val_loss: 6.7800\n",
      "Epoch 113/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.0062 - val_loss: 6.5493\n",
      "Epoch 114/200\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 2.2868 - val_loss: 6.9299\n",
      "Epoch 115/200\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 1.9082 - val_loss: 7.8155\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 5.755818730660741\n",
      "Mean Absolute Error (MAE): 1.6033028588532243\n",
      "Root Mean Squared Error (RMSE): 2.3991287440778875\n",
      "Time taken: 480.5378830432892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=6,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 32, 512)           1052672   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 512)          2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 512)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 32, 256)           787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,047,747\n",
      "Trainable params: 2,046,723\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_1224\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold       MSE       MAE      RMSE  Time taken\n",
      "0        1  6.008039  1.636072  2.451130  487.184193\n",
      "1        2  6.365082  1.702756  2.522911  423.910430\n",
      "2        3  6.205851  1.696427  2.491155  376.735415\n",
      "3        4  6.211410  1.680531  2.492270  478.404547\n",
      "4        5  5.755819  1.603303  2.399129  480.537883\n",
      "5  Average  6.109240  1.663818  2.471319  449.354494\n",
      "Results saved to 'Sensors 32_PL_model_1_Scattered_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('Sensors 32_PL_model_1_Scattered_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'Sensors 32_PL_model_1_Scattered_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
