{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d4e64b",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a085cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014d550",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a290f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.read_excel('PL_model_1_Scattered_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb43499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5   \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "              6           7           8           9   ...         38  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "              39         40         41          42          43          44  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "              45          46          47  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7103d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.read_excel('real_positions_iReg_f.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088c1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1      2\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ead48",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3cbc",
   "metadata": {},
   "source": [
    "### Sensors Data -- Labeling Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d29950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_Number_of_Columns = sensors_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07c4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensors_columns = [\"sensor\" + str(x) for x in range(1,Sensors_Number_of_Columns + 1)]\n",
    "sensors_data.columns = (Sensors_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb9c359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor39</th>\n",
       "      <th>sensor40</th>\n",
       "      <th>sensor41</th>\n",
       "      <th>sensor42</th>\n",
       "      <th>sensor43</th>\n",
       "      <th>sensor44</th>\n",
       "      <th>sensor45</th>\n",
       "      <th>sensor46</th>\n",
       "      <th>sensor47</th>\n",
       "      <th>sensor48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "      <td>89.453295</td>\n",
       "      <td>97.318384</td>\n",
       "      <td>...</td>\n",
       "      <td>81.685404</td>\n",
       "      <td>84.830110</td>\n",
       "      <td>86.513881</td>\n",
       "      <td>81.048996</td>\n",
       "      <td>114.964811</td>\n",
       "      <td>120.010616</td>\n",
       "      <td>103.909997</td>\n",
       "      <td>133.568532</td>\n",
       "      <td>57.626093</td>\n",
       "      <td>109.708209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "      <td>92.314999</td>\n",
       "      <td>112.314087</td>\n",
       "      <td>...</td>\n",
       "      <td>81.526583</td>\n",
       "      <td>92.908051</td>\n",
       "      <td>94.438277</td>\n",
       "      <td>89.628271</td>\n",
       "      <td>114.498751</td>\n",
       "      <td>106.887589</td>\n",
       "      <td>99.505693</td>\n",
       "      <td>128.544662</td>\n",
       "      <td>67.730350</td>\n",
       "      <td>113.436964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "      <td>99.182335</td>\n",
       "      <td>106.232463</td>\n",
       "      <td>...</td>\n",
       "      <td>75.930487</td>\n",
       "      <td>82.432658</td>\n",
       "      <td>87.572150</td>\n",
       "      <td>90.919428</td>\n",
       "      <td>116.186110</td>\n",
       "      <td>121.150696</td>\n",
       "      <td>96.193748</td>\n",
       "      <td>134.116483</td>\n",
       "      <td>68.863500</td>\n",
       "      <td>116.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "      <td>86.763744</td>\n",
       "      <td>106.168512</td>\n",
       "      <td>...</td>\n",
       "      <td>79.984057</td>\n",
       "      <td>99.957787</td>\n",
       "      <td>93.313344</td>\n",
       "      <td>84.668294</td>\n",
       "      <td>111.953201</td>\n",
       "      <td>119.676628</td>\n",
       "      <td>106.414441</td>\n",
       "      <td>137.948662</td>\n",
       "      <td>69.634344</td>\n",
       "      <td>114.024685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "      <td>83.559242</td>\n",
       "      <td>103.091764</td>\n",
       "      <td>...</td>\n",
       "      <td>75.279364</td>\n",
       "      <td>87.349475</td>\n",
       "      <td>97.655142</td>\n",
       "      <td>89.118820</td>\n",
       "      <td>126.637608</td>\n",
       "      <td>114.886056</td>\n",
       "      <td>101.361093</td>\n",
       "      <td>126.482809</td>\n",
       "      <td>66.133931</td>\n",
       "      <td>109.168340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "      <td>107.105731</td>\n",
       "      <td>96.441980</td>\n",
       "      <td>...</td>\n",
       "      <td>91.496394</td>\n",
       "      <td>121.729389</td>\n",
       "      <td>87.948166</td>\n",
       "      <td>77.602308</td>\n",
       "      <td>127.656991</td>\n",
       "      <td>114.668824</td>\n",
       "      <td>127.756278</td>\n",
       "      <td>109.362652</td>\n",
       "      <td>102.983525</td>\n",
       "      <td>78.077730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "      <td>104.631338</td>\n",
       "      <td>98.998328</td>\n",
       "      <td>...</td>\n",
       "      <td>92.880258</td>\n",
       "      <td>108.747017</td>\n",
       "      <td>88.541794</td>\n",
       "      <td>75.344392</td>\n",
       "      <td>125.557441</td>\n",
       "      <td>111.031434</td>\n",
       "      <td>134.494231</td>\n",
       "      <td>116.813742</td>\n",
       "      <td>112.599318</td>\n",
       "      <td>79.992646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "      <td>106.966013</td>\n",
       "      <td>96.617547</td>\n",
       "      <td>...</td>\n",
       "      <td>89.648431</td>\n",
       "      <td>106.485343</td>\n",
       "      <td>93.400271</td>\n",
       "      <td>71.177932</td>\n",
       "      <td>123.918015</td>\n",
       "      <td>105.789520</td>\n",
       "      <td>127.670906</td>\n",
       "      <td>109.512188</td>\n",
       "      <td>104.166149</td>\n",
       "      <td>83.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "      <td>105.897605</td>\n",
       "      <td>91.914775</td>\n",
       "      <td>...</td>\n",
       "      <td>86.126272</td>\n",
       "      <td>106.959002</td>\n",
       "      <td>88.494586</td>\n",
       "      <td>63.991014</td>\n",
       "      <td>129.409898</td>\n",
       "      <td>109.907911</td>\n",
       "      <td>126.391262</td>\n",
       "      <td>111.268189</td>\n",
       "      <td>100.508162</td>\n",
       "      <td>70.592735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "      <td>97.022346</td>\n",
       "      <td>99.972913</td>\n",
       "      <td>...</td>\n",
       "      <td>88.589209</td>\n",
       "      <td>107.322913</td>\n",
       "      <td>86.795897</td>\n",
       "      <td>75.659668</td>\n",
       "      <td>122.322131</td>\n",
       "      <td>117.782888</td>\n",
       "      <td>126.797409</td>\n",
       "      <td>117.722182</td>\n",
       "      <td>110.106607</td>\n",
       "      <td>76.549859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8     sensor9    sensor10  ...   sensor39  \\\n",
       "0     103.508252  125.193887   89.453295   97.318384  ...  81.685404   \n",
       "1     106.645699  137.372609   92.314999  112.314087  ...  81.526583   \n",
       "2     103.789337  135.667714   99.182335  106.232463  ...  75.930487   \n",
       "3     102.460744  129.928887   86.763744  106.168512  ...  79.984057   \n",
       "4     116.786233  139.061346   83.559242  103.091764  ...  75.279364   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2438  123.942335  108.196626  107.105731   96.441980  ...  91.496394   \n",
       "2439  136.835759  113.267986  104.631338   98.998328  ...  92.880258   \n",
       "2440  129.875574  120.944104  106.966013   96.617547  ...  89.648431   \n",
       "2441  125.361425  123.071554  105.897605   91.914775  ...  86.126272   \n",
       "2442  127.958184  113.784393   97.022346   99.972913  ...  88.589209   \n",
       "\n",
       "        sensor40   sensor41   sensor42    sensor43    sensor44    sensor45  \\\n",
       "0      84.830110  86.513881  81.048996  114.964811  120.010616  103.909997   \n",
       "1      92.908051  94.438277  89.628271  114.498751  106.887589   99.505693   \n",
       "2      82.432658  87.572150  90.919428  116.186110  121.150696   96.193748   \n",
       "3      99.957787  93.313344  84.668294  111.953201  119.676628  106.414441   \n",
       "4      87.349475  97.655142  89.118820  126.637608  114.886056  101.361093   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "2438  121.729389  87.948166  77.602308  127.656991  114.668824  127.756278   \n",
       "2439  108.747017  88.541794  75.344392  125.557441  111.031434  134.494231   \n",
       "2440  106.485343  93.400271  71.177932  123.918015  105.789520  127.670906   \n",
       "2441  106.959002  88.494586  63.991014  129.409898  109.907911  126.391262   \n",
       "2442  107.322913  86.795897  75.659668  122.322131  117.782888  126.797409   \n",
       "\n",
       "        sensor46    sensor47    sensor48  \n",
       "0     133.568532   57.626093  109.708209  \n",
       "1     128.544662   67.730350  113.436964  \n",
       "2     134.116483   68.863500  116.446807  \n",
       "3     137.948662   69.634344  114.024685  \n",
       "4     126.482809   66.133931  109.168340  \n",
       "...          ...         ...         ...  \n",
       "2438  109.362652  102.983525   78.077730  \n",
       "2439  116.813742  112.599318   79.992646  \n",
       "2440  109.512188  104.166149   83.022547  \n",
       "2441  111.268189  100.508162   70.592735  \n",
       "2442  117.722182  110.106607   76.549859  \n",
       "\n",
       "[2443 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe88f5b",
   "metadata": {},
   "source": [
    "# Taking Sensor 01 - Sensor 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fad6410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.870132</td>\n",
       "      <td>134.252574</td>\n",
       "      <td>72.801390</td>\n",
       "      <td>108.446568</td>\n",
       "      <td>130.203502</td>\n",
       "      <td>150.760073</td>\n",
       "      <td>103.508252</td>\n",
       "      <td>125.193887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.656974</td>\n",
       "      <td>133.421922</td>\n",
       "      <td>76.037698</td>\n",
       "      <td>115.578180</td>\n",
       "      <td>124.237134</td>\n",
       "      <td>144.797812</td>\n",
       "      <td>106.645699</td>\n",
       "      <td>137.372609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.889598</td>\n",
       "      <td>140.640194</td>\n",
       "      <td>71.553137</td>\n",
       "      <td>106.871465</td>\n",
       "      <td>123.654012</td>\n",
       "      <td>148.446127</td>\n",
       "      <td>103.789337</td>\n",
       "      <td>135.667714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.508164</td>\n",
       "      <td>130.788193</td>\n",
       "      <td>73.179060</td>\n",
       "      <td>122.566756</td>\n",
       "      <td>128.558120</td>\n",
       "      <td>144.121205</td>\n",
       "      <td>102.460744</td>\n",
       "      <td>129.928887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.073940</td>\n",
       "      <td>127.217426</td>\n",
       "      <td>69.730286</td>\n",
       "      <td>115.690253</td>\n",
       "      <td>120.920018</td>\n",
       "      <td>148.666096</td>\n",
       "      <td>116.786233</td>\n",
       "      <td>139.061346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>126.520010</td>\n",
       "      <td>110.917507</td>\n",
       "      <td>102.822108</td>\n",
       "      <td>62.853700</td>\n",
       "      <td>149.747652</td>\n",
       "      <td>127.099840</td>\n",
       "      <td>123.942335</td>\n",
       "      <td>108.196626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>122.656116</td>\n",
       "      <td>114.785269</td>\n",
       "      <td>98.718438</td>\n",
       "      <td>76.449249</td>\n",
       "      <td>152.660776</td>\n",
       "      <td>140.174139</td>\n",
       "      <td>136.835759</td>\n",
       "      <td>113.267986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>126.597748</td>\n",
       "      <td>119.491178</td>\n",
       "      <td>105.538634</td>\n",
       "      <td>75.394449</td>\n",
       "      <td>145.766322</td>\n",
       "      <td>143.595590</td>\n",
       "      <td>129.875574</td>\n",
       "      <td>120.944104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>139.564043</td>\n",
       "      <td>109.141995</td>\n",
       "      <td>106.936201</td>\n",
       "      <td>78.218026</td>\n",
       "      <td>144.561741</td>\n",
       "      <td>141.507291</td>\n",
       "      <td>125.361425</td>\n",
       "      <td>123.071554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>132.013398</td>\n",
       "      <td>115.430773</td>\n",
       "      <td>105.461899</td>\n",
       "      <td>71.804618</td>\n",
       "      <td>151.624598</td>\n",
       "      <td>143.982949</td>\n",
       "      <td>127.958184</td>\n",
       "      <td>113.784393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor1     sensor2     sensor3     sensor4     sensor5     sensor6  \\\n",
       "0     101.870132  134.252574   72.801390  108.446568  130.203502  150.760073   \n",
       "1     101.656974  133.421922   76.037698  115.578180  124.237134  144.797812   \n",
       "2     102.889598  140.640194   71.553137  106.871465  123.654012  148.446127   \n",
       "3     100.508164  130.788193   73.179060  122.566756  128.558120  144.121205   \n",
       "4     104.073940  127.217426   69.730286  115.690253  120.920018  148.666096   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2438  126.520010  110.917507  102.822108   62.853700  149.747652  127.099840   \n",
       "2439  122.656116  114.785269   98.718438   76.449249  152.660776  140.174139   \n",
       "2440  126.597748  119.491178  105.538634   75.394449  145.766322  143.595590   \n",
       "2441  139.564043  109.141995  106.936201   78.218026  144.561741  141.507291   \n",
       "2442  132.013398  115.430773  105.461899   71.804618  151.624598  143.982949   \n",
       "\n",
       "         sensor7     sensor8  \n",
       "0     103.508252  125.193887  \n",
       "1     106.645699  137.372609  \n",
       "2     103.789337  135.667714  \n",
       "3     102.460744  129.928887  \n",
       "4     116.786233  139.061346  \n",
       "...          ...         ...  \n",
       "2438  123.942335  108.196626  \n",
       "2439  136.835759  113.267986  \n",
       "2440  129.875574  120.944104  \n",
       "2441  125.361425  123.071554  \n",
       "2442  127.958184  113.784393  \n",
       "\n",
       "[2443 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_data = pd.concat([sensors_data.iloc[:,:8]], axis=1)\n",
    "sensors_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e98b",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bef9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_data = pd.DataFrame(sensors_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6e6ea",
   "metadata": {},
   "source": [
    "### Position Data -- Labeling Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data.columns = ['Pos X', 'Pos Y', 'Pos Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0422e1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos X</th>\n",
       "      <th>Pos Y</th>\n",
       "      <th>Pos Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-45.581275</td>\n",
       "      <td>30.239368</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-45.188830</td>\n",
       "      <td>30.181623</td>\n",
       "      <td>-59.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-44.791865</td>\n",
       "      <td>30.131806</td>\n",
       "      <td>-59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.390422</td>\n",
       "      <td>30.089935</td>\n",
       "      <td>-59.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.984540</td>\n",
       "      <td>30.056029</td>\n",
       "      <td>-59.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>-59.939858</td>\n",
       "      <td>51.788725</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-59.963718</td>\n",
       "      <td>51.389997</td>\n",
       "      <td>37.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-59.981583</td>\n",
       "      <td>50.990713</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>-59.993448</td>\n",
       "      <td>50.591032</td>\n",
       "      <td>37.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-59.999315</td>\n",
       "      <td>50.191116</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pos X      Pos Y  Pos Z\n",
       "0    -45.581275  30.239368 -60.00\n",
       "1    -45.188830  30.181623 -59.96\n",
       "2    -44.791865  30.131806 -59.92\n",
       "3    -44.390422  30.089935 -59.88\n",
       "4    -43.984540  30.056029 -59.84\n",
       "...         ...        ...    ...\n",
       "2438 -59.939858  51.788725  37.52\n",
       "2439 -59.963718  51.389997  37.56\n",
       "2440 -59.981583  50.990713  37.60\n",
       "2441 -59.993448  50.591032  37.64\n",
       "2442 -59.999315  50.191116  37.68\n",
       "\n",
       "[2443 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b88633",
   "metadata": {},
   "source": [
    "### Converting to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6129a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_data = pd.DataFrame(position_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742983ae",
   "metadata": {},
   "source": [
    "# Converting Numpy Arrays to Pandas DataFrames for Sensor and Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sensors_data\n",
    "y = position_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array into pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83978bb",
   "metadata": {},
   "source": [
    "# 1. Importing Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df5e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.layers import LSTM, BatchNormalization, Activation, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919b46",
   "metadata": {},
   "source": [
    "# 2. Define Network with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a45037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "time_taken = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b10dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 10ms/step - loss: 1004.1840 - val_loss: 685.0783\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 533.1400 - val_loss: 412.8948\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 331.6511 - val_loss: 277.7466\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 217.0195 - val_loss: 176.3835\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 131.6183 - val_loss: 117.6205\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 86.1012 - val_loss: 79.3638\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 62.3157 - val_loss: 53.3398\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 51.4987 - val_loss: 52.3608\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 45.6422 - val_loss: 56.8969\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 42.8499 - val_loss: 40.6010\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 40.1226 - val_loss: 41.3927\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 39.8685 - val_loss: 51.7133\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 37.7929 - val_loss: 40.0599\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 38.8011 - val_loss: 37.5422\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 34.8212 - val_loss: 35.5730\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 36.4027 - val_loss: 42.5357\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 35.1808 - val_loss: 36.2260\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.9027 - val_loss: 56.3436\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 33.5918 - val_loss: 34.7597\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.0032 - val_loss: 38.0341\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.3964 - val_loss: 37.8856\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 32.9830 - val_loss: 36.5530\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 32.8487 - val_loss: 35.9590\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.0378 - val_loss: 36.9113\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 31.2749 - val_loss: 32.3416\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.4156 - val_loss: 37.5144\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 30.4910 - val_loss: 33.9443\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 30.3844 - val_loss: 41.0387\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 30.5621 - val_loss: 40.4722\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.7005 - val_loss: 35.6972\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 29.7561 - val_loss: 35.5934\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.0041 - val_loss: 31.5870\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.9516 - val_loss: 31.7526\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 29.6774 - val_loss: 33.5141\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 28.5602 - val_loss: 33.4643\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 28.5456 - val_loss: 35.1459\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 28.3764 - val_loss: 35.9379\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.7341 - val_loss: 34.0413\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.1283 - val_loss: 35.6696\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 27.2971 - val_loss: 35.2774\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.1094 - val_loss: 33.4632\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.0776 - val_loss: 32.2446\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.7589 - val_loss: 32.4897\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 27.6858 - val_loss: 37.0532\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 26.8379 - val_loss: 36.7491\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.3362 - val_loss: 38.4284\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.8736 - val_loss: 32.4970\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.8521 - val_loss: 33.7490\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.4189 - val_loss: 35.0733\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.7348 - val_loss: 31.7325\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.6783 - val_loss: 30.3259\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 24.3616 - val_loss: 35.8945\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.7247 - val_loss: 35.5752\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.3851 - val_loss: 43.7712\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.6249 - val_loss: 31.3767\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.4411 - val_loss: 37.9014\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.6894 - val_loss: 31.0557\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 24.8720 - val_loss: 31.5096\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.6672 - val_loss: 35.1061\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.4481 - val_loss: 32.7024\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.0385 - val_loss: 32.1677\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 24.0570 - val_loss: 43.1512\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 24.2695 - val_loss: 35.3301\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.1530 - val_loss: 31.7737\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 22.8581 - val_loss: 32.3082\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.9417 - val_loss: 31.5625\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 23.9033 - val_loss: 31.7609\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 22.5425 - val_loss: 33.0492\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.0331 - val_loss: 32.4696\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 22.4970 - val_loss: 40.1106\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 22.3682 - val_loss: 31.0273\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.5596 - val_loss: 32.1880\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 22.4310 - val_loss: 30.7545\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 22.7543 - val_loss: 31.9038\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 22.2467 - val_loss: 32.6053\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.6447 - val_loss: 31.0017\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 21.8538 - val_loss: 36.4432\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 21.2349 - val_loss: 34.0649\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 21.0999 - val_loss: 33.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 20.7212 - val_loss: 31.0750\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 20.6724 - val_loss: 32.1203\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 1\n",
      "Mean Squared Error (MSE): 30.33253619494253\n",
      "Mean Absolute Error (MAE): 3.8912238615815924\n",
      "Root Mean Squared Error (RMSE): 5.5074981792954345\n",
      "Time taken: 219.54097723960876\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 12ms/step - loss: 1063.5353 - val_loss: 821.8315\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 707.0158 - val_loss: 570.3239\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 451.1753 - val_loss: 343.2848\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 258.5373 - val_loss: 184.5600\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 141.8727 - val_loss: 99.5119\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 87.3873 - val_loss: 66.9276\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 60.6182 - val_loss: 54.5387\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 52.0616 - val_loss: 42.6333\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 46.5261 - val_loss: 41.7476\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 42.7213 - val_loss: 37.7941\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 41.5943 - val_loss: 49.1196\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 39.6377 - val_loss: 37.6976\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 37.4816 - val_loss: 35.2890\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 36.3349 - val_loss: 34.2605\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 35.0037 - val_loss: 43.1937\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 34.4540 - val_loss: 31.0358\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 35.2684 - val_loss: 31.6124\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.1348 - val_loss: 34.0193\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.2272 - val_loss: 34.6049\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 32.6446 - val_loss: 35.1503\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.9926 - val_loss: 34.0090\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 31.5559 - val_loss: 37.5245\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 30.6059 - val_loss: 37.9819\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 32.1250 - val_loss: 32.0993\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 31.7594 - val_loss: 38.9775\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 30.0368 - val_loss: 32.7835\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.7713 - val_loss: 33.8447\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.1109 - val_loss: 32.0519\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.0472 - val_loss: 39.3790\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.5912 - val_loss: 32.6214\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.5297 - val_loss: 32.5106\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.7252 - val_loss: 32.6218\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.2481 - val_loss: 31.6227\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 28.5385 - val_loss: 30.9146\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.5114 - val_loss: 33.2701\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.9830 - val_loss: 32.8338\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 26.9780 - val_loss: 42.7849\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 28.9501 - val_loss: 35.0290\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 26.8962 - val_loss: 30.3217\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 28.0026 - val_loss: 32.7556\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 27.1715 - val_loss: 30.3947\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 26.3952 - val_loss: 34.2572\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 26.6514 - val_loss: 32.3103\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 26.6169 - val_loss: 31.6690\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.3225 - val_loss: 30.3489\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 26.0277 - val_loss: 31.8564\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.3507 - val_loss: 37.8304\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.7277 - val_loss: 31.7571\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.0027 - val_loss: 31.9599\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.8892 - val_loss: 29.7815\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 25.0905 - val_loss: 32.7403\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.1633 - val_loss: 33.4657\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.0363 - val_loss: 31.5611\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.6460 - val_loss: 29.7278\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.6592 - val_loss: 34.2346\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 23.8082 - val_loss: 31.9969\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 24.7533 - val_loss: 30.1291\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.4155 - val_loss: 31.9430\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.5916 - val_loss: 33.7615\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.7343 - val_loss: 29.3890\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.1975 - val_loss: 30.9348\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 23.0692 - val_loss: 36.0942\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.0398 - val_loss: 29.1011\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.4827 - val_loss: 33.4628\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.8751 - val_loss: 34.3608\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.8278 - val_loss: 30.8209\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.5699 - val_loss: 29.4925\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.4331 - val_loss: 38.0200\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.9775 - val_loss: 31.4834\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.8534 - val_loss: 28.6489\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.6691 - val_loss: 32.0859\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.8257 - val_loss: 30.7502\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 20.8144 - val_loss: 37.8488\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.6341 - val_loss: 33.3041\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 21.8508 - val_loss: 31.4373\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.0522 - val_loss: 31.2921\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 20.8062 - val_loss: 32.4929\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.5192 - val_loss: 31.5865\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.0517 - val_loss: 31.7258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.0556 - val_loss: 32.1597\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 20.1652 - val_loss: 31.9606\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 20.0213 - val_loss: 30.1152\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 20.2062 - val_loss: 32.9825\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.8418 - val_loss: 33.1091\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.9613 - val_loss: 35.0916\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.6568 - val_loss: 30.3894\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.2169 - val_loss: 31.5649\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.4197 - val_loss: 31.2871\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 18.8154 - val_loss: 32.5868\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.4999 - val_loss: 31.5987\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 2s 6ms/step - loss: 18.8288 - val_loss: 32.0398\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 19.0652 - val_loss: 33.0304\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.6418 - val_loss: 32.7514\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 2s 6ms/step - loss: 18.3938 - val_loss: 30.7974\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.9507 - val_loss: 32.1687\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.1821 - val_loss: 31.4222\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.8757 - val_loss: 30.4007\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.9121 - val_loss: 32.9910\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.5104 - val_loss: 30.4107\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 18.1912 - val_loss: 32.1285\n",
      "16/16 [==============================] - 1s 21ms/step\n",
      "Evaluation Results for Fold 2\n",
      "Mean Squared Error (MSE): 28.649524249299933\n",
      "Mean Absolute Error (MAE): 3.6977323464703686\n",
      "Root Mean Squared Error (RMSE): 5.352525034906416\n",
      "Time taken: 268.4034252166748\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 11ms/step - loss: 1008.7127 - val_loss: 630.4079\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 515.1860 - val_loss: 388.7378\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 330.3063 - val_loss: 243.9247\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 201.0819 - val_loss: 137.2360\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 121.3822 - val_loss: 88.9624\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 79.2268 - val_loss: 77.0164\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 61.3272 - val_loss: 51.2226\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 52.2395 - val_loss: 54.0061\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 45.3115 - val_loss: 55.2562\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 42.4784 - val_loss: 39.2035\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 42.1949 - val_loss: 43.2636\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 39.1795 - val_loss: 46.1560\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 38.1451 - val_loss: 38.3570\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 36.4682 - val_loss: 38.3977\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 35.4967 - val_loss: 52.6974\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 36.1445 - val_loss: 36.3501\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 34.9772 - val_loss: 57.5177\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 35.1388 - val_loss: 43.2582\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.4421 - val_loss: 35.9968\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 32.3260 - val_loss: 43.9095\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 32.4573 - val_loss: 42.3639\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 32.5711 - val_loss: 35.3430\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.7899 - val_loss: 45.4586\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.4022 - val_loss: 33.4750\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.1204 - val_loss: 33.6539\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 31.4467 - val_loss: 33.2336\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.5252 - val_loss: 35.1402\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.0022 - val_loss: 38.6146\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.9816 - val_loss: 34.4494\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.8769 - val_loss: 34.6865\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.2506 - val_loss: 32.1147\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.6841 - val_loss: 40.8344\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 28.7666 - val_loss: 34.9265\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.8498 - val_loss: 36.9318\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.0227 - val_loss: 37.6472\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.5406 - val_loss: 33.1032\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.2779 - val_loss: 37.0444\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.9627 - val_loss: 37.4202\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 28.2112 - val_loss: 35.1204\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 27.2314 - val_loss: 32.5210\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.3845 - val_loss: 32.2358\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.0577 - val_loss: 36.0521\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.6746 - val_loss: 32.9818\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.0710 - val_loss: 31.9020\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.4716 - val_loss: 34.1905\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 25.9370 - val_loss: 30.7616\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 26.0726 - val_loss: 33.6431\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 25.3885 - val_loss: 35.7128\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 26.8597 - val_loss: 31.3760\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 25.4817 - val_loss: 35.6113\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.0830 - val_loss: 33.9617\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 25.3683 - val_loss: 35.5628\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.7226 - val_loss: 33.7476\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.7566 - val_loss: 35.4332\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.2622 - val_loss: 36.8207\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.2660 - val_loss: 37.0713\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.3880 - val_loss: 31.5181\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.3672 - val_loss: 32.4956\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.1044 - val_loss: 34.0382\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.8564 - val_loss: 32.2598\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.6059 - val_loss: 33.5880\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 23.1248 - val_loss: 33.9826\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 23.3038 - val_loss: 33.0151\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 23.0367 - val_loss: 34.9618\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 23.2268 - val_loss: 32.2889\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.1033 - val_loss: 33.0539\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.5901 - val_loss: 52.0233\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 22.4558 - val_loss: 33.6687\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.7747 - val_loss: 32.9476\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.7737 - val_loss: 33.1766\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 22.3706 - val_loss: 32.3415\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 20.8396 - val_loss: 34.2224\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 21.9979 - val_loss: 32.0267\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 21.2204 - val_loss: 36.7118\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.7798 - val_loss: 31.3279\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 21.1803 - val_loss: 33.8035\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 3\n",
      "Mean Squared Error (MSE): 30.775337390417434\n",
      "Mean Absolute Error (MAE): 3.9408756777964764\n",
      "Root Mean Squared Error (RMSE): 5.547552378339247\n",
      "Time taken: 209.26388955116272\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 11ms/step - loss: 984.5922 - val_loss: 750.7995\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 550.6985 - val_loss: 480.8900\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 335.7583 - val_loss: 283.7024\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 203.3257 - val_loss: 198.8980\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 121.0883 - val_loss: 96.0923\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 79.5804 - val_loss: 67.4661\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 59.9675 - val_loss: 51.6595\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 53.1717 - val_loss: 48.8532\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 48.5038 - val_loss: 51.4185\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 44.2982 - val_loss: 37.4458\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 42.5090 - val_loss: 60.8590\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 41.8414 - val_loss: 43.8579\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 41.2040 - val_loss: 36.9900\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 38.3726 - val_loss: 36.1547\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 36.1553 - val_loss: 33.9257\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 35.8015 - val_loss: 44.7607\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 35.8609 - val_loss: 33.1518\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 34.6094 - val_loss: 32.7239\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 34.0524 - val_loss: 33.8160\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 33.2093 - val_loss: 40.2071\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 33.8950 - val_loss: 34.2504\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 33.5701 - val_loss: 32.8743\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 32.7346 - val_loss: 32.2723\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 32.8865 - val_loss: 30.9405\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 32.4639 - val_loss: 37.7134\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.4949 - val_loss: 40.3520\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.9573 - val_loss: 32.3889\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.5920 - val_loss: 33.8977\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.1872 - val_loss: 32.1638\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.3605 - val_loss: 38.7994\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.2256 - val_loss: 33.8624\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.6555 - val_loss: 31.9915\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.1831 - val_loss: 35.9953\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.5556 - val_loss: 28.3109\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.9164 - val_loss: 28.4547\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 29.7857 - val_loss: 34.6301\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.6526 - val_loss: 33.9878\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.0862 - val_loss: 27.0758\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.2110 - val_loss: 29.8390\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 29.1605 - val_loss: 29.5147\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 29.0258 - val_loss: 28.4689\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.9300 - val_loss: 30.8621\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 27.7240 - val_loss: 29.2559\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 28.0288 - val_loss: 29.4819\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.9308 - val_loss: 33.6229\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 27.6747 - val_loss: 47.1212\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 26.8727 - val_loss: 28.6402\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 26.4113 - val_loss: 28.4344\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.9260 - val_loss: 32.4758\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.1082 - val_loss: 27.3609\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.4885 - val_loss: 27.2743\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.3682 - val_loss: 28.8050\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 26.9837 - val_loss: 33.1320\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.2031 - val_loss: 32.9413\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 25.8833 - val_loss: 35.4868\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 25.4052 - val_loss: 35.5365\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.3231 - val_loss: 32.1102\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.0068 - val_loss: 35.0946\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.6485 - val_loss: 30.8290\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.2042 - val_loss: 28.3743\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.1711 - val_loss: 39.4166\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 24.8376 - val_loss: 28.0562\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 23.6355 - val_loss: 28.4879\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.9379 - val_loss: 32.9012\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 23.7579 - val_loss: 38.7104\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 22.9663 - val_loss: 30.2705\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 23.3676 - val_loss: 29.5542\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 23.4175 - val_loss: 34.8911\n",
      "16/16 [==============================] - 1s 20ms/step\n",
      "Evaluation Results for Fold 4\n",
      "Mean Squared Error (MSE): 27.06364978717014\n",
      "Mean Absolute Error (MAE): 3.696205558583346\n",
      "Root Mean Squared Error (RMSE): 5.202273520987736\n",
      "Time taken: 184.4875898361206\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 [==============================] - 7s 12ms/step - loss: 1074.1779 - val_loss: 761.2883\n",
      "Epoch 2/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 597.4741 - val_loss: 504.3564\n",
      "Epoch 3/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 394.7515 - val_loss: 320.8956\n",
      "Epoch 4/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 245.3562 - val_loss: 206.1488\n",
      "Epoch 5/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 140.7626 - val_loss: 107.9119\n",
      "Epoch 6/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 86.9424 - val_loss: 104.7764\n",
      "Epoch 7/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 63.7404 - val_loss: 63.8951\n",
      "Epoch 8/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 52.4709 - val_loss: 47.9151\n",
      "Epoch 9/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 46.7186 - val_loss: 40.5280\n",
      "Epoch 10/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 42.4877 - val_loss: 45.7990\n",
      "Epoch 11/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 41.4463 - val_loss: 42.8272\n",
      "Epoch 12/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 39.3282 - val_loss: 36.6298\n",
      "Epoch 13/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 36.4577 - val_loss: 37.8551\n",
      "Epoch 14/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 37.7652 - val_loss: 39.9634\n",
      "Epoch 15/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 37.1757 - val_loss: 36.2053\n",
      "Epoch 16/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 35.7522 - val_loss: 37.0636\n",
      "Epoch 17/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 34.9931 - val_loss: 36.6356\n",
      "Epoch 18/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 34.5830 - val_loss: 33.1528\n",
      "Epoch 19/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.8824 - val_loss: 34.5325\n",
      "Epoch 20/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 32.9591 - val_loss: 42.4175\n",
      "Epoch 21/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 33.1545 - val_loss: 34.4215\n",
      "Epoch 22/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 33.0906 - val_loss: 34.2864\n",
      "Epoch 23/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 31.1782 - val_loss: 35.7592\n",
      "Epoch 24/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.6189 - val_loss: 36.6531\n",
      "Epoch 25/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 30.4379 - val_loss: 32.1447\n",
      "Epoch 26/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 31.6389 - val_loss: 33.5412\n",
      "Epoch 27/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 31.8751 - val_loss: 31.5573\n",
      "Epoch 28/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 30.6271 - val_loss: 33.5544\n",
      "Epoch 29/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 30.5463 - val_loss: 51.6840\n",
      "Epoch 30/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 30.6650 - val_loss: 34.3855\n",
      "Epoch 31/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 29.4429 - val_loss: 42.9787\n",
      "Epoch 32/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 30.9057 - val_loss: 38.3099\n",
      "Epoch 33/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 29.1627 - val_loss: 31.3976\n",
      "Epoch 34/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 29.2621 - val_loss: 31.4286\n",
      "Epoch 35/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 28.3215 - val_loss: 33.0718\n",
      "Epoch 36/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.7375 - val_loss: 31.9039\n",
      "Epoch 37/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.5559 - val_loss: 34.6636\n",
      "Epoch 38/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.7507 - val_loss: 32.0555\n",
      "Epoch 39/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.6817 - val_loss: 30.2841\n",
      "Epoch 40/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 27.4398 - val_loss: 37.1085\n",
      "Epoch 41/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.3824 - val_loss: 33.8605\n",
      "Epoch 42/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.7404 - val_loss: 32.3299\n",
      "Epoch 43/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 27.8096 - val_loss: 36.2607\n",
      "Epoch 44/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 26.7138 - val_loss: 30.9864\n",
      "Epoch 45/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 25.6907 - val_loss: 31.6231\n",
      "Epoch 46/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 25.7178 - val_loss: 30.3118\n",
      "Epoch 47/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 27.0709 - val_loss: 30.0050\n",
      "Epoch 48/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 26.3605 - val_loss: 33.3017\n",
      "Epoch 49/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 26.4343 - val_loss: 30.1066\n",
      "Epoch 50/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.8244 - val_loss: 32.2919\n",
      "Epoch 51/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.8075 - val_loss: 37.2551\n",
      "Epoch 52/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.9648 - val_loss: 33.0892\n",
      "Epoch 53/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 24.3426 - val_loss: 32.3768\n",
      "Epoch 54/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.4315 - val_loss: 35.9517\n",
      "Epoch 55/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 24.8744 - val_loss: 32.1446\n",
      "Epoch 56/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.6949 - val_loss: 30.5187\n",
      "Epoch 57/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.4689 - val_loss: 35.2247\n",
      "Epoch 58/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 24.8668 - val_loss: 33.1144\n",
      "Epoch 59/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.5572 - val_loss: 44.4656\n",
      "Epoch 60/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.6871 - val_loss: 33.3438\n",
      "Epoch 61/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 23.3142 - val_loss: 31.0453\n",
      "Epoch 62/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 24.4479 - val_loss: 31.6877\n",
      "Epoch 63/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.6672 - val_loss: 31.1761\n",
      "Epoch 64/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.0321 - val_loss: 35.6212\n",
      "Epoch 65/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 23.3104 - val_loss: 33.1241\n",
      "Epoch 66/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.6209 - val_loss: 30.6850\n",
      "Epoch 67/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.6668 - val_loss: 30.6173\n",
      "Epoch 68/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 21.7201 - val_loss: 33.7788\n",
      "Epoch 69/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.8891 - val_loss: 30.4038\n",
      "Epoch 70/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.5758 - val_loss: 29.9373\n",
      "Epoch 71/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.4109 - val_loss: 35.8418\n",
      "Epoch 72/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 22.8175 - val_loss: 30.2425\n",
      "Epoch 73/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 22.1081 - val_loss: 32.0465\n",
      "Epoch 74/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 20.5678 - val_loss: 36.2449\n",
      "Epoch 75/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 21.9282 - val_loss: 29.8903\n",
      "Epoch 76/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 20.9256 - val_loss: 33.9281\n",
      "Epoch 77/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 21.3210 - val_loss: 34.1656\n",
      "Epoch 78/200\n",
      "326/326 [==============================] - 2s 8ms/step - loss: 20.9979 - val_loss: 31.7375\n",
      "Epoch 79/200\n",
      "326/326 [==============================] - 3s 10ms/step - loss: 20.3944 - val_loss: 32.1915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 20.3398 - val_loss: 29.6842\n",
      "Epoch 81/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.8643 - val_loss: 34.3038\n",
      "Epoch 82/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.9364 - val_loss: 32.2216\n",
      "Epoch 83/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.8922 - val_loss: 36.7013\n",
      "Epoch 84/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 20.7235 - val_loss: 30.5354\n",
      "Epoch 85/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.6705 - val_loss: 31.8595\n",
      "Epoch 86/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.3448 - val_loss: 36.6013\n",
      "Epoch 87/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.1931 - val_loss: 31.5919\n",
      "Epoch 88/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.4698 - val_loss: 42.6272\n",
      "Epoch 89/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.2466 - val_loss: 32.0709\n",
      "Epoch 90/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 19.1199 - val_loss: 35.5239\n",
      "Epoch 91/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 19.3062 - val_loss: 32.7161\n",
      "Epoch 92/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.2194 - val_loss: 31.1133\n",
      "Epoch 93/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.7092 - val_loss: 31.7719\n",
      "Epoch 94/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.3555 - val_loss: 32.5904\n",
      "Epoch 95/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.1277 - val_loss: 31.8963\n",
      "Epoch 96/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.4604 - val_loss: 32.2661\n",
      "Epoch 97/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.8494 - val_loss: 33.0602\n",
      "Epoch 98/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.4604 - val_loss: 35.3678\n",
      "Epoch 99/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.9196 - val_loss: 35.5676\n",
      "Epoch 100/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 18.4121 - val_loss: 34.3161\n",
      "Epoch 101/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.1995 - val_loss: 32.7908\n",
      "Epoch 102/200\n",
      "326/326 [==============================] - 3s 9ms/step - loss: 16.9982 - val_loss: 31.2062\n",
      "Epoch 103/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.7633 - val_loss: 32.4676\n",
      "Epoch 104/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.3518 - val_loss: 32.5498\n",
      "Epoch 105/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.5402 - val_loss: 35.2107\n",
      "Epoch 106/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 16.5350 - val_loss: 30.6283\n",
      "Epoch 107/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 17.0300 - val_loss: 31.1915\n",
      "Epoch 108/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 16.1640 - val_loss: 30.7933\n",
      "Epoch 109/200\n",
      "326/326 [==============================] - 2s 7ms/step - loss: 17.2793 - val_loss: 32.2201\n",
      "Epoch 110/200\n",
      "326/326 [==============================] - 3s 8ms/step - loss: 15.7613 - val_loss: 33.5873\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Evaluation Results for Fold 5\n",
      "Mean Squared Error (MSE): 29.656059136723183\n",
      "Mean Absolute Error (MAE): 3.8681294423621058\n",
      "Root Mean Squared Error (RMSE): 5.4457377036287\n",
      "Time taken: 294.26669812202454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(3))\n",
    "    \n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200, batch_size=6,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    rmse_scores.append(rmse)\n",
    "    time_taken.append(end_time - start_time)\n",
    "\n",
    "    print(\"Evaluation Results for Fold\", fold)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "    print(\"Time taken:\", end_time - start_time)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f170f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 8, 512)            1052672   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 512)           2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 512)            0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 8, 256)            787456    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,047,747\n",
      "Trainable params: 2,046,723\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52768fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,'LSTM.png', show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683875b",
   "metadata": {},
   "source": [
    "# 3. Evaluate Network: Calculate average results across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a23a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(mse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_time_taken = np.mean(time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d528",
   "metadata": {},
   "source": [
    "# 4. Create a DataFrame for all fold results and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a3e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_6692\\3174907360.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(avg_results, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Fold': list(range(1, kfold.n_splits + 1)),\n",
    "    'MSE': mse_scores,\n",
    "    'MAE': mae_scores,\n",
    "    'RMSE': rmse_scores,\n",
    "    'Time taken': time_taken\n",
    "})\n",
    "\n",
    "# Append average results to the DataFrame\n",
    "avg_results = {'Fold': 'Average', 'MSE': avg_mse, 'MAE': avg_mae, 'RMSE': avg_rmse, 'Time taken': avg_time_taken}\n",
    "results_df = results_df.append(avg_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80271b",
   "metadata": {},
   "source": [
    "# 5. Save the results to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12fa5708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all Folds and Average Results:\n",
      "      Fold        MSE       MAE      RMSE  Time taken\n",
      "0        1  30.332536  3.891224  5.507498  219.540977\n",
      "1        2  28.649524  3.697732  5.352525  268.403425\n",
      "2        3  30.775337  3.940876  5.547552  209.263890\n",
      "3        4  27.063650  3.696206  5.202274  184.487590\n",
      "4        5  29.656059  3.868129  5.445738  294.266698\n",
      "5  Average  29.295421  3.818833  5.411117  235.192516\n",
      "Results saved to 'Sensors 8_PL_model_1_Scattered_iReg_f.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an Excel file\n",
    "results_df.to_excel('Sensors 8_PL_model_1_Scattered_iReg_f.xlsx', index=False)\n",
    "\n",
    "# Display the results table\n",
    "print(\"Results for all Folds and Average Results:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "print(\"Results saved to 'Sensors 8_PL_model_1_Scattered_iReg_f.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ffa6e",
   "metadata": {},
   "source": [
    "# 6. Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ced195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a493e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ddfe36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss', linewidth=2)\n",
    "plt.plot(val_loss, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
